# PREREQUISITES AND PRELIMINARIES

In Sections 1-6 we summarize for the reader's convenience some basic material with which he is ass umed to be thoroughly familiar (with the possible exception of the distinction between sets and proper classes (Section 2), the characterization of the Cartesian product by a universal mapping property (Theorem 5.2) and the Recursior Theorem 6.2). The definition of cardinal number (frst part of Section 8) will be used frequently. The Axiom of Choice and its equivalents (Section 7) and cardinal arithmetic (last part of Section 8) may be postponed until this information is actually used. Finally the reader is presumed to have some familiarity with the fields Q, R, and C of rational, real, and complex numbers respectively

## 1. LOGIC

We adopt the usual logical conventions, and consider only statements that have a truth value of either true or false (not both). If $P$ and $Q$ are statements, then the statement $“P$ and $Q^{,,}$ is true if both $P$ and $Q$ are true and false otherwise. The statement $“P$ or $Q^{,,}$ is true in allcases except when both $P$ and $Q$ are false. An implicatior is a statement of the form $“P$ implies $Q^{,,}$ or "if $P$ , then $Q^{\prime\prime}$ (written symbolically ase) $P\Rightarrow Q$ .An implication is false if $P$ is true and $Q$ is false; it is true in all other cases. In particular, an implication with a false premise is always a true implication. An equivalence or biconditional is a statement of the form $“P$ implies $Q$ and $Q$ implies $P$ " This is generally abbreviated to $“P$ if and only if $Q^{,,}$ (symbolically $P\Leftrightarrow Q$ ). The biconditional “$P\Leftrightarrow Q”$ is true exactly when $P$ and $Q$ are both true or both false; otherwise it is false.Thenegation of the statement $P$ is the statement “it is not the case that $P$ " It is true if and only if $P$ is false.

## 2. SETS AND CLASSES

Our approach to the theory of sets will be quite informal. Nevertheless in order to define adequately both cardinal numbers (Section 8) and categories (Section I.7) it

------------------------------------------------------------------

will be necessary to introduce at least the rudiments of a formal axiomatization of set theory. In fact the entire discussion may, if desired, be made rigorously precise; see Eisenberg [8] or Suppes [10]. An axiomatic approach to set theory is also useful in order to avoid certain paradoxes that are apt to cause difficulty in a purely intuitive treatment of the subject. A paradox occurs in an axiom system when both a statement and its negation are deducible from the axioms. This in turn implies (by an exercise in elementary logic) that every statement in the system is true, which is hardly a very desirable state of affairs. In the Godel-Bernays form of axiomatic set theory, which we shall follow, the

primitive (undefined) notions are class, membership, and equality. Intuitively we consider a class to be a collection $A$ of objects (elements) such that given any object $x$ it is possible to determine whether or not $x$ is a member (or element) of $A$ . We write $x\in A$ for $“x$ is an element of $A^{\prime\prime}$ and $x\notin A$ for $““x$ is not an element of $A$ ." The axioms are formulated in terms of these primitive notions and the first-order predicate calculus (that is, the language of sentences built up by using the connectives and, or, not, implies and the quantifiers there exists and for all). For instance, equality is assumed to have the following properties for all classes $A,B$ ， $C:A=A$ $A=B\Rightarrow B=A$ ; $A=B$ and $B=C\Rightarrow A=C$ ; $A=B$ and $x\in A\Rightarrow x\in B$ . The axiom of extensionality asserts that two classes with the same elements are equal (formally, $[x\in A\Leftrightarrow x\in B]\Rightarrow A=B$ A class $A$ is defined to be a set if and only if there exists a class $B$ such that $A\varepsilon B$

Thus a set is a particular kind of class. A class that is not a set is called a proper class. Intuitively the distinction between sets and proper classes is not too clear. Roughly speaking a set is a “small class and a proper class is exceptionally "large."The axiom of class formation asserts that for any statement $P(y)$ in the first-order predicate calculus involving a variable $y$ ,there exists a class $A$ such that $x\in A$ if and only if $x$ is a set and the statement $P(x)$ is true. We denote this class $A$ by $\{x\mid P(x)\}$ , and refer to “the class of all $x$ such that $P(x)$ Sometimes a class is described simply by listing its elements in brackets, for example, $\{a,b,c\}$

EXAMPLE.1 Consider the class $M=\{X\mid X\}$ is a set and $X\notin X\}$ . The statement $X\neq X$ is not unreasonable since many sets satisfy it (for example, the set of all books is not a book). $M$ is a proper class. For if $M$ were a set, then either $M\varepsilon M$ or $M\notin M$ But by the definition of $M,M\in M$ implies $M\notin M$ and $M\notin M$ implies $M\varepsilon M$ . Thus in either case the assumption that $M$ is a set leads to an untenable paradox: $M\varepsilon M$ and $M\notin M$ We shall now review a number of familiar topics (unions, intersections, functions,

relations, Cartesian products, etc.). The presentation will be informal with the mention of axioms omitted for the most part. However, it is also to be understood that there are sufficient axioms to guarantee that when one of these constructions is performed on sers, the result is also a set (for example, the union of sets is a set; a subclass of a set is a set). The usual way of proving that a given class is a set is to show that it may be obtained froma set by a sequence of these admissible constructions A class $A$ is a subclass of a class $B$ (written $A\subset B$ ) provided:

$$\text{for all x e A, x e A x e B.}$$

1This was first propounded (in somewhat different form) by Bertrand Russell in 1902 as a paradox that indicated the necessity of a formal axiomatization of set theory.

------------------------------------------------------------------

By the axioms of extensionality and the properties of equality

$$A=B\quad\Leftrightarrow\quad A\subset B$$
and $B\subset A$

A subclass $A$ of a class $B$ that is itself a set is called a subset of $B$ . There are axioms to insure that a subclass of a set is a subset. The empty set or null set (denoted $\varnothing$ ） is the set with no elements (that is, given

any $x,x\notin\varnothing)$ . Since the statement $“x\in\varnothing”$ is always false, the implication (1) is always true when $A=\varnothing$ . Therefore $\varnothing\subset B$ for every class B. A is said to be a proper subclass of $B$ if $A\subset B$ but $A\neq\varnothing$ and $A\neq B$ The power axiom asserts that for every set $A$ the class $P(A)$ of all subsets of $A$ is

itself a set. $P(A)$ is called thepower set of $A$ ; it is also denoted $2^{A}$

A family of sets indexed by (the nonempty class) $I$ is a collection of sers $A_i$, one for each $i\varepsilon I$ (denoted $\{A_{i}\mid i\in I\}$ 0. Given such a family, its union and intersection are defined to be respectively the classes.

$$\begin{aligned}&\bigcup_{i\in I}A_{i}=\{x\mid x\varepsilon A_{i}\quad\mathrm{for~some}\quad i\varepsilon I\};\mathrm{and}\\&\bigcap_{i\in I}A_{i}=\{x\mid x\varepsilon A_{i}\quad\mathrm{for~every}\quad i\varepsilon I\}.\end{aligned}$$

If $I$ is a set, then sitable axioms insure that $\bigcup_{i\in I}A_i$ and $\bigcap A_i$ are actully sets If $I=\{1,2,\ldots,n\}$ one frequently writes $A_1$ U $A_2$ U...U $A_n$ in place of UA; and $\bigcup_{i\in I}A_i$ similarly for intersections. If $A\cap B=\varnothing$, $A$ and $B$ are said to be disjoint. If $A$ and $B$ are classes, the relative complement of $A$ in $B$ is the following subclass

of $B$

$$B-A=\{x\mid x\in B\quad\mathrm{and}\quad x\notin A\}.$$

If all the classes under discussion are subsets of some fixed set $U$ (called the universe of discussion), then $U-A$ is denoted $A^{\prime}$ and called simply the complement of. $A$ The reader should verify the following statements.

$$\begin{aligned}&A\cap(\bigcup_{i\in I}B_{i})=\bigcup_{i\in I}(A\cap B_{i})\quad\mathrm{and}\\&A\cup(\bigcap_{i\in I}B_{i})=\bigcap_{i\in I}(A\cup B_{i}).\end{aligned}$$

$$(\bigcup_{ieI}A_i)'=\bigcap_{ieI}A_i'\quad\mathrm{and}\quad(\bigcap_{ieI}A_i)'=\bigcup_{ieI}A_i'\text{(DeMorgan's Laws).}$$

$$A\cup B=B\quad\Leftrightarrow\quad A\subset B\quad\Leftrightarrow\quad A\cap B=A.$$

## 3. FUNCTIONS

Given classes $A$ and $B$ , a function (or map or mapping) $f$ from $A$ to $B$ (written $f{:}A\to B)$ assigns to each a e $A$ exactly one element $b\varepsilon B;b$ b $b$ is called the value of the function at a or the image of $a$ and is usually written $f(a)$ . A is the domain of the function (sometimes written $\mathbf{Dom}f)$ S $f)$ and $B$ is the range or codomain. Sometimes it is convenient to denote the effect of the functionfon an element of $A$ by $a\models f(a)$ .Two functions are equal if they have the same domain and range and have the same value for eachelement of their common domain.

------------------------------------------------------------------

If $f{:}A\to B$ is a function and $S\subset A$ , the function from $S$ to $B$ given by

$$a\mapsto f(a),\quad\mathrm{for}\quad a\in S$$

is called the restriction of $f$ to $S$ and is denoted $f|\boldsymbol{S}:S\to B$ .If $A$ is any class, the identity function on $A$ (denoted $\mathbf{1}_A:A\to A)$ is the function given by. $a|\mapsto a.$ If $S\subset A$ the function $1_A|S:S\to A$ is called the inclusion map of $S$ into $A$

Let f: $A\to B$ and $g:B\to C$ be functions. The composite of fand. $g$ is thefunction $A\to C$ given by

$$a|\mapsto g(f(a)),\quad a\in A.$$

The composite function is denoted $g\circ f$ or simply gf. If $h:C\to D$ is a third function it is easy to verify that $h(gf)=(hg)f$ If $f$ $:A\to B$ , then $f\circ1_{A}=f=1_{B}\circ f{:}A\to B$ A diagram of functions:

$$A\underset{h}{\operatorname*{\overset{f}{\operatorname*{\overset{f}{\operatorname*{\overset{f}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\operatorname*{\overset{g}{\operatorname*{\operatorname*{\overset{g}{\operatorname*{\operatorname*{\operatorname*{\overset{g}{\operatorname*{\overset{g}{\operatorname*{\operatorname*{\operatorname*{\overset{g}{\operatorname*{\operatorname*{\operatorname*{\overset{g}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$$

is said to be commutative if $gf=h$ . Similarly, the diagram

![](https://storage.simpletex.cn/view/f3Q8lMer0anoGD7qNz9gLgOH9YzV7DN82)

is commutative if $kh=gf$ Frequently we shall deal with more complicated diagram. composed of a number of triangles and squares as above. Such a diagram is said to be commutative if every triangle and square in it is commutative. Let $f{:}A\to B$ be a function. If $S\subset A$ , the image of S under f (denoted $f(S))$ is

the class

$$\{b\:\varepsilon B\:|\:b=f(a)\quad\mathrm{for~some}\quad a\:\varepsilon S\}.$$

The class $f(A)$ is called the image of f and is sometimes denoted $\operatorname{Im}f.$ If $T\subset B$ ,the inverse image of $T$ under $f$ (denoted $f^{-1}(T))$ is the class

$$\{a\varepsilon A\mid f(a)\varepsilon T\}.$$

If $T$ consists of a single element, $T=\{b\}$ , we write $f^{-1}(b)$ in place of $f^{-1}(T)$ .The following facts can be easily verified:.

$$\mathrm{for~}S\subset A,f^{-1}(f(S))\supset S;\\\mathrm{for~}T\subset B,f(f^{-1}(T))\subset T.$$

For any family $\left\{T_{i}\mid i\in I\right\}$ of subsets of $B$

$$f^{-1}(\bigcup_{i\in I}T_{i})=\bigcup_{i\in I}f^{-1}(T_{i});\\f^{-1}(\bigcap_{i\in I}T_{i})=\bigcap_{i\in I}f^{-1}(T_{i}).$$

A function $f{:}A\to B$ is said to be injective (or one-to-one) provided

$$\text{for all }a,a^{\prime}\in A,\quad a\neq a^{\prime}\quad\Rightarrow\quad f(a)\neq f(a^{\prime});$$

------------------------------------------------------------------

alternatively, $f$ is injective if and only if

for all $a,a^{\prime}\varepsilon A$ ， $f( a) = f( a^{\prime })$ $\Rightarrow$ $a= a^{\prime }.$

A function $f$ is surjective (or onto) provided $f(A)=B$ ; in other words,

for each bε B, $b=f(a)$ for some ae A.

A function $f$ is said to be bijective (or a bijection or a one-to-one correspondence) if it is both injective and surjective. It follows immediately from these definitions that for any class $A.$ , the identity map $\mathbf{l}_A:A\to A$ is bijective. The reader should verify that for maps $f{:}A\to B$ and $g:B\to C$

$$f\mathrm{~and~}g\mathrm{~injective}\quad\Rightarrow\quad gf\mathrm{~is~injective};\\f\mathrm{~and~}g\mathrm{~surjective}\quad\Rightarrow\quad gf\mathrm{~is~surjective};\\gf\mathrm{~injective}\quad\Rightarrow\quad f\mathrm{~is~injective};\\gf\mathrm{~surjective}\quad\Rightarrow\quad g\mathrm{~is~surjective}.$$

Theorem 3.1. Let f: $\mathbf{A}\rightarrow\mathbf{B}$ be a function, with A nonempty

(i)f is injective if and only if there is a map $\mathbf{g}:\mathbf{B}\to\mathbf{A}$ such that gf $=\mathbf{1}_{\mathbf{A}}$ (i) If Ais a set,thenf is surjective if and only if there is amaph： ${:}\mathbf{B}\to\mathbf{A}$ such that.

$fh=1_{B}$

PROOF. Since every identity map is bijective, (11) and (12) prove the implica. tions $(\Leftarrow)$ in (i) and (i). Conversely if $f$ is injective, then for each $b\in f(A)$ there is a unique a e $A$ with $f(a)=b$ . Choose a fixed $a_0$ E $A$ and verify that the map $g:B\to A$ defined by

$$g(b)=\begin{cases}a&\text{if}\quad b\in f(A)\quad\text{and}\quad f(a)=b\\a_0&\text{if}\quad b\notin f(A)\end{cases}$$

is such that $gf=1_{A}$ . For the converse of (i) suppose $f$ is surjective. Then $f^{-1}(b)\subset A$ is a nonempty set for every $b\varepsilon B.$ For each $b\varepsilon B$ choose $a_b\in f^{-1}(b)$ (Note: this requires theAxiom of Choice; seeSection7).Verify that the map $h:B\to A$ defined by $h(b)=a_b$ is such that $fh=1_{B}$ .！

The map $g$ as in Theorem 3.1 is called a left inverse of $f$ and $h$ is called a right inverse of $f$ If a map $f{:}A\to B$ has both a left inverse 8 and a right inverse $h$ , then

$$g=g1_{B}=g(fh)=(gf)h=1_{A}h=h$$

and the map $g=h$ is called a two-sided inverse of $f$ This argument also shows that the two-sided inverse of a map (if it has one) is unique. By Theorem 3.1 if $A$ is a set and $f{:}A\to B$ a function, then

$$fisbijectivesfhasatwo-sidedinverse.2$$

The unique two-sided inverse of a bijection $f$ is denoted $f^{-1}$ ; clearly $f$ is a two-sided 'inverse of $f^{-1}$ so that $f^{-1}$ is also a bijection.

2(13) is actually true even when $A$ is a proper class; see Eisenberg [8; p. 146],

------------------------------------------------------------------

## 4. RELATIONS AND PARTITIONS

The axiom of pair formation states that for any two sets [elements] $a,b$ there is a set $P=\{a,b\}$ such that $x\varepsilon P$ if and only if $x=a$ or $x=b;$ if $a=b$ then $P$ is the singleton $\{a\}$ . The ordered pair $(a,b)$ is defined to be the set $\{\left\{a\right\},\left\{a,b\right\}$ ; its first com- ponent is $a$ and its second component is $b$ . It is easy to verify that $(a,b)=(a^{\prime},b^{\prime})$ if and only if $a=a^{\prime}$ and $b=b^{\prime}$ .The Cartesian product of classes $A$ and $B$ is the class

$$A\times B=\{(a,b)|a\varepsilon A,b\varepsilon B\}.$$

Note that $A\times\varnothing=\varnothing=\varnothing\times B$

A subclass $R$ of $A\times B$ is called a relation on $A\times B$ .For example, if $f{:}A\to B$ is a function, the graph of $f$ is the relation $R=\left\{(a,f(a))\mid a\in A\right\}$ . Since $f$ is a function, $R$ has the special property:

every element of $A$ is the first component of one and only one ordered pair in $R.$

Conversely any relation $R$ on $A\times B$ that satisfes (14), determines a unique function $f{:}A\to B$ whose graph is $R$ (simply define $f(a)=b$ ，where $(a,b)$ is the unique ordered pair in $R$ with first component $a$ ). For this reason it is customary in a formal axiomatic presentation of set theory to identify a function with its graph, that is, to define a function to be a relation satisfying (14). This is necessary, for example, in order to prove from the axioms that the image of a set under a function is in fact a set. Another advantage of this approach is that it permits us to define functions with

empty domain. For since $\varnothing\times B=\varnothing$ is the unique subset of $\varnothing\times B$ and vacuously satisfies (14), there is a unique function $\varnothing\rightarrow B$ It is also clear from (14) that there can be a function with empty range only if the domain is also empty. Whenever convenient we shall think of a function as a relation satisfying (14). A relation $R$ on $A\times A$ is an equivalence relation on $A$ provided $R$ is:

reflexive: $(a,a)\in R$ for all aεA;

symmetric: $(a,b)\varepsilon R\:\Rightarrow\:(b,a)\varepsilon R;$

$$transitive:(a,b)\varepsilon Rand(b,c)\varepsilon R\Rightarrow(a,c)\varepsilon R.$$

If $R$ is an equivalence relation on $A$ and $(a,b)\in R$ ,we say that $a$ is equivalent to $b$ under $R$ and write $a\sim b$ or aRb ; in this notation (15)-(17) become:

$$\begin{aligned}a&\sim a;\\a&\sim b\quad\Rightarrow\quad b\sim a;\\a&\sim b\quad\mathrm{and}\quad b\sim c\quad\Rightarrow\quad a\sim c.\end{aligned}$$

Let $R\left(\sim\right)$ be an equivalence relation on $A$ .If ae $A$ , the equivalence class of a (denoted $\bar{a}$ )is the classof all thoseelementsof $A$ that are equivalent to $a$ ; that is. $\bar{a}=\left\{b\in A\mid b\sim a\right\}$ . The class of all equivalence classes in $A$ is denoted $A/R$ and called the quotient class of $A$ by $R$ Since $R$ is reflexive, $a\varepsilon\bar{a}$ a $\bar{a}$ for everyae $A$ ;hence

$\bar{a}\neq\varnothing$ ， for every aεA; and if $A$ is a set

$$\bigcup_{a\epsilon A}\bar{a}=A=\bigcup_{\bar{a}\epsilon A/R}\bar{a}.$$

------------------------------------------------------------------

Also observe that

$$\bar{a}=b\quad\Leftrightarrow\cdot a\thicksim b;$$

for if $\bar{a}=b$ , then a $\varepsilon\bar{a}\Rightarrow a\varepsilon b\Rightarrow a\thicksim b$ .Conversely, if $a\thicksim b$ and $c\varepsilon\bar{a}$ ,then $c\sim a$ and $a\thicksim b\Rightarrow c\thicksim b\Rightarrow c\in b$ .Thus $\bar{a}\subset b$ ; a symmetric argument shows that $b\subset\bar{a}$ and therefore $\bar{a}=b$ . Next we prove:

$$\mathrm{for~}a,b\in A,\quad\mathrm{either}\quad\bar{a}\cap\bar{b}=\varnothing\quad\mathrm{or}\quad\bar{a}=b.$$

If $\bar{a}\cap b\neq\varnothing$ , then there is an element $c\varepsilon\bar{a}\cap b$ Hence $c\sim a$ and $c\thicksim b$ .Using symmetry, transitivity and (20) we have: $a\thicksim c$ and $c\thicksim b\Rightarrow a\thicksim b\Rightarrow\bar{a}=b$ Let $A$ be a nonempty class and $\{A_{i}\mid i\in I\}$ afamily of subsets of $A$ such that:

$$\begin{aligned}
&A_{i}\neq\emptyset,\:\mathrm{for~each}\:i\varepsilon I; \\
&\bigcup_{ieI}A_{i}=A; \\
&A_{i}\cap A_{j}=\emptyset\quad\mathrm{for~all}\quad i\neq j\varepsilon I;
\end{aligned}$$

then $\{A_i\mid i\in I\}$ is said to be a partition of $A$

Theorem 4.1.IfA is a nonempty set,then the assignment $\mathbf{R}\mapsto\mathbf{A}/\mathbf{R}$ defines a bijection from theset E(A)ofall equivalencerelations on A ontotheset Q(A) ofall parti tions of A.

SKETCH OF PROOF. If $R$ is an equivalence relation on $A$ , then the set $A/R$ of equivalenceclasses is a partition of $A$ by (18), (19), and (21) so that $R\vdash A/R$ defines a function $f{:}\boldsymbol{E}(A)\to Q(A)$ . Define a function $g:Q(A)\to E(A)$ as follows. If $S=\{A_{i}\mid i\in I\}$ is a partition of $A$ ,let $g(S)$ be theequivalence relation on $A$ given by:

for some (unique) i ε I
$$a\thicksim b\Leftrightarrow a\varepsilon A_i\quad\mathrm{and}\quad b\in A_i$$

Verify that $g(S)$ is in fact an equivalence relation such that $\bar{a}=A_{i}$ for a ε A. Complete the proof by verifying that $fg=1_{Q(A)}$ and $gf=1_{E(A)}$ .Then $f$ is bijective by (13).

## 5. PRODUCTS

Note. In this section we deal only with sers. No proper classes are involved

Consider the Cartesian product of two sets $A_1\times A_2$ .An element of $A_1\times A_2$ is a pair $(a_1,a_2)$ with a; e Ai, $i=1,2$ . Thus the pair $(a_1,a_2)$ determines a function $f$ s $f{:}\{1,2\}$ $A_2$ A2 $\rightarrow A_1\cup A_2$by$:f(1)=a_1,f(2)=a_2$ . Conversely, every function $f{:}\{1,2\}\to A_1\cup A_2$ A2 $A_2$ with the property that $f(1)$ f(1) $f(1)\in A_1$ A $A_1$ and $f(2)$ E $A_2$ determines an element $(a_{1},a_{2})=$ $(f(1),f(2))$ of $A_1\times A_2$ . Therefore it is not difficult to see that there is a one-to-one correspondence between the set of all functions of this kind and the set $A_1\times A_2$ This fact leads us to generalize the notion of Cartesian product as follows.

Definition 5.1. Let {Ai $\{A_i$ $\{ \mathbf{A} _{\mathrm{i} }\mid \mathbf{i} \varepsilon \mathbf{I} \}$ be a family of sets indexed bya(nonempty) set I. The (Cartesian) product of the sers Ai is the set of all functions f $:\mathbf{I}\to\bigcup_{i\in I}$ A; such that f(i) Ai foralli I Ilis denoled $\prod_{ieI}A_i$

------------------------------------------------------------------

If $I=\{1,2,\ldots,n\}$ the product $\prod_{ieI}A_i$ is often denoted by $A_1\times A_2\times\cdots\times A_n$ and is identifed with the set of all ordered $n$ -tuples $(a_1,a_2,\ldots,a_n)$ where $a_i\varepsilon A_i$ for $i=1,2,\ldots,n$ just as in the case mentioned above, where $I=\{1,2\}$ . A similar notation is often convenient when $I$ is infinite. We shall sometimes denote the function $f\varepsilon\prod_{ieI}A_i$ by $\{a_i\}_{leI}$ or simply $\{a_i\}$ where $f(i)=a_{i}\varepsilon A_{i}$ for each i .

If some $A_i=\varnothing$ , then $\prod_{i\in I}A_i=\varnothing$ sine therecan be no function $f{:}I\to\cup A_i$ such that $f(j)\in A_i$

thene $\{A_{i}\mid i\in I\}$ 1am $I\to\bigcup_{i\in I}B_i$ B.Ua. $\left\{B_{i}\mid i\in I\right\}$ aeteolesoet ee $B_i\subset A_i$ $I\to\bigcup A_i$ che fore we consider $\prod_{i\in I}B_i$ to be a subset of $\prod_{i\in I}A_i$

Let $\prod_{i\in I}A_i$ be aCartesian product.For each $k$ I dfne a map $\pi_{k}:\prod_{i\in I}A_{i}\to A_{k}$ by $f\vdash f(k)$ , or in the other notation, $\{a_i\}\vdash a_k$ $\pi_k$ is called the (canonical) projection of the product onto its kth component (or factor). If every $A_{\mathrm{i}}$ is nonempty, then each $\pi_k$ is surjective (see Exercise 7.6). The product $\prod_{ieI}A_i$ and its projections are precisly what we need in order

to prove:

Theorem 5.2. Ler $\{A_{\mathrm{i}}$ |ieI}bea family of sers indexedbyI.Then thereexists a set D, together with a family of maps $\{ \pi _{\mathrm{i} }: \mathbf{D} \rightarrow \mathbf{A} _{\mathrm{i} }$ | i e I} with the following property: for any set Cand family ofmaps $\{ \varphi _{\mathrm{i} }: \mathbf{C} \to \mathbf{A} _{\mathrm{i} }\mid$i$\varepsilon$I$\}$ ,there existsa unique map $\varphi:\mathbf{C}\to\mathbf{D}$ such that $\pi_{\mathrm{i}}\varphi=\varphi_{\mathrm{i}}$ for all i e I. Furthermore, D is uniquely determined up to a bijection

The last sentence means that if $D^{\prime}$ is a set and $\{\pi_{i}^{\prime}:D^{\prime}\rightarrow A_{i}\mid i\in I\}$ a family of maps,which have the sameproperty as $D$ and $\{\pi_i\}$ , then there is a bijection $D\to D^{\prime}$

PROOF OF 5.2. (Existence) Let $D=\prod_{i\in I}A_{i}$ and let the maps $\pi_i$ be the projec tions onto the th components. Given $C$ and the maps $\varphi_{i,}$ define $\varphi:C\to\prod_{i\in I}A_i$ by $c\vdash f_c$, where $f_{c}(i)=\varphi_{i}(c)\varepsilon A_{i}$ . It follows immediately that $\pi_{i}\varphi=\varphi_{i}$ for all i e I. To $\pi_{i}\varphi^{\prime}=\varphi_{i}$ $\varphi$ i n e we aseme $\varphi=\varphi^{\prime}$ $\varphi^{\prime}:C\to\prod_{i\in I}A_{i}$ Si nothe aesuch tehe $c\in C,\varphi(c)$ , and $\varphi^{\prime}(c)$ are the same element of $\prod_{i\in I}A_i$ -that is, $\varphi(c)$ and $\varphi^{\prime}(c)$ agree as functions on $I{:}(\varphi(c))(i)=(\varphi^{\prime}(c))(i)$ for all i e $I.$ But by hypothesis and the definition of $\pi_{i}$ we have for every i e I:

$$(\varphi'(c))(i)=\pi_{i}\varphi'(c)=\varphi_{i}(c)=f_{c}(i)=(\varphi(c))(i).$$

(Uniqueness) Suppose $D^{\prime}$ (with maps $\pi_{i}^{\prime}:D^{\prime}\rightarrow A_{i})$ has the same property as $D=\prod_{\mathrm{ie}I}A_{i}$ If we apply this property (for $D$ ) to the familyo maps $\{\pi_i^{\prime}:D^{\prime}\rightarrow A_i\}$ and also apply it (for $D^{\prime}$ ）to the family $\{\pi_{i}:D\to A_{i}\}$ ,we obtain (unique) maps

------------------------------------------------------------------

$\varphi:D^{\prime}\to D$ and $\psi:D\to D^{\prime}$ such that the following diagrams are commutative for each i e I:

$$\overset{D\overset{\psi}{\operatorname*{\to}}D^{\prime}}{\operatorname*{\to}}\overset{D^{\prime}}{\operatorname*{\to}}\overset{D^{\prime}}{\operatorname*{\to}}\overset{D^{\prime}}{\operatorname*{\to}}\overset{D^{\prime}}{\operatorname*{\to}}\overset{D^{\prime}}{\operatorname*{\to}}\overset{D^{\prime}}{\operatorname*{\to}}\overset{D}{\operatorname*{\to}}\overset{D}{\operatorname*{\to}}\overset{D}{\operatorname*{\to}}\overset{D}{\operatorname*{\to}}\overset{D}{\operatorname*{\to}}\overset{D}{\operatorname*{\to}}\overset{D}{\operatorname*{\to}}\overset{D}{\operatorname*{\to}}\overset{D}{\operatorname*{\to}}$$

Combining these gives for each i e $I$ a commutative diagram

$$\overset{D}{\operatorname*{\pi_i}}\overset{\varphi\psi}{\operatorname*{P_i}}\overset{D}{\operatorname*{P_i}}$$

Thus $\varphi\boldsymbol{\psi}:D\rightarrow D$ is a map such that $\pi_{i}(\varphi\psi)=\pi_{i}$ for all i e I. But by the proof above there is a unique map with this property. Since the map $\mathbf{1}_D:D\rightarrow D$ is also such that $\pi_{i}\mathbf{1}_{D}=\pi_{i}$ $\psi_{\varphi}=1_{D^{\prime}}$ Teruse, $\varphi$ 48 $\varphi\psi=1_D$ I y y i eng $D=\prod_{i\in I}A_{i}$ I aurumen determined up to a bijection.

Observe that the statement of Theorem 5.2 does not mention elements; it involves only ses and maps I ay, in ffet, that the product $\prod_{i\in I}A_i$ is characteried by a certain universal mapping property. We shall discuss this concept with more precision when we deal with categories and functors below.

## 6. THE INTEGERS

We do not intend to give an axiomatic development of the integers. Instead we assume that the reader is thoroughlyfamiliar with the set $\mathbf{Z}$ of integers, the set $\mathbf{N}=\{0,1,2,\ldots\}$ of nonnegative integers (or natural numbers) the set $\mathbf{N}^{*}=\{1,2,\ldots\}$ of positive integers and the elementary properties of addition, multiplication, and order. In particular, for all $a,b,c\in\mathbf{Z}$

$(a+b)+c=a+(b+c)$ and $(ab)c=a(bc)$ (associative laws);

$a+b=b+a$ and $ab=ba$ (commutative laws);

$a(b+c)=ab+ac$ and $(a+b)c=ac+bc$ (distributive laws)

$$a+0=a\quad\mathrm{and}\quad a1=a$$
(identity elements)

for each a e $\mathbf{Z}$ there exists $-a\in\mathbf{Z}$ such that $a+(-a)=0$ (additive inverse); we write $a-b$ for $a+(-b)$

$$ab=0\quad\Leftrightarrow\quad a=0\quad\mathrm{or}\quad b=0;$$

$$a<b\quad\Rightarrow\quad a+c<b+c\quad\mathrm{for~all}\quad c\in\mathbf{Z};$$

$$a<b\quad\Rightarrow\quad ad<bd\quad\text{for all}\quad d\text{e}\mathbf{N}^*.$$

Wewrite $a<b$ and $b>a$ interchangeably and write $a\leq b$ if $a<b$ or $a=b$ . The absolute value $|a|$ of $a\varepsilon Z$ is defined to be $a$ if $a\geq0$ and $-a$ if $a<0$ . Finally we assume as abasic axiom the

------------------------------------------------------------------

Law ofWell Ordering.Euery nonempty subset Sof N contains a least element (that is, an element beS such that b ≤ c for allc e S)

In particular, O is the least element of N.

In addition to the above we require certain facts from elementary number theory, some of which are briefly reviewed here.

Theorem 6.1.(Principle of Mathematical Induction)IfS is a subsetof the set N of natural numbers such that $0\varepsilon S$ and either

(i $n\varepsilon S\:\Rightarrow n+1\varepsilon S$ for all n ε N;

or

(i) m ε S for all $0\leq\mathfrak{m}<\mathfrak{n}\Rightarrow$ n$\varepsilon S$ for all n e N;

then $S=N$

PROOF. If $\mathbf{N}-S\neq\varnothing$ , let $n\neq0$ be its least element. Then for every $m<n.$ we must have $m\notin\mathbb{N}-S$ and hence m e S. Consequently either (i) or (ii) implies $n\varepsilon S$ , which is a contradiction. Therefore $\mathbf{N}-S=\varnothing$ and $N=S$ ■

REMARK. Theorem 6.1 also holds with 0, N replaced by $c,M_{c}=\{x\in\mathbf{Z}|x\geq c\}$ for any c e Z.

In order to insure that various recursive or inductive definitions and proofs in the sequel (for example, Theorems 8.8 and II1.3.7 below) are valid, we need a technical result:

Theorem 6.2. (Recursion Theorem) If S is a set, a e S and for each n e N, $\mathbf{f}_{\mathrm{n}}:\mathbf{S}\to\mathbf{S}$ is a function, then there is a unique function $\varphi:\mathbb{N}\to\mathbb{S}$ such that $\varphi(0)=$ a and $\varphi($n+1)= $f_n(\varphi(n))$ for every n e N.

SKETCH OF PROOF. We shall construct a relation $R$ on $N\times S$ that is the graph of a function $\varphi:\mathbf{N}\to S$ with the desired properties. Let $S$ be the set of all subsets $Y$ of $N\times S$ such that

neN.
$$(0,a)\varepsilon Y;\quad\mathrm{and}\quad(n,x)\varepsilon Y\quad\Rightarrow\quad(n+1,f_n(x))\varepsilon Y\quad\mathrm{for~a}$$

Theon $N$ S $\mathcal{G}\neq\varnothing$ sinco $N\times S\varepsilon G$ 3 $n\varepsilon N$ $R=\:\bigcap_{Y\boldsymbol{\epsilon}\mathcal{G}}Y$ Srthen $R\varepsilon G$ ntte $M$ M $x_n\varepsilon S$ S the sub.

$(n,x_n)\varepsilon R$ . We shall prove $M=N$ by induction. If $0\notin M$ , then there exists $(0,b)$ E $R$ with $b\neq a$ and the set $R-\left\{(0,b)\right\}\subset\mathbb{N}\times S$ is in S. Consequently $R=\:\bigcap_{Y\in\mathcal{S}}Y$

$\subset R-\{(0,b)\}$ ,which is a contradiction. Therefore, $0\varepsilon M$ . Suppose inductively that. $n$ E $M$ (that is, $(n,x_n)$ E $R$ for aunique $x_n$ E $S$ ).Then $(n\:+\:1,f_{n}(x_{n}))$ E $R$ also.If $(n+1,c)$ E $R$ with $c\neq f_n(x_n)$ then $R-\{(n+1,c)\}\varepsilon S$ (verify!), which leads to a contradiction as above. Therefore, $x_{n+1}=f_{n}(x_{n})$ is the unique element of $S$ such that $(n+1,x_{n+1})\in R$ R $R$ . Therefore by induction (Theorem 6.1) $\mathbf{N}=M$ , whence the

------------------------------------------------------------------

assignment $n|\mapsto x_n$ defines a function $\varphi:\mathbb{N}\to S$ with graph $R$ . Since $(0,a)$ E $R$ we must have $\varphi(0)\:=\:a$ .For each n ε $N.$ $(n,x_{n})=(n,\varphi(n))\in R$ R $R$ and hence $(n+1,f_{n}(\varphi(n))\in R$ since $R\varepsilon G$ . But $(n+1,x_{n+1})\in R$ R $R$ and the uniqueness of. $x_{n+1}$ imply that $\varphi(n+1)=x_{n+1}=f_{n}(\varphi(n))$ .■

If $A$ is a nonempty set,then a sequence in $A$ is a function $\mathbf{N}\rightarrow A$ .Asequence is usually denoted $\{a_0,a_1,\ldots\}$ or $\left\{a_i\right\}_{ieN}$ or $\{a_i\}.$ where $a_i$ ai $a_i\varepsilon A$ is the image of $i\varepsilon N$ Similarly a function $\mathbf{N}^{*}\rightarrow A$ is also called a sequence and denoted $\{a_1,a_2,\ldots\}$ or $\left\{a_i\right\}_{ieN^{\circ}}$ or $\{a_i\};$ this will cause no confusion in context.

Theorem 6.3. (Division Algorithm) If a,b, e Z and a. $\neq0$ , then there exists unique integers q and r such that $\mathbf{b}=\mathbf{aq}+\mathbf{r}$ ,and $0\leq r<$ [al

SKETCH OF PROOF. Show that the set $S=\{b-ax|x\in\mathbf{Z},b-ax\geq0\}$ is a nonempty subset of N and therefore contains a least element. $r=b-aq$ (for some $q\in\mathbf{Z})$ . Thus $b=aq+r$ .Use the fact that $r$ is the least element in $S$ toshow $0\leq r<|a|$ and the uniqueness of $q,r$ .

We say that an integer $a\neq0$ divides an integer $b$ (written $a|b)$ if there is an integer $k$ such that $ak=b$ . If $a$ does not divide $b$ we write aXb

Definition 6.4.The positive integer c is said tobe thegreatest common divisor ofthe integers $\mathrm{a_1,a_2,\ldots,a_n}if$

(1) c | a; for $1\leq$i$\leq$n (2) d ε $\mathbf{Z}$ and d|ai for
$$1\leq\mathrm{i}\leq\mathrm{n}\quad\Rightarrow\quad\mathrm{d|c}.$$

c is denoted $(\mathrm{a}_1,\mathrm{a}_2,\ldots,\mathrm{a}_n)$

Theorem 6.5. If $\mathrm{a_1,a_2,\ldots,a_n}$ are integers, not all O, then $(\mathrm{a}_1,\mathrm{a}_2,\ldots,\mathrm{a}_n)$ exists Furthermore there are integers. $k_1,k_2,\ldots,k_n$ $k_n$ $k_n$ such tha

$$\mathrm{(a_1,a_2,\ldots,a_n)=k_1a_1+k_2a_2+\cdots+k_na_n.}$$

SKETCH OF PROOF. Use the Division Algorithm to show that the least posi tive element of the nonempty set $S=\{x_{1}a_{1}+x_{2}a_{2}+\cdots+x_{n}a_{n}\mid x_{i}\varepsilon\mathbf{Z},\sum_{i}x_{i}a_{i}>0\}$ is the greatest common divisor of. $a_1,\ldots,a_n$ . For details see Shockley [51,p.10].

The integers $a_1,a_2,\ldots,a_n$ an $a_n$ are said to be relatively prime if $(a_{1},a_{2},\ldots,a_{n})=1$ .A positive integer $p>1$ is said to be prime if its only divisors are $\pm1$ and $\pm p$ . Thus if $p$ is prime and a e $\mathbf{Z}$ ,either $(a,p)=p$ (if $p\mid a)$ or $(a,p)=1$ (if $pXa)$

Theorem 6.6. If a and b are relatively prime integers and a | bc, then a|c. If p is prime and p $|a_{\mathrm{l}}a_{2}\cdots a_{\mathrm{n}}$ then pI ai for some i.

------------------------------------------------------------------

T

SKETCH OF PROOF. By Theorem $6.51=ra+sb$ ,whence $c=rac+sbc$ Therefore $a|c$ . The second statement now follows by induction on $n$ .

Theorem 6.7. (Fundamental Theorem of Arithmetic) Any positive integer n. > 1may be written uniquely in the form. $\mathbf{n}=\mathbf{p}_{1}^{\mathbf{t}_{1}}\mathbf{p}_{2}^{\mathbf{t}_{2}}\cdots\mathbf{p}_{\mathbf{k}}^{\mathbf{t}_{\mathbf{k}}}$ ,where $p_1<p_2<\cdots<p_k$ are primes and $t_i>0$ for all i.

The proof, which proceeds by induction, may be found in Shockley [51, p.17] Let $m>0$ be a fixed integer. If a,b ε Z and $m\mid(a-b)$ then $a$ is said to be congruent to $b$ modulo m.This is denoted by $a\equiv b$ (mod $m$

Theorem 6.8. Let $m>0$ be an integer and a,b,c,d e Z

(i) Congruence modulo m is an equivalence relarion on the set of integers Z, which has precisely m equivalence classes. (i) $If$ a$\equiv\mathbf{b}$ (mod m) and $c\equiv d$ (mod m), then $a+c\equiv b+d$ (mod m) and

$\mathbf{ac}\equiv\mathbf{bd}$ (mod m) (i)If ab= ac(modm) and a and m arerelatively prime,then b=c $b\equiv c$ $\mathbf{b}\equiv$c$(\mathrm{mod~m})$

PROOF. (i) The fact tlat congruence modulo $m$ is an equivalence relation is an easy consequence of the appropriate definitions. Denote the equivalence class of an integer $a$ by $\bar{a}$ and recall property (20),which can be stated in this context as:

$$\bar{a}=b\quad\Leftrightarrow\quad a\equiv b\pmod{m}.$$

Given any $a\varepsilon Z$ , there are integers $q$ and $r$ ,with $0\leq r<m$ ,such that $a=mq+r$ Hence $a-r=mq$ and $a\equiv r\left(\mathrm{mod}\:m\right)$ m $m$ ; therefore, $\bar{a}=\bar{r}$ by (20). Since $a$ was arbitrary and $0\leq r<m$ ,it follows that every equivalence class mustbe one of $0,1,\bar{2},\bar{3},\ldots,(\overline{m-1})$ .However, these $m$ equivalence classes are distinct: for if $0\leq i<j<m$ , then 0<(j-i)<m $0<(j-i)<m$ $0<(j-i)<m$ and $m\not\mid(j-i).$ Thus $i\not\equiv j(\mathrm{mod}m)$ mx(i-i) $m\nmid(j-i)$ $i\not\equiv j({\mathrm{mod}}m)$ i # j (mod m) and hence $i\neq j$ by (20'). Therefore, there are exactly $m$ equivalence classes (ii) We are given $m\mid a-b$ and $m\mid c-d.$ Hence $m$ divides $(a-b)+(c-d)$

$=(a+c)-(b+d)$ and therefore $a+c\equiv b+d$ (mod $m$ ). Likewise, $m$ divides $(a-b)c+(c-d)b$ and therefore divides $ac-bc+cb-db=ac-bd$ ：thus $ac\equiv bd\left(\mathrm{mod}\:m\right)$ (ii) Since ab = ac $ab\equiv ac$ $ab\equiv ac\pmod{m},m\mid a(b-c)$ $m.$ m m | a(b - c) $m\mid a(b-c)$ Since $(m,a)=1,m\mid b-c$ by Theo-

rem 6.6,and thus $b\equiv c$ (mod $m$ ).

## 7. THE AXIOM OF CHOICE, ORDER, AND ZORN'S LEMMA

Nore. In this section we deal only with sers. No proper classes are involved.

If $I\neq\varnothing$ and $\{A_i\mid i\in I\}$ is a family of sets such that $A_i\neq\emptyset$ for all i e I, then we wouldlike toknow that $\prod_{i\in I}A_i\neq\varnothing$ It has been proved that this apparently in nocuous conclusion cannot be deduced from the usual axioms of set theory (although it is not inconsistent with them — see P. J. Cohen [59]). Consequently we shall assume

------------------------------------------------------------------

The Axiom of Choice. The product of a family of nonempty sets indexed by a nonempty set is nonempty

See Exercise 4 for another version of the Axiom of Choice. There are two propo sitions equivalent to the Axiom of Choice that are essential in the proofs of a number of important theorems. In order to state these equivalent propositions we must introduce some additional concepts. A partially ordered set is a nonempty set $A$ together with a relation $R$ on $A\times A$

(called a partial ordering of $A^{\cdot}$ )which is refexive and transitive (see (15),(17) in section 4) and

$$antisymmetric:(a,b)\varepsilon Rand(b,a)\varepsilon R\Rightarrow a=b.$$

If $R$ is a partial ordering of $A$ , then we usually write $a\leq b$ in place of $(a,b)\in R$ R $R$ . In this notation the conditions (15), (17), and (31) become (for all $a,b,c\in A$

$$a\leq a;\\a\leq b\quad\mathrm{and}\quad b\leq c\quad\Rightarrow\quad a\leq c;\\a\leq b\quad\mathrm{and}\quad b\leq a\quad\Rightarrow\quad a=b.$$

We write $a<b$ if $a\leq b$ and $a\neq b$

Elements $a,b\in A$ are said to be comparable, provided $a\leq b$ or $b\leq a$ . However twogiven elements of a partially ordered set need not be comparable.A partial ordering of a set $A$ such that any two elements are comparable is calleda linear (or total or simple) ordering

EXAMPLE. Let $A$ be the power set (set of all subsets) of {1,2,3,4,5}. Define $C\leq D$ if and only if $C\subset D$ . Then $A$ is partially ordered, but not linearly ordered (for example, {1,2} and {3,4} are not comparable)

Let $(A,\leq)$ be a partially ordered set.An element a e A is maximal in $A$ if for every $c\varepsilon A$ which is comparable to a, $c\leq a;$ in other words, for all c e A, $a\leq c\Rightarrow a=c$ Note that if $a$ is maximal, it need not be the case that $c\leq a$ for all c ε A (there may exist $c\varepsilon A$ that are not comparable to $a$ ). Furthermore, a given set may have many maximal elements (Exercise 5) or none at all (for example, $\mathbf{Z}$ with its usual ordering) An upper bound of a nonempty subset $B$ of $A$ is an element d e A such that $b\leq d$ for every $b\varepsilon B$ .A nonempty subset $B$ of $A$ that is linearly ordered by $\leq$ is called a chain in $A$

Zorn's Lemma. If A is a nonempty partially ordered set such that every chain in A has an upper bound in A, then A contains a maximal element

Assuming that all the other usual axioms of set theory hold, it can be proved that Zorn's Lemma is true if and only if the Axiom of Choice holds; that is, the two are equivalent — see E. Hewitt and K. Stromberg [57: p. 14]. Zorn's Lemma is a powerful tool and will be used frequently in the sequel. Let $B$ be a nonempty subset of a partially ordered set $(A,\leq)$ . An element c E $B$ is a

least (or minimum) element of $B$ provided $c\leq b$ for every $b\varepsilon B$ . If every nonempty subset of $A$ has a least element, then $A$ is said to be well ordered.Every well-ordered set is linearly ordered (but not vice versa) since for all $a,b\in A$ the subset $\{a,b\}$ must

------------------------------------------------------------------

have a least element; that is, $a\leq b$ or $b\leq a$ .Here is another statement that can be proved to be equivalent to the Axiom of Choice (see E. Hewitt and K. Stromberg [57; p.14]).

The Well Ordering Principle. If A is a nonempty set, then there exists a linear ordering $\leq$ ofA such that $(\mathbf{A},\leq)$ is well ordered.

EXAMPLES. We have already assumed (Section 6) that the set $N$ of natural numbers is well ordered. The set $\mathbf{Z}$ of all integerswith the usual ordering by magnitude is linearly ordered but not well ordered (for example, the subset of negative integers has no least element). However, each of the following is a well ordering of $\mathbf{Z}$ (where by definition $a<b\Longleftrightarrow a$ is to the left of $b$ ：

(ii)
$$\begin{aligned}
&)\:0,1,-1,2,-2,3,-3,\ldots,n,-n,\ldots; \\
&0,1,3,5,7,\ldots,2,4,6,8,\ldots,-1,-2,-3,-4,\ldots \\
&\text{)0,3,4,5,6,\ldots,-1,-2,-3,-4,\ldots,1,2.}
\end{aligned}$$
(ii)

These orderings are quite different from one another. Every nonzero element a in ordering (i) has an immediate predecessor (that is an element $c$ such that $a$ is theleast element in the subset $\{x\mid c<x\}$ ). But the elements - 1 and 2 in ordering (ii) and - 1 and 1 in ordering (ii) have no immediate predecessors. There are no maximal elements in orderings (i) and (i), but 2 is a maximal element in ordering (i). The element O is the least element in all three orderings.

The chief advantage of the well-ordering principle is that it enables us to extend the principle of mathematical induction for positive integers (Theorem 6.1) to any well ordered set..

Theorem 7.1.(Principle of Transfinite Induction) If B is a subset of a well-ordered set $(\mathbf{A},\leq)$ such that for every a e A,

$$\{c\varepsilon A|c<a\}CB\Rightarrow a\varepsilon B,$$

then $\mathbf{B}=\mathbf{A}$

PROOF. If $A-B\neq\varnothing$ , then there is a least element a e $A-B$ .By the defini tions of least element and $A-B$ we must have $\left\{c\in A\mid c<a\right\}\subset B$ . By hypothesis then, $a\varepsilon B$ so that $a\varepsilon B\cap(A-B)=\varnothing$ ,which is a contradiction. Therefore, $A-B=\varnothing$ and $A=B$ .

### EXERCISES

1. Let $(A,\leq)$ be a partially ordered set and $B$ a nonempty subset. A lower bound of $B$ is an element de A such that $d\leq b$ for every $b\varepsilon B.$ A greatest lower bound (g.l.b.) of $B$ is a lower bound $d_0$ of $B$ such that $d\leq d_0$ for every other lower bound dof $B$ A least upper bound (l.u.b.) of $B$ is an upper bound $t_0$ of $B$ such that $t_0\leq t$ for every other upper bound 1 of $B$ $(A,\leq)$ is a lattice if for all $a,b$ E $A$ the set $\{a,b\}$ has both a greatest lower bound and a least upper bound.

------------------------------------------------------------------

(a) If $S\neq\varnothing$ , then the power set $P(S)$ ordered by set-theoretic inclusion is a lattice, which has a unique maximal element. (b) Give an example of a partially ordered set which is nor a lattice.

(c) Give an example of a lattice with no maximal element and an example of a partially ordered set with two maximal elements.

2. A lattice $(A,\leq)$ (see Exercise 1) is said to be complete if every nonempty subset of A has both a least upper bound and a greatest lower bound. A map of partially ordered sets $f{:}A\to B$ is said to preserve order if $a\leq a^{\prime}$ in $A$ implies $f(a)\leq f(a^{\prime})$ in $B$ Prove that an order-preserving map $f$ of a complete lattice $A$ into itself has at least onefixedelement(that is,ana E $A$ such that $f(a)=a$

3.Exhibit a well ordering of the set $Q$ of rational numbers.

4. Let $S$ be a set. A choice function for $S$ is a function $f$ from the set of all nonempty subsets of S to $S$ such that $f(A)$ E $A$ for all $A\neq\varnothing$ $A\subset S.$ Show that the Axiom of Choice is equivalent to the statement that every set $S$ has a choice function.

5. Let $S$ be the set of all points $(x,y)$ in the plane with $y\leq0$ . Define an ordering by $(x_{1},y_{1})\leq(x_{2},y_{2})\Leftrightarrow x_{1}=x_{2}$ and $y_1\leq y_2$ .Show that this is a partial ordering of $S$ , and that $S$ has infinitely many maximal elements.

6. Prove that if all the sets in the family $\{A_i\mid i\in I\neq\varnothing\}$ are nonempty, then each of the projections $\pi_{k}:\prod_{i\in I}A_{i}\to A_{k}$ is surjetive

7. Let $(A,\leq)$ be a linearly ordered set. The immediate successor of a e $A$ (ifit exists) is the least element in the set $\{x\in A\mid a<x\}$ . Prove that if $A$ is well ordered by $\leq$ , then at most one element of $A$ has no immediate successor. Give an example of alinearly ordered set in which precisely two elements have no immediate successor.

## 8. CARDINAL NUMBERS

The definition and elementary properties of cardinal numbers will be needed frequently in the sequel. The remainder of this section (beginning with Theorem 8.5), however, will be used only occasionally (Theorems II.1.2 and IV.2.6; Lemma V.3.5; Theorems V.3.6 and V1.1.9). It may be omitted for the present, if desired

Two sets, $A$ and $B$ , are said to be equipollent, if there exists a bijective map $A\to B$ in this case we write $A\sim B$

Theorem 8.1. Eguipollence is an equivalence relation on the class S of all sets.

PROOF. Exercise; note that $\varnothing\sim\varnothing$ since $\varnothing\subset\varnothing\times\varnothing$ is a relation that is (vacuously) a bijective function.3

Let $I_{0}=\varnothing$ and for each n e $N^*$ let $I_n=\{1,2,3,\ldots,n\}$ . It is not difficult to prove that $I_{m}$ and $I_{n}$ are equipollent if and only if $m=n$ (Exercise 1). To say that a set $A$

------------------------------------------------------------------

has precisely n elements means that $A$ and $I_n$ are equipollent, that is, that $A$ and $I_n$ are in the same equivalence class under the relation of equipollence. Such a set $A$ (with $A\sim I_n$ for some unique $n\geq0$ ) is said to be finite; a set that is not finite is infinite. Thus, for a finite set $A$ ,the equivalence class of $A$ under equipollence provides an answer to the question:how many elements are contained in $A?$ These considerations motivate

Definition 8.2. The cardinal number (or cardinality) of a ser A, denoted |A], is the equivalence class of A under the equivalence relation ofequipollence. $|\mathbf{A}|$ is an infinite or finite cardinal according as A is an infinite or finite set..

Cardinal numbers will also be denoted by lower case Greek letters: $\alpha,\beta,\gamma$ ,etc. For the reasons indicated in the preceding paragraph we shall idenrify the integer $n\geq0$ with the cardinal number $|I_n|$ and write $|I_n|=n$ , so that the cardinal number of a finite set is precisely the number of elements in the set.

Cardinal numbers are frequently defined somewhat differently than we have done so that a cardinal number is in fact a set (instead of a proper class as in Definition 8.2)) . We have chosen this definition both to save time and because it better reflects the intuitive notion of “the number of elements in a set." No matter what definition of cardinality is used, cardinal numbers possess the following properties (the frst two of which are, in our case, immediate consequences of Theorem 8.1 and Definition 8.2).

(i) Every set has a unique cardinal number;.

(i)two sets have the same cardinal number if and only if they are equipollen $(|A|=|B|\Leftrightarrow A\sim B)$

(ii) the cardinal number of a finite set is the number of elements in the set.

Therefore statements about cardinal numbers are simply statements about equipollence of sets.

EXAMPLE. The cardinal number of the set N of natural numbers is customarily denoted $N_0$ (read "aleph-naught"). A set. $A$ of cardinality $N_0$ (that is, one which is equipollent toN) is said to be denumerable.The set $N^*$ , the set $\mathbf{Z}$ of integers, and the set Q of rational numbers are denumerable(Exercise 3),but the set R of real numbers is nor denumerable (Exercise 9).

Definition 8.3. Let α and $\beta$ be cardinal numbers. The sum $\alpha+\beta$ is defined to be the cardinal number $|AUB|$ ,where A and B are disjoint sets such that $|\mathbf{A}|=\alpha$ and $|B|=\beta$ . The product $\alpha\beta$ is defined to be the cardinal number. $|\mathbf{A}\times\mathbf{B}|$

It is not actually necessary for $A$ and $B$ to be disjoint in the definition of the product $\alpha\beta$ (Exercise 4). By the definition of a cardinal number $\alpha$ there always exists a set $A$ such that $|A|=\alpha$ .It is easytoverify that disjoint sets, as requiredfor the definition of $\alpha+\beta.$ always exist and that the sum $\alpha+\beta$ and product $\alpha\beta$ are independent of the choice of the sets $A,B$ (Exercise 4). Addition and multiplication of cardinals are associative and commutative, and the distributive laws hold (Exercise 5). Furthermore, addition and multiplication of fnite cardinals agree with addition

------------------------------------------------------------------

and multiplication of the nonnegative integers with which they are identified; for if $A$ has $m$ elements, $B$ has $n$ elements and $A\cap B=\varnothing$ , then $A\cup B$ B $B$ has $m+n$ elements and $A\times B$ has mn elements (for more precision, see Exercise 6).

Definition 8.4. Let $\alpha,\beta$ be cardinal numbers and A,B sets such that. $|\mathbf{A}|=\alpha,|\mathbf{B}|=\beta$ [B| =β $|\mathbf{B}|=\beta$ $\alpha$ isHess than or equal to $\beta$ , denoted $\alpha\leq\beta$ or $\beta\geq\alpha$ β≥α $\beta\geq\alpha$ if A is equipollent with a subset of B (that is, there is an injective map. $\mathbf{A}\rightarrow\mathbf{B}$ ）. $\alpha$ is strictly less than $\beta$ , denoted $\alpha<\beta$ or $\beta>\alpha$ if $\alpha\leq\beta$ and $\alpha\neq\beta$

It is easy to verify that the definition of $\leq$ does not depend on the choice of $A$ and $B$ (Exercise 7). It is shown in Theorem 8.7 that the class of all cardinal numbers is linearly ordered by $\leq$ . For finite cardinals $\leq$ agrees with the usual ordering of the. nonnegative integers (Exercise 1). The fact that there is no largest cardinal number is an immediate consequence of

Theorem 8.5. If A is a set and P(A) its power set, then $|\mathbf{A}|<|\mathbf{P}(\mathbf{A})|$

SKETCH OF PROOF. The assignment $a\vdash\{a\}$ defines an injective map $A\to P(A)$ so that $|A|\leq|P(A)|$ . If there were a bijective map $f{:}A\to P(A)$ , then for some $a_0\varepsilon A$ ， $f(a_{0})=B$ where $B=\{a\varepsilon A|a\notin f(a)\}\subset A$ . But this yields a contradiction: $a_0$ ao $a_0\varepsilon B$ B $B$ and $a_0\notin B.$ . Therefore $|A|\neq|P(A)|$ and hence $|A|<|P(A)|$ .

REMARK. By Theorem 8.5, $\aleph_0=|N|<|P(\mathbb{N})|$ . It can be shown that $|P(\mathbf{N})|=|\mathbf{R}|$ ,where $R$ is the set of real numbers. The conjecture that there is no cardinal number $\beta$ such that $\aleph_0<\beta<|P(\mathbb{N})|=|\mathbb{R}|$ is called the Continuum Hypothesis. It has been proved to be independent of the Axiom of Choice and of the other basic axioms of set theory; see P. J. Cohen [59].

The remainder of this section is devoted to developing certain facts that will be needed at several points in the sequel (see the first paragraph of this section)

Theorem 8.6. (Schroeder-Bernstein) If A and B are sets such that $|A|\leq|B|$ and $|\mathbf{B}|\leq|\mathbf{A}|$ ,then $|\mathbf{A}|=|\mathbf{B}|$

SKETCH OF PROOF. By hypothesis there are injective maps $f{:}A\to B$ and $g:B\to A$ . We shall use $f$ and $g$ to construct a bijection $h:A\to B$ . This will imply that $A\sim B$ and hence $|A|=|B|$ . If ae $A$ , then since $g$ is injective the set $g^{-1}(a)$ is either empty (in which case we say that $a$ is parentless) or consists of exactly one element $b\varepsilon B$ (in which case we write $g^{-1}(a)=b$ and say that $b$ is the parenr of $a$ ). Similarly for $b\varepsilon B$ , we have either $f^{-1}(b)=\varnothing$ $\langle b$ is parentless) or $f^{-1}(b)=a^{\prime}\varepsilon A$ $'a'$ is the parenr of $b$ ). If we continue to trace back the “ancestry" of anelement a E $A$ in this manner, one of three things must happen. Either we reach a parentless element in $A$ (an ancestor of a E $A$ ), or we reach a parentless element in $B$ (an ancestor

------------------------------------------------------------------

of $a$ ), or the ancestry of a e $A$ can be traced back forever (infinite ancestry). Now define three subsets of $A$ [resp. B] as follows:

$$\begin{aligned}
&A_{1} =\{a\:\varepsilon\:A\mid a\:\mathrm{has~a~parentless~ancestor~in~}A\}; \\
&A_{2} =\left\{\begin{matrix}{a}&{\varepsilon}&{A}&{\mid a}&{\mathrm{has~a~parentless~ancestor~in~}}\\\end{matrix}\right\}; \\
&A_{3} =\left\{\begin{matrix}{a}&{\varepsilon}&{A}&{\mid a}&{\mathrm{has~infinite~ancestry}}\\\end{matrix}\right\}; \\
&\boldsymbol{B}_{1} =\left\{b\varepsilon B\mid b\text{ has a parentless ancestor in }A\right\}; \\
&B_{2} =\left\{\begin{matrix}{b}&{\varepsilon}&{B}&{\mid b}&{\mathrm{has~a~parentless~ancestor~in~}}\\\end{matrix}\right\}; \\
&B_{3} =\left\{b\:\varepsilon\:B\mid b\:\mathrm{has~infinite~ancestry}\right\}. 
\end{aligned}$$

Verify that the $A_i$ [resp. $B_i]$ are pairwise disjoint, that their union is $A$ [resp. $B]$ ; that $f|\left.A_i\right.$ is a bijection $A_{i}\to B_{i}$ for $i=1$ , 3; and that $g\mid B_2$ is a bijection $B_2\to A_2$ . Consequently the map $h:A\to B$ given as follows is a well-defined bijection:

$$h(a)=\begin{cases}f(a)&\text{if}&a\:\varepsilon\:A_1\:\bigcup\:A_3;\\g^{-1}(a)&\text{if}&a\:\varepsilon\:A_2.&\blacksquare\end{cases}$$

Theorem 8.7.The class of all cardinal numbers is linearly ordered by $\leq$ . Ifα and $\beta$ are cardinal numbers, then exactly one of the following is true.

$$\alpha<\beta;\quad\alpha=\beta;\quad\beta<\alpha\quad(\text{Trichotomy Law}).$$

SKETCH OFPROOF.It is easy to verify that $\leq$ is a partial ordering. Let $\alpha,\beta$ be cardinals and $A,B$ be sets such that $|A|=\alpha$ $|B|=\beta$ .We shall show that $\leq$ is a linear ordering (that is, either $\alpha\leq\beta$ or $\beta\leq\alpha$, by applying Zorn's Lemma to the set $\mathcal{F}$ of all pairs $(f,X)$, where $X\subset A$ and $f{:}X\to B$ is an injective map. Verify that $\mathcal{F}\neq\varnothing$ and that the ordering of $\mathcal{F}$ given by $(f_1,X_1)\leq(f_2,X_2)$ if and only if $X_1\subset X_2$ and $f_{2}|X_{1}=f_{1}$ is a partial ordering of §. If $\left\{(f_{i},X_{i})\mid i\in I\right\}$ is a chain in $\mathcal{F}$ ,let X = U X; and define $f{:}X\to B$ by $f(x)=f_{i}(x)$ for $x\varepsilon X_i$ . Show that $f$ is a well-de- $X=\bigcup_{i\in I}X_i$ fined injective map, and that ( $f,X)$ is an upper bound in $\mathcal{F}$ of the given chain. There-

fore by Zorn's Lemma there is a maximal element $(g,X)$ of $\mathcal{F}$ . We claim that either $X=A$ or $Img=B$ . For if both of these statements were false we could find a e. $A-X$ and $b\varepsilon B-Img$ and define an injective map $h:X\cup\{a\}\to B$ by $h(x)=g(x)$ for $x\varepsilon X$ and $h(a)=b$ . Then $(h,X\cup\{a\})\in\mathcal{F}$ and $(g,X)<(h,\dot{X}\cup\{a\})$ ，which contradicts the maximality of $(g,X)$ . Therefore either $X=A$ so that $|A|\leq|B|$ or $\mathbf{Im}g=B$ in which case theinjective map $B\overset{g^{-1}}{\operatorname*{\to}}X\subset A$ shows that $|B|\leq|A|$ . Use these facts, the Schroeder-Bernstein Theorem 8.6 and Definition 8.4 to prove the Trichotomy Law.

REMARKS. A family of functions partially ordered as in the proof of Theorem 8.7 is said to be ordered by extension. The proof of the theorem is a typical example of the use of Zorn's Lemma. The details of similar arguments in the sequel will frequently be abbreviated

------------------------------------------------------------------

SKETCH OF PROOF. If $B$ is a finite subset of the infinite set $A$ , then $A-B$ is nonempty. For each finite subset $B$ of $A$ , choose an element $x_B$ E $A-B$ (Axiom of Choice). Let $F$ be the set of all finite subsets of $A$ and defne a map $f:F\to F$ by $f(B)=B\cup\{x_B\}$ {xB} $\{x_B\}$ . Choose a ε A. By the Recursion Theorem 6.2 (with $f_{n}=f$ for all $n$ ) there exists a function $\varphi:\mathbf{N}\rightarrow F$ such that

$$\varphi(0)=\{a\}\quad\mathrm{and}\quad\varphi(n+1)=f(\varphi(n))=\varphi(n)\cup\{x_{\varphi(n)}\}\:(n\geq0).$$

Let $g:\mathbb{N}\to A$ be the function defined by

$$g(0)=a;g(1)=x_{\varphi(0)}=x_{\{a\}};\ldots;g(n+1)=x_{\varphi(n)};\ldots.$$

Use the order properties of $N$ and the following facts to verify that $g$ is injective

(i $g(n)\in\varphi(n)$ for all $n\geq0$ ; (i) $g(n)\notin\varphi(n-1)$ for all $n\geq1$ (ii) $g(n)\notin\varphi(m)$ for all $m<n$

Therefore Im $g$ is a subset of $A$ such that $|\mathbf{Im}\:g|=|\mathbf{N}|=\mathbf{\aleph}_{0}$

Lemma 8.9. If A is an infinite set and F a finite set then $|\mathcal{A}\cup\mathcal{F}|=|\mathcal{A}|$ . In particular $\alpha+\mathbf{n}=\alpha$ for every infinite cardinal number $\alpha$ and erery natural number (finite cardinal) n.

SKETCH OF PROOF. It suffices to assume $A\cap F=\varnothing$ (replace $F$ by $F-A$ if necessary). If $F=\{b_{1},b_{2},\ldots,b_{n}\}$ and $D=\left\{x_i\mid i\varepsilon\mathbf{N}^*\right\}$ is a denumerable subset of $A$ (Theorem 8.8), verify that $f{:}A\to A\cup F$ F $F$ is a bijection, where $f$ isgiven by

$$f(x)=\begin{cases}b_i&\text{for}\quad x=x_i,1\leq i\leq n;\\x_{i-n}&\text{for}\quad x=x_i,i>n;\\x&\text{for}\quad x\in A-D.\end{cases}$$

Theorem 8.10. If $\alpha$ and $\beta$ are cardinal numbers such that $\beta\leq\alpha$ and $\alpha$ is infinite thien $\alpha+\beta=\alpha$

SKETCH OF PROOF. It suflices to prove $\alpha+\alpha=\alpha$ (simply verify that $\alpha\leq\alpha+\beta\leq\alpha+\alpha=\alpha$ and apply the Schroeder-Bernstein Theorem to conclude $\alpha+\beta=\alpha)$ 0. Let $A$ be a set with $|A|=\alpha$ and let $\mathcal{F}$ be the set of all pairs $(f,X)$ where $X\subset A$ and $f{:}X\times\{0,1\}\to X$ is a bijection. Partially order $\mathcal{F}$ by extension (as in the proof of Theorem 8.7) and verify that the hypotheses of Zorn's Lemma are satisfied. The only difficulty is showing that $\mathcal{F}\neq\varnothing$ . To do this note that the map $\mathbb{N}\times\{0,1\}\to\mathbb{N}$ given by $(n,0)\vdash2n$ and $(n,1)\vdash2n+1$ is a bijection. Use this fact to construct a bijection $f{:}D\times\{0,1\}\to D$ ,where $D$ is a denumerable subset of $A$ (that is, $|D|=|\mathbf{N}|$ ; see Theorem 8.8). Therefore by Zorn's Lemma there is a maximal element $(g,C)\in\mathcal{F}$

Clearly $C_{0}=\left\{(c,0)\mid c\in C\right\}$ and $C_{\mathrm{l}}=\left\{(c,1)\mid c\in C\right\}$ are disjoint sets such that $|C_{0}|=|C|=|C_{1}|$ and $C\times\{0,1\}=C_{0}\cup C_{\mathrm{i}}$ .The map $g:C\times\{0,1\}\to C$ is a bijection. Therefore by Definition 8.3,

$$|C|=|C\times\{0,1\}|=|C_0\cup C_1|=|C_0|+|C_1|=|C|+|C|.$$

------------------------------------------------------------------

To complete the proof we shall show that $|C|=\alpha$ .If $A-C$ were infinite, it would contain a denumerable subset $B$ by Theorem 8.8, and as above, there would be a bijection $\zeta:B\times\{0,1\}\to B$ . By combining 5 with $g$ , we could then construct a bijection $h:(C\cup B)\times|0,1\rangle\to C\cup B$ so that $(g,C)<(h,C\cup B)\varepsilon$ $f(g,C)<(h,C\cup B)\varepsilon$ $f(g,C)<(h,C\cup B)\varepsilon$ ,which would contradict the maximality of $(g,C)$ . Therefore $A-C$ must be finite. Since $A$ is in finite and $A=C\cup(A-C)$, $(A-C)$ $(A-C)$ $C$ must also be infnite. Thus by Lemma 8.9, $|C|=$ $|C\cup(A-C)|=|A|=\alpha$ .

Theorem 8.11. If $\alpha$ and $\beta$ are cardinal numbers such that. $0\neq\beta\leq\alpha$ and $\alpha$ is infinite. then $\alpha\beta=\alpha$ : in particular, $\alpha\mathbf{\aleph}_0=\alpha$ andif $\beta$ is finite $\aleph_{\mathrm{o}}\beta=\aleph_{\mathrm{o}}$

SKETCH OF PROOF. Since $\alpha\leq\alpha\beta\leq\alpha\alpha$ it suffices (as in the proof of Theorem 8.10) to prove $\alpha\alpha=\alpha$ .Let $A$ be an infinite set with $|A|=\alpha$ and let $\mathcal{F}$ be the set of all bijections $f{:}X\times X\to X$ ,where $X$ is an infinite subset of $A$ . To show that $\mathcal{F}\neq\varnothing$ , use the facts that $A$ has a denumerable subset $D$ (so that $|D|=|\mathbf{N}|=|\mathbf{N}^{*}|)$ and that the map $\mathbb{N}^*\times\mathbb{N}^*\to\mathbb{N}^*$ given by $(m,n)|\mapsto2^{m-1}(2n-1)$ is a bijection. Partially order $\mathcal{F}$ by extension and use Zorn's Lemma to obtain a maximal element $g:B\times B\to B$ . By the definition of. $g$ $|B||B|=|B\times B|=|B|$ .To complete the proof we shall show that $|B|=|A|=\alpha$ Suppose $|A-B|>|B|$ .Then by Definition 8.4 there is a subset $C$ of $A-B$ such

that $|C|=|B|$ .Verify that $|C|=|B|=|B\times B|=|B\times C|=|C\times B|=|C\times C|$ and that these sets are mutually disjoint. Conseyuently by Definition 8.3 and Theor $|(B\cup C)\times(B\cup C)|=|(B\times B)$ $|(B\cup C)\times(B\cup C)|=|(B\times B)$ em $8.10\:|(B\cup C)\times(B\cup C)|=|(B\times B)\cup(B\times C)\cup(C\times B)\cup(C\times C)|$ $(B\times C)$ (B × C) (C × C)I $(C\times C)|$ $=|B\times B|+|B\times C|+|C\times B|+|C\times C|=(|B|+|B|)+(|C|+|C|)=|B|+$ $|C|=|B\cup C|$ and there is a bijection $(B\cup C)\times(B\cup C)\to(B\cup C)$ ,which contradicts the maximality of $g$ in F. Therefore, by Theorems 8.7 and $8.10|A-B|\leqslant|B|$ and $|B|=|A-B|+|B|=|(A-B)\cup B|=|A|=\alpha.$ $B|=|A|=\alpha$ $B|=|A|=\alpha$

Theorem 8.12.Let A be a set and for each integer n $\geq1$ let $\mathbf{A}^{n}=\mathbf{A}\times\mathbf{A}\times\cdots\mathbf{X}$ (n factors).

(i)If A isfinite,then $\left|\mathbf{A}^{n}\right|=\left|\mathbf{A}\right|^{n}$ , and if A is infinite, then $\left|\mathbf{A}^{n}\right|=\left|\mathbf{A}\right|$ (i) $|\bigcup_{n\epsilon\mathbf{N}^{*}}\mathbf{A}^{n}|=\mathbf{N}_{0}|\mathbf{A}|$

SKETCH OF PROOF. (i) is trivial if $|A|$ is finite and may be proved by induc tion on $n$ if $|A|$ is infinite (the case $n=2$ is given by Theorem 8.11). (i) The sets $A^n\left(n\geq1\right)$ are mutually disjoint. If $A$ is infinite, then by (i) there is for each $n$ a bijection $f_n:A^n\to A$ . The map $\bigcup_{n\to\infty}A^n\to\mathbb{N}^*\times A$ , which sends u e $A^n$ onto $(n,f_n(u))$ ,is a bijection. Therefore $|\bigcup_{n\in\mathbb{N}^{*}}A^{n}|=|\mathbf{N}^{*}\times A|=|\mathbf{N}^{*}||A|=\aleph_{0}|A|$ . (i is obviously true if $A=\varnothing$ . Suppose, therefore, that $A$ is nonempty and finite. Then each $A^n$ is nonempty and it is easy to show that Ro =|N*|≤ | UA"|.Furthermore each $A^n$ is ${\mathbf{N}}_{0}=|{\mathbf{N}}^{*}|\leq|\bigcup_{n\in\mathbb{N}^{*}}A^{n}|$ fnite and there is for each $n$ an injective map $g_{n}:A^{n}\to\mathbf{N}^{*}$ . The map $\bigcup_{n\in\mathbf{N}^*}A^n\to$ $\mathbf{N}^*\times\mathbf{N}^*$ , which sends ue $A^n$ onto $(n,g_n(u))$ is injective so that | U A"| ≤ IN* × N* $|\bigcup_{n\epsilon\mathbf{N}^{*}}A^{n}|\leq|\mathbf{N}^{*}\times\mathbf{N}^{*}|$ $=|\mathbf{N}^{*}|=\mathbf{N}_{0}$ by Theorem 8.11. Therefore by the Schroeder-Bernstein Theorem 1 U A| = &。. But $\aleph_0=\aleph_0|A|$ since $A$ is fnite (Theorem 8.11). $|\bigcup_{n\in\mathbb{N}^{*}}A^{n}|\:=\aleph_{0}$

------------------------------------------------------------------

Corollary 8.13.If A is an infinite set and F(A) the set ofall finite subsets of A, then $|\mathbf{F}(\mathbf{A})|=|\mathbf{A}|$

PROOF. The map $A\to F(A)$ given by $a\vdash\{a\}$ is injective so that $|A|\leq|F(A)|$ For each $n$ -element subset $S$ of $A$ ,choose $(a_1,\ldots,a_n)\varepsilon$ $A^n$ such that $S=\{a_{1},\ldots,a_{n}\}$ This defnes an injective map $F(A)\to\bigcup_{n\in\mathbb{N}^*}$ $A^n$ so that $|F(A)|\leq|\bigcup_{n\in\mathbb{N}^*}A^n|=\aleph_0|A|=|A|$ by Theorems 8.11 and 8.12. Therefore, $|A|=|F(A)|$ by the Schroeder-Bernstein Theorem 8.6.

## EXERCISES

1.Let $I_{0}=\varnothing$ and for each $n\in\mathbb{N}^*$ let $I_n=\{1,2,3,\ldots,n\}$ (a) $I_n$ is not equipollent to any of its proper subsets $[Hint$ : induction]

(b) $I_{m}$ and $I_n$ are equipollent if and only if $m=n$ (c) $I_{m}$ is equipollent to a subset of $I_n$ but $I_n$ is not equipollent to any subset of $I_{m}$ if and only if $m<n$

2. (a) Every infinite set is equipollent to one of its proper subsets. (b) A set is finite if and only if it is not equipollent to one of its proper subsets [see Exercise 1].

3. (a) $\mathbf{Z}$ is a denumerable set. (b) The set $\mathbf{Q}$ of rational numbers is denumerable. [Hinr: show that

$|\mathbf{Z}|\leq|\mathbf{Q}|\leq|\mathbf{Z}\times\mathbf{Z}|=|\mathbf{Z}|.$

4. If $A,A^{\prime},B,B^{\prime}$ are sets such that $|A|=|A^{\prime}|$ and $|B|=|B^{\prime}|$ ,then $|A\times B|=|A^{\prime}\times B^{\prime}|$ If in addition $A\cap B=\varnothing=A^{\prime}\cap B^{\prime}$ , then $|A\cup B|=|A^{\prime}\cup B^{\prime}|$ . Therefore multiplication and addition of cardinals is well defined..

5. For all cardinal numbers $\alpha,\beta,\gamma$

(a) $\alpha+\beta=\beta+\alpha$ and $\alpha\beta=\beta\alpha$ (commutative laws) (b) $(\alpha+\beta)+\gamma=\alpha+(\beta+\gamma)$ and $(\alpha\beta)\gamma=\alpha(\beta\gamma)$ (associative laws) (c) $\alpha(\beta+\gamma)=\alpha\beta+\alpha\gamma$ and $(\alpha+\beta)\gamma=\alpha\gamma+\beta\gamma$ (distributive laws) (d) $\alpha+0=\alpha$ and $\alpha\mathbf{l}=\alpha$ (e) If $\alpha\neq0$ , then there is no $\beta$ such that $\alpha+\beta=0$ and if $\alpha\neq1$ ,then there is no $\beta$ such that $\alpha\beta=1$ . Therefore subtraction and division of cardinal numbers cannot be defined.

6. Let $I_n$ be as in Exercise 1. If $A\sim I_m$ and $B\sim I_n$ and $A\cap B=\varnothing$ , then $(A\cup B)$ $\sim I_{m+n}$ and $A\times B\sim I_{mn}$ . Thus if we identify $|A|$ with $m$ and $|B|$ with $n$ ,then $|A|+|B|=m+n$ and $|A||B|=mn$

7. If $A\sim A^{\prime}$ ， $B\sim B^{\prime}$ and $f{:}A\to B$ is injective, then there is an injective map $A^{\prime}\to B^{\prime}$ .Therefore the relation $\leq$ on cardinal numbers is well defined

8. An infinite subset of a denumerable set is denumerable..

9. The infinite set of real numbers $R$ is not denumerable (that is, $\aleph_0<|\mathbf{R}|$ .[Hint: it suffices to show that the open interval (O,1) is not denumerable by Exercise 8. You may assume each real number can be written as an infinite decimal. If (0,1) is denumerable there is a bijection $f{:}\mathbf{N}^*\to(0,1)$ . Construct an infinite decimal (real number) $a_{1}a_{2}\cdots$ in (0,1) such that $a_n$ is not the nth digit in the decimal expansion. of $f(n)$ . This number cannot be in $Imf.]$ f $f.$

------------------------------------------------------------------

[

10.If $\alpha,\beta$ are cardinals, define $\alpha^\beta$ to be the cardinal number of the set of all functions $B\to A$ , where $A,B$ are sets such that $|A|=\alpha$ $|B|=\beta$ (a) $\alpha^\beta$ is independent of the choice of $A,B$ (b) $\alpha^{\beta+\gamma}=(\alpha^\beta)(\alpha^\gamma)$ α+ =(α)(αr) $\alpha^{\beta+\gamma}=(\alpha^{\beta})(\alpha^{\gamma});(\alpha\beta)^{\gamma}=(\alpha^{\gamma})(\beta^{\gamma});\alpha^{\beta\gamma}=(\alpha^{\beta})^{\gamma}$ (αβ)r = (αr)(βr) $(\alpha\beta)^{\gamma}=(\alpha^{\gamma})(\beta^{\gamma})$ $\alpha^{\beta\gamma}=(\alpha^{\beta})^{\gamma}$ α=(α) (c) If $\alpha\leq\beta$ , then $\alpha^{\gamma}\leq\beta^{\gamma}$ (d) If $\alpha,\beta$ are finite with $\alpha>1$ $\beta>1$ and $\gamma$ is infinite, then $\alpha^{\nu}=\beta^{\gamma}$ (e)For every finite cardinal $n$ $\alpha^{n}=\alpha\alpha\cdots\alpha$ $in$ factors). Hence $\alpha^n=\alpha$ if $\alpha$ is infinite. (f) If $P(A)$ is the power set of a set $A$ , then $|P(A)|=2^{|A|}$

11. If I is an infinite set, and for each i e I $A_i$ is a finite set, then IU Al ≤ [/|. $|\bigcup_{i\in I}A_i|\leq|I|$ -

12. Let $\alpha$ be a fixed cardinal number and suppose that for every i e $I,A_i$ is a set with $|A_{i}|=\alpha$ Then $|\bigcup_{i\in I}A_i|\leq|I|\alpha$

------------------------------------------------------------------

# GROUPS

The concept of a group is of fundamental importance in the study of algebra. Groups which are, from the point of view of algebraic structure, essentially the same are said to be isomorphic. Ideally the goal in studying groups is to classify all groups up to isomorphism, which in practice means finding necessary and sufficient conditions for two groups to be isomorphic. At present there is little hope of classifying arbitrary groups. But it is possible to obtain complete structure theorems for various restricted classes of groups, such as cyclic groups (Section 3), finitely generated abelian groups (Section I1.2), groups satisfying chain conditions (Section II.3) and finite groups of small order (Section I1.6). In order to prove even these limited structure theorems, it is necessary to develop a large amount of miscellaneous information about the structure of (more or less) arbitrary groups (Sections 1, 2, 4, 5, and 8 of Chapter I and Sections 4 and 5 of Chapter II). In addition we shall study some classes of groups whose structure is known in large part and which have useful applications in other areas of mathematics, such as symmetric groups (Section 6), free [abelian] groups (Sections 9 and 11.1), nilpotent and solvable groups (Sections I1.7 and I1.8). There is a basic truth that applies not only to groups but also to many other

algebraic objects (for example, rings, modules, vector spaces, felds): in order to study effectively an objectwith a given algebraicstructure, it is necessary to study as well the functions that preserve the given algebraic structure (such functions are called homomorphisms). Indeed a number of concepts that are common to the theory of groups, rings, modules, etc. may be described completely in terms of objects and homomorphisms. In order to provide a convenient language and a useful conceptual framework in which to view these common concepts, the notion of a category is introduced in Section 7 and used frequently thereafter. Of course it is quite possible to study groups, rings, etc. without ever mentioning categories. However, the small amount of effort needed to comprehend this notion now will pay large dividends later in terms of increased understanding of the fundamental relationships among the various algebraic structures to be encountered With occasional exceptions such as Section 7, each section in this chapter de-

pends on the sections preceding it.

------------------------------------------------------------------

## 1. SEMIGROUPS, MONOIDS AND GROUPS

If $G$ is a nonempty set, a binary operation on $G$ is a function $G\times G\to G$ .There are several commonly used notations for the image of $(a,b)$ under a binary operation: ab (multiplicative notation),. $a+b$ (additive notation), $a\cdot b$ ， $a*b$ ,etc. For convenience we shall generally use the multiplicative notation throughout this chapter and refer to ab as the product of $a$ and $b$ . A set may have several binary operations defned on it (for example, ordinary addition and multiplication on $\mathbf{Z}$ given by $(a,b)\vdash a+b$ and $(a,b)\vdash ab$ respectively).

1

1

Definition 1.1. A semigroup is a nonempty set G together with a binary operation on G whichis

(i) associative: $\mathbf{a}(\mathbf{bc})=(\mathbf{ab})\mathbf{c}$ for all a, b, c ε G; .

a monoid is a semigroup G which contains a

(ii) (two-sided) identity element e e G such that ae = = $\mathbf{e}=\mathbf{ea}=\mathbf{a}$ = = for all a eG.

$A$ group is a monoid G such that.

(ii) for every a eG there exists a (two-sided) inverse element $a^{-1}\varepsilon G$ such thal $\mathrm{a^{-1}a=aa^{-1}=e}$

A semigroup G is said to be abelian or commutative if its binary operation is

(iv) commutative: ab = ba for all a,b ε G

Our principal interest is in groups. However, semigroups and monoids are convenient for stating certain theorems in the greatest generality. Examples are given below. The order of a group $G$ is the cardinal number $|G|$ . $G$ is said to be finite [resp. infinite] if $|G|$ is fnite [resp. infnite]

1

1

Theorem 1.2. IfG is a monoid, then the identity element e is unique. If G is a group then

(i) cεG and $\mathsf{cc}=\mathsf{c}\Rightarrow\mathsf{c}=\mathsf{e}$ (i) for all a, b, cε G ab =ac$\Rightarrow\mathbf{b}=\mathbf{c}$ and $\mathbf{ba}=$ca$\Rightarrow\mathbf{b}=\mathbf{c}$ (left and right cancellation); (ii) for each a e G, the inverse element $a^{-1}$ is unique; (iv) for each a ε G, $(\mathrm{a}^{-1})^{-1}=$a (v) for a, bε G, $(\mathbf{ab})^{-1}=\mathbf{b}^{-1}\mathbf{a}^{-1}$ (vi)for a,b e G the equations $\mathbf{ax}=\mathbf{b}$ and ya $=\mathbf{b}$ have unique solutions in. $\mathbf{G}:\mathbf{x}=\mathbf{a}^{-1}\mathbf{b}$ and $\mathbf{y}=\mathbf{ba}^{-1}$

SKETCH OF PROOF. If $e^{\prime}$ is also a two-sided identity,then $e=ee^{\prime}=e^{\prime}$ (i) $cc=c\Rightarrow c^{-1}(cc)=c^{-1}c\Rightarrow(c^{-1}c)c=c^{-1}c\Rightarrow ec=e\Rightarrow c=e$ (ii),(ii) and (vi are proved similarly. (v) $(ab)(b^{-1}a^{-1})=a(bb^{-1})a^{-1}=(ae)a^{-1}=aa^{-1}=e\Rightarrow(ab)^{-1}$ $=b^{-1}a^{-1}$ by (ii); (iv) is proved similarly.

------------------------------------------------------------------

If $G$ is a monoid and the binary operation is written multiplicatively, then the identity elenient of $G$ will always be denoted $e$ . If the binary operation is written additively, then $a+b(a,b\in G)$ is called the sum of $u$ and $b$ , and the idcntity elcment is denoted O; if $G$ is a group the inverse of $u\equiv G$ is denoted by $-a$ . We write $u-b$ for $(u+(-h))$ . Abelian groups are frequently written additively.

The axionis used in Definition 1.1 to define a group can actually be weakened considerably.

Proposition 1.3.Let G be a sentigroup. Then G is a group ifand only ifthe following conditions hold:

(i)there exists an element eeG such that ea = a for all a eG(left identity element); (ii) for each a s G, there exists an element. a-1 $a^{-1}$ $\mathbf{a}^{-1}\varepsilon\mathbf{G}$ such that $\mathbf{a}^{-\mathbf{l}}\mathbf{a}=\mathbf{e}$ (left inrerse)

REMARK. An analogous result holds for "right inverses'" and a "right identity.'

SKETCH OF PROOF OF1.3. $(\Rightarrow)$ Trivial. $(\Leftarrow)$ Note that Theorem 1.2(i) is true under these hypotheses. $G\neq\varnothing$ since $e\varepsilon G$ .Ifae $G$ ,then by (i) $(aa^{-1})(aa^{-1})$ $=a(a^{-1}a)a^{-1}=a(ea^{-1})=au^{-1}$ and hence $uu^{-1}=e$ by Theorem 1.2(i). Thus $a^{-1}$ is a two-sided inverse of $u$ . Since $ae=a(u^{-1}u)=(aa^{-1})a=ea=a$ for every a e $G$ $e$ is a two-sided identity. Therefore $G$ is a group by Definition 1.1.

Proposition 1.4. Lei G be a semigroup. Then G is a group if and only if for all. a, b e G the equations ax $=\mathbf{b}$ andya $=\mathbf{b}$ have solutions in G.

PROOF. Exercise; use Proposition 1.3.

EXAMIPLES. The integers $\mathbf{Z}$ ,the rational numbers Q,and thereal numbers R are each infinite abelian groups under ordinary addition. Each is a monoid under ordinary multiplication. but not a group (O has no inverse). However, the nonzero elements of Q and R respectively form infinite abelian groups under multiplication The even integers under multiplication form a semigroup that is not a monoid.

EXAMPLE. Consider the square with vertices consecutively numbered 1,2,3,4.. center at the origin of the $x-y$ plane, and sides parallel to the axes.

![](https://storage.simpletex.cn/view/fNVnLKgVgaIyDquuK4tfrBMMeHapeOlPw)

Let $D_4*$ be the following set of “transformations" of the square. $D_{4}^{*}=$ $\{\:R,R^{2},R^{3},I,T_{x},T_{y},T_{1.3},T_{2.4}\}$ , where $R$ is a counterclock wise rotation about the center of $90^\circ$ ， $R^2$ a counterclockwise rotation of. $180^{\circ}$ ， $R^3$ a counterclockwise rotation of. $270^{\circ}$

------------------------------------------------------------------

and $I$ a rotation of $360^{\circ}\left(=0^{\circ}\right)$ ; $T_{x}$ is a refection about the $x$ axis, $T_{1,3}$ a reflection about the diagonal through vertices 1 and 3; similarly for $T_{v}$ and' $T_{2,4}$ . Note that each $U$ E $D_4^*$ is a bijection of the square onto itself.Define the binary operation in $D_4^*$ to be composition of functions: for $U,V$ E $D_4^*$ $U\circ V$ is the transformation Vfol lowed by the transformation $U$ $D_4^*$ is a nonabelian group of order 8 called the group of symmetries of the square. Notice that each symmetry (element of $D_4^*$ ) is completely determined by its action on the vertices.

EXAMPLE. Let $S$ be a nonempty set and $A(S)$ the set of all bijections $S\to S$ Under the operation of composition of functions, $f\circ g,A(S)$ is a group, since composition is associative, composition of bijections is a bijection, $1s$ is a bijection, and every bijection has an inverse (see (13) of Introduction, Section 3). The elements of $A(S)$ are called permutations and $A(S)$ is called the group of permutations on the set $S$ . If $S=\{1,2,3,\ldots,n\}$ ,then $A(S)$ is called the symmetric group on n letters and denoted $S_{n.}$ Verify that $|S_n|=n!$ (Exercise 5). The groups $S_n$ play an important role in the theory of finite groups.

Since an element $\sigma$ of $S_n$ is a function on the finite set $S=\{1,2,\ldots,n\}$ ,it canbe described by listing the elements of. $S$ on a line and the image of each element under $\sigma$ directly blow it: $\begin{pmatrix}1&2&3&\cdots&n\\i_1&i_2&i_3&&i_n\end{pmatrix}$ The produt $\sigma\tau$ of two lements of $S_n$ is the composition function $\tau$ followed by $\sigma$ ; that is, the function on $S$ given by $k\vdash\sigma(\tau(k)).$ For instane, et $\sigma=\begin{pmatrix}1&2&3&4\\3&1&2&4\end{pmatrix}$ and $\tau=\begin{pmatrix}1&2&3&4\\4&1&2&3\end{pmatrix}$ be lements of $S_{4}$ Then undr o7, $1\models\sigma(\tau(1))=\sigma(4)=4$ etc; hus $\sigma\tau=\begin{pmatrix}1&2&3&4\\3&1&2&4\end{pmatrix}\begin{pmatrix}1&2&3&4\\4&1&2&3\end{pmatrix}$ $=\begin{pmatrix}1&2&3&4\\4&3&1&2\end{pmatrix}$ imiariy, $\tau\sigma=\begin{pmatrix}1&2&3&4\\4&1&2&3\end{pmatrix}\begin{pmatrix}1&2&3&4\\3&1&2&4\end{pmatrix}=\begin{pmatrix}1&2&3&4\\2&4&1&3\end{pmatrix}$ This example also shows that $S_n$ need not be abelian Another source of examples is the following method of constructing new groups

from old. Let $G$ and $H$ be groups with identities $e_G$ eG $e_G,e_{II}$ enl $e_{ll}$ respectively, and define the direct product of $G$ and $H$ to be the group whose underlying set is $G\times H$ and whose binary operation is given by:

$$(a,b)(a^{\prime},b^{\prime})=(aa^{\prime},bb^{\prime}),\quad\mathrm{where}\quad a,a^{\prime}\varepsilon G;b,b^{\prime}\varepsilon H.$$

Observe that there are three different operations in $G$ $H$ and $G\times H$ involved in this statement. It is easy to verify that $G\times H$ is, in fact, a group that is abelian if both $G$ and $H$ are; $(e_G,e_H)$ is the identity and $(a^{-1},b^{-1})$ the inverse of $(a,b)$ . Clearly $|G\times H|$ $=|G||H|$ (Introduction, Definition 8.3). If $G$ and $H$ are written additively, then we write $G\oplus H$ in place of $G\times H$

Theorem 1.5. Let R $(\sim)$ be an equitcalencerelation ona monoid G such that $\mathbf{a}_1\sim\mathbf{a}_2$ and $\mathbf{b}_1\sim\mathbf{b}_2$ imply $a_1b_1\sim a_2b_2$ for all $\mathbf{a_i,b_i\in G}$ . Then the set $G/R$ of all eyuivalence classes of G under R is a monoid under the binary operation defined by $(\bar{\mathrm{a}})(\bar{\mathrm{b}})=\overline{\mathrm{ab}}$ where×denotes the equivalence class of xe G.If G is an[abelian] group,then so is $G/R$

------------------------------------------------------------------

An equivalence relation on a monoid $G$ that satisfies the hypothesis of the theorem is called a congruence relation on $G$

PROOF OF 1.5. If $\bar{a}_{1}=\bar{a}_{2}$ and $\bar{b}_{1}=\bar{b}_{2}(a_{i},b_{i}\in G)$ ,then $a_1\sim a_2$ and $b_1\thicksim b_2$ by (20) of Introduction, Section 4. Then by hypothesis $a_1b_1\sim a_2b_2$ so that $\overline{a_{1}b_{1}}=\overline{a_{2}b_{2}}$ by (20) again. Therefore the binary operation in $G/R$ is well defined (that is, independent of the choice of equivalence class representatives). It is associative since $\bar{a}(\bar{b}\:\bar{c})=\bar{a}(\overline{bc})=\overline{a(bc)}=\overline{(ab)c}=(\overline{ab})\bar{c}=(\bar{a}\:\bar{b})\bar{c}$ .é is the identity element since $(\bar{a})(\bar{e})=\overline{ae}=\bar{a}=\overline{ea}=(\bar{e})(\underline{a})$ . Therefore $G/R$ is a monoid. If $G$ is a group, then $\bar{a}\in G/R$ clearly has inverse $\overline{a^{-1}}$ so that $G/R$ is also a group. Similarly, $G$ abelian implies $G/R$ abelian. 

EXAMPLE. Let $m$ be a fixed integer. Congruence modulo $m$ is a congruence relation on the additive group $\mathbf{Z}$ by Introduction, Theorem 6.8. Let $Z_m$ denote the set of equivalence classes of $\mathbf{Z}$ under congruence modulo $m$ .By Theorem 1.5 (with additive notation) $Z_m$ is an abelian group, with addition given by $\bar{a}+b=\overline{a+b}\left(a,b\in\mathbf{Z}\right)$ The proof of Introduction, Theorem 6.8 shows that $Z_{m}=\{\bar{0},\bar{1},\ldots,\overline{m-1}\}$ so that $Z_m$ is a finite group of order $m$ under addition. $Z_m$ is called the (additive) group of integers modulo m. Similarly since $\mathbf{Z}$ is a commutative monoid under multiplication and congruence modulo $m$ is also a congruence relation with respect to multiplication (Introduction, Theorem 6.8), $Z_{m}$ is a commutative monoid, with multiplicatior given by $(\bar{a})(b)=\overline{a}\overline{b}\left(a,b\in\mathbf{Z}\right)$ . Verify that for all $\bar{a},b,\bar{c}\varepsilon Z_m$
$$\bar{a}(\bar{b}+\bar{c})=\bar{a}\bar{b}+\bar{a}\bar{c}\quad\mathrm{and}\quad(\bar{a}+b)\bar{c}=\bar{a}\bar{c}+b\bar{c}$$

(distributivity)

Furthermore if $p$ is prime, then the nonzero elements of $Z_p$ form a multiplicative group of order $p-1$ (Exercise 7). It is customary to denote the elements of $Z_m$ as $0,1,\ldots,m-1$ rather than $\bar{0},\bar{1},\ldots,\overline{m-1}$ . In context this ambiguous notation will cause no difficulty and will be used whenever convenient.

EXAMPLE. The following relation on the additive group Q of rational numbers is a congruence relation (Exercise 8):

$$a\sim b\Leftrightarrow a-b\varepsilon\mathbf{Z}.$$

By Theorem 1.5 the set of equivalence classes (denoted $\mathbf{Q}/\mathbf{Z})$ is an (infinite) abelian group, with addition given by $\bar{a}+b=\overline{a+b}.\mathbf{Q}/\mathbf{Z}$ is called the group of rationals modulo one.

Given $a_{1},\ldots,a_{n}\in G\left(n\geq3\right)$ $(n\geq3)$ (n ≥ 3) it is intuitively plausible that there are manyways of inserting parentheses in the expression $a_1a_2\cdots a_n$ so as to yield a “meaningful product in $G$ ofthese $n$ elements in this order. Furthermore it is plausible that any two such products can be proved equal by repeated use of the associative law. A necessary prerequisite for further study of groups and rings is a precise statement and proof of these conjectures and related ones. Given any sequence of elements of a semigroup $G$ ， $\{a_{1},a_{2}\ldots\}$ define inductively a

meaningful product of $a_1,\ldots,a_n$ an $a_n$ (in this order) as follows. If $n=1$ ,the only meaningfui product is $a_1$ . If $n>1$ , then a meaningful product is defined to be any product of the form $(a_1\cdots a_m)(a_{m+1}\cdots a_n)$ where $m<n$ and $(a_1\cdots a_m)$ and $(a_{m+1}\cdots a_n)$ are meaningful products of $m$ and $n-m$ elements respectively.2 Note that for each

------------------------------------------------------------------

[

1

1

$n\geq3$ there may be many meaningful products of $a_1,\ldots,a_n$ . For each $n\varepsilon N^*$ we single out a particular meaningful product by defining inductively the standard n product $\prod_{i=1}^na_i$ Ⅱa $\prod_{i=1}^na_i$ of $a_1,\ldots,a_n$ a,, . $a_1,\ldots,a_n$ as followus

$$\prod_{i=1}^{1}a_{i}=a_{1};\quad\text{and for}n>1,\prod_{i=1}^{n}a_{i}=\biggl(\prod_{i=1}^{n-1}a_{i}\biggr)a_{n}.$$

The fact that this definition defines for each $n\varepsilon N^*$ a unique element of $G$ (which is clearly a meaningful product) is a consequence of the Recursion Theorem 6.2 of the Introduction (Exercise 16).

Theorem 1.6. (Generalized Associative Law) IfG is a semigroup and $\mathbf{a}_{1},\ldots,\mathbf{a}_{\mathrm{n}}\varepsilon\mathbf{G}$ aneG $a_n\varepsilon G$ then any two meaningful products of aj, ...,. $a_n$ in this order are equal

PROOF.Weuse induction toshow that for every $n$ any meaningful produc $u_1\cdots a_n$ isequl to the standard $n$ product $\prod_{i=1}^na_i.$ This ertainly rue or $n=1,2$ If $n>2$ . then by definition. $(a_1\cdots a_n)=(a_1\cdots a_m)(a_{m+1}\cdots a_n)$ forsome $m<n$ Therefore, by induction and associativity

$$\begin{aligned}
(a_{1}\cdot\cdot\cdot a_{n})\:=\:(a_{1}\cdot\cdot\cdot a_{m})(a_{m+1}\cdot\cdot a_{n})& =\left(\prod_{i=1}^{m}a_{i}\right)\left(\prod_{i=1}^{n-m}a_{m+i}\right) \\
=\left(\prod_{i=1}^{m}a_{i}\right)\biggl(\biggl(\prod_{i=1}^{n-m-1}a_{m+i}\biggr)a_{n}\biggr)& =\left(\left(\prod_{i=1}^{m}a_{i}\right)\:\left(\prod_{i=1}^{n-m-1}a_{m+i}\right)\right)a_{n} \\
=\left(\prod_{i=1}^{n-1}a_{i}\right)a_{n}& =\prod_{i=1}^{n}a_{i}.\quad\blacksquare 
\end{aligned}$$

In view of Theorem 1.6 we can and do write any meaningful product of $a_{1},\ldots,a_{n}\in G$ G $G$ $G$ a semigroup) as $a_1a_2\cdots a_n$ without parentheses or ambiguity

Corollary 1.7. (Generalized Commutative Law) 1fG is a commutative semigroup anc $\mathbf{a}_1,\ldots,\mathbf{a}_n\in\mathbf{G}$ ,then for any permutation. $\mathrm{i_1,\ldots,i_n}$ of 1, 2,...n, $\mathrm{a_1a_2\cdots a_n}=$ $a_{i_1}a_{i_2}\cdots a_{i_n}$

PROOF. Exercise.

Definition 1.8. Ler G be a semigroup, a e G and n ε $N^*$ . The element a" e G is defined to be the sandardh rouct $\prod_{i=1}^na_i$ $\prod_{i=1}^na_i$ $\prod_{i=1}^n$a$_\mathrm{i}$with$\mathrm{a_i}=$a ai=a $a_i=a$ for $1\leq$i$\leq$n IfG is monoid, $a^0$ 设defined to be the identity element e. If G is a group, then for each n e. $N^*$ $a^{-n}$ is defined tobe $(\mathbf{a}^{-1})^{n}\varepsilon\mathbf{G}$

The remarks preceding Theorem 1.6 and Exercise 16 show that exponentiation is well defined. By definition, then,. $a^{\mathbf{l}}=a,a^{2}=aa$ l =a,a²=aa $v^{1}=a,a^{2}=aa,a^{3}=(aa)a=aaa,\ldots,a^{n}=a^{n-1}a$ an = an-1a $a^{n}=a^{n-1}a$

1

1

------------------------------------------------------------------

$=aa\cdots a$ (n factors). Note that we may have $a^{m}=a^{n}$ with $m\neq n$ (for example, in $\mathbf{C},-1=i^{2}=i^{6})$

ADDITIVE NOTATION. If the binary operation in $G$ is written additively then we write na in place of $a^n$ . Thus $0a=0$ ， $1a=a$ $na=(n-1)a+a$ ,etc.

Theorem 1.9. If G is a group [resp. semigroup, monoid] and a eG, then for all m, n e $\mathbf{Z}$ [resp. $N^{*}$ ,Nl:

(i) $a^{m}a^{n}=a^{m+n}$ (additive notation: $\mathrm{ma+na=(m+n)a)}$ (i) $(\mathbf{a}^{\mathrm{m}})^{\mathrm{n}}=\mathbf{a}^{\mathrm{mn}}$ (additive notation: $\mathbf{n}(\mathbf{ma})=\mathbf{mna}$

SKETCH OF PROOF. Verify that $(a^{n})^{-1}=(a^{-1})^{n}$ for all $n\varepsilon N$ and that $a^{-n}=(a^{-1})^n$ for all $n\varepsilon Z$ . (i) is true for $m>0$ and $n>0$ since the product of a standard $n$ product and a standard $m$ product is a meaningful product equal to the standard $(m+n)$ product by Theorem 1.6. For $m<0$ , and $n<0$ replace a, m, n by $a^{-1}$ a-1 $a^{-1},-m$, $-n$ and use the preceding argument. The case. $m=0$ or $n=0$ is trivial and the cases $m\geq0$ $n<0$ and $m<0$ $n\geq0$ are handled by induction on $m$ and $n$ respectively. (ii) is trivial if $m=0$ .The case when $m>0$ and n e $\mathbf{Z}$ is proved by induction on $m$ . Use this result to prove the case $m<0$ and $n\varepsilon Z$ .

## EXERCISES

1. Give examples other than those in the text of semigroups and monoids that are not groups.

2. Let $G$ be a group (written additively), $S$ a nonempty set, and $M(S,G)$ the set of all functions $f{:}S\to G$ .Define addition in $M(S,G)$ as follows: $(f+g):S\to G$ is given by $s|\mapsto f(s)+g(s)\varepsilon G$ Prove that $M(S,G)$ is a group, which is abelian if $G$ is.

3. Is it true that a semigroup which has a left identity element and in which every element has a right inverse (see Proposition 1.3) is a group?

4. Write out a multiplication table for the group $D_4^*$

 5. Prove that the symmetric group on $n$ letters, $S_n$ , has order $n!$

6. Write out an addition table for $Z_2\oplus Z_2.Z_2\oplus Z_2$ is called the Klein four group. 7. If $p$ is prime, then the nonzero elements of $Z_p$ form a group of order $p-1$ under multiplication. [Hint: $\bar{a}\neq\bar{0}\Rightarrow(a,p)=1$ ; use Introduction, Theorem 6.5.] Show that this statement is false if $p$ is not prime. 8. (a) The relation given by $a\sim b\Leftrightarrow a-b\varepsilon\mathbf{Z}$ is a congruence relation on the additive group $Q$ [see Theorem 1.5]. (b) The set $\mathbf{Q}/\mathbf{Z}$ of equivalence classes is an infinite abelian group. 9. Let $p$ be a fixed prime. Let $R_{p}$ be the set of all those rational numbers whose denominator is relatively prime to $P$ Let $R^p$ be the set of rationals whose denominator is a power of $p$ $,(p^{i},i\geq0)$ .Prove that both $R_{p}$ and $R^p$ are abelian groups under ordinary addition of rationals.

------------------------------------------------------------------

1

1

10. Let $p$ be a prime and let $Z(p^{\infty})$ be the following subset of the group $\mathbf{Q}/\mathbf{Z}$ (see pg.27):

$$Z(p^{\infty})=\left\{\overline{a/b}\:\varepsilon\:\mathbf{Q}/\mathbf{Z}\mid a,b\:\varepsilon\:\mathbf{Z}\quad\mathrm{and}\quad b=p^{i}\:\mathrm{for~some}\:i\geq0\right\}.$$

Show that $Z(p^{\infty})$ is an infinite group under the addition operation of $\mathbf{Q}/\mathbf{Z}$

11. The following conditions on a group $G$ are equivalent: (i) $G$ is abelian; (ii) $(ab)^2$ $=a^2b^2$ for all $a,b\varepsilon G$ ; (ii) $(ab)^{-1}=a^{-1}b^{-1}$ for all $a,b\varepsilon G$ ; (iv) $(ab)^n=a^nb^n$ for all $n\varepsilon Z$ Z $\mathbf{Z}$ and all $a,b\varepsilon G$ ; (v) $(ab)^n=a^nb^n$ for three consecutive integers $n$ and all $a,b\varepsilon G$ .Show that $(\mathbf{v})\Longrightarrow(\mathbf{i})$ is false if "three” is replaced by “two."

12. If $G$ is a group, $a,b$ E $G$ and $bab^{-1}=a^r$ for some r e N, then $b^{i}ab^{-i}=a^{r^j}$ for all $j\varepsilon N$

13. If $a^2=e$ for all elements $a$ of a group $G$ , then $G$ is abelian.

14. If $G$ is a finite group of even order, then $G$ contains an element $a\neq e$ such that $a^{2}=e$

15.Let $G$ be a nonempty finite set with an associative binary operation such that for all $a,b,c\in G$ $ab=ac\Rightarrow b=c$ and $ba=ca\Rightarrow b=c$ . Then $G$ is a group. Show that this conclusion may be false if $G$ is infinite.

16.Let $a_1,a_2,\ldots$ be a sequence of elements in a semigroup $G$ . Then there exists a unique function $\psi:\mathbf{N}^*\to G$ such that (1) = a $\psi(1)=a_{1}$ y(2) = aa2 $\psi(2)=a_1a_2$ $\psi(1)=a_{1},\psi(2)=a_{1}a_{2},\psi(3)=(a_{1}a_{2})a_{3}$ (3) =(aa2)aa $\psi(3)=(a_1a_2)a_3$ and for $n\geq1$ $\psi(n+1)=(\psi(n))a_{n+1}$ . Note that $\psi(n)$ is precisely the standard $n$ product $\prod_{i=1}^na_i.$ [Hit Apling he Recurson Theorem . o he Irtodue tion with $a=a_{1}$ $S=G$ and $f_n:G\to G$ given by $x|\mapsto xa_{n+2}$ yields a function $\varphi:\mathbb{N}\to G$ .Let $\psi=\varphi\theta$ ,where $\theta:\mathbf{N}^*\to\mathbf{N}$ is given by $k\vdash k-1.]$

[

## 2. HOMOMORPHISMS AND SUBGROUPS

Essential to the study of any class of algebraic objects are the functions that pre. serve the given algebraic structure in the following sense.

Definition 2.1.Ler Gand H besermigroups.A functionf : $G\to\mathcal{H}$ is a homomorphism provided

$$\mathrm{f(ab)=f(a)f(b)\quad for~all\quad a,b~\varepsilon G.}$$

Iff is injective as a map of sets, f is said to be a monomorphism. If f is surjectite, f is called an epimorphism. Iff is bijective, f is called an isomorphism. In this case G and H are said to be isomorphic (written $\mathbf{G}\cong\mathbf{H}$ ）. $A$ homomorphism $\mathbf{f}:\mathbf{G}\to\mathbf{G}$ is called an endomorphism of G and an isomorphism $\mathbf{f}:\mathbf{G}\to\mathbf{G}$ is calledan automorphism ofG.

If $f{:}G\to H$ and $g:H\to K$ are homomorphisms of semigroups, it is easy to see that $gf{:}G\to K$ is also a homomorphism. Likewise the composition of monomorphisms is a monomorphism; similarly for epimorphisms, isomorphisms and automorphisms. If $G$ and $H$ are groups with identities $e_G$ and $e_{H}$ respectively and

------------------------------------------------------------------

$f{:}G\to H$ is a homomorphism, then $f(e_G)=e_H$ ; however, this is not true for monoids (Exercise 1). Furthermore $f(a^{-1})=f(a)^{-1}$ for all ae $G$ (Exercise 1).

EXAMPLE. The map $f{:}\mathbf{Z}\to\mathbf{Z}_m$ given by $x|\mapsto x$ (that is, each integer is mapped onto its equivalence class in $Z_{m}$ )is an epimorphism of additive groups. fis called the canonical epimorphism of $\mathbf{Z}$ onto $Z_m$ .Similarly, the map $g:\mathbf{Q}\to\mathbf{Q}/\mathbf{Z}$ givenby $r|\mapsto\bar{r}$ is also an epimorphism of additive groups.

EXAMPLE. If $A$ is an abelian group, then the map given by $a\vdash a^{-1}$ is an automorphism of $A$ . The map given by $a\vdash a^2$ is an endomorphism of $A$

EXAMPLE. Let $1<m$ 1<m $1<m,k\in\mathbb{N}^*$ keN* $k\varepsilon N^*$ . The map $g:Z_m\to Z_{mk}$ given by $x|\mapsto\overline{kx}$ is a monomorphism.

EXAMPLE. Given groups $G$ and $H$ there are four homomorphismsi GG × HH, given by $\iota_{1}(g)=(g,e)$ (g,e) t2(h) = (e,h) $\iota_{2}(h)=(e,h)$ $= ( g, e) ;$ $\iota _{2}( h) = ( e, h) ;$ $\pi _{1}( g, h) = g;$ $\pi _{2}( g, h) = h$ $\pi_{1}(g,h)=g$ π1(g,h) = g π2(g,h) = h $\pi_2(g,h)=h$ T2 $\iota_i$ is a monomorphism and $\pi_{j}$ is an epimorphism $(i,j=1,2)$

Definition 2.2. Let $\mathbf{f}:\mathbf{G}\to\mathbf{H}$ be a homomorphism of groups. The kernel off (denoted Ker f)is $\{a\varepsilon G|f(a)=e\varepsilon H\}$ .IfA is a subset of G, then $\mathbf{f}(\mathbf{A})=\{\mathbf{b}\varepsilon\mathbf{H}|\mathbf{b}=\mathbf{f}(\mathbf{a})$ for some a e A} is the image of A. f(G) is called the image of f and denoted Im f. If B is. a subset of H, $f^{-1}(B)=\{a\varepsilon G|f(a)\varepsilon B\}$ is the inverse image of B.

Theorem 2.3. Ler f : $\mathbf{G}\to\mathbf{H}$ be a homomorphism of groups. Then

(i) f is a monomorphism if and only if Ker $\mathbf{f}=\{\mathbf{e}\}$ (i)f is an isomorphism ifand only if there is a homomorphism $\mathbf{f}^{-1}:\mathbf{H}\to\mathbf{G}$ such that $\mathbf{ff}^{-1}=\mathbf{1}_{\mathbf{H}}$ and $\mathbf{f}^{-1}\mathbf{f}=\mathbf{l}_{\mathbf{G}}$

PROOF. (i) If $f$ is a monomorphism and ae Ker $f$, then $f(a)=e_{H}=f(e)$, whence $a=e$ and Ker $f=\{e\}$ . If Ker $f=\{e\}$ and $f(a)=f(b)$ ,then $e_{H}=f(a)f(b)^{-1}$ $=f(a)f(b^{-1})=f(ab^{-1})$ so that $ab^{-1}$ εKer $f.$ Therefore, $ab^{-1}=e$ (that is, $a=b$ )and $f$ is a monomorphism (i) If $f$ is an isomorphism, then by (13) of Introduction, Section 3 there is a map

ofsets $f^{-1}:H\to G$ such that $f^{-1}f=\mathbf{l}_G$ and $ff^{-1}=\mathbf{1}_{H}.f^{-1}$ is easily seen to be a homomorphism. The converse is an immediate consequence of (13) of Introduction Section 3 and Definition 2.1.

Let $G$ be a semigroup and $H$ a nonempty subset of $G.$ .If for every a,b e H we have $ab\varepsilon H.$ we say that $IH$ is closed under the product in $G$ . This amounts to saying that the binary operation on $G$ ,when restricted to $H.$ is infact abinary operation on $H.$

Definition 2.4. Ler G be a group and H a nonempty subset that is closed under the product in G.If H is itselfa group under the product in G,then H is said tobe a sub group ofG.This is denoted by $H<G$

------------------------------------------------------------------

1

1

Two examples of subgroups of a group $G$ are $G$ itself and the trivial subgroup $\langle e\rangle$ consisting only of the identity element.A subgroup $H$ such that $H\neq G$ $H\neq\langle e\rangle$ is called a proper subgroup.

EXAMPLE. The set of all multiples of some fixed integer $n$ is a subgroup of $\mathbf{Z}$ which is isomorphic to $\mathbf{Z}$ (Exercise 7).

EXAMPLE. In $S_n$ , the group of all permutations of $\{1,2,\ldots,n\}$ ,the set of all permutations that leave $n$ fixed forms a subgroup isomorphic to $S_{n-1}$ (Exercise 8).

EXAMPLE. In $\imath Z_{6}=\{0,1,2,3,4,5\}$ , both ↓0,3} and ↓0,2,4} are subgroups under addition. If $p$ is prime, $(Z_p,+)$ has no proper subgroups.

EXAMPLE. If $f{:}G\to H$ is a homomorphism of groups, then Ker $f$ is a subgroup of $G$ . If $A$ is a subgroup of $G,f(A)$ is a subgroup of $H$ ; in particular Im fis a subgroup of $H$ .If $B$ is a subgroup of $H$ $f^{-1}(B)$ is a subgroup of $G$ (Exercise 9).

EXAMPLE. If $G$ is a group, then the set Aut $G$ of all automorphisms of $G$ is a group, with composition of functions as binary operation (Exercise 15).

By Theorem 1.2 the identity element of any subgroup $H$ is the identity element of $G$ and the inverse of $a\varepsilon H$ H $H$ is the inverse $a^{-1}$ of $a$ in $G$

1

1

Theorem 2.5.Ler H be a nonempty subset ofa group G.Then H is a subgroup of G if and only $ifab^{-1}\varepsilon H$ for all a,b e H.

PROOF. $(\Leftarrow)$ There exists a e $H$ and hence $e=aa^{-1}\varepsilon H$ .Thus for any $b\in H,b^{-1}$ $=eb^{-1}\varepsilon H.$ If $a,b\in H$ H $H$ ,then $b^{-1}\varepsilon H$ and hence $ab=a(b^{-1})^{-1}\varepsilon H$ . The product in $H$ is associative since $G$ is a group. Therefore $H$ is a (sub)group. The converse is. trivial.

Corollary 2.6. IfG is a group and $\{H_{i}\mid i\varepsilon I\}$ is u nonempty family of subgroups, ther $\bigcap_{i\in I}H_{i}$ is a subgroup of $G$

PROOF. Exercise.

Definition 2.7. Let G be a group and X a subset of G. Let $\{\mathbf{H_{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\}$ be the family of allsubgroups of G which contain X. Then $\bigcap H_i$ is called thesubgroup of G generated

by the set $X$ and denoted $\langle\mathbf{X}\rangle$

The elements of $X$ are the generators of the subgroup $\langle X\rangle$ ，which may also be generated by other subsets (that is, we may have $\langle X\rangle=\langle Y\rangle$ with $X\neq Y$ .If $X=\{a_{1},\ldots,a_{n}\}$ , we write $\langle a_{1},\ldots,a_{n}\rangle$ in place of $\langle X\rangle$ .If $G=\langle a_{1},\ldots,a_{n}\rangle$ $(a_i\varepsilon G)$ $G$ is said to be finitely generated. If a e $G$ , the subgroup $\langle a\rangle$ is called the cyclic (sub)- group generated by $a$

1

------------------------------------------------------------------

Theorem 2.8. IfG is agroupand $X$ isa nonempty subset of G, then the subgroup $\langle\mathbf{X}\rangle$ generated by X consists of all finite products $\mathrm{a_{1}^{n_{1}}a_{2}^{n_{2}}\cdots a_{t}^{n_{t}}(a_{i}\varepsilon X;n_{i}\varepsilon Z)}$ aieX $\mathrm{\'{a}_i\varepsilon X}$ $n_i\varepsilon Z.$ nieZ In particular for every ae $G$ $\langle$a$\rangle=\{$a$^\mathrm{n}|$n$\varepsilon\mathbf{Z}\}$

SKETCH OF PROOF. Show that the set $H$ of all such products is a subgroup of $G$ that contains $X$ and is contained in every subgroup containing $X$ . Therefore $H<\langle X\rangle<H$

EXAMPLES. The additive group $\mathbf{Z}$ is an infnite cyclic group with generator 1, since by Definition 1.8 (additive notation), $m1=m$ for all $m\varepsilon Z$ . Of course the "powers" of the generating element need not all be distinct as they are in $\mathbf{Z}.$ The trivial subgroupe $\langle e\rangle$ of any group is cyclic; the multiplicative subgroup $\langle i\rangle$ in C is cyclic of order 4 and for each $m$ the additive group $Z_m$ is cyclic of order $m$ with generator $1\varepsilon Z_m$ . In Section 3 we shall prove that every cyclic subgroup is isomorphic either to $\mathbf{Z}$ or $Z_m$ forsome $m$ .Also, see Exercise 12.

If $\{H_{i}\mid i\in I\}$ is a family of subgroups of a group $G$ , then $\bigcup H_i$ $H_{i}$ H is not a subgroup iel of $G$ in general. The subgroup $\langle\bigcup_{i\in I}H_i\rangle$ generated by the set $\bigcup_{i\in I}^{ieI}H_i$ is called the sub group generated by the groups $\{\mathbf{H}_{\mathrm{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\}$ . If $H$ and $K$ are subgroups, the subgroup $\langle H\cup K\rangle$ generated by $H$ and $K$ is called the join of $H$ and $K$ and is denoted $H\vee K$ (additive notation:) $H+K$

### EXERCISES

1. If $f$ $G\to H$ is a homomorphism of groups, then $f(e_G)=e_H$ and $f(a^{-1})=f(a)^{-1}$ for all a e $G$ .Show by example that the frst conclusion may be false if G $G$ $G,H$ H $H$ are monoids that are not groups.

2. A group $G$ is abelian if and only if the map $G\to G$ given by $x|\mapsto x^{-1}$ is an automorphism.

3. Let $Q_{8}$ be the group (under ordinary matrix multiplication) generated by the complex matrices $A=\begin{pmatrix}0&1\\-1&0\end{pmatrix}$ and $B=\begin{pmatrix}0&i\\i&0\end{pmatrix}$ where $i^{2}=-1$ Show tht $Q_{8}$ is a nonabelian group of order 8. $Q_{8}$ is called the quaternion group. $[Hint$ Observe that $BA=A^3B$ ,whence everyelement of $Q_{8}$ is of the form $A^{\prime}B^{i}$ .Note also that $A^{4}\:=\:B^{4}\:=\:I$ where $I=\begin{pmatrix}1&0\\0&1\end{pmatrix}$ isthe identy lement of $Q_{8}$

4. Let $H$ be the group (under matrix multiplication) of real matrices generated by $C=\begin{pmatrix}0&1\\-1&0\end{pmatrix}$ and $D=\begin{pmatrix}0&1\\1&0\end{pmatrix}.$ Show hat! $H$ I nomabeian a o odee which is nor isomorphic to the quaternion group of Exercise 3, but is isomorphic to the group $D_4^*$

5. Let $S$ be a nonempty subset of a group $G$ anddefine arelation on $G$ by $a\thicksim b$ if and only if $ab^{-\mathbf{r}}\varepsilon S$ . Show that $\sim$ is an equivalence relation if and only if $S$ isa subgroup of $G$

------------------------------------------------------------------

厂

1

1

1

6. A nonempty finite subset of a group is a subgroup if and only if it is closed under the product in $G$

7. If $n$ is a fixed integer, then $\{kn\mid k\in\mathbf{Z}\}\subset\mathbf{Z}$ is an additivesubgroup of $\mathbf{Z}$, which is isomorphic to Z.

8. The set $\{\sigma\varepsilon S_{n}\mid\sigma(n)=n\}$ is a subgroup of $S_n$ which is isomorphic to $S_{n-1}$

9. Let $f{:}G\to H$ be a homomorphism of groups, $A$ a subgroup of $G$ , and $B$ a sub group of $H.$ (a) Ker $f$ and $f^{-1}(B)$ are subgroups of $G$ (b) $f(A)$ is a subgroup of $H$

10. List all subgroups of $Z_2\oplus Z_2$ . Is $Z_2\oplus Z_2$ isomorphic to $Z_4$

11.If $G$ is a group, then $C=\{a\in G\mid ax=xa$ for all $x\varepsilon G$ is an abelian subgroup of $G$ . $C$ is called the center of $G$

12. The group $D_4^*$ is not cyclic, but can be generated by two elements. The same is true of $S_n$ (nontrivial). What is the minimal number of generators of the additive group $\mathbf{Z}\oplus\mathbf{Z}?$

13. If $G=\langle a\rangle$ is a cyclic group and $H$ is any group, then every homomorphism $f{:}G\to H$ is completely determined by the element $f(a)_{\in}H$

 14. The following cyclic subgroups are all isomorphic: the multiplicative group $\langle i\rangle$ in C, the aditive group $Z_4$ and the subgroup $\left\langle\begin{pmatrix}1&2&3&4\\2&3&4&1\end{pmatrix}\right\rangle$ of $S_{4}$

15. Let $G$ be a group and Aut $G$ the set of all automorphisms of $G$ (a) Aut $G$ is a group with composition of functions as binary operation. [Hint. $1_G$ EAut $G$ is an identity; inverses exist by Theorem 2.3.] (b) Aut $\mathbf{Z}\cong\mathbf{Z}_2$ and Aut $Z_6\cong Z_2$ ;Aut $Z_8\cong Z_2\oplus Z_2$ ;Aut $Z_p\cong Z_{p-1}$ $(p$ prime). (c) What is Aut $Z_n$ for arbitrary n e $N^*?$

16. For each prime $p$ the additive subgroup $Z(p^{\infty})$ of $\mathbb{Q}/\mathbb{Z}$ (Exercise 1.10) is generated by the set $\{$Т$/p^n\mid n\in\mathbf{N}^*\}$

17. Let $G$ be an abelian group and let $H,K$ be subgroups of $G$ . Show that the join $H\vee K$ is the set $\{ab\mid a\in H,b\in K\}$ . Extend this result to any finite number of subgroups of $G$

18. (a) Let $G$ be a group and $\{H_{i}\mid i\in I\}$ a family of subgroups. State and prove a condition that ill imply that $\bigcup_{ieI}H_{i}$ H $H_{i}$ is a subgroup, that is that U $H_{i}=\langle\bigcup H_{i}\rangle$ (b) Give an example of a group $G$ and a family of subgroups $\{H_{i}\mid i\in I\}$ such that $\bigcup_{i\in I}H_{i}\neq\langle\bigcup_{i\in I}H_{i}\rangle$

19. (a) The set of all subgroups of a group $G.$ ,partially ordered by set theoretic inclusion, forms a complete lattice (Introduction, Exercises 7.1 and 7.2) in which the g..b. of $\left\{H_{i}\mid i\in I\right\}$ is $\bigcap_{ieI}H_i$ and the l.u.b. is $\langle\bigcup_{i\in I}H_{i}\rangle$

(b) Exhibit the lattice of subgroups of the groups $S_{3},D_{4}^{*},Z_{6},Z_{27}$ and $Z_{36}$

1

1

1

------------------------------------------------------------------

## 3. CYCLIC GROUPS

The structure of cyclic groups is relatively simple.We shall completely characterize all cyclic groups (up to isomorphism).

Theorem 3.1. Euery subgroup H of the additice group $\mathbf{Z}$ is cyclic. Either $\mathbf{H}=\langle0\rangle$ or $\mathbf{H}=\langle\mathbf{m}\rangle$ ,where m is the least positice integer in H. If $\mathbf{H}\neq\langle0\rangle$ ,then $H$ is infinite

PROOF. Either $H=\langle0\rangle$ or $H$ contains a least positive integer $m$ . Clearly $\langle m\rangle=\{km\mid k\varepsilon\mathbf{Z}\}\subset H$ . Conversely if $h\varepsilon H.$ , then $h=qm+r$ with $q$ g $q,r\varepsilon\mathbf{Z}$ and $0\leq r<m$ (division algorithm). Since $r=h-qm\varepsilon H$ the minimality of $m$ implies $r=0$ and $h=qm$ . Hence $H\subset\langle m\rangle$ . If $H\neq\langle0\rangle$ , it is clear that $H=\langle m\rangle$ is infnite.

Theorem 3.2. Euery infinite cyclic group is isomorphic to the additive group $\mathbf{Z}$ and every finite cyclic group of order r. is isomorphic to the additive group $\mathbf{Z}_{\mathrm{m}}$

PROOF. If $G=\langle a\rangle$ is a cyclic group then the map $\alpha:\mathbf{Z}\to G$ given by $k|\mapsto a^k$ is an epimorphism by Theorems 1.9 and 2.8. If Ker $\alpha=0$ , then $\mathbf{Z}\cong G$ by Theorem 2.3 (i). Otherwise Ker $\alpha$ is a nontrivial subgroup of $\mathbf{Z}$ (Exercise 2.9) and hence Ker $\alpha=\langle m\rangle$ ,where $m$ is the least positive integer such that $a^{m}=e$ (Theorem 3.1). For all r, s ε Z,

$$\begin{aligned}a^{r}=a^{s}&\Leftrightarrow\quad a^{r-s}=e\quad\Leftrightarrow\quad r-s\:\varepsilon\:\mathrm{Ker}\:\alpha=\langle m\rangle\\&\Leftrightarrow\quad m\mid(r-s)\quad\Leftrightarrow\quad\bar{r}=\bar{s}\:\mathrm{in}\:Z_{m},\end{aligned}$$

(where $\bar{k}$ is the congruence class of $k\varepsilon\mathbf{Z}$ 0.Therefore the map $\beta:Z_m\to G$ given by $\bar{k}\models a^k$ is a well-defined epimorphism. Since

$$\beta(\bar{k})=e\quad\Leftrightarrow\quad a^k=e=a^0\quad\Leftrightarrow\quad\bar{k}=\bar{0}\:\mathrm{in}Z_m,$$

$\beta$ is a monomorphism (Theorem 2.3(i)), and hence an isomorphism $Z_{m}\cong G$ .

Definition 3.3. Let G be a group anda e G. The order of a is the order of the cycli subgroup $\langle$a$\rangle$ and is denoted|al

Theorem 3.4. Ler G be a group and a ε G. If a has infinite order, then

(i $a^k=e$ if and only $if\mathbf{k}=0$ (ii) the elements $a^k$ (k e Z) are all distinct.

Ifa hasfinite order $m>0$ ,then

(ii) m is the least positive integer such that $\mathbf{a}^{\mathrm{m}}=\mathbf{e}$ (iv) $\mathbf{a}^{\mathbf{k}}=\mathbf{e}$ if and only ifm | k; (v) $\mathbf{a}^{\mathbf{r}}=\mathbf{a}^{\mathbf{s}}$ if and only $if$r$\equiv\mathbf{s}$ ifr=s $if$r$\equiv$s$(mod$ m) (vi) (a) consists of the distinct elements $\mathrm{a,a^{2},\ldots,a^{m-1},a^{m}=e}$ (vi) for each k such that $\mathbf{k}\mid\mathbf{m},|\mathbf{a}^{\mathbf{k}}|=\mathbf{m}/\mathbf{k}$

------------------------------------------------------------------

厂

SKETCH OF PROOF. (i)-(vi) are immediate consequences of the proof of Theorem 3.2. (vii) $(a^{k})^{m/k}=a^{m}=e$ and $(a^k)^r\neq e$ for all $0<r<m/k$ since otherwise $a^{kr}=e$ with $kr<k(m/k)=m$ contradicting (ii). Therefore,. $|a^k|=m/k$ by (ii).

Theorem 3.5. Euery homomorphic image and every subgroup of a cyclic group G is cyclic. In particular, ifH is a nontrivial subgroup of $\mathbf{G}=\langle\mathbf{a}\rangle$ and m is the least positive integer such that $a^m\varepsilon H$ ,then $\mathbf{H}=\langle\mathbf{a}^{\mathrm{m}}\rangle$

SKETCH OF PROOF. If $f{:}G\to K$ is a homomorphism of groups, then $\operatorname{Im}f=\langle f(a)\rangle$ .To prove the second statement simply translate.the proof of Theorem 3.1 into multiplicative notation (that is, replace every I E $\mathbf{Z}$ by $a^l$ throughout). This proof works even if $G$ is finite.

Recall that two distinct elements in a group may generate the same cyclic subgroup.

1

1

1

Theorem 3.6. Let $\mathbf{G}=\langle\mathbf{a}\rangle$ be a cyclic group. If G is infnite, then a and $a^{-1}$ arethe only generators of G. If G is finite of order m, then $a^k$ is a generator of G if and only. $if(\mathbf{k},\mathbf{m})=1$

SKETCH OF PROOF. It suffces to assume either that $G=\mathbf{Z}$, in which case the conclusion is easy to prove, or that $G=Z_{m}$ . If $(k,m)=1$ , there are $c,d\varepsilon Z$ such that $ck+dm=1$ ; use this fact to show that $\bar{k}$ generates $Z_m$ . If $(k,m)=r>1$ ,show that for n=m!r<m $n=m/r<m$ $n=m/r<m,n\bar{k}=\overline{n}\bar{k}=\bar{0}$ nk=nk=0 $n\bar{k}=\overline{nk}=\bar{0}$ and hence $\bar{k}$ cannot generate $Z_{m}$ .

A naive hope might be that the techniques used above could be extended to groups with two generators and eventually to all finitely generated groups, and thus provide a description of the structure of such groups. Unfortunately, however, even groups with only two generators may have a very complex structure. (They need not be abelian for one thing; see Exercises 2.3 and 2.4.) Eventually we shall be able to characterize all fnitely generated abelian groups, but even this will require a great deal more machinery

1

1

1

### EXERCISES

1. Let $a,b$ be elements of group $G$ . Show that $|a|=|a^{-1}|;\:|ab|=|ba|$ ,and $|a|=|cac^{-1}|$ for all c ε $G$

2. Let $G$ be an abelian group containing elements $a$ and $b$ of orders $m$ and n re spectively. Show that $G$ contains an element whose order is the least common multiple of $m$ and $n$ .[Hinr: first try the case when $(m,n)=1.$ 3. Let $G$ be an abelian group of order $pq$ ,with $(p,q)=1$ . Assume there exist $a,b\in G$ G $G$ such that $|a|=p,|b|=q$ [b] = q $|b|=q$ and show that $G$ is cyclic. 4.If $f$ $G\to H$ is a homomorphism, $a$ E $G$ ,and $f(a)$ has finite order in $H$ ,then $|a|$ is infinite or $|f(a)|$ divides $|a|$

------------------------------------------------------------------

5. Let $G$ be the multiplicative group of all nonsingular $2\times2$ matrices with rational entres Show that $a=\begin{pmatrix}0&-1\\1&0\end{pmatrix}$ has ordr 4 nd $b=\begin{pmatrix}0&1\\-1&-1\end{pmatrix}$ hasorder , but ab has infinite order. Conversely, show that the additive group $Z_2\oplus\mathbf{Z}$ contains nonzero elements $a,b$ of infinite order such that $a+b$ has finite order.

6.If $G$ is a cyclic group of order $n$ and $k\mid n$, then $G$ has exactly one subgroup of order $k$

7. Let $p$ be prime and $H$ a subgroup of $Z(p^{\infty})$ (Exercise 1.10). (a) Every element of $Z(p^{\infty})$ has finite order $P^n$ for some $n\geq0$

(b) If at least one element of $H$ has order $p^k$ and no element of $H$ has order greater than $p^k$ , then $H$ is the cyclic subgroup generated by $\overline{1/p^k}$ , whence $H\cong Z_{p^k.}$ (c) If there is no upper bound on the orders of elements of $H$ ，then $H=Z(p^{\infty})$ ; [see Exercise 2.16]. (d) The only proper subgroupsof $Z(p^{\infty})$ are the finite cyclic groups. $C_n=\langle\overline{1/p^n}\rangle$ $(n\:=\:1,2,\:\ldots)$ . Furthermore, $\langle0\rangle=C_{0}<C_{1}<C_{2}<C_{3}<\cdots.$ (e) Let $x_1,x_2,\ldots$ be elements of an abelian group $G$ such that $|x_1|=p_1$ $px_{2}=x_{1}$ ， $px_{3}=x_{2},\ldots,px_{n+1}=x_{n},\ldots$ .The subgroup generated by the $x_{i}(i\geq1)$ is isomorphic to $Z(p^{\infty})$ . [Hinr: Verify that the map induced by $x_{i}|\to\overline{1/p^{i}}$ is a well-defined isomorphism.]

8. A group that has only a finite number of subgroups must be finite.

9. If $G$ is an abelian group, then the set $T$ of all elements of $G$ with finite order is a subgroup of $G$ . [Compare Exercise 5.]

10. An infinite group is cyclic if and only if it is isomorphic to each of its proper subgroups

### 4. COSETS AND COUNTING

In this section we obtain the frst significant theorems relating the structure of a finite group $G$ with the number theoretic properties of its order $|G|$ . We begin by extending the concept of congruence modulo $m$ in the group $\mathbf{Z}$ . By definition $a\equiv b$ (mod $m$ )if and only if $m\mid a-b$, that is, if and only if $a-b$ is an element of the subgroup $\langle m\rangle=\{mk\mid k\in\mathbf{Z}\}$ . More generally (and in multiplicative notation) we have

Definition 4.1. Ler H be a subgroup ofa group G and a,b e G.a is right congruent 1o b modulo H, denoted a $\equiv_{\mathrm{r}}$ b (mod H) $ifab^{-1}\varepsilon H.$ a is left congruent ro b modulo H, denoted a $\equiv_1b$ (mod H), if a-ib e H.

If $G$ is abelian, then right and left congruence modulo $H$ coincide (since $ab^{-1}\varepsilon H$ $\Leftrightarrow(ab^{-1})^{-1}\varepsilon H$ and $(ab^{-1})^{-1}=ba^{-1}=a^{-1}b)$ 0. There also exist nonabelian groups $G$ and subgroups $H$ such that right and left congruence coincide (Section 5), but this is not true in general.

------------------------------------------------------------------

[

Theorem 4.2. Let H be a subgroup of a group G.

(i) Right [resp. lefi)] congruence modulo $H$ is an equivalence relation on G. (i)The equivalence class of a e G under right [resp. left) congruence modulo H is

the set $\mathrm{Ha}=\{\mathbf{h}a\mid\mathbf{h}\varepsilon\mathbf{H}\}$ [resp. $\mathbf{aH}=\{\mathbf{ah}\mid\mathbf{h}\varepsilon\mathbf{H}\}$ (ii) |Ha|=|H|=|aH| for all a e G.

The set Ha is called a right coset of $H$ in $G$ and $aH$ is called a left coset of $H$ in $G$ In general it is nor the case that a right coset is also a left coset (Exercise 2).

PROOF OF 4.2. We write $a\equiv b$ for a=rb $a\equiv_rb$ $a\equiv_rb\left(\mathrm{mod}H\right)$ and prove the theorem for right congruence and right cosets. Analogous arguments apply to left congruence.

(i) Let $a,b,c\in G$ . Then $a\equiv a$ since $aa^{-1}=e\varepsilon H$ ; hence = is reflexive. $\equiv$ is clearly symmetric $(a\equiv b\Rightarrow ab^{-1}$ $H\Rightarrow(ab^{-1})^{-1}\in$ $H\Rightarrow(ab^{-1})^{-1}\in$ $:H\Rightarrow(ab^{-1})^{-1}\varepsilon\:H\Rightarrow ba^{-1}\varepsilon\:H\Rightarrow b\equiv a)$ H=bar1e $H\Rightarrow ba^{-1}\varepsilon$ $H\Rightarrow b\equiv a$ H=b=a . Finally $a\equiv b$ and $b\equiv c$ imply $ab^{-1}\varepsilon H$ and $bc^{-1}\varepsilon H$ . Thus $ac^{-1}=(ab^{-1})(bc^{-1})\varepsilon H$ and $a\equiv c$ ；hence $\equiv$ is transitive. Therefore, right congruence modulo $H$ isan equivalence relation. (ii) The equivalence class of $a\varepsilon G$ G $G$ under right congruence is $\{x\in G\mid x\equiv a\}$

$=\{x^{\prime}\varepsilon G|xa^{-1}\varepsilon H\}=\{x\varepsilon G|xa^{-1}=h\varepsilon H\}=\{x\varepsilon G|x=ha;h\varepsilon H\}$ $=\{ha\mid h\varepsilon H\}=Ha$

(ii) The map $Ha\to H$ given by $ha\vdash h$ is easily seen to be a bijection.

Corollary 4.3. Let H be a subgroup of a group G.

(i) G is the union of the right [resp. left] cosets of H in G. (i) Two right [resp. left) cosets of H in G are either disjoint or equal. (ii) For all a,b ε G, $\mathbf{Ha}=\mathbf{Hb}\Leftrightarrow\mathbf{ab}^{-1}\varepsilon\mathbf{H}$ and $\mathbf{aH}=\mathbf{bH}\Leftrightarrow\mathbf{a}^{-1}\mathbf{b}\varepsilon\mathbf{H}$ (iv) If R is the set of distinct right cosets of H in G and $\mathcal{L}$ is the set of distinct left cosets of H in G, then $|{\mathcal{R}}|=|{\mathcal{X}}|$

PROOF. (i)-(iii) are immediate consequences of the theorem and statements (19)-(21) of Introduction, Section 4. (iv) The map $\mathbb{R}\to\mathfrak{L}$ given by $Ha\vdash a^{-1}H$ is a bijection since $Ha=Hb\Leftrightarrow ab^{-1}$ ab-1 $H\Leftrightarrow(a^{-1})^{-1}b^{-1}$ H =(a-1)-'b-1 $\Leftrightarrow ab^{-1}\varepsilon H\Leftrightarrow(a^{-1})^{-1}b^{-1}\varepsilon H\Leftrightarrow a^{-1}H=b^{-1}H$ $H\Leftrightarrow a^{-1}H=b^{-1}H$ H=aH =b-H .

ADDITIVE NOTATION. If $H$ is a subgroup of an additive group, then right congruence modulo $H$ is defined by: $a\equiv_rb$ (mod $H)\Leftrightarrow a-b\varepsilon H$ The equivalence class of $a\varepsilon G$ is the right coset $H+a=\{h+a\mid h\varepsilon H\}$ ; similarly for left congruence and left cosets.

Definition 4.4. Let H be a subgroup of a group G. The index of H in G, denoted $[G:H]$ , is the cardinal number of the set of distinct right [resp. left] cosets of H in G.

In view of Corollary 4.3 (iv), $[G:H]$ does not depend on whether right or left cosets are used in the definition. Our principal interest is in the case when $[G:H]$ is finite, which can occur even when $G$ and $H$ are infinite groups (for example, $[\mathbf{Z}:\langle m\rangle]=m$ by Introduction, Theorem 6.8(i)). Note that if $H=\langle e\rangle$ , then $Ha=\{a\}$ for every a e $G$ and $[G:H]=|G|$

------------------------------------------------------------------

A complete set of right coset representatives of a subgroup $H$ in a group $G$ is a set $\{a_i\}$ consisting of precisely one element from each right coset of $H$ in $G$ . Clearly the set $\{a_i\}$ has cardinality $[G:H]$ . Note that such a set contains exactly one element of $H$ since $H=He$ is itself a right coset. Analogous statements apply to left cosets.

Theorem 4.5. If K,H,G are groups with $\mathbf{K}<\mathbf{H}<\mathbf{G}$ ,then $[\mathcal{G}:\mathbf{K}]=[\mathcal{G}:\mathcal{H}][\mathcal{H}:\mathbf{K}]$ If any two of these indices are finite, then so is the third

PROOF. By Corollary $4.3\:G=\bigcup_{i=1}H$ Ha:with $a_i\varepsilon G$ aie G $a_i\varepsilon G,|I|=[G:H]$ and the cosets ieI $Ha_i$ mutually disjoint (that is, $Ha_i=Ha_j\Leftrightarrow i=j)$ . Similarly H = U Kb; with $b_i\varepsilon H.$ $|J|=[H:K]$ and the cosets $Kb_i$ are mutually disjoint. Therefore $G=\bigcup_{ieI}Ha_{i}=$ $\bigcup_{i\in I}\left(\bigcup_{j\in J}Kb_{j}\right)a_{i}=\bigcup_{(i,j)\in I\times J}Kb_{j}a_{i}$ Itsuffices to show that thecosets $Kb_ia_i$ are mutually disjoint. For then by Corollary 4.3. we must have $[G:K]=|I\times J|$ , whence $[G:K]$ $=|I\times J|=|I||J|=[G:H][H:K]$ . If $Kb_ja_i=Kb_ra_t$ , then $b_ja_i=kb_ra_t\left(k\in K\right)$ Since $b_i,b_r,k\in H$ we have $Ha_{i}=Hb_{j}a_{i}=Hkb_{r}a_{t}=Ha_{t}$ ;hence $i=1$ and $b_{j}=kb_{r}$ Thus $Kb_{j}=Kkb_{r}=Kb_{r}$and$j=r$ j=r $j=r.$ Therefore, the cosets $Kb_ja_i$ are mutually disjoint. The last statement of the theorem is obvious.

Corollary 4.6. (Lagrange). IfH is a subgroup of a group G, then $|\mathcal{G}|=|\mathcal{G}:\mathcal{H}||\mathcal{H}|$ In particular ifG is finite, the order |al ofa e G divides $|\mathbf{G}|$

PROOF. Apply the theorem with $K=\langle e\rangle$ for thefirststatement.The second is a special case of the frst with $H=\langle a\rangle$ .

A number of proofs in the theory of (finite) groups rely on various “counting" techniques,some of which we now introduce. If $G$ is a group and $H,K$ are subsets of $G$ ,we denote by $HK$ the set $\{ab\mid a\varepsilon H,b\varepsilon K\}$ ; a right or left coset of a subgroup is a special case. If $H,K$ are subgroups, $HK$ may nor be a subgroup (Exercise 7).

Theorem 4.7. Let $H$ and K be finite subgroups of a group G. Then $|HK|=$ $|\mathbf{H}||\mathbf{K}|/|\mathbf{H}\cap\mathbf{K}|$

SKETCH OF PROOF. $C=H\cap K$ is a subgroup of $K$ of index $n=$ $|K|/|H\cap K|$ and $K$ is the disjoint union of right cosets Ck1 $Ck_1$ $Ck_1\cup Ck_2\cup\cdots\cup Ck_n$ Ckn $Ck_n$ for some $k_i$ E $K$ . Since $HC=H$ this implies that $HK$ is the disjoint union $Hk_1$ U $Hk_2$ U ...U $Hk_n$ . Therefore, $|HK|=|H|\cdot n=|H||K|/|H\cap K|$ .■

Proposition 4.8. If H and $K$ are subgroups of a group G ，then $[\mathbf{H}:\mathbf{H}\cap\mathbf{K}]\leq$ $[G:K]$ .If $|G:K]$ is finite, then $[\mathbf{H}:\mathbf{H}\cap\mathbf{K}]=[\mathbf{G}:\mathbf{K}]$ if and only if $G=KH$

SKETCH OF PROOF. Let $A$ be theset of all right cosets of $H\cap K$ in $H$ and $B$ the set of all right cosets of $K$ in $G$ . The map $\varphi:A\to B$ given by $(H\cap K)h\vdash Kh$

------------------------------------------------------------------

厂

$(h\in H)$ is well defined since $(H\cap K)h^{\prime}=(H\cap K)h$ implies $h^{\prime}h^{-1}\varepsilon H\cap\kappa\subset K$ and hence $Kh^{\prime}=Kh$ . Show that $\varphi$ is injective. Then $[H:H\cap K]=|A|\leq|B|$ $=[G:K]$ If $[G:K]$ is finite, then show that $[H:H\cap K]=[G:K]$ if and only if $\varphi$ is surjective and that $\varphi$ is surjective if and only if $G=KH$ .Note that for $h\varepsilon H$ $k$ E $K$ $Kkh=Kh$ since $(kh)h^{-1}=k\varepsilon K$ ■

Proposition 4.9. Let H and K be subgroups of finite index of a group G. Then $[G:H\cap K]$ is finite and $[G:H\cap K]\leq[G:H][G:K]$ . Furthermore, $[G:H\cap K]$ $=[\mathcal{G}:\mathcal{H}][\mathcal{G}:\mathbf{K}]$ if andonlyi $f\mathbf{G}=\mathbf{HK}$

PROOF. Exercise; use Theorem 4.5 and Proposition 4.8.

1

### EXERCISES

1. Let $G$ be a group and $\{H_{i}\mid i\in I\}$ a family of subgroups. Then for any a e $G$ $(\bigcap_{i}H_{i})a=\bigcap_{i}H_{i}a$

2. (a) Let $H$ be the clie subgroup of order 2) of $S_3$ generated by $\begin{pmatrix}1&2&3\\2&1&3\end{pmatrix}$ Then no left coset of $H$ (except $H$ itself) is also a right coset.There exists $a\varepsilon S_3$ S $S_3$ such that $aH\cap Ha=\{a\}$ (b) If $K$ isthe yliesubgroup o order ) of $S_3$ generated by $\begin{pmatrix}1&2&3\\2&3&1\end{pmatrix};$ thenm every left coset of $K$ is also a right coset of $K$

3. The following conditions on a finite group $G$ are equivalent. (i) $|G|$ is prime.

(i) $G\neq\langle e\rangle$ and $G$ has no proper subgroups. (i) $G\cong Z_p$ for some prime $P$

4. (Euler-Fermat) Let $a$ be an integer and $p$ a prime such that pXa . Then $a^{p-1}\equiv1$ (mod $p$ ). [Hint: Consider $\bar{a}\varepsilon Z_p$ and the multiplicative group of nonzero elements of $Z_p$ ; see Exercise 1.7.] It follows that $a^p\equiv a$ (mod $p$ ) for any integer $a$

5. Prove that there are only two distinct groups of order 4 (up to isomorphism), namely $Z_4$ and $Z_2\oplus Z_2$ .[Hinr: By Lagrange's Theorem 4.6 a group of order 4 that is not cyclic must consist of an identity and three elements of order 2.]

6. Let $H,K$ be subgroups of a group $G$ . Then HK is a subgroup of $G$ if and only if $HK=KH$

7. Let $G$ be a group of order $p^km$ ,with $p$ prime and $(p,m)=1$ Let $H$ be a subgroup of order $p^k$ and $K$ a subgroup of order $p^d$ , with $0<d\leq k$ and $K\not\subset H.$ Show that $HK$ is not a subgroup of $G$

8. If $H$ and $K$ are subgroups of finite index of a group $G$ such that $[G:H]$ and $[G:K]$ are relatively prime, then $G=HK$

9. If $H,K$ and $N$ are subgroups of a group $G$ such that $H<N$ , then $HK\cap N$ $=H(K\cap N)$

1

|

1

1

------------------------------------------------------------------

10. Let $H,K,N$ be subgroups of a group $G$ such that $H<K$ $H\cap N=K\cap N$, and $HN=KN$ . Show that $H=K$ 11. Let $G$ be a group of order $2n$ ; then $G$ contains an element of order 2. If $n$ is odd and $G$ abelian, there is only one element of order 2. 12. If $H$ and $K$ are subgroups of a group $G$ , then $[H\vee K:H]\geq[K:H\cap K]$ 13. If $p>q$ are primes, a group of order pq has at most one subgroup of order $P$ [Hint: Suppose $H,K$ are distinct subgroups of order $p$ .Show $H\cap K=\langle e\rangle$ ；use Exercise 12 to get a contradiction.] 14. Let $G$ be a group and a,b e $G$ such that (i) $|a|=4=|b|$ ;(i) $a^2=b^2$ ;(ii) $ba=a^3b$ $=a^{-1}b$ (iv) $a\neq b$ ；(v) $G=\langle a,b\rangle$ . Show that $|G|=8$ and $G\cong Q_{8}$ .(See Exercise 2.3; observe that the generators $A,B$ of $Q_{8}$ also satisfy (i)-(v).)

## 5. NORMALITY, QUOTIENT GROUPS, AND HOmOMORPHISMS

We shall study thosesubgroups $N$ of a group $G$ such that left and right congruence modulo $N$ coincide. Such subgroups play an important role in determining both the structure of a group $G$ and the nature of homomorphisms with domain $G$

Theorem 5.1.If N is a subgroup of a group G,then thefollowing conditions are equivalent.

(i) Left and right congruence modulo N coincide (that is, define the same equiva lence relation on G); (ii) every left coset of N in G is a right coset ofN in G;

(i) $\mathbf{aN}=\mathbf{Na}$ for all a e G; (iv) for all a ε G, $aNa^{-1}\subset N$ where $\mathbf{aNa^{-1}=\{ana^{-1}\mid n\varepsilon N\}}$ (v) for all a ε G, $aNa^{-1}=N$

PROOF. (i) $\Leftrightarrow$ (ii) Two equivalence relations $R$ and $S$ are identical if and only if the equivalence class of each element under $R$ is equal to its equivalence class under S. In this case the equivalence classes are the left and right cosets respectively of $N$ $\Longrightarrow$ = $(\mathrm{ii})\Rightarrow(\mathrm{iii})$ If $aN=Nb$ for some $b\varepsilon G$ , then a e Nb $\bigcap$ Na, which implies $Nb=Na$ since two rightcosets areeither disjoint or equal. $(\mathrm{iii})=(\mathrm{iv})$ is trivial. $(\mathbf{iv})\Rightarrow(\mathbf{v})$ Wehave $aNa^{-1}\subset N$ . Since (iv) also holds for. $a^{-1}\varepsilon G$ $G$ G ， $a^{-1}Na\subset N$ . Therefore for every ne $N$ $n=a(a^{-1}na)a^{-1}$ E aNa-1 and $N\subset aNa^{-1}$ $(\mathbf{v})\Rightarrow(\mathbf{i}\mathbf{i})$ is immediate.

Definition 5.2. A subgroup N of a group G which satisfies the equivalent conditions of Theorem 5.1 is said to be normal in G (or a normal subgroup ofG); we write $N\triangleleft G$ ifN is normal in G.

In view of Theorem 5.1 we may omit the subscripts “r" and “" when denoting congruence modulo a normal subgroup.

------------------------------------------------------------------

一

EXAMPLES. Every subgroup of an abelian group is trivially normal. The subgroup $H$ generated by $\begin{pmatrix}1&2&3\\2&3&1\end{pmatrix}$ in $S_3$ is normal Exercise4.2). More eneral any subgroup $N$ of index 2 in a group $G$ is normal (Exercise 1). The intersection of any family of normal subgroups is a normal subgroup (Exercise 2).

If $G$ is a group with subgroups $N$ and $M$ such that $N\lhd M$ and $M\triangleleft G$ ,it does not follow that $N\lhd G$ (Exercise 10). However, it is easy to see that if $N$ is normal in $G$ ,then $N$ is normal in every subgroup of $G$ containing $N.$ Recall that the join $H\vee K$ of two subgroups is the subgroup $\langle H\cup K\rangle$ generated

by $H$ and $K$

Theorem 5.3. Let K and N be subgroups of a group G with N normal in G. Then

(i $\mathbb{N}\cap K$ is a normal subgroup ofK; (i) $N$ is a normal subgroupof $NVK$ (ii) $\mathbf{NK}=\mathbf{N}\lor\mathbf{K}=\mathbf{KN}$ (iv) if K is normal in G and K $\cap\mathbf{N}=\langle\mathbf{e}\rangle$ ,then nk $=kn$ for all k e K and n e N.

PROOF.(i) If $n\in N\cap K$ K $K$ and ae $K.$ ,then ana-1 ε $N$ since $N\triangleleft G$ and ana1 K since $K<G$ . Thus $a(N\cap K)a^{-1}\subset N\cap K$ and $N\cap K\lhd K$ . (ii) is trivial since $N<N\vee K$ . (i) Clearly $NK\subset N\vee K$ .An element $x$ of $NVK$ is a product of the form $n_1k_1n_2k_2\cdots n_rk_r$, with $n_i\in N,k_i\in K$ kieK $k_i\varepsilon K$ (Theorem 2.8). Since N<G $N\lhd G$ $N\lhd G,n_ik_j=k_jn_i^{\prime}$ $n_i'\varepsilon N$ and therefore $x$ can be written in the form $n(k_1\cdots k_r)$ ， $n\in N$ N $N$ Thus $N\vee K\subset NK$ . Similarly $KN=N\vee K$ (iv) Let $k\varepsilon K$ and $n\in N.$ . Then $nkn^{-1}\varepsilon K$ K $K$ since $K\lhd G$ and $kn^{-1}k^{-1}\varepsilon N$ since $N\lhd G$ Hence $(nkn^{-1})k^{-1}=n(kn^{-1}k^{-1})\varepsilon N\cap$ $K=\langle e\rangle$ ,which implies $kn=nk$ .

Theorem 5.4. If N is a normal subgroup ofa group G and $G/N$ is the set ofall (left) cosets of N in G, then. $G/N$ isa group oforder $[G:\mathbb{N}]$ under the binary operation given by $(aN)(bN)=abN$

PROOF. Since the coset aN [resp. bN, abN] is simply the equivalence class of $a\varepsilon G$ G $G$ [resp. $b\varepsilon G$ , ab e G] under the equivalence relation of congruence modulo $N$ ,it suffices by Theorem 1.5 to show that congruence modulo $N$ is a congruence relation, that is,that $a_1\equiv a$ (mod $N.$ ）and $b_1\equiv b$ (mod $N$ ）imply $a_1b_1\equiv ab$ (mod $N.$ ）.By assumption $a_{1}a^{-1}=n_{1}\varepsilon\:N$ and $b_1b^{-1}=n_2\varepsilon\boldsymbol{N}$ Hence $(a_1b_1)(ab)^{-1}=a_1b_1b^{-1}a^{-1}$ $=(a_1n_2)a^{-1}$ . But since $N$ is normal, $a_{1}N=Na_{1}$ which implies that $a_1n_2=n_3a_1$ for some $n_3\varepsilon N$ . Consequently $(a_1b_1)(ab)^{-1}=(a_1n_2)a^{-1}=n_3a_1a^{-1}=n_3n_1\varepsilon N$ ，whence $a_1b_1\equiv ab$ (mod $N$ ).■

If $N$ is a normal subgroup of a group $G$ , then the group $G/N.$ as in Theorem 5.4, is called the quotient group or factor group of $G$ by $N$ .If $G$ is written additively, then the group operation in $G/N$ is given by $(a+N)+(b+N)=(a+b)+N$

REMARK. If $m>1$ is a (fixed) integer and $k\varepsilon\mathbf{Z}$ , then the remarks preceding Definition 4.1 show that the equivalence class of $k$ under congruence modulo $m$ is

------------------------------------------------------------------

43

precisely the coset of $\langle m\rangle$ in $\mathbf{Z}$ which contains $k$ ; that is, as sets, $Z_{m}=\mathbf{Z}/\langle m\rangle$ .Theorems 1.5 and 5.4 show that the group operations coincide, whence $Z_{m}=\mathbf{Z}/\langle m\rangle$ as groups. We now explore the relationships between normal subgroups, quotient groups.

and homomorphisms.

Theorem 5.5. If $f{:}\mathbf{G}\to\mathbf{H}$ is a homomorphism of groups,then thekernel off is a normal subgroup of G. Conversely, ifN is a normal subgroup ofG,thenthemap $\pi:\mathbb{G}\to\mathbb{G}/\mathbb{N}$ given by $\pi($a)=aN is an epimorphism with kernel $N$

PROOF. If $x$ εKer $f$ and ae $G$ , then

$$f(axa^{-1})=f(a)f(x)f(a^{-1})=f(a)ef(a)^{-1}=e$$

and $axa^{-1}\varepsilon$ Ker $f.$ Therefore $a($Ker $f)a^-1\subset$Ker $f$ and Ker $f\triangleleft G$ .The map $\pi:G\to G/N$ is clearly surjective and since $\pi(ab)=abN=aNbN=\pi(a)\pi(b)$ $\pi$ is an epimorphism. Ker $\pi\:=\:\{a\varepsilon\:G\mid\pi(a)\:=\:e\:N\:=\:N\}\:=\:\{a\:\varepsilon\:G\mid a\:N=\:N\}$ $=\{a\in G\mid a\in N\}\:=\:N.$

The map $\pi:G\to G/N$ is called the canonical epimorphism or projection.Here after unless stated otherwise $G\to G/N$ $(N\lhd G)$ always denotes the canonical epimorphism

Theorem 5.6. Iff : $G\to H$ is a homomorphism of groups and N is a normal subgroup ofG contained in the kernel off, then thereis aunique homomorphism $\mathbf{\bar{f}}:\mathbf{G/N}\to\mathbf{H}$ such that $\bar{\mathbf{f}}(\mathbf{aN})=$f$(\mathbf{a})$ for all a ε G. Im $\mathbf{f}=Im$ fand Ker $\bar{\mathbf{f}}=(Ker\:\mathrm{f})/\mathbb{N}$ .fis an isomorphism if and only iff is an epimorphism and $\mathbf{N}=Ker$ f.

The essential part of the conclusion maybe rephrased: there exists a unique homomorphism $\bar{f}{:}G/N\to H$ such that the diagram

![](https://storage.simpletex.cn/view/f1Boda799xdnGYQhKa8Fg8w8X0szzNPuS)

is commutative. Corollary 5.8 below may also be stated in terms of commutative diagrams.

PROOF OF 5.6. If $b\varepsilon aN$ ,then $b=an,\:n\in N$ ,and $f(b)=f(an)=f(a)f(n)$ $=f(a)e=f(a)$ ,since $N<$Ker $f$ $f.$ f Therefore, $f$ has the same effect on every element of the coset aN and the map $\bar{f}{:}G/N\to H$ given by $\bar{f}(aN)=f(a)$ is a well-defined function. Since $\bar{f}(aNbN)\:=\:\bar{f}(abN)\:=\:f(ab)\:=\:f(a)\:f(b)\:=\:\bar{f}(aN)\:\bar{f}(bN),\:\bar{f}$ $\bar{f}$ F is a homomorphism. Clearly I ${\mathfrak{m}}\bar{f}={\mathbf{I}}{\mathfrak{m}}$ fand

------------------------------------------------------------------

$$aN\varepsilon Ker\bar{f}\Leftrightarrow f(a)=e\Leftrightarrow a\varepsilon Kerf,$$

whence Ker $\bar{f}=\{aN\mid$ ae Ker $f\}\:=($Ker $f)/N.$ $\bar{f}$ is unique since it is completely determined by $f.$ Finally it is clear that $\bar{f}$ is an epimorphism if and only if $f$ is. By Theorem $2.3\bar{f}$ is a monomorphism if and only if Ker $\bar{f}=($Ker $f)/N$ is the trivial subgroup of $G/N$ which occurs if and only if Ker $f=N$ .

Corollary 5.7. (First Isomorphism Theorem) If $\mathbf{f}:\mathbf{G}\to\mathbf{H}$ is a homomorphism of groups, then f induces an isomorphism $\mathrm{G/Ker~f\cong Im~}$ f.

PROOF. $f{:}G\to\mathbf{Im}$ fis an epimorphism. Apply Theorem 5.6 with $N=$ Ker $f.$ ■

Corollary 5.8. If $\mathbf{f}:\mathbf{G}\to\mathbf{H}$ is a homomorphism of groups, $\mathbb{N}\lhd G$ ， $M\lhd H$ and $\mathbf{f}(N)<\mathbf{M}$ , then f induces a homomorphism. $\bar{\mathbf{f}}:G/\mathbb{N}\to H/M$ givenby $\mathbf{aN}\mapsto\mathbf{f}(\mathbf{a})\mathbf{M}$ f is an isomorphism if and only if Im f √ $\mathbf{M}=\mathbf{H}$ and $\mathbf{f}^{-1}(\mathbf{M})\subset\mathbf{N}$ In particular if fis an epimorphism such that. $f(\mathbf{N})=M$ and Ker $f\subset\mathbb{N}$ , then f is an isomorphism.

SKETCH OF PROOF. Consider the composition $G\overset{f}{\operatorname*{\to}}H\overset{\pi}{\operatorname*{\to}}H/M$ and verify that $N\subset f^{-1}(M)=\ker\pi f$ By Theorem 5.6 (applied to $\pi f)$ the map $G/N\to H/M$ given by $aN\vdash(\pi f)(a)=f(a)M$ is a homomorphism that is an isomorphism if and only if $\pi f$ is an epimorphism and $N=$Ker $\pi f$ But the latter conditions hold if and only if Im $f\vee M=H$ and $f^{-1}(M)\subset N$ . If $f$ is an epimorphism, then $H=\operatorname{Im}f$ $=\operatorname{Im}f\vee M$ . If $f(N)=M$ and Ker $f\subset N.$ ,then $f^{-1}(M)\subset N$ ，whence $\tilde{f}$ is an isomorphism.

Corollary 5.9. (Second Isomorphism Theorem) IfK and N are subgroups of a group G,with N normal in G,then $\mathbf{K}/(\mathbf{N}\cap\mathbf{K})\cong\mathbf{N}\mathbf{K}/\mathbf{N}$

PROOF. $N\lhd NK=N\vee K$ by Theorem 5.3. The composition $K\overset{\mathcal{E}}{\operatorname*{\operatorname*{\operatorname*{\operatorname*{\operatorname*{S}}}}}}NK\overset{\pi}{\operatorname*{\operatorname*{\longrightarrow}}}$ $NK/N$ is a homomorphism $f$ with kernel $K\cap N$ ,whence $\bar{f}{:}K/K\cap N\cong$Im $f$by $N\cong\mathbf{Im}$ N≤ Im $f$ f Corollary 5.7. Every element in. $NK/N$ is of the form $nkN(n\in N,k\in K)$ .The normality of $N$ implies that $nk=kn_{1}(m\in N)$ , whence $nkN=kn_{1}N=kN=f(k).$ There fore $f$ is an epimorphism and hence Im $f=NK/N$ .■

Corollary 5.10. (Third Isomorphism Theorem). 1f H and K are normal subgroups of a group G such that $K<H$ ，then $H/K$ is a normal subgroup of $G/K$ and (G/K)/(H/K)$\cong$G/H

PROOF. The identity map. $\mathbf{l}_G:G\to G$ has $\mathbf{l}_G(K)<H$ and therefore induces an epimorphism $I:G/K\to G/H$ with $I(aK)=aH.$ Since $H=I(aK)$ if and only if ae $H.$ ,Ker $I=\left\{aK\mid a\varepsilon H\right\}=H/K$ .Hence $H/K\lhd G/K$ by Theorem 5.5 and $G/H=$Im$I\cong(G/K)/$Ke Cr $I=(G/K)/(H/K)$ by Corollary 5.7.

------------------------------------------------------------------

Theorem 5.11. If $\mathbf{f}:\mathbf{G}\to\mathbf{H}$ is an epimorphism of groups, then the assignment $\mathbf{K}\mapsto\mathbf{f}(\mathbf{K})$ defines a one-to-one correspondence between the set $S_{\mathrm{f}}(G)$ of all subgroups. K ofG which contain Ker f and the set S(H) of all subgroups ofH. Under this correspondence normal subgroups correspond to normal subgroups

SKETCH OF PROOF. By Exercise 2.9 the assignment $K\vdash f(K)$ defines a function $\varphi:S_{f}(G)\to S(H)$ and $f^{-1}(J)$ is a subgroup of $G$ for every subgroup $J$ of $H.$ Since $J<H$ implies Ker $f<f^{-1}(J)$ and $f(f^{-1}(J))=J$ $\varphi$ is surjective. Exercise 18 shows that $f^{-1}(f(K))=K$ if and only ifKer $f<K$ . It follows that $\varphi$ is injective. To prove the last statementverify that $K\lhd G$ implies $f(K)\lhd H$ and $J\lhd H$ implies $f^{-1}(J)\lhd G$ .

Corollary5.12.IfN is a normal subgroup ofa group G,then every subgroup of G/N is oftheform $K/N$ ,whereK is a subgroupof G thatcontains N.Furthermore, $K/N$ is normal in $G/N$ if and only ifK is normal in G.

PROOF. Apply Theorem 5.11 to the canonical epimorphism $\pi:G\to G/N$ If $N<K<G$ , then $\pi(K)=K/N$ ■

## EXERCISES

1. If $N$ is a subgroup of index 2 in a group $G$ , then $N$ is normal in $G$

2. If $\{N_{i}\mid i\in I\}$ is a family of normal subgroups of a group $G$ , then $\bigcap_{i,J}N_{i}$ is a normal subgroup of $G$ 3. Let $N$ be a subgroup of a group $G.N$ is normal in $G$ if and only if (right) congruence modulo $N$ is a congruence relation on $G$ 4. Let $\sim$ be an equivalence relation on a group $G$ and let $N=\{a\varepsilon G\mid a\sim e\}$ Then $\sim$ is a congruence relation on $G$ if and only if $N$ is a normal subgroup of $G$ and $\sim$ is congruence modulo $N$ 5. Let $N<S_4$ consist of all those permutations $\sigma$ such that $\sigma(4)=4.$ Is $N$ normal in $S_4$ 6. Let $H<G$ ; then the set aHa-1 is a subgroup for each a e $G$ , and $H\cong aHa^{-1}$ 7. Let $G$ be a finite group and $\bar{H}$ a subgroup of $G$ of order $n$ . If $H$ is the only subgroup of $G$ of order $n$ , then $H$ is normal in $G$ 8.All subgroups of the quaternion group are normal (see Exercises 2.3 and 4.14) 9. (a) If $G$ is a group, then the center of $G$ is a normal subgroup of $G$ (see Exercise 2.11); (b) the center of $S_n$ is the identity subgroup for all $n>2$ 10. Find subgroups $H$ and $K$ of $D_4^*$ such that $H\triangleleft K$ and $K\lhd D_{4}^{*}$ ,but $H$ isnot normal in $D_4^*$ 11. If $H$ is a cyclic subgroup of a group $G$ and $H$ is normal in $G$ , then every subgroup of $H$ is normal in $G$ . [Compare Exercise 10.]

------------------------------------------------------------------

「

12. If $H$ is a normal subgroup of a group $G$ such that $H$ and $G/H$ are finitely generated, then so is $G$

13. (a) Let $H\lhd G$ $K\lhd G$ . Show that $H\vee K$ is normal in $G$ (b) Prove that the set of all normal subgroups of $G$ forms a complete lattice under inclusion (Introduction, Exercise 7.2).

14.If $N_1\lhd G_1$ ， $N_2\lhd G_2$ then $(N_1\times N_2)\lhd(G_1\times G_2)$ and $(G_1\times G_2)/(N_1\times N_2)$ $\cong(G_1/N_1)\times(G_2/N_2)$

15.Let $N\lhd G$ and $K\lhd G$ . If $N\cap K=\langle e\rangle$ and $N\vee K=G$ , then $G/N\cong K$

16. If $f{:}G\to H$ is a homomorphism, $H$ is abelian and $N$ is a subgroup of $G$ containing Ker $f$, then $N$ is normal in $G$

17. (a) Consider the subgroups (6) and (30) of $\mathbf{Z}$ and show that $\langle6\rangle/\langle30\rangle\cong Z_5$ (b) For any $k,m>0$ ， $\langle k\rangle/\langle km\rangle\cong Z_m$ ; in particular, $\mathbf{Z}/\langle m\rangle=\langle1\rangle/\langle m\rangle\cong Z_{m}$ 18. If $f{:}G\to H$ is a homomorphism with kernel $N$ and $K<G$ , then prove that $f^{-1}(f(K))=KN$ Hence $f^{-\mathbf{l}}(f(K))=K$ if and only if $N<K$ 19. If $N\lhd G$ $[G:N]$ finite, $H<G,|H|$ [H] $|H|$ finite, and $[G:N]$ and $|H|$ are relatively prime, then $H<N$ 20. If $N\lhd G,|N|$ [M] $|N|$ finite, H<G $H<G$ $H<G,[G:H]$ [G : H] $[G:H]$ finite, and $[G:H]$ and $|N|$ are relatively prime, then $N<H$ 21. If $H$ is a subgroup of $Z(p^{\infty})$ and $H\neq Z(p^{\infty})$ , then $Z(p^{\infty})/H\cong Z(p^{\infty})$ .[Hint: if $H=\langle\overline{1/p^{n}}\rangle$ , let $x_{i}={\overline{1/p^{n+i}}}+H$ and apply Exercise 3.7(e).)

## 6. SYMMETRIC, ALTERNATING, AND DIHEDRAL GROUPS

In this section we shall study in some detail the symmetric group $S_n$ and certain of its subgroups. By definition $S_n$ is the group of all bijections $I_{n}\to I_{n}$ , where $I_{n}=$ $\{1,2,\ldots,n\}$ . The elements of $S_n$ are called permutations. In addition to the notation given on page 26 for permutations in $S_n$ there is another standard notation?

Definition 6.1. Let $\mathrm{i_1,i_2,\ldots,i_r,(r\leq n)}$ (r≤n) $(\mathbf{r}\leq\mathbf{n})$ be distinct elements of $\mathbf{I_{n}}=\{1,2,\ldots\mathbf{n}\}$ Then $(\mathrm{i}_1\mathrm{i}_2\mathrm{i}_3\cdots\mathrm{i}_r)$ denotes the permutation that maps $i_1\vdash i_2$, $\mathrm{i}_2|\to\mathrm{i}_3$ ， $\mathrm{i}_3\vdash\mathrm{i}_4,\ldots$, $\mathrm{i}_{\mathrm{r-1}}\mapsto\mathrm{i}_{\mathrm{r}}$, and $i_r\mapsto i_l$ ,and mapsevery otherelement of $I_n$ onto itself. $(\mathrm{i_{1}i_{2}\cdots i_{r}})$ is called a cycle of length r or an r-cycle; a 2-cycle is called $a$ transposition

The cycle notation is not unique (see below); indeed, strictly speaking, the cycle notation is ambiguous since $(i_1\cdots i_r)$ may be an element of any $S_n,n\geq r$ In context, however, this will cause no confusion. A 1-cycle $(k)$ is the identity permutation. Clearly, an $r$ -cycle is an element of order $r$ in $S_n$ . Also observe that if $\tau$ is a cycle and $\tau(x)\neq x$ for some $x\varepsilon I_n$ In $I_n$ , then $\tau=(x\tau(x)\tau^{2}(x)\cdots\tau^{d}(x))$ forsome $d\geq1$ .The inverse of the cycle $(i_1i_2\cdots i_r)$ is the cycle $(i_ri_{r-1}i_{r-2}\cdots i_2i_1)=(i_1i_ri_{r-1}i_{r-2}\cdots i_2)$ (verify!)

EXAMPLES. Th permutaion $\tau=\begin{pmatrix}1&2&3&4\\4&1&2&3\end{pmatrix}$ is a 4-cylet $\tau=(1432)$ =(4321)=(3214)=(2143) .If $\sigma$ is the 3-cycle(125), then $\sigma\tau=(125)(1432)=(1435)$

------------------------------------------------------------------

(remember: permutations are functions and $\sigma\tau$ means $\tau$ followed by $\sigma$ ); similarly $\tau\sigma=(1432)(125)=(2543)$ so that $\sigma\tau\neq\tau\sigma$ .There is one case, however, when two permutations do commute

Definition 6.2. The permutations $\sigma_{1},\sigma_{2},\ldots,\sigma_{\mathrm{r}}of$Sn Or $\sigma_{\mathrm{r}}$ Sn $\mathrm{S_n}$ are said to be disjoint provided thatfor each $1\leq i\leq r$ and every $k\varepsilon I_n$ $\sigma_{\mathrm{i}}(\mathbf{k})\neq\mathbf{k}$ implies $\sigma_{\mathrm{j}}(\mathbf{k})=\mathbf{k}$ for all $\mathrm{j\neq i}$

In other words $\sigma_1,\sigma_2,\ldots,\sigma_n$ are disjoint if and only if no element of $I_{n}$ is moved by more than one of $\sigma_{1},\ldots,\sigma_{r}$ . It is easy to see that $\tau\sigma=\sigma\tau$ whenever $\sigma$ and $\tau$ are disjoint.

Theorem 6.3. Every nonidentity permutation in $S_{\mathrm{n}}$ is uniquely (up to the order of the factors) a product of disjoint cycles, each of which has length at least 2.

SKETCH OF PROOF. Let $\sigma\varepsilon S_{n:}$ $\sigma\neq(1)$ .Verify that the following is an equivalence relation on $I_n$ : for $x,y\in I_{n},x\sim y$ ifand only if $y=\sigma^{m}(x)$ for some m e Z The equivalence classes $\{B:\mid1\leq i\leq s\}$ of this equivalence relation are called the orbits of $\sigma$ and form a partition of $I_n$ (Introduction, Theorem 4.1). Note that if $x\in B_i$, then $B_{i}=\{u\mid x\sim u\}=\{\sigma^{m}(x)\mid m\in\mathbf{Z}\}$ . Let $B_1,B_2,\ldots,B_r$ $(1\leq r\leq s)$ bethose orbits that contain more than one element each $(r\geq1$ since $\sigma\neq(1)$ ).For each $i\leq r$ define $\sigma_i\varepsilon S_n$ by:

$$\sigma_i(x)=\begin{cases}\sigma(x)&\text{if}\quad x\in B_i;\\x&\text{if}\quad x\notin B_i.\end{cases}$$

Each $\sigma_i$ is a well-defined nonidentity permutation of $I_n$ since $\sigma\mid B_i$ is a bijection $B_{i}\to B_{i}$ . $\sigma_{1},\sigma_{2},\ldots,\sigma_{r}$ are disjoint permutations since the sets $B_{\mathrm{l}},\ldots,B_{r}$ are mutually disjoint. Finally verify that $\sigma=\sigma_{1}\sigma_{2}\cdots\sigma_{r}$ ; (note that $x\in B_i$ implies $\sigma(x)=\sigma_i(x)$ if i r and $\sigma(x)=x$ if $i>r$ ; use disjointness). We must show that each $\sigma_i$ is a cycle.

If $x\in B_{i}\left(i\leq r\right)$ , then since $B_{i}$ is finite there is a least positive integer $d$ such that $\sigma^{d}(x)=\sigma^{i}(x)$ for somej $i(0\leq j<d)$ .Since $\sigma^{d-i}(x)=x$ and $0<d-j\leq d$ ,wemust have $j=0$ and $\sigma^{d}(x)=x$ . Hence $(x\sigma(x)\sigma^{2}(x)\cdots\sigma^{d-1}(x))$ is a well-defined cycle of length at least 2. If $\sigma^{m}(x)\in B_{i}$, then $m=ad+b$ for some $a,b\in\mathbf{Z}$ such that $0\leq b<d$ Hence $\sigma^{m}(x)=\sigma^{b+ad}(x)=\sigma^{b}\sigma^{ad}(x)=\sigma^{b}(x)\varepsilon\{x,\sigma(x),\sigma^{2}(x),\ldots,\sigma^{d-1}(x)\}$ .Therefore $B_{i}=\{x,\sigma(x),\sigma^{2}(x),\ldots,\sigma^{d-1}(x)\}$ and it follows that $\sigma_i$ is the cycle

$$.(x\sigma(x)\sigma^{2}(x)\cdots\sigma^{d-1}(x)).$$

Suppose $\tau_1,\ldots,\tau_l$ Tt $\tau_{l}$ are disjoint cycles such that $\sigma\:=\:\tau_{1}\tau_{2}\cdots\tau_{l}$ .Let $x\in I_n$ be such that $\sigma(x)\neq x$ By disjointness there exists a unique $j(1\leq j\leq t)$ with $\sigma(x)=\tau_{j}(x)$ Since $\sigma\tau_{j}=\tau_{j}\sigma$ , we have $\sigma^{k}(x)=\tau_{j}^{k}(x)$ for all $k$ k $k\varepsilon Z$ .Therefore, the orbit of $x$ under $\tau_{i}$ is precisely the orbit of $x$ under $\sigma$ ,say $B_{i}$ . Consequently, $\tau_{i}(y)=\sigma(y)$ for every $y\varepsilon B_i$ (since $y=\sigma^{n}(x)=\tau_{i}^{n}(x)$ for some $n\varepsilon Z$ ).Since $\tau_{i}$ is a cycle it has only one nontrivial orbit (verify!), which must be $B_i$ since $x\neq\sigma(x)=\tau_{i}(x)$ . Therefore $\tau_{j}(y)=y$ for all $y\notin B_i$, whence $\tau_{j}=\sigma_{i}$ . A suitable inductive argument shows that $r=1$ and (after reindexing) $\sigma_{i}=\tau_{i}$ for each $i=1,2,\ldots,r$ .

------------------------------------------------------------------

Corollary 6.4.The order of a permutation $\sigma$ E $S_{\mathrm{n}}$ is the least common multiple of the. orders of its disjoint cycles.

PROOF. Let $\sigma=\sigma_{1}\cdots\sigma_{r}$, with $\{\sigma_i\}$ disjoint cycles. Since disjoint cycles commute, $\sigma^{m}=\sigma_{1}^{m}\cdots\sigma_{r}^{m}$ for all $m\varepsilon Z$ $\mathbf{Z}$ Z and $\sigma^{m}=(1)$ if and only if $\sigma_{i}^{m}=(1)$ for all $i$ Therefore $\sigma^{m}=(1)$ if and only if $|\sigma_i|$ divides $m$ for all $i$ (Theorem 3.4). Since $|\sigma|$ is theleast such $m$ , the conclusion follows.

Corollary 6.5. Euery permutation in $S_{\mathrm{n}}$ can be written as a product of (not necessaril). disjoint) transpositions.

PROOF. It suffices by Theorem 6.3 to show that every cycle is a product of transpositions.This is easy: $(x_{1})=(x_{1}x_{2})(x_{1}x_{2})$ and for $r>1$ ， $(x_{1}x_{2}x_{3}\cdots x_{r})$ $=(x_1x_r)(x_1x_{r-1})\cdots(x_1x_3)(x_1x_2)$ .

Definition 6.6. A permutation $\tau\varepsilon S_n$ Sn $S_{\mathrm{n}}$ is said to be even [resp. odd] if t can be written. as a product of an even [resp. odd) number o f transpositions

The sign of a permutation $\tau$ , denoted sgn $\tau$ , is 1 or -1 according as $\tau$ is even or odd. The fact that sgn $\tau$ is well defined is an immediate consequence of

Theorem 6.7.A permutation in $S_{\mathrm{n}}$ Sn $\mathbf{S}_{\mathrm{n}}\left(\mathbf{n}\geq2\right)$ cannot be both even and odd

PROOF. Let $i_1,i_2,\ldots,i_n$ be the integers $1,2,\ldots,n$ in some order and define $\Delta(i_1,\ldots,i_n)$ to be the integer $\mathbf{II}\left(i_{j}-i_{k}\right)$ , where the product is taken over all pairs $(j,k)$ such that $1\leq j<k\leq n$ . Note that $\Delta(i_1,\ldots,i_n)\neq0$ .We first compute $\Delta(\sigma(i_1),\ldots,\sigma(i_n))$ when $\sigma\varepsilon S_n$ is a transposition, say $\sigma=(i_{c}i_{d})$ with $c<d.$ Wehave $\Delta(i_1,\ldots,i_n)=(i_c-i_d)ABCDEFG$ where

$$\begin{aligned}
&A=\prod_{\begin{array}{c}j<k\\j,k\neq c,d\end{array}}(i_{i}-i_{k});\quad B=\prod_{j<c}(i_{i}-i_{c});\quad C=\prod_{j<c}(i_{i}-i_{d}); \text{1} \\
&D=\prod_{c<j<d}(i_{i}-i_{d});\quad E=\prod_{c<k<d}(i_{c}-i_{k});\quad F=\prod_{d<k}(i_{c}-i_{k}); \\
&G=\prod_{d<k}(i_{d}-i_{k}).
\end{aligned}$$

We write $\sigma(A)$ for I (o(i) - o(is) and similarly for $\sigma(B),\:\sigma(C)$ , etc. Verify that iksed $\sigma(A)=A$ ； $\sigma(B)=C$ and $\sigma(C)=B$ ； $\sigma(D)=(-1)^{d-c-1}E$ and $\sigma(E)=(-1)^{d-c-1}D$ $\sigma(F)=G$ , and $\sigma(G)=F$ . Finally, $\sigma(i_{c}-i_{d})=\sigma(i_{c})-\sigma(i_{d})=i_{d}-i_{c}=-(i_{c}-i_{d})$ Consequently,

$$\begin{aligned}\Delta(\sigma(i_{1}),\ldots,\sigma(i_{n}))&=\sigma(i_{c}-i_{d})\sigma(A)\sigma(B)\cdots\sigma(G)\:=\:(-1)^{1+2(d-c-1)}(i_{c}-i_{d})ABCDEFG\\&=\:-\Delta(i_{1},\ldots,i_{n}).\end{aligned}$$

Suppose for some $\tau\varepsilon S_n$ ， $\tau=\tau_{1}\cdots\tau_{r}$ and $\tau=\sigma_{1}\cdots\sigma_{s}$ with $\tau_i,\:\sigma_i$ transposi tions, $r$ even and $s$ odd. Then for $(i_1,\ldots,i_n)=(1,2,\ldots,n)$ the previous paragrapl implies $\Delta(\tau(1),\ldots,\tau(n))=\Delta(\tau_1\cdots\tau_r(1),\ldots,\tau_1\cdots\tau_r(n))=-\Delta(\tau_2\cdots\tau_r(1)$, TT,(n)) =-(T,(1),. $\tau_1\cdots\tau_r(n))=-\Delta(\tau_2\cdots\tau_r(1),\ldots$,

1

------------------------------------------------------------------

$\tau_{2}\cdots\tau_{r}(n))=\cdots=(-1)r\Delta(1,2,\ldots,n)=\Delta(1,2,\ldots,n)$ Similarly $\Delta(\tau(1),\ldots,\tau(n))$ $=(-1)^*\Delta(1,2,\ldots,n)=-\Delta(1,2,\ldots,n)$ , whence $\Delta(1,2,\ldots,n)=-\Delta(1,2,\ldots,n)$ This is a contradiction since $\Delta(1,2,\ldots,n)\neq0$ .

Theorem 6.8. For each $n\geq2$ let $\mathbf{A}_{\mathrm{n}}$ be the set of all even permutations of $S_{\mathrm{n}}$ Then $\mathbf{A}_{\mathrm{n}}$ is a normal subgroup of $S_{\mathrm{n}}$ of index 2 and order $|S_{\mathrm{n}}|/2=$n!/2. Furthermore $\mathbf{A}_{\mathbf{n}}$ is the only subgroup of $S_{\mathrm{n}}$ of index 2

The group $A_n$ is called the alternating group on n letters or the alternating group of degree n.

SKETCH OF PROOF OF 6.8. Let $C$ be the multiplicative subgroup {1,- 1! of the integers. Define a map $f{:}S_n\to C$ by $\sigma\vdash$ $\sigma\vdash$sgn $\sigma$ and verify that $f$ is an epimorphism of groups.Since the kernel of fis clearly An $A_n$ $A_n,A_n$ An $A_n$ is normal in $S_n$ .By the First Isomorphism Theorem $S_n/A_n\cong C$ , which implies $[S_n:A_n]=2$ and $|A_n|=|S_n|/2$ $A_n$ is the unique subgroup of $S_n$ of index 2 by Exercise 6.

Definition6.9.A group G is said to be simpleifG has noproper normal subgroups.

The only simple abelian groups are the $Z_p$ with $p$ prime(Exercise 4.3). There are a number of nonabelian simple groups; in particular, we have

Theorem 6.10. The alternating group $\mathbf{A}_{\mathrm{n}}$ is simple if and only ij. $f\mathbf{n}\neq4$

The proof we shall give is quite elementary. It will be preceded by two lemmas Recall that if $\tau$ is a 2-cycle, $\tau^{2}=(1)$ and hence $\tau=\tau^{-1}$

Lemma 6.11. Let r,s be distinct elements of $\{1,2,\ldots,n\}$ .Then $\mathbf{A}_{\mathrm{n}}(\mathbf{n}\geq3)$ isgen erated by the 3-cycles $|1\leq\mathbf{k}\leq\mathbf{n}$ $|1\leq\mathbf{k}\leq\mathbf{n}$ |(rsk$)|1\leq$k$\leq$n,k$\neq$r,s$\rangle$ k≠r,s} $\mathbf{k\neq r,s}$

PROOF. Assume $n>3$ (the case $n=3$ is trivial). Every element of. $A_n$ is a product of terms of the form $(ab)(cd)$ or $(ab)(ac)$ ,where $a,b,c,d$ are distinct elements of $\{1,2,\ldots,n\}$ . Since $(ab)(cd)=(acb)(acd)$ and $(ab)(ac)=(acb)$ $A_n$ is generated by the set of all 3-cycles. Any 3-cycle is of the form (rsa), (ras), $(rab)$ , (sab), or $(abc)$ where $a,b,c$ are distinct and $a,b,c\neq r,s$ .Since $(ras)=(rsa)^2$ ， $(rab)=(rsb)(rsa)^2$ $(sab)=(r$s$b)^2(rsa)$ , and $(abc)=(rsa)^{2}(rsc)(rsb)^{2}(rsa)$ $A_n$ is generated by

$$\{(rsk)\mid1\leq k\leq n,k\neq r,s\}.$$

Lemma 6.12.If N is a normal subgroup of $\dot{}\mathbf{A}_{\mathrm{n}}$ (n$\geq3.$ ) and N contains a 3-cycle, then. $\mathbf{N}=\mathbf{A}_{\mathbf{n}}$

PROOF. If $(rsc)\varepsilon N$ ，then for any $k\neq r,s,c$ （≠r,s,c $:\neq r,s,c,\:(rsk)=\:(rs)(ck)(rsc)^{2}(ck)(rs)$ $=[(rs)(ck)](rsc)^{2}[(rs)(ck)]^{-1}\varepsilon N$ Hence $N=A_{n}$ by Lemma 6.11.

------------------------------------------------------------------

PROOF OF THEOREM 6.10. $A_{2}=(1)$ and $A_3$ is the simple cyclic group of order 3. It is easy to verify that {(1),(12)(34),(13)(24),(14)(23) is a normal subgroup of $A_4$ (Exercise 7). If $n\geq5$ and $N$ is a nontrivial normal subgroup of $A_n$ we shall show $N=A_n$ by considering the possible cases.

CASE 1. $N$ contains a 3-cycle; hence $N=A_{n}$ by Lemma 6.12.

CASE 2. $N$ contains an element $\sigma$ , the product of disjoint cycles, at least one of which has length $r\geq4$ . Thus $\sigma=(a_{1}a_{2}\cdots a_{r})\tau$ (disjoint). Let $\delta=(a_{1}a_{2}a_{3})\varepsilon A_{n}$ .Then $\sigma^{-1}(\delta\sigma\delta^{-1})\varepsilon\:N$ by normality. But

$$\sigma^{-1}(\delta\sigma\delta^{-1})\:=\:\tau^{-1}(a_{1}a_{r}a_{r-1}\cdots a_{2})(a_{1}a_{2}a_{3})(a_{1}a_{2}\cdots a_{r})\tau(a_{1}a_{3}a_{2})\:=\:(a_{1}a_{3}a_{r})\:\varepsilon\:N.$$

Hence $N=A_{n}$ by Lemma 6.12.

CASE 3. $N$ contains an element $\sigma$ , the product of disjoint cycles, at least two of whichhave length 3, so that $\sigma=(a_{1}a_{2}a_{3})(a_{4}a_{5}a_{6})\tau$ -(disjoint). Let $\delta=(a_{1}a_{2}a_{4})\varepsilon\:A_{n}$ $A_n$ $A_n$ Then as above, $N$ contains $\sigma^{-1}(\delta\sigma\delta^{-1})=\tau^{-1}(a_{4}a_{6}a_{5})(a_{1}a_{3}a_{2})(a_{1}a_{2}a_{4})(a_{1}a_{2}a_{3})(a_{4}a_{5}a_{6})\tau$ $(a_1a_4a_2)=(a_1a_4a_2a_6a_3)$ .Hence $N=A_{n}$ by case 2.

CASE 4. $N$ contains an element $\sigma$ that is the product of one 3-cycle and some 2-cycies, say $\sigma=(a_{1}a_{2}a_{3})\tau$ (disjoint), with $\tau$ a product of disjoint 2-cycles. Then $\sigma^2\varepsilon N$ and $\sigma^{2}=(a_{1}a_{2}a_{3})\tau(a_{1}a_{2}a_{3})\tau=(a_{1}a_{2}a_{3})^{2}\tau^{2}=(a_{1}a_{2}a_{3})^{2}=(a_{1}a_{3}a_{2})$ ,whence $N=A_{n}$ by Lemma 6.12.

CASE 5. Every element of $N$ is the product of (an even number of) disjoint 2-cycles. Let $\sigma\varepsilon N$ ，with $\sigma=(a_{1}a_{2})(a_{3}a_{4})\tau$ (disjoint). Let $\delta=(a_{1}a_{2}a_{3})\in A_{n}$ ; then $\sigma^{-1}(\delta\sigma\delta^{-1})$ E $N$ as above. Now $\sigma^{-1}(\delta\sigma\delta^{-1})=\tau^{-1}(a_{3}a_{4})(a_{1}a_{2})(a_{1}a_{2}a_{3})(a_{1}a_{2})(a_{3}a_{4})\tau(a_{1}a_{3}a_{2})$ $=(a_1a_3)(a_2a_4)$ .Since $n\geq5$ , there is an element $b\in\{1,2,\ldots,n\}$ distinct from $a_1,a_2,a_3,a_4$ . Since $\xi=(a_{1}a_{3}b)\varepsilon\:A_{n}$ An $A_n$ and $\zeta=(a_{1}a_{3})(a_{2}a_{4})\varepsilon\:N,\zeta(\xi\zeta\xi^{-1})\varepsilon\:N.$ But $\zeta(\xi\zeta\xi^{-1})$ $=(a_{1}a_{3})(a_{2}a_{4})(a_{1}a_{3}b)(a_{1}a_{3})(a_{2}a_{4})(a_{1}ba_{3})=(a_{1}a_{3}b)\varepsilon\:N.$ Hence $N=A_n$ by Lemma 6.12. Since the cases listed cover all the possibilities, $A_n$ has no proper normal sub-

groups and hence is simple.

Another important subgroup of $S_n\left(n\geq3\right)$ is the subgroup $D_n$ generated by $a=(123\cdots n)$ and

$$b=\begin{pmatrix}1&2&3&4&5&\cdots&i&\cdots&n-1&n\\1&n&n-1&n-2&n-3&\cdots&n+2-i&\cdots&3&2\end{pmatrix}$$

$=\prod_{2\leq i<n+2-i}(i\:n+2-i).D_n$ iscalled the dihedral group of degre n. The group $D_n$ is isomorphic to and usually identified with the group of all symmetries of a regular

polygon with $n$ sides (Exercise. 13). In particular $D_{4}$ is (isomorphic to) the group $D_4^*$ of symmetries of the square(seepages 25-26).

Theorem 6.13. For each $n\geq3$ the dihedral group $\mathbf{D}_{\mathrm{n}}$ is a groupoforder 2nwhose generators a and b satisfy:

$$\mathrm{a^n=(1);b^2=(1);a^k\neq(1)~if~0<k<n;}$$
(ii) $\mathbf{ba}=\mathbf{a}^{-1}\mathbf{b}$

------------------------------------------------------------------

Any group G which is generated by elements a,b e G satisfying (i) and (i) for some $n\geq3$ (with e e G in place of(1)) is isomorphic to $\mathbf{D}_{\mathrm{n}}$

SKETCH OF PROOF. Verify that $a,b$ E $D_n$ as defined above satisfy (i) and (i) whence $D_{n}=\langle a,b\rangle=\left\{a^{i}b^{i}\mid0\leq i<n;j=0,1\right\}$ j = 0,1 $j=0,1$ (see Theorem 2.8). Then verify that the $2n$ elements $a^{i}b^{i}\left(0\leq i<n;j=0,1\right.$ ) are all distinct (just check their action on 1 and 2), whence $|D_{n}|=2n$ Suppose $G$ is a group generated by $a,b\varepsilon G$ and $a,b$ satisfy (i) and (i) for some

$n\geq3$ ByTheorem 2.8 every element of $G$ is a finite product $a^{m_1}b^{m_2}a^{m_3}b^{m_4}\cdots b^{m_k}(m_i\varepsilon\mathbf{Z})$ By repeated use of (i) and (i) any such product may be written in the form abi with $0\leq i<n$ and $j=0,1$ (in particular note that $b^2=e$ and (i) imply $b=b^{-1}$ and $ab=ba^{-1}$ ). Denote the generators of $D_n$ by $a_1,b_1$ to avoid confusion and verify that the mapf: $D_n\to G$ givenby $a_1^ib_1^j\to a^ib^j$ is an epimorphism of groups. To complete the proof we show that $f$ is a monomorphism. Suppose $f(a_{1}^{i}b_{1}^{i})=a^{i}b^{i}=e\varepsilon G$ with $0\leq i<n$ and $j=0,1$ . If $j=1$ ,then $a^{i}=b$ and by (i) $a^{i+1}=a^{i}a=ba=a^{-1}b$ $=a^{-1}a^{i}=a^{i-1}$ , which implies $a^2=e$ . This contradicts (i) since $n\geq3$ . Therefore $j=0$ and $e\:=\:a^{i}b^{0}\:=\:a^{i}$ with $0\leq i<n$ ,which implies $i=0$ by (i). Thus $f(a_1ib_1i)=e$ implies $a_{1}ib_{1}i=a_{1}0b_{1}^{0}=(1)$ . Therefore $f$ is a monomorphism by Theorem 2.3.

This theorem is an example of a characterization of a group in terms of "generators and relations." A detailed discussion of this idea will be given in Section 9.

### EXERCISES

1. Find four different subgroups of $S_4$ that are isomorphic to $S_3$ and nine isomorphic to $S_2$

2. (a) $S_n$ is generated by the $n-1$ transpositions (12), (13), (14), . . . , (1n). [Hint. ( $1i)(1j)(1i)=(ij).$ (b) $S_n$ is generated by the $n-1$ transpositions (12), (23), (34), . . . ,(n - 1 n) [H $Iint:(1j)=(1\:j-1)(j-1\:j)(1\:j-1)$ ; use (a).)

3. If $\sigma=(i_{1}i_{2}\cdots i_{r})\varepsilon S_{n}$ and $\tau\varepsilon S_n$ , then $\tau\sigma\tau^{-1}$ is the $r$ -cycle $(\tau(i_{1})\tau(i_{2})\cdots\tau(i_{r}))$

4.(a) $S_n$ is generated by $\sigma_{1}=(12)$ and $\tau=(123\cdots n)$ . [Hint: Apply Exercise 3 to $\sigma_{1}$ $\sigma_{2}=\tau\sigma_{1}\tau^{-1}$ $\sigma_{3}=\tau\sigma_{2}\tau^{-1}$ ,..., $\sigma_{n-1}=\tau\sigma_{n-2}\tau^{-1}$ and use Exercise 2(b).] (b) $S_n$ is generated by (12) and $(23\cdots n)$

5. Let $\sigma,\tau\varepsilon S_n$ . If $\sigma$ is even (odd), then so is $\tau\sigma\tau^{-1}$

6. $A_n$ is the only subgroup of $S_n$ of index 2. [Hinr: Show that a subgroup of index 2 must contain all 3-cycles of $S_n$ and apply Lemma 6.11.]

7. Show that $N=\{(1),(12)(34),(13)(24),(14)(23)\}$ is a normal subgroup of $S_4$ con tained in $A_4$ such that $S_4/N\cong S_3$ and $A_4/N\cong Z_3$

8. The group $A_4$ has no subgroup of order 6.

9. For $n\geq3$ let $G_n$ be the multiplicative group of complex matrices generated by $x=\begin{pmatrix}0&1\\1&0\end{pmatrix}$ and $y=\begin{pmatrix}e^{2\pi i/n}&0\\0&e^{-2\pi i/n}\end{pmatrix}$ where $i^{2}=-1$ .Show hat $G_{n}\cong D_{n}$ (Hint: recall that $e^{2\pi i}=1$ and $e^{k2\pi i}\neq1$ ,where $k$ is real, unless $k\varepsilon Z$

------------------------------------------------------------------

10. Let a be the generator of order $n$ of $D_n$ . Show that $\langle a\rangle\lhd D_n$ and $D_n/\langle a\rangle\cong Z_2$ 11. Find all normal subgroups of $D_n$

12. The center (Exercise 2.11) of the group $D_n$ is $\langle e\rangle$ if $n$ is odd and isomorphic to $Z_2$ if $n$ is even.

13. For each $n\geq3$ let $P_n$ be a regular polygon of $n$ sides (for $n=3,P_{n}$ Pn $P_n$ is an equilateral triangle; for $n=4$ ,a square). A symmetry of $P_n$ is a bijection $P_n\to P_n$ that preserves distances and maps adjacent vertices onto adjacent vertices.

(a)The set $D_n^*$ of all symmetries of $P_n$ is a group under the binary operation of composition of functions. (b) Every fe $D_n^*$ is completely determined by its action on the vertices of $P_n$

Number the vertices consecutively $1,2,\ldots,n;$ then each $f\varepsilon D_n^*$ determines a unique permutation $\sigma_f$ of $\{1,2,\ldots,n\}$ . The assignment $f$仁$\sigma_f$ defines a monomorphism of groups $\varphi:D_n^*\to S_n$ (c) $D_n^*$ is generated by fand $g$ ,where $f$ is a rotation of $2\pi/n$ degrees about the

center of $P_n$ and $g$ is a reflection about the "diameter" through the center and. vertex 1.
$$n)\quad\mathrm{and}\quad\sigma_{q}=\begin{pmatrix}1&2&3&\cdots&n-1&n\\1&n&n-1&\cdots&3&2\end{pmatrix},$$

whence (d) $\sigma_{I}=(123\cdots n)$ Im $\varphi=D_{n}$ and $D_n^*\cong D_n$

## 7. CATEGORIES: PRODUCTS, COPRODUCTS, AND FREE OBJECTS

Since we now have several examples at hand, this is an appropriate time to introduce the concept of a category. Categories will serve as a useful language and provide a general context for dealing with a number of different mathematical situations. They are studied in more detail in Chapter $X$ The intuitive idea underlying the definition of a category is that several of the

mathematical objects already introduced (sets, groups, monoids) or to be introduced (rings, modules) together with the appropriate maps of these objects (functions for sets; homomorphisms for groups,etc.) have a number of formal properties in common.For example, in each case composition of maps (when defined) is associative; each object A has an identity map $\mathbf{l}_A:A\to A$ with certain properties. These notions are formalized in

Definition 7.1. A category is aclass C of objects (denoted A,B,C, . . .) together with

(i)aclass of disjoint sets, denoted hom(A,B),one for each pair of objects in ୧ ;(an element'f of hom(A,B) is called a morphism from A to B and is denoted $\mathbf{f}:\mathbf{A}\to\mathbf{B}$ (i)for each triple(A,B,C) of objects of C a function

$$hom(B,C)\times hom(A,B)\to hom(A,C);$$

(for morphisms $\mathbf{f}:\mathbf{A}\to\mathbf{B}$ f:A→B $\mathbf{f}:\mathbf{A}\to\mathbf{B}$, g$:\mathbf{B}\to\mathbf{C}$, $\mathbf{g}:\mathbf{B}\to\mathbf{C}$, g:B→C this function is written $(\mathbf{g},\mathbf{f})\mapsto\mathbf{g}\circ\mathbf{f}$ and $\mathbf{g}\circ\mathbf{f}:\mathbf{A}\to\mathbf{C}$ is called the composite off and g); all subject to the two axioms:

(l) Associativity. Iff : $\mathbf{A}\to\mathbf{B}\mathbf{g}:\mathbf{B}\to\mathbf{C},\mathbf{h}:\mathbf{C}\to\mathbf{D}$ are morphisms of C,then $\mathbf{h}\circ(\mathbf{g}\circ\mathbf{f})=(\mathbf{h}\circ\mathbf{g})\circ\mathbf{f}$

------------------------------------------------------------------

(I) Identity. For each object B of ୧ there exists a morphism $\mathbf{1}_{\mathbf{B}}:\mathbf{B}\to\mathbf{B}$ such thatfor anyf： $\mathbf{A}\rightarrow\mathbf{B}$, $\mathbf{g}:\mathbf{B}\to\mathbf{C}$

$$\mathbf{1}_{\mathbf{B}}\circ\mathbf{f}=\mathbf{f}\quad\mathrm{and}\quad\mathbf{g}\circ\mathbf{1}_{\mathbf{B}}=\mathbf{g}.$$

In a category ୧ a morphism $f:A\to B$ is called an equivalence if there is in ୧ a morphism $g:B\to A$ such that $g\circ f=1_{A}$ and $f\circ g=1_B$ . The composite of two equivalences, when defined, is an equivalence. If. $f:A\to B$ is an equivalence, $A$ and $B$ are said to be equivalent.

EXAMPLE. Let S be the class of all sets; for $A,B\in S.$ A,B ε S $A,B\in S$, hom$(A,B)$ is the set of all functions $f:A\to B$ . Then S is easily seen to be a category. By (13) of Introduction, Section 3, a morphism $f$ of S is an equivalence if and only if $f$ is a bijection.

EXAMPLE. Let S be the category whose objects are all groups; $\hom(A,B)$ is the set of all group homomorphisms $f:A\to B$ . By Theorem 2.3, a morphism $f$ is an equivalence if and only if $f$ is an isomorphism. The category $G$ of all abelian groups is deflned similarly.

EXAMPLE. A (multiplicative) group $G$ can be considered as a category with one object, $G$ .Let hom $(G,G)$ be the set of elements of $G$ ; composition of morphisms $a,b$ is simply the composition ab given by the binary operation in $G$ .Every morphism is an equivalence (since every element of $G$ has an inverse). $1_G$ is the identity element $e$ of $G$

EXAMPLE. Let the objects be all partially ordered sets $(S,\leq)$ .A morphism $(S,\leq)\to(T,\leq)$ is a function $f:S\to T$ such that for x,yeS $x,y\varepsilon S$ $x,y\in S,x\leq y\Rightarrow f(x)\leq f(y)$

EXAMPLE. Let C be any category and define the category $\mathcal{D}$ whose objects are all morphisms of ୧ .If $f:A\to B$ and $g:C\to D$ are morphisms of $\mathbb{C}$ ,then $\hom(f,g)$ consists of all pairs $(\alpha,\beta)$ ，where $\alpha:A\to C$ ， $\beta:B\to D$ are morphisms of $\mathbb{C}$ such that the following diagram is commutative:

![](https://storage.simpletex.cn/view/fWe9dEmRvNsuHPtK09yzLCnYgr6aggouP)

Definition 7.2. Let ୧ be a category and $\{A_i$ IAi $\{\mathbf{A}_{\mathrm{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\}$ a family of objects of C. A product for the family {Ai $\{A_{\mathrm{i}}$ $\{\mathbf{A}_{\mathrm{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\}$ is an object $P$ of C together with u family of mor-. phisms $\{\pi_{\mathrm{i}}:\mathbf{P}\to\mathbf{A}_{\mathrm{i}}$ i e I} such that for any object B and family of morphisms. $\{\varphi_{\mathrm{i}}:B\to\mathbf{A}_{\mathrm{i}}|$iεI 3, there is a unique morphism $\varphi:\mathbf{B}\to\mathbf{P}$ such that $\pi_{\mathrm{i}}\circ\varphi=\varphi_{\mathrm{i}}$ for all ie I.

A product $P$ of $\{A_i\mid i\in I\}$ isusul denoled $\prod_{i\in I}A_i$ .Ilis so mtime elfuto de scribe a product in terms of commutative diagrams, especially in the case $I=\{1,2\}$ A product for $\{A_1,A_2\}$ is a diagram (of objects and morphisms) $A_{1}\stackrel{\pi_{1}}{\leftarrow}P\stackrel{\pi_{2}}{\rightarrow}A_{2}$ such that: for any other diagram of the form $A_{1}\stackrel{\varphi_{1}}{\operatorname*{\leftarrow}}B\stackrel{\varphi_{2}}{\operatorname*{\rightarrow}}A_{2}$ , there is a unique morphism $\varphi:B\to P$ such that the following diagram is commutative.

------------------------------------------------------------------

![](https://storage.simpletex.cn/view/fBIiXy1Ipt5bModaezKHoU7bt2NShtSWR)

A family of objects in a category need not have a product. In several familiar categories, however, products always exist. For example, in the category of sets the Cartesian product $\prod_{i\in I}A_i$ is a product o the family $\{A_i\mid i\in I\}$ by Introduction, Theorem 5.2. In the next section we shall show that products exist in the category of groups.

Theorem 7.3. If $(\mathbf{P},\{\pi_{\mathrm{i}}\}.$ and $(\mathbb{Q},\{\psi_i\})$ are both products of thefamily $\{\mathbf{A}_{\mathrm{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\}$ of objects of a category C, then $P$ and $Q$ are equivalent

PROOF. Since $P$ and $Q$ are both products, there exist morphisms $f:P\to Q$ and $g:Q\to P$ such that the following diagrams are commutative for each i e I:

![](https://storage.simpletex.cn/view/fESsl63RW8Nz7KgSEYupsGUSoVqGtC8c9)

Composing these gives for each i e $I$ a commutative diagram:

![](https://storage.simpletex.cn/view/fDRbL1TLSnYEbnTrfRaMpQUoGU6edRWBE)

Thus $g\circ f:P\to P$ is a morphism such that $\pi_i\circ(g\circ f)=\pi_i$ for all i e I. But by the definition of product there is a unique morphism with this property. Since the map $|_P:P\to P$ is also such that $\pi_{i}\circ\mathbf{l}_{P}=\pi_{i}$ for all $i\varepsilon I.$ we must have $g\circ f=1_{P}$ by uniqueness. Similarly, using the fact that $Q$ is a product, one shows that $f\circ g=1_Q$ Hence $f:P\to Q$ is an equivalence.

Since abstract categories involve only objects and morphisms (no elements) every statement about them has a dual statement, obtained by reversing all the arrows (morphisms) in the original statement. For example, the dual of Definition 7.2 is

Definition 7.4. A coproduct (or sum) for the family $\{\mathbf{A}_{\mathrm{i}}|$ i e I} of objects in a cate-. gory ୧ is an object S of C,together with a family ofmorphisms $\{\iota_{\mathrm{i}}:\mathbf{A}_{\mathrm{i}}\to\mathcal{S}|$ ieI} such that for any object B and family of morphisms. $\{\psi_{\mathrm{i}}:\mathbf{A_{i}}\to\mathbf{B}$ |i e I}, there is $a$ unique morphism $\psi:\mathcal{S}\to\mathbf{B}$ such that $\psi\circ\iota_{\mathrm{i}}=\psi_{\mathrm{i}}$ for all i e I.

------------------------------------------------------------------

Thereis no unform notation fo coproducs although $\coprod_{i\in I}A_i$ is sometimes used. In the next two sections we shall discuss coproducts in the category S of groups and the category $G$ of abelian groups. The following theorem may be proved by using the “dual argument" to the one used to prove Theorem 7.3 (do it!).

Theorem 7.5. $If(\mathcal{S},\{\iota_{\mathrm{i}}\})$ and $(\mathbf{S}^{\prime},\{\lambda_{\mathrm{i}}\})$ are both coproducts for the family {A; | i eI} of objects of a category C, then S and $\mathbf{S}^{\prime}$ are equivalent.

In several of the categories mentioned above (for example, groups), every object in the category is in fact a set (usually with some additional structure) and every morphism $f:A\to B$ in the category is a function on the “underlying sets" (usually with some other properties as well).We formalize this idea in

Definition 7.6. A concrete category is a category C together with a function $\sigma$ that assigns to each object A of C a set $\sigma(\mathbf{A})$ (called the underlying set of A) in such a way that:

(i) every morphism $\mathbf{A}\to\mathbf{B}$ of C is a function on the underlying sets $\sigma(\mathbf{A})\to\sigma(\mathbf{B})$ (i) the identity morphism of each object A of C is the identity function on the

underl ying set $\sigma(\mathbf{A})$ (i)composition of morphisms in C agrees with composition offunctions on the

underl ying sets.

EXAMPLES. The.category of groups, equipped with the function that assigns to each group its underlying set in the usual sense, is a concrete category. Similarly the categories of abelian groups and partially ordered sets, with the obvious underlying sets, are concrete categories.However, in the third example after Definition 7.1, if the function $\sigma$ assigns to the group $G$ the usual underlying set $G$ ,then the category in question is not a concrete category (since the morphisms are not functions on the set $G$ ).

Concrete categories are frequently useful since one has available not only the properties of a category, but also certain properties of sets, subsets, etc. Since in virtually every concrete category we are interested in, the function $\sigma$ assignsto an object its underlying set in the usual sense (as in the examples above), we shall denote both the object and its underlying set by the same symbol and omit any explicit reference to $\sigma$ . There is little chance of confusion since we shall be careful in a concrete category $\mathbb{C}$ to distinguish morphisms of ୧ (which are by definition also functions on the underlying sets) and maps (functions on the underlying sets, which may not be morphisms of C).

------------------------------------------------------------------

The essential fact about a free object $F$ is that in order to define a morphism with domain $F$ ,it suffices to specify the image of the subset $i(X)$ as is seen in the following examples.

EXAMPLES. Let $G$ be any group and $g\varepsilon G$ . Then the map $\bar{f}:\mathbf{Z}\to G$ defined by $\bar{f}(n)=g^n$ is easily seen to be the unique homomorphism $\mathbf{Z}\to G$ such that $11\mapsto g$ Consequently, if $X=\{1\}$ and $i:X\to\mathbf{Z}$ is the inclusion map, then $\mathbf{Z}$ is free on $X$ in the category of groups; (given $f:X\to G$ , let $g=f(1)$ and define $\bar{f}$ as above). In other words, to determine a unique homomorphism from $\mathbf{Z}$ to $G$ we need only specify the image of 1 ε Z (that is, the image of $i(X))$ . The (additive) group $\mathbf{Q}$ of rational numbers does nor have this property. It is not difficult to show that there is no nontrivial homomorphism $\mathbf{Q}\to S_3$ . Thus for any set $X$ , function $i:X\to\mathbf{Q}$ and function $f:X\to S_3$ with $f(x_1)\neq(1)$ for some $x_1\varepsilon X$ , there is no homomorphism $\bar{f}:\mathbf{Q}\to S_3$ with $\bar{f}i=f.$

Theorem 7.8.If C is a concrete category,F and $\mathbf{F}^{\prime}$ are objecis of C such that F is free onthe setX and $\mathbf{F}^{\prime}$ isfree ontheset $X^{\prime}$ and $|\mathbf{X}|=|\mathbf{X}^{\prime}|$ , then F is equivalent to $F^{\prime}$

Note that the hypotheses are satisfied when $F$ and $F^{\prime}$ are both free on the same set $X$

PROOF OF 7.8. Since $F,\:F^{\prime}$ $F^{\prime}$ $F^{\prime}$ are free and $|X|=|X^{\prime}|$ ,there is a bijectior $f:X\to X^{\prime}$ and maps $i:X\to F$ and $j:X^{\prime}\to F^{\prime}$ . Consider the map $jf:X\to F^{\prime}$ .Since $F$ is free, there is a morphism $\varphi:F\to F^{\prime}$ such that the diagram

![](https://storage.simpletex.cn/view/fzpoO3cQ0Dz3HLmgfODVleLGlheTlGigP)

is commutative. Similarly, since the bijection $f$ has an inverse $f^{-1}:X^{\prime}\to X$ and $F^{\prime}$ is free, there is a morphism $\psi:F^{\prime}\to F$ such that:

![](https://storage.simpletex.cn/view/fXWc3XgVhV7DLS2khTDyGkOgUMzSpcYBn)

is commutative. Combining these gives a commutative diagram.

![](https://storage.simpletex.cn/view/fuqEIbtOqAm64pDfOnDAhNLloOAWXtk6D)

------------------------------------------------------------------

Hence $(\psi\circ\varphi)i=i\mathbf{1}_{X}=i.$ But $1_{Fi}=i.$ . Thus by the uniqueness property of free objects we must have $\psi\circ\varphi=1_{F}$ . A similar argument shows that $\varphi\circ\psi=1_{F^{\prime}}$ . Therefore $F$ is equivalent to $F^{\prime}$ .

Products, coproducts,and free objects are all defined via universal mapping properties (that is, in terms of the existence of certain uniquely determined morphisms). We have also seen that any two products (or coproducts) for a given family of objects are actually equivalent (Theorems 7.3 and 7.5). Likewise twofree objects on the same set are equivalent (Theorem 7.8). Furthermore there is a distinct similarity between the proofs of Theorems 7.3 and 7.8. Consequently it is not surprising that all of the notions just mentioned are in fact special cases of a single concept

Definition 7.9. An objecr I in a category C is said to be universal (or initial) if for each object C of C there exists one and only one morphism. $\mathbf{I}\to\mathbf{C}$ . An object T of C. is said to becouniversal (or terminal) if for eachobject $C$ of $\mathbb{C}$ there exists one and. only one morphism $\mathbb{C}\to\mathbb{T}$

We shall show below that products, coproducts, and free objects may be considered as (co)universal objects in suitably chosen categories. However, this characterization is not needed in the sequel. Since universal objects will not be mentioned again (except in occasional exercises) until Sections II1.4,II1.5,and IV.5, the reader maywish to omit thefollowing material for the present.

Theorem 7.10. Any two universal [resp. couniversal] objects in a category C are equivalent.

PROOF. Let I and $J$ be universal objects in C. Since $I$ is universal, there is a unique morphism $f:I\to J$ Similarly, since $J$ is universal, there is a unique morphism $g:J\to I.$ The composition $g\circ f:I\to I$ is a morphism of ୧ .But $1_I:I\to I$ is also a morphism of'e. The universality of Iimplies that there is a unique morphism $I\to I.$ whence $g\circ f=1_{I}$ . Similarly the universality of $J$ implies that $f\circ g=1_J$ . Therefore $f:I\to J$ is an equivalence. The proof for couniversal objects is analogous.

EXAMPLE. The trivial group $\langle e\rangle$ is both universal and couniversal in thecategory of groups.

EXAMPLE. Let $F$ be a free object on the set $X$ (with $i:X\to F$ )in a concrete category ୧ Define a new category $\textcircled{1}$ as follows. The objects of $\textcircled{1}$ are all mapsofsets $f:X\to A$ , where $A$ is (the underlying set of) an object of $\mathbb{C}.$ A morphism in $\mathcal{D}$ from $f:X\to A$ to $g:X\to B$ is defined to be a morphism $h:A\to B$ of ୧ such that the diagram:

![](https://storage.simpletex.cn/view/fZNDYyCemn7CIWG8l8TEVtqbGMqCYS4g5)

------------------------------------------------------------------

1

is commutative (that is, $hf=g.$ 0.Verify that $\mathbf{1}_A:A\to A$ is the identity morphism from fto $f$ in $\mathfrak{D}$ and that $h$ is an equivalence in $\mathfrak{D}$ if and only if $h$ is an equivalence in ୧ .Since $F$ is free on the set $X$ , there is for each map $f:X\to A$ a unique morphism $\bar{f}:F\to A$ such that $\bar{f}i=f.$ This is precisely the statement that $i:X\to F$ is a universal object in the category $\mathcal{D}$

EXAMPLE. Let $\{A_i\mid i\in I\}$ be a family of objects in a category C. Defne a category & whose objects are all pairs $(B,\{\:f_{i}\mid i\in I\})$ ,where $B$ is an object of ୧ and for each i, $f_{i}:B\to A_{i}$ is a morphism of C. A morphism in & from $(B,\{f_{i}|i\in I\})$ to $(D,|g_{i}|i\in I\})$ is defined to be a morphism $h:B\to D$ of C such that $g_{i}\circ h=f_{i}$ for every i e I. Verify that $1_{B}$ is the identity morphism from $(B,\{f_i\})$ to $(B,\{f_i\})$ in&and that $h$ is an equivalence in & if and only if $h$ is an equivalence in C. If a product exists in C for the family $\{A_i\mid i\in I\}$ (with maps $\pi_k:\dot{\Pi}A_i\to A_{\underline{k}}$ for each $k\in I)$ , then for every $(B,\{f_i\})$ in & there exists a unique morphism $f:B\to\prod A_i$ such that $\pi_i\circ f$ $=f_{\mathrm{i}}$ for every i e I. But this says that $(\prod A_{i},\{\pi_{i}\mid i\in I\})$ is a couniversal object in the category &. Similarly the coproduct of a family of objects in C may be considered as a universal object in an appropriately constructed category.

Since a product $\Pi_{A_i}$ of a family $\{A_i\mid i\in I\}$ in a category may be considered as a couniversal object in a suitable category, it follows immediately from Theorem 7.10 that $\prod A_i$ is uniquely determined up to equivalence. Analogous results hold for coproducts and free objects..

## EXERCISES

1. A pointed set is a pair $(S,x)$ with $S$ a set and $x\varepsilon S$ .A morphism ofpointed sets $(S,x)\to(S^{\prime},x^{\prime})$ is a triple $(f,x,x^{\prime})$ ,where $f{:}S\to S^{\prime}$ is a function such that $f(x)=x^{\prime}$ Show that pointed sets form a category. 2.If $f:A\to B$ is an equivalence in a category ୧ and $g:B\to A$ is the morphism such that $g\circ f=1_{A}$ $f\circ g=1_B$ , show that $g$ is unique. 3. In the category S of groups, show that the group $G_1\times G_2$ together with the homomorphisms $\pi_1:G_1\times G_2\to G_1$ and $\pi_2:G_1\times G_2\to G_2$ (as in the Example preceding Definition 2.2) is a product for $\{G_1,G_2\}$ 4. In the category $G$ of abelian groups, show that the group $A_1\times A_2$ ,together with the homomorphisms $\iota_1:A_1\to A_1\times A_2$ and $\iota_2:A_2\to A_1\times A_2$ (as in the Example preceding Definition 2.2) is a coproduct for $\{A_1,A_2\}$ 5. Every family $\{A_i\mid i\in I\}$ in the category of sets has a coproduct. [Hinr: consider U $A_{i}=\{(a,i)\varepsilon(\cup A_{i})\times I|\alpha\varepsilon A_{i}\}$ with $A_i\to\cup A_i$ given by $a\vdash(a,i)$ . $U_{A_i}$ is called the disjoint union of the sets $A_i$ ] 6. (a) Show that in the category $S_{*}$ of pointed sets (see Exercise 1) products always. exist; describe them. (b) Show that in $S_{*}$ every family of objects has a coproduct (often called a "wedge product"); describe this coproduct 7. Let $F$ be a free object on a set $X\left(i:X\to F\right)$ in a concrete category C. If ୧ contains an object whose underlying set has at least two elements in it, then $i$ is an injective map of sets.

------------------------------------------------------------------

8. Suppose $X$ is a set and $F$ is a free object on $X$ (with $i:X\to F$ in the category of groups (the existence of $F$ is proved in Section 9). Prove that $i(X)$ is a set of generators for the group $F$ . [Hint : If $G$ is the subgroup of $F$ generated by $i(X)$, then there is a homomorphism $\varphi:F\to G$ such that $\varphi i=i.$ Show that $F\overset{\varphi}{\operatorname*{\rightarrow}}G\overset{\mathcal{C}}{\operatorname*{\rightarrow}}F$ is the identity map.]

### 8. DIRECT PRODUCTS AND DIRECT SUMS

In this section we study products in the category of groups and coproducts in the category of abelian groups. These products and coproducts are important not only as a means of constructing new groups from old, but also for describing the structure of certain groups in terms of particular subgroups (whose structure, for instance, may already be known)..

We begin by extending the definition of the direct product $G\times H$ of groups $G$ and $H$ (see page 26) to an arbitrary (possibly infinite) family of groups $\left\{G_{i}\mid i\in I\right\}$ Define a binary operation on the Caresian product (of sets) $\prod_{i\in I}G_i$ as follows f $f,g\in\prod_{i\in I}G_i$ (hat is, $f,g:I\to\bigcup_{i\in I}$ $G_i$ and $f(i),g(i)\in G_i$ $G_i$ G. for tach, hen $fg:I\to\bigcup_{i\in I}G_{i}$ is the function given by. $i\to f(i)g(i)$ .Since each $G_i$ is a group, $f(i)g(i)\in G_i$ G $G_i$ for every $i$ whence $fg\in\prod_{i\in I}G_i$ by Introduction, Definition 5.1 If we identity $f\varepsilon\prod_{i\in I}G_i$ with its image $\left\{a_{i}\right\}(a_{i}=f(i)$ for each i e $I$ as is usually done in the case when $I$ is fnite, then the binary operationin $\prod_{ieI}G_i$ is he familia component-wise multplication: $\left\{a_i\right\}\left\{b_i\right\}$ $=\{a_ib_i\}$ = ab} $=\left\{a_{i}b_{i}\right\}.\prod_{i\in I}G_{i}$, together with this binary operation,is alled the direct product (or complete direct sum) of the family of groups $\{G_i\mid i\in I\}$ . If $I=\{1,2,\ldots,n\}$ $\prod_{ieI}G_i$ is usually denoted $G_1\times G_2\times\cdots\times G_n$ (or in adive notation, $G_1\oplus G_2$ $\oplus\cdots\oplus G_n)$

Theorem 8.1. $If\left\{G_{\mathrm{i}}|i\varepsilon I\right\}$ is a family of groups, then

(i) thedrec roduct $\prod_{i\in I}G_i$ is a group;

(i) for each k e I, the map Tk : II G;→ Gk given by f |—→ f(k) [or $\{\mathbf{a}_{\mathrm{i}}\}\vdash\mathbf{a}_{\mathrm{k}}]$ is an epimorphism of groups.

PROOF. Exercise.

The maps $\pi_k$ in Theorem 8.1 are called the canonical projections of the direct product.

Theorem 8.2. Let $\{G_i$ |i e I} bea family of groups and $\{\varphi_{\mathrm{i}}:\mathbf{H}\to\mathbf{G}_{\mathrm{i}}|$ ieILa family of group homomorphisms.Then there is a unique homomorphism $\varphi:\mathbf{H}\to\prod_{\mathrm{ie}I}\dot{\mathbf{G}}_{\mathrm{i}}$ such that $\pi_{\mathrm{i}}\varphi=\varphi_{\mathrm{i}}$ for all i I and this propery deermines $\prod_{ieI}G_i$ uniquely up to isomorphism. In other words, $\prod_{i\in I}G_i$ is a product in thecaegory of groups

------------------------------------------------------------------

PROOF. By Introduction, Theorem 5.2, the map o sets $\varphi:H\to\prod_{i\in I}G_{i}$ given by $\varphi(a)=\left\{\varphi_{i}(a)\right|_{ieI}\varepsilon\prod_{ieI}G_{i}$ isthe uniquefuntion such that $\pi_{i}\varphi=\varphi_{i}$ for all I Itis easy to verify that $\varphi$ is a homomorphsm. Hence $\prod_{ieI}G_i$ is a produet i the categorical sense) and therefore determined up to isomorphism (equivalence) by Theorem 7.3.

Since the direct product of abelian groups is clearly abelian, it follows that the direct product of abelian groups is a product in the category of abelian groups also.

Definition 8.3. The (external) weak direct product of a family of groups $\left\{\mathbf{G}_{\mathbf{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\right\}$ denored $\prod_{iel}^{\mathrm{w}}G_{\mathrm{i}}$, Iisthe ser ofll e $\prod_{ieI}G_i$ such that $\mathbf{f}(\mathbf{i})=\mathbf{e}_{\mathbf{i}}$, the idenityin $\mathbf{G_i}$ forall but afinite number ofi I. Ifall the groups $G_{\mathrm{i}}$ are (addirive) abelian, $\prod_{ieI}^{w}G_i$ is usually called the (extermal) direct sum and is denored $\sum_{isI}G_i$

If $I$ is fnite, the weak direct product coincides with the direct product. In any case, we have

Theorem 8.4. If $\{G_i$ |ie I} is a family of groups, then

@ $\prod_{ieI}^nG_i$ is a nornal subgoup ofII G: (i) for each k e I, the map uk : Gk → IIw Gi given by $\iota_{\mathrm{k}}($a$)=\left\{\mathbf{a}_{\mathrm{i}}\right\}_{\mathrm{ieI}}$, where $a_{\mathrm{i}}=e$ for $i\neq k$ and $\mathbf{a}_{\mathrm{k}}=\mathbf{a}$ , is a monomorphism of groups, (i) for each i I, $\iota_i(G_i)$ is a normal subgroup ofI G;

PROOF. Exercise.

The maps $Lk$ in Theorem 8.4 are called the canonical injections.

1

Theorem 8.5. Ler $\{\mathbf{A}_{\mathrm{i}}|$ ie I bea family ofabelian groups(written additively). If B is an abeliangroup and $\{\psi_{\mathrm{i}}:\mathbf{A_{i}}\to\mathbf{B}$ i e I} a family of homomorphisms, then there is $a$ unique homomorphism $\psi:\sum_{i\in I}\mathbf{A}_{\mathrm{i}}\to\mathbf{B}$ such that $\psi_{\iota_{\mathrm{i}}}=\psi_{\mathrm{i}}$ for all ia I and thispropert determines $\sum_{ieI}A_i$ uniquely up to isomorphism. In other words, $\sum_{i\epsilon l}\mathbf{A}_{\mathrm{i}}$ is a coproduct in the category of abelian groups

REMARK. The theorem is false if the word abelian is omitted. The externa. weak direct product is not a coproduct in the category of all groups (Exercise 4)

PROOF OF 8.5. Throughout this proof all groups will be written additively. If $0\not=\{a_{i}\}\:\varepsilon\:\sum A_{i}$, :EA $\psi:\sum A_i\to B$ by $\psi\{0\}=0$ man # $a_{i}$ $\psi(\{a_{i}\})=\psi_{i_{1}}(a_{i_{1}})+\psi_{i_{2}}(a_{i_{2}})+\cdots+\psi_{i_{r}}(a_{i_{r}})$ $a_{i_1,a_{i_2}},\ldots,a_{i_r}$ aute+ yiao. $=\sum_{i\epsilon I_{0}}\psi_{i}(a_{i})$ where $I_0$ is the set $\{i_{1},i_{2},\ldots,i_{r}\}=\{i\varepsilon I\mid a_{i}\neq0\}$ . Since $B$ is abelian

1

一

------------------------------------------------------------------

it is readily verifed that $\psi$ is a homomorphism and that $\psi_{\iota_{i}}=\psi_{i}$ for all ie I. For each $\left\{a_{i}\right\}\varepsilon\sum A_{i},\left\{a_{i}\right\}=\sum_{i\in I_{0}}\iota_{i}(a_{i}),I_{0}$ I $I_0$ finite as above. If $\xi:\sum A_i\to B$ is a homomor phism such that $\xi\iota_{i}=\psi_{i}$ for all $i$ then $\xi(\{a_{i}\})=\xi(\sum_{I_{0}}\iota_{i}(a))=\sum_{I_{0}}\xi\iota_{i}(a_{i})=\sum_{I_{0}}\psi_{i}(a_{i})$ $=\sum_{I_{0}}\psi\iota_{i}(a_{i})=\psi(\sum_{I_{0}}\iota_{i}(a_{i}))=\psi(\{a_{i}\})$ ; hence $\xi=\psi$ and $\psi$ is unique. Therefore $\sum A_i$ is a coproduct in the category of abelian groups and hence is determined up to isomorphism (equivalence) by Theorem 7.5.

Next we investigate conditions under which a group $G$ is isomorphic to theweak direct product of a family of its subgroups

Theorem 8.6. Let $\{N_i|$ ie I} be a family of normal subgroups of a group G such thal

(i $\mathbf{G}=\langle\bigcup_{i\in I}\mathbf{N}_{\mathrm{i}}\rangle$ (i) for each k e I, $\mathbf{N}_{\mathrm{k}}\cap\langle\bigcup_{i\neq k.}\mathbf{N}_{\mathrm{i}}\rangle=\langle\mathbf{e}\rangle.$ Then $G\cong\prod_{i\in I}^{w}N_i$

Before proving the theorem we note a special case that is frequently used. Observe that for normal subgroups $N_1,N_2,\ldots,N_r$ of a group $G$ $\langle N_{1}\cup N_{2}\cup\cdots\cup N_{r}\rangle$ $=N_1N_2\cdots N_r=\{n_1n_2\cdots n_r\mid n_i\in N_i\}$ by an easily proved generalization of Theorem 5.3. In additive notation $N_1N_2\cdots N_r$ is written $N_{1}+N_{2}+\cdots+N_{r}$ . It may be helpful for the reader to keep the following corollary in mind since the proof of the general case is essentially the same.

Corollary 8.7. If $\mathbf{N}_{1},\mathbf{N}_{2},\ldots,\mathbf{N}_{r}$ are normal subgroups of a group G such that $\mathbf{G}=\mathbf{N}_{1}\mathbf{N}_{2}\cdots\mathbf{N}_{\mathrm{r}}$ and for each $1\leq\mathbf{k}\leq\mathbf{r}$ $1\leq\mathbf{k}\leq\mathbf{r}$ Nk $N_k$ $1\leq k\leq r,N_k\cap(N_1\cdots N_{k-1}N_{k+1}\cdots N_r)=\langle e\rangle$ ,ther $\mathbf{G}\cong\mathbf{N}_1\times\mathbf{N}_2\times\cdots\times\mathbf{N}_r$ .

PROOF OF THEOREM 8.6. If $\{a_{i}\}\in\prod^{w}N_{i}$ . then $a_{i}=e$ for all but a finite number of $i\varepsilon I.$ Let $I_0$ be the fnie set $\{i\varepsilon I\mid a_{i}\neq e\}$ Then $\prod_{i\in I_0}a_i$ is well-defned element of $G$ , since for ae $N_{i}$ and $b\varepsilon N_{j},(i\neq j),a\underline{b}=ba$ ab=ba $ab=ba$ by Theorem 5.3(iv). Consequently the map $\varphi:\prod^{w}N_{i}\to G$ given by $\{a_{i}\}\vdash\prod_{i\in I_{0}}a_{i}\varepsilon\dot{G}$ (and $\{e\}\vdash e)$ , i a homo morphism such that $\varphi_{li}(a_{i})=a_{i}$ for $a_i\varepsilon N_i$ Since $G$ is generated by the subgroups $N_{i}$ , every element $a$ of $G$ is a finite product

of elenents from various $N_{i}$ . Since elements of $N_{i}$ and $N_{j}$ commute (for $i\neq j$, ,a can be written as a product $\prod_{i\in I_0}a_i$ , where $a_i\varepsilon N_i$ and $I_0$ is some finite subset of $I$ Hence $\prod_{i\in I_{0}}\iota_{i}(a_{i})\varepsilon\prod^{w}N_{i}$ and $\varphi(\prod_{i\in I_{0}}^{i\varepsilon I_{0}}\iota_{i}(a_{i}))=\prod_{i\in I_{0}}\varphi_{i}(a_{i})=\prod_{i\in I_{0}}a_{i}=a$ Therefore, $\varphi$ is an epi morphism.

Eetsee 4i-1- $I_0=\{1,2,\ldots,n\}$ $\varphi(\{a_{i}\})=\prod_{i\in I_{0}}a_{i}=e\varepsilon G.$ $\coprod_{i\in I_{0}}a_{i}=a_{1}a_{2}\cdots a_{n}=e$ forco $a_i\varepsilon N_i$ eo no $a_{1}^{-1}=a_{2}\cdots a_{n}\varepsilon N_{1}\cap\langle\bigcup_{i\neq1}N_{i}\rangle=\langle e\rangle$ and therefore $a_{1}=e$ Repetition of this argu ment shows that $a_{i}=e$ for all $i\varepsilon I.$ Hence $\varphi$ is a monomorphism.

------------------------------------------------------------------

### Theorem 8.6 motivates

Definition 8.8. Let $\{N_i\mid$ i e I} bea family ofnormal subgroupsofagroup G suchthat $\mathbf{G}=\langle\bigcup_{ieI}\mathbf{N}_{\mathrm{i}}\rangle$ and for each k I, $Nk$ Nk $\mathbf{N}_{\mathrm{k}}\cap\langle\bigcup_{i\neq k}\mathbf{N}_{\mathrm{i}}\rangle=\langle\mathbf{e}\rangle$ Then G is aid to be the internal weak directproduct of thefamily $\{N_i$ |i e I}(or theinternal direct sum ifG is(additive) abelian).

As an easycorollary of Theorem 8.6we have the following characterization of internal weak direct products.

Theorem 8.9. Let $\{N_i\mid$ ie I} bea family of normal subgroups of a group G. G is the internal weak direct product of the family $\{N_i$ |ie I} if and only ifevery nonidentity element of G is a unique product $a_{i_1}a_{i_2}\cdots a_{i_n}$ with $\mathbf{i}_{1},\ldots,\mathbf{i}_{\mathrm{n}}$ $\dot{h}_{\mathrm{n}}$ in distinct elemenis of I and $\mathbf{e}\neq\mathbf{a_{i_{k}}}\in\mathbf{N_{i_{k}}}$ for each $\mathbf{k}=1,2,\ldots,\mathbf{n}$

### PROOF. Exercise.

There is a distinction between internal and external weak direct products. If a group $G$ is the internal weak direct product of groups $N_i$, then by definition each $N_i$ is actually a subgroup of $G$ and $G$ is isomorphic to the external weak direct produc!. $\prod_{i\epsilon I}^{w}N_{i}.$ $N_{i}$ Ven he etene ae diec ct $\prod_{i\epsilon I}^{w}N_i$ dio $\iota_i(N_i)$ callonmain 8.4 and Exercise 10). Practically speaking, this distinction is not very important and the adjectives "internal" and "external" will be omitted whenever no confusion is possible. In fact we shall use the following notation.

NOTATION. We write $G=\prod_{i<I}^{w}N_{i}$ to indicate that the group $G$ is the internal weak direct product of the family of its subgroups $\{N_i\mid i\in I\}$

Theorem 8.10. Ler $\{\mathbf{f}_{\mathrm{i}}:\mathbf{G}_{\mathrm{i}}\to\mathbf{H}_{\mathrm{i}}|$i$\varepsilon$ I} be a family of homomorphisms of groups. and ler $\mathbf{f}=\prod\mathbf{f}_{\mathrm{i}}be$ the map $\prod_{i\in I}\mathbf{G}_{\mathrm{i}}\to\prod_{i\in I}\mathbf{H}_{\mathrm{i}}$ giten by $\{a_{i}\}\mapsto\{f_{i}(a_{i})\}$ Then fi ahomo morphism ofgroups such that $f(\prod_{i\in I}^{w}G_{i})\subset\prod_{i\in I}^{w}H_{i}$, Ker $\mathbf{f}=\prod_{ieI}$ Ker f and Im f $=\prod_{i\in I}\mathbf{Imf}_{\mathrm{i}}$ Consequenly fi monomorphs rep.morphism if an nl ifac fi is.

PROOF. Exercise.

Corollary 8.11. Let $\{G_i$ |ie I} and $\left\{\mathbf{N_i}\right|$ i a I be families of groups such that $N_{\mathrm{i}}$ isa normal subgroup of $\mathbf{G}_{\mathbf{i}}$ for each ie I.

@ $\prod_{i\in I}^{i\varepsilon I}\mathbf{w}\mathbf{N}_{\mathrm{i}}$ a $\prod_{i\in I}^{ieI}\mathbf{w}\mathbf{G}_{\mathrm{i}}$ $\prod_{\mathrm{G_i/\prod N_i\cong\prod G_i/N_i.}}$ GUM

—

------------------------------------------------------------------

PROOF. (i) For each $i$, let $\pi_i:G_i\to G_i/N_i$ be the canonical epimorphism. By Thorem 8.10, the map $\prod_{\pi_i}:\prod_{i<I}G_i\to\prod_{i<I}G_i/N_i$ is an epimorphism with kernel $\prod_{ieI}N_i.$ Therefore $\prod G_i/\prod N_i\cong\prod G_i/N_i$ by the Fis Isomorphism Theorem. i is similar.

### EXERCISES

1. $S_3$ is nor the direct product of any family of its proper subgroups. The same is true of $Z_{p^n}(p$ prime, $n\geq1.$ )and $\mathbf{Z}$

 2. Give an example of groups $H_{i}$ $K_{j}$ such that $H_1\times H_2\cong K_1\times K_2$ and no $H_{i}$ is isomorphic to any $K_{i}.$

3. Let $G$ be an (additive) abelian group with subgroups $H$ and $K$ . Show that $G\cong H\oplus K$ if and only if there are homomorphisms $H\stackrel{\pi_1}{\operatorname*{\operatorname*{=}}}G\stackrel{\pi_2}{\operatorname*{\operatorname*{=}}}K$ such that $\pi_{1ll}=\mathbf{1}_{H}$ Tl = 1H $\pi_{1}\iota_{1}=1_{H},\:\pi_{2}\iota_{2}=1_{K},\:\pi_{1}\iota_{2}=0$ T2l2 = 1k $\pi_{2\boldsymbol{\iota}_{2}}=\mathbf{l}_{K}$ T1l2 = 0 $\pi_{1}\iota_{2}=0$ and $\pi_{2}\iota_{1}=0$ ,where O is the map sending every element onto the zero (identity)element, and $\iota_1\pi_1(x)+\iota_2\pi_2(x)=x$ for all $x\in G$ G $G$

4. Give an example to show that the weak direct product is not a coproduct in the category of all groups. (Hint: it suffices to consider the case of two factors $G\times H.$

5. Let $G$ , H be finite cyclic groups. Then $G\times H$ is cyclic if and only if $(|G|,|H|)=1$

6. Every finitely generated abelian group $G\neq\langle e\rangle$ in which every element (except e) has order $p\left(p\right.$ prime) is isomorphic to $Z_p\oplus Z_p\oplus\cdots\oplus Z_p$ $(n$ summands) for some $n\geq1$ . [Hinr: Let $A=\{a_{1},\ldots,a_{n}\}$ be a set of generators such that no proper subset of $A$ generates $G$ . Show that $\langle a_i\rangle\cong Z_p$ and $G=\langle a_{1}\rangle\times\langle a_{2}\rangle\times\cdots$ $\times\langle a_n\rangle.]$

7. Let $H,K,N$ be nontrivial normal subgroups of a group $G$ and suppose $G=H\times K$ Prove that $N$ is in the center of $G$ or $N$ intersects one of $H,K$ nontrivially. Give examples to show that both possibilities can actually occur when $G$ is nonabelian.

8. Corollary 8.7 is false if one of the $N_{i}$ is not normal.

9. If a group $G$ is the (internal) direct product of its subgroups $H,K$ , then $H\cong G/K$ and $G/H\cong K$

10. If $\{G_i\mid i\in I\}$ is a family of groups, then $\prod^wG_i$ is the internal weak direct product its subgroups $\{\iota_i(G_i)\mid i\in I\}$

11. Let $\{N_i\mid i\in I\}$ be a family of subgroups of a group $G$ . Then $G$ is the internal weak direct product of $\{N_{i}\mid i\in I\}$ if and only if: (i) $a_ia_j=a_ja_i$ for all $i\neq j$ and $a_{i}\in N_{i},a_{j}\in N_{j}$ ; (i) every nonidentity element of $G$ is uniquely a product $a_{i_1}\cdots a_{i_n}$, where $i_1,\ldots,i_n$ in $i_n$ are distinct elements of $I$ and $e\neq u_{i_k}$ E $N_{ik}$ for each $k$ . [Compare Theorem 8.9.]

12. A normal subgroup $H$ of a group $G$ is said to be a direct factor (direct summand if $G$ is additive abelian) if there exists a (normal) subgroup $K$ of $G$ such that $G=H\times K$

------------------------------------------------------------------

(a) If $H$ is a direct factor of $K$ and $K$ is a direct factor of $G$ , then $H$ is normal in $G$ . [Compare Exercise 5.10.] (b) If $H$ is a direct factor of $G$ , then every homomorphism $H\to G$ may be ex-

tended to an endomorphism $G\to G$ . However, a monomorphism $H\to G$ need not be extendible to an automorphism $G\to G$

13. Let $\left\{G_i\mid i\in I\right\}$ be a family of groups and $J\subset I.$ The map $\alpha:\prod_{j\in J}G_{i}\to\prod_{i\in I}G_{i}$ givenby $\{a_i\}\mapsto\{b_i\}$ ,where $b_{i}=a_{j}$ for $i$ E $J$ and $b_{i}=e_{i}$ (identity of $G$ )for $i\notin J.$ is a monomorphism of groups and $\prod_{ieI}G_i/\alpha(\prod_{jeJ}G_i)\cong\prod_{ieI-J}G_i$

14.For $i=1,2$ let $H_i\lhd G_i$ and give examples to show that each of the following statements may be false: (a) $G_1\cong G_2$ and $H_1\cong H_2\Rightarrow G_1/H_1\cong G_2/H_2$ (b) $G_{1}\cong G_{2}$ and $G_1/H_1\cong G_2/H_2\Rightarrow H_1\cong H_2$ (c) $H_{1}\cong H_{2}$ and $G_1/H_1\cong G_2/H_2$ $\Rightarrow G_{1}\cong G_{2}$

## 9. FREE GROUPS, FREE PRODUCTS, AND GENERATORS AND RELATIONS

We shall show that free objects (free groups) exist in the (concrete) category of groups, and we shall use these to develop a method of describing groups in terms of "generators and relations." In addition, we indicate how to construct coproducts (free products) in the category of groups.. Given a set $X$ we shall construct a group $F$ that isfreeon theset $X$ in the sense of

Definition 7.7. If $X=\varnothing$ $F$ is the trivial group $\langle e\rangle$ $\mathbf{If}X\neq\varnothing$ ,let $X^{-1}$ be a set disjoint from $X$ such that $|X|=|X^{-1}|$ . Choose a bijection $X\to X^{-1}$ and denote the image of $x\varepsilon X$ X $X$ by $x^{-1}$ . Finally choose a set that is disjoint from $X$ U $X^{-1}$ and has exactly one element; denote this element by 1. A word on $X$ is a sequence $(a_1,a_2,\ldots)$ with $a_i\varepsilon$ $X$ U $X^{-1}$ U {1} such that for some n ε $N^*$ ， $a_k=1$ for all $k\geq n$ . The constant sequence (1,1,.. .) is called the empty word and is denoted 1. (This ambiguous notationwill cause no confusion.)A word $(a_1,a_2,\ldots)$ on $X$ is said to be reduced provided that (i) for all $x\in X$ ， $x$ and $x^{-1}$ are not adjacent (that is, $a_{i}=x\Rightarrow a_{i+1}\neq x^{-1}$ and

$a_{i}=x^{-1}\Rightarrow a_{i+1}\neq x$ for all $i\varepsilon N^*$ icN* $i\varepsilon\mathbf{N}^{*},\:x\in X)$ xEX) $x\in X)$ and

(i) $a_k=1$ implies $a_i=1$ for all $i\geq k$ In particular, the emptyword 1 is reduced.

Every nonempty reducedword is of the form $(x_{1}^{\lambda_{1}},x_{2}^{\lambda_{2}},\ldots,x_{n}^{\lambda_{n}},1,1,\ldots)$ ,where $n\varepsilon N^*$ $x_i\varepsilon X$ and $\lambda_{i}=\pm1$ (and by convention $x^1$ denotes $x$ for all $x\varepsilon X$ ). Hereafter we shall denote this word by. $x_{1}^{\lambda_{1}}x_{2}^{\lambda_{2}}\cdots x_{n}^{\lambda_{n}}$ . This new notation is both more tractable. and more suggestive. Observe that the definition of equality of sequences shows that two reduced words $x_{1}\lambda_{1}\ldots x_{m}\lambda_{m}$ and $y_{1}^{\delta_{1}}\cdots y_{n}^{\delta_{n}}\left(x_{i},\dot{y}_{j}\:\varepsilon X;\:\lambda_{i},\delta_{j}=\pm1\right)$ areequalif and only if both are 1 or $m=n$ and $x_{i}=y_{i},\:\lambda_{i}=\delta_{i}$ for each $i=1,2,...,n.$ Consequently the mapfrom $X$ into the set $F(X)$ of all reduced words on $X$ given by $x|\mapsto x^{1}=x$ is injective. We shall identify $X$ with its image and consider $X$ to be a subset of $F(X)$ Next we define a binary operation on the set $F=F(X)$ ofall reducedwords on $X$

The emptyword 1 is to act as an identity element $(w1=1w=w$ for all $w\varepsilon F)$ .Informally, we would like to have the product of nonempty reduced words to be given by juxtaposition, that is,

$$({x_{1}}^{\lambda_{1}}\cdots{x_{m}}^{\lambda_{m}})({y_{1}}^{\delta_{1}}\cdots{y_{n}}^{\delta_{n}})={x_{1}}^{\lambda_{1}}\cdots{x_{m}}^{\lambda_{m}}{y_{1}}^{\delta_{1}}\cdots{y_{n}}^{\delta_{n}}.$$

------------------------------------------------------------------

Unfortunately the word on the right side of the equation may not be reduced (for example, if $x_{m}\lambda_{m}=y_{1}^{-\delta_{1}}$ ).Therefore, we define the product to be given by juxtaposition and (if necessary) cancellation of adjacent terms of the form $xx^{-1}$ or $x^{-1}x$ ; for example $(x_{1}^{1}x_{2}^{\ldots-1}x_{3}^{1})(x_{3}^{-1}x_{2}^{1}x_{4}^{1})=x_{1}^{1}x_{4}^{1}.$ More precisely, if. $x_{1}^{\lambda\mathbf{I}}\ldots x_{m}\lambda_{m}$ and $y_{1}^{\delta_{1}}\ldots y_{n}^{\delta_{n}}$ are nonempty reduced words on $X$ with $m\leq n$ ，let $k$ be the largest integer $(0\leq k\leq m)$ such that $x_{m-j}^{\lambda_{m-j}}=y_{j+1}^{-\delta_{j+1}}$ for $j=0,1,\ldots,k-1$ Then define

$$({x_{1}}^{\lambda_{1}}\cdots{x_{m}}^{\lambda_{m}})({y_{1}}^{\delta_{1}}\cdots{y_{n}}^{\delta_{n}})=\begin{cases}{x_{1}}^{\lambda_{1}}\cdots{x_{m-k}}^{\lambda_{m-k}}{y_{k+1}}^{\delta_{k+1}}\cdots{y_{n}}^{\delta_{n}}\:\mathrm{if}\:k<m;\\{y_{m+1}}^{\delta_{m+1}}\cdots{y_{n}}^{\delta_{n}}\quad\mathrm{if}\quad k=m<n;\\1\quad\mathrm{if}\quad k=m=n.\end{cases}$$

If $m>n$ , the product is defined analogously. The definition insures that the produc of reduced words is a reduced word.

Theorem 9.1.IfX is a nonempty set and $\mathbf{F}=\mathbf{F}(\mathbf{X})$ is the set of all reduced words on. $X$ , then F is a group under the binary operation defined above and. $\mathbf{F}=\langle\mathbf{X}\rangle$

The group $F=F(X)$ is called the free group on the set $X.$ (The terminology *free'. is explained by Theorem 9.2 below.)

SKETCH OF PROOF OF 9.1. Since 1 is an identity element and $x_{1}^{\delta_{1}}\ldots x_{n}\delta_{n}$ has inverse $x_{n}^{-\delta_{n}}\cdots x_{1}^{-\delta_{1}}$ , we need only verify associativity. This may be done by induction and a tedious examination of cases or by the following more elegant device. For each $x\varepsilon X$ X $X$ and $\delta=\pm1$ let $|x^{\delta}|$ be the map $F\to F$ given by $1\vdash x^{\delta}$ and

$${x_{1}}^{\delta_{1}}\cdots{x_{n}}^{\delta_{n}}\models\left\{\begin{matrix}x^{\delta}{x_{1}}^{\delta_{1}}\cdots{x_{n}}^{\delta_{n}}&\mathrm{if}&x^{\delta}\neq{x_{1}}^{-\delta_{1}};\\x_{2}^{\delta_{2}}\cdots{x_{n}}^{\delta_{n}}&\mathrm{if}&x^{\delta}={x_{1}}^{-\delta_{1}}(=1\mathrm{~if}n=1).\end{matrix}\right.$$

Since $|x||x^{-1}|=|_{F}=|x^{-1}||x|$ ,every $|x^{\delta}|$ is a permutation (bijection) of $F$ (with inverse $|x^{-\delta}|)$ by (13) of Introduction, Section 3. Let $A(F)$ be the group of all permutations of $F$ (see page 26) and $F_0$ the subgroup generated by $\{|x|\mid x\in X\}$ . The map $\varphi:F\to F_0$ given by $1\vdash\mathbf{1}_F$ and $x_{1}^{\delta_{1}}\cdots x_{n}^{\delta_{n}}|\mapsto|x_{1}^{\delta_{1}}|\cdots|x_{n}^{\delta_{n}}|$ is clearly a surjection such that $\varphi(w_{1}w_{2})=\varphi(w_{1})\varphi(w_{2})$ for all $w_{i}\in F.$ Since $1\vdash x_{1}^{\delta_{1}}\cdots x_{n}^{\delta_{n}}$ under the map $\left|x_{1}\delta_{1}\right|\cdots\left|x_{n}\delta_{n}\right|$ , it follows that $\varphi$ is injective. The fact that $F_0$ is a group implies that associativity holds in $F$ and that $\varphi$ is an isomorphism of groups. Obviously $F=\langle X\rangle$ .

Certain properties of free groups are easily derived. For instance if $|X|\geq2.$ then the free group on $X$ is nonabelian $(x,y\in X$ and $x\neq y\Rightarrow x^{-1}y^{-1}xy$ is reduced $\Rightarrow x^{-1}y^{-1}xy\neq1\Rightarrow xy\neq yx)$ .Similarly every element (except 1) in a free grouphas infnite order (Exercise 1). If $X=\{a\}$ , then the free group on $X$ is the infinite cyclic group $\langle a\rangle$ (Exercise 2). A decidedly nontrivial fact is that every subgroup of a free group is itself a free group on some set (see J. Rotman [19]).

Theorem 9.2. Let F be the free group on a set X and . $\mathbf{c}:\mathbf{X}\to\mathbf{F}$ the inclusion map. If G is a group and f : $\mathbf{X}\to\mathbf{G}$ a map of sets,then there exists a unique homomorphism of groups f : ${:}\mathbf{F}\to\mathbf{G}$ such that $\bar{\mathbf{f}}\iota=\mathbf{f}.$ In other words, $F$ is a free object on the set $X$ inthe category of groups.

------------------------------------------------------------------

REMARK. If $F^{\prime}$ is another free object on the set $X$ in the category of groups (with $\lambda:X\to F^{\prime})$ 0, then Theorems 7.8 and 9.2 imply that there is an isomorphism $\varphi:F\cong F^{\prime}$ such that $\varphi\iota=\lambda.$ In particular $\lambda(X)$ is a set of generators of $F^{\prime}$ ; this fact may also be proved directly from the definition of a free object.

SKETCH OF PROOF OF9.2. Define $\bar{f}(1)=e$ and if $x_{1}^{\delta_{1}}\ldots x_{n}\delta_{n}$ is a nonenpty reduced word on $X$ ，define $\bar{f}(x_{1}^{\delta_{1}}\cdots x_{n}^{\delta_{n}})=f(x_{1})^{\delta_{1}}f(x_{2})^{\delta_{2}}\cdots f(x_{n})^{\delta_{n}}$ .Since $G$ is a group and $\delta_{i}=\pm1$ , the product $f(x_1)^{\delta_1}\cdots f(x_n)^{\delta_n}$ is a well-defined element of $G$ Verify that $\bar{f}$ is a homomorphism such that $\bar{f}_{\iota}=f.$ If $g:F\to G$ is any homomorphism such that $g\iota=f$, then $g(x_{1}^{\delta_{1}}\cdots x_{n}^{\delta_{n}})=g(x_{1}^{\delta_{1}})\cdots g(x_{n}^{\delta_{n}})=g(x_{1})^{\delta_{1}}\cdots g(x_{n})^{\delta_{n}}$ $=g\iota(x_{1})^{\delta_{1}}\cdots g\iota(x_{n})^{\delta_{n}}=f(x_{1})^{\delta_{1}}\cdots f(x_{n})^{\delta_{n}}=\bar{f}(x_{1}^{\delta_{1}}\cdots x_{n}^{\delta_{n}}).$ Therefore $\bar{f}$ is unique.

Corollary 9.3. Every group $G$ is the homomorphic image of a free group.

PROOF. Let $X$ be a set of generators of $G$ and let $F$ be the free group on the set $X$ . By Theorem 9.2 the inclusion map $X\to G$ induces a homomorphism $\bar{f}:F\to G$ such that $x|\mapsto x\in G$ . Since $G=\langle X\rangle$ , the proof of Theorem 9.2 shows that $\bar{f}$ is an epimorphism.

An immediate consequence of Corollary 9.3 and theFirst Isomorphism Theorem is that any group $G$ is isomorphic to a quotient group $F/N.$ where $G=\langle X\rangle$ $F$ is the free group on $X$ and $N$ is the kernel of the epimorphism $F\to G$ of Corollary 9.3. Therefore, in order to describe $G$ up to isomorphism we need only specify $X,F.$ and $N$ .But $F$ is determined up to isomorphism by $X$ (Theorem 7.8) and $N$ is determined by any subset that generates it as a subgroup of $F$ . Now if $w=x_{1}^{\delta_{1}}\cdots x_{n}^{\delta_{n}}\varepsilon F$ is a generator of $N$ ，then under the epimorphism $F\to G$ ， $w|\mapsto x_{1}^{\delta_{1}}\cdots x_{n}^{\delta_{n}}=e\varepsilon G$ The equation $x_{1}^{\delta_{1}}\cdots x_{n}^{\delta_{n}}=e$ in $G$ is called arelation on thegenerators $x_i$ . Clearly a given group $G$ may be completely described by specif ying a set $X$ of generators of $G$ and a suitable set $R$ of relations on these generators. This description is not unique since there are many possible choices of both $X$ and $R$ for a given group $G$ (see Exercises 6 and 9). Conversely, suppose we are given a set $X$ 2nd a set $Y$ of (reduced) words on the

elements ofX. Question: does there exist a group $G$ such thiat $G$ is generated by $X$ and all the relations $w=e\left(w\varepsilon Y\right)$ are valid(where $w=x_{1}\delta_{1}\ldots x_{n}\delta_{n}$ now denotes a product in $G$ )? We shall see that the answer is yes, providing one allows for the possibility that in the group $G$ the elements of $X$ may not all be distinct. For instance, if $a,b\varepsilon X$ and $a^1b^{-1}$ is a (reduced) word in $Y$ , then any group containing $a,b$ and satisf ying $a^{ı}b^{-1}=e$ must have $a=b$ Given a set of"generators" $X$ and a set $Y$ of (reduced) words on theelements of $\dot{X}$

we construct such a group as follows. Let $F$ be the free group on $X$ and $N$ the normal subgroup of $F$ generated by Y.3 Let $G$ be the quotient group $F/N$ and identify $X$ with its image in $F/N$ under the map $X\subset F\to F/N$ ; as noted above, this may involve identifying some elements of $X$ with one another. Then $G$ is a group generated by $X$ (subject to identifications) and by construction all the relations $w=e\left(w\varepsilon Y\right)$ are satisfied $( w= x_{1}^{\delta _{1}}\cdots x_{n}^{\delta _{n}}$ $g$ $Y\Rightarrow x_1\delta_1\cdots\chi_n\delta_n$ E $N\Rightarrow x_1^{\delta_1}N\cdots x_1^{\delta_n}N=N$ ; that is, $x_{1}^{\delta_{1}}\ldots x_{n}^{\delta_{n}}=e$ in $G=F/N$

------------------------------------------------------------------

Definition 9.4.Let X be a set and Y a set of(reduced) words on X.A group G is said to be the group defined by the generators $x\varepsilon X$ and relations $w=e$ (w ε Y) provided $\mathbf{G\cong F/N}$ ,where $F$ is the free group on $X$ and $N$ the normal subgroup ofF generated by Y. One says that $(\mathbf{X}\mid\mathbf{Y})$ is a presentation of G.

The preceding discussion shows that the group defined by given generators and relations always exists. Furthermore it is the largest possible such group in the following sense.

Theorem 9.5. (Van Dyck) Let X be a set, Y a setof(reduced) wordson X and G the group defined by the generators x e X and relations $W=e$ (w e Y). IfH is any group such that $\mathbf{H}=\langle\mathbf{X}\rangle$ and $H$ satisfies all the relations $w=e$ (w e Y), then there is an epimorphism $\mathbf{G}\to\mathbf{H}$

REMARK. The elements of $Y$ are being interpreted as words on $X$ , products in $G$ , and products in $H$ as the context indicates.

PROOF OF 9.5. If $F$ is the free group on $X$ then the inclusion map $X\to H$ induces an epimorphism $\varphi:F\to H$ by Corollary 9.3. Since $H$ satisfies the relations $w=e\left(w\varepsilon Y\right)$ $Y\subset$Ker $\varphi$ \$ $\varphi$ . Consequently, the normal subgroup $N$ generated by $Y$ in $F$ is contained in Ker $\varphi$ .By Corollary $5.8\varphi$ induces an epimorphism $F/N\to\mathbf{H}/0$ Therefore the composition $G\cong F/N\to\mathbf{H}/0\cong H$ is an epimorphism.

The following examples of groups defined by generators and relations illustrate the sort of ad hoc arguments that are often the only way of investigating a given pre. sentation. When convenient, we shall use exponential notation for words (for example, $x^2y^{-3}$ in place of $x^{1}x^{1}y^{-1}y^{-1}y^{-1})$

EXAMPLE. Let $G$ be the group defined by generators $a,b$ and relations $a^4=e$ $a^2b^{-2}=e$ and $abab^{-1}=e$ Since $Q_{8}$, the quaternion group of order 8, is generated by elements $a,b$ satisfying these relations (Exercise 4.14), there is an epimorphism $\varphi:G\to Q_{8}$ by Theorem 9.5. Hence $|G|\geq|Q_{8}|=8.$ Let $F$ be the free group on $\{a,b\}$ and $N$ the normal subgroup generated by $\{a^4,a^2b^{-2},abab^{-1}\}$ . It is not difficult to show that every element of $F/N$ is of theform a²biNwith $0\leq i\leq3$ and $j=0,1$ ，whence $|G|=|F/N|\leq8$ . Therefore $|G|=8$ and $\varphi$ is an isomorphism. Thus the group defined by the given generators and relations is (isomorphic to) $Q_{8}$

EXAMPLE. The group defined by the generators $a,b$ and the relations $a^n=e$ $(3\leq n\varepsilon\mathbf{N}^{*})$ $b^2=e$ and abab $=e$ (or $ba=a^{-1}b$ is thedihedral group $D_n$ (Exercise 8)

EXAMPLE. The group defined by one generator $b$ and the single relation $b^{m}=e\left(m\in\mathbf{N}^{*}\right)$ is $Z_m$ (Exercise 9)

EXAMPLE. The free group $F$ on a set $X$ is the group defined by the generators $x\varepsilon X$ and no relations (recall that $\langle\varnothing\rangle=\langle e\rangle$ by Defnition 2.7). The terminology "free" arises from the fact that $F$ is relation-free

------------------------------------------------------------------

We close this section with a brief discussion of coproducts (free products) in the category of groups. Most of the details areleft to thereader since the process is quite similar to the construction of free groups. Given a family of groups $\left\{G_{i}\mid i\in I\right\}$ we may assume (by relabeling if necessary)

that the $G_i$ are mutually disjoint sets. Let $X=\bigcup_{i\in I}G_i$ and et 1 bea one-element set disjoint from $X$ . A word on $X$ is any sequence $(a_1,a_2,\ldots)$ such that $a_i\varepsilon X\cup\{1\}$ and for some n e $N^*$ $a_i=1$ for all $i\geq n.$ A word $(a_1,a_2,\ldots)$ is reduced provided: (i) no $a_i\varepsilon X$ is the identity element in its group $G_{i}$

(ii) for all $i,j\geq1$ $a_i$ and $a_{i+1}$ are nor in the samegroup $G_{j}$

(ii) $a_k=1$ implies $a_i=1$ for all $i\geq k$

In particular $1=(1,1,\ldots)$ is reduced.Every reduced word $(\neq1)$ may be written

uniquely as $a_1a_2\cdots a_n=(a_1,a_2,\ldots,a_n,1,1,\ldots)$ ,where $a_i\varepsilon X$ Let $\prod_{i\in I}^{*}G_{i}$ (or $G_1*G_2*\cdots*G_n$ if $I$ is fnite) ethe set o allredued words on $X$

$\prod_{ieI}^*G_i$ forms a group, clle he re produet of the famaly $\{G_i\mid i\varepsilon I\}$ , under the binary operation defined as follows. 1 is the identity element and the product of two reduced words $(\neq1)$ essentially is to be given by juxtaposition. Since the juxtaposed product of two reduced words may not be reduced, one must make the necessary cancellations and contractions. For example, if $a_i,b_i\in G_i$ for $i=1,2,3$ ,，then $(a_1a_2a_3)(a_3^{-1}b_2b_1b_3)=a_1c_2b_1b_3=(\underline{a_1,}c_2,b_1,b_3,1,1,\ldots)$ where $c_{2}=a_{2}b_{2}\varepsilon G_{2}$ Finally, for each $k$ ε I the map $\iota_{k}:G_{k}\rightarrow\prod_{i\in I}^{*}G_{i}$ given by $e|\mapsto1$ and $a\vdash a=(a,1,1,\ldots)$ is a monomorphism of groups. Consequently, we sometimes identify. $G_{k}$ with its isomorphic image in $\prod_{i\epsilon I}^{\tilde{\boldsymbol{\Pi}}^*G_i}$ (for example Exercse 15).

Theorem 9.6. Let $\left\{G_{\mathrm{i}}\right.$ Ii I bea fomily o groups and $\prod_{i\in I}^*G_i$ their free producr If $\{\psi_i:\mathcal{G}_i\to\mathcal{H}|$ lieI}is a family of group homomorphisms,then there exists a unique homomorphism : II*G; → H such that $\psi_{\iota_{i}}=\psi_{i}$ for all i e I and this properry deter- $\psi:\prod_{i\in I}^{*}\mathcal{G}_{;}\to\mathcal{H}$ mines $\prod_{i\epsilon I}^*G_i$ uniquely up to isomorphism. In other words $\prod_{i\in I}^*G_i$ is a coproduc in the category of groups..

SKETCH OF PROOF. If $a_1a_2\cdots a_n$ is a reduced word in $\prod_{i\in I}^*G_i$ wich $a_k\varepsilon G_{i_k}$, define $\psi(a_1\cdots a_n)$ tobe $\psi_{i_1}(a_1)\psi_{i_2}(a_2)\cdots\psi_{i_n}(a_n)\varepsilon H.$

### EXERCISES

1. Every nonidentity element in a free group $F$ has infinite order.

2. Show that the free group on the set $\{a\}$ is an infinite cyclic group, and hence isonorphic to $\mathbf{Z}$

3. Let $F$ be a free group and let $N$ be the subgroupgenerated by the set $\{x^n\mid x\in F\}$ $n$ a fxed integer}. Show that $N\lhd F$ 4. Let $F$ be the free group on the set $X.$ ,and let $Y\subset X.$ If $H$ is the smallest normal subgroup of $F$ containing $Y$ ,then $F/H$ is a free group

------------------------------------------------------------------

5. The group defined by generators $a,b$ and relations $a^{8}=b^{2}a^{4}=ab^{-1}ab=e$ has order at most 16. 6. The cyclic group of order 6 is the group defined by generators $a,b$ and relations $a^{2}=b^{3}=a^{-1}b^{-1}ab=e$ 7. Show thatthe group defined by generators $a,b$ and relations a²=e $a^2=e$ $a^{2}=e,b^{3}=e$ $b^3=e$ b²=e is in finite and nonabelian 8. The group defined by generators $a,b$ and relations $Q^n=e$ an = e (3≤ne N*) $(3\leq n\in N^{*})$ $a^{n}=e\left(3\leq n\in N^{*}\right),b^{2}=e$ b2 = e $b^2=e$ and $abab=e$ $=e$ =e is the dihedral group $D_n$ . [See Theorem 6.13.] 9. The group defined by the generator $b$ and the relation $b^{m}=e\left(m\in N^{*}\right)$ is the cyclic group $Z_m$ 10. The operation of free product is commutative and associative: for any groups $A,B,C,A*B\cong B*A$ and $A*(B*C)\cong(A*B)*C$ 11. If $N$ is the normal subgroup of $A*B$ generated by $A$ , then $(A*B)/N\cong B$ 12. If $G$ and $H$ each have more than one element, then $G*H$ is an infnite group with center $\langle e\rangle$ 13.A free group is a free product of infinite cyclic groups. 14. If $G$ is the group defined by generators $a,b$ and relations $a^2=e$ a² = e $a^{2}=e,b^{3}=e$, b² = e $b^3=e$ ther $G\cong Z_2*Z_3$ . [See Exercise 12 and compare Exercise 6.] 15. If $f:G_1\to G_2$ and $g:H_1\to H_2$ are homomorphisms of groups, then there is a unique homomorphism $h:G_1*H_1\to G_2*H_2$ such that h $\mid G_{1}=f$and$h\mid H_1=g$ $H_{1}=g$ H= g

------------------------------------------------------------------

1

CHAPTER II

# THE STRUCTURE OF GROUPS

We continue our study of groups according to the plan outlined in the introduction of Chapter I. The chief emphasis will be on obtaining structure theorems of some depth for certain classes of abelian groups and for various classes of (possibly non- abelian) groups that share some desirable properties with abelian groups. The chapter has three main divisions which are essentially independent of one another. except that results from one may be used as examples or motivation in the others. The interdependence of the sections is as follows.

![](https://storage.simpletex.cn/view/f8ToWbrGsVLvmUZbRamglnGKu4T1CbgkT)

Most of Section 8 is independent of the rest of the chapter.

## 1. FREE ABELIAN GROUPS

We shall investigatefreeobjects in the category of abeliangroups.As is the usual custom when dealing with abelian groups additive notation is used throughout this section. The following dictionary may be helpful.

![](https://storage.simpletex.cn/view/fn8QywT4FFpwI9ldyHOTfrXgungGAZTNr)

------------------------------------------------------------------



------------------------------------------------------------------

$n_{i}=m_{i}$ for every $i$ since $X$ is a basis. Consequently the map $\bar{f}:F\to G$ ,given by $\bar{f}(u)=\bar{f}\left(\sum_{i=1}^{k}n_{i}x_{i}\right)=n_{1}f(x_{1})+\cdots+n_{k}f(x_{k})$ Iis a we-deined function such that $\bar{f}_{l}=f.$ Since $G$ is abelian $\bar{f}$ is easily seen to be a homomorphism. Since $X$ generates $F$ , any homomorphism $F\to G$ is completely detemined by its action on $X$ . Thus if $g:F\to G$ is a homomorphism such that $g\iota=f$, then for any $x\in X$ $g( x) = g( \iota ( x) )$ $=f(x)=\bar{f}(x)$ ,whence $g=\bar{f}$ and $\bar{f}$ is unique. Therefore, by Defnition $\mathbf{I.7.7}$ F $F$ is a free object on the set $X$ in the category of abelian groups (iv$)\Rightarrow$ $\Longrightarrow$ = (ii). Given $\iota:X\to F$ , construct the direct sum $\sum\mathbf{Z}$ with the copies of $\mathbf{Z}$

indexed by $X$ Let $Y=\{\theta_{x}\mid x\in X\}$ be a basis of $\sum_{i=1}^{\infty}\frac{1}{2}$ $\mathbf{Z}$ as in the proof of (iii$) \Rightarrow ($i) The proof of (iii$) \Rightarrow ($i$) \Rightarrow ($i$v)$ shows that $\sum_{i=1}^{\infty}\frac{1}{2}$ $\mathbf{Z}$ is a free object on the set Y. Since we clearly have $|X|=|Y|,F\cong\sum$ $F\cong\sum$ F≤∑ $\mathbf{Z}$ by Theorem I.7.8.

Given any set $X$ , the proof of Theorem 1.1 indicates how to construct a free abelian group $F$ with basis $X$ .Simply let $F$ be the direct $sum\sum\mathbf{Z}_{:}$ with the copies of $\mathbf{Z}$ indexed by $X$ . As in the proof of (iii$) \Rightarrow ($i) $\{\theta_x\mid x\in X\}$ is a basis of $F=\sum\mathbf{z}$, and $F$ is free on the set $\{\theta_x\mid x\in X\}$ . Since the map $\iota:X\to F$ given by $x|\mapsto\theta_x$ is injective it follows easily that $F$ is free on $X$ in the sense of condition (iv) of Theorem 1.1. In this situation we shall identify. $X$ with its image under $\iota$ so that $X\subset F$ and the cyclic sub- &roue $F=\sum_{x\in X}\mathbf{Z}x.$ # $\langle\theta_{x}\rangle=\{n\theta_{x}\mid n\varepsilon\mathbf{Z}\}=\mathbf{Z}\theta_{x}$ Cear $\langle x\rangle=\mathbf{Z}x$ 万$F$ Tint $n_{1}x_{1}+\cdots+n_{k}x_{k}$ $F=\sum_{x\in X}\langle\theta_{x}\rangle$ #— $(n_{i}\varepsilon\mathbf{Z},x_{i}\varepsilon X)$ . In particular, $X=\iota(X)$ is a basis of $F$

Theorem 1.2. Any rwo bases of a free abelian group $F$ have the same cardinality

The cardinal number of any basis $X$ of the free abelian group $F$ is thus an invariant of $F$ F $F;|X|$ is called the rank of $F$

SKETCH OF PROOF OF 1.2. First suppose $F$ has a basis $X$ of finite cardinality $n$ so that $F\cong\mathbf{Z}\oplus\cdots\oplus\mathbf{Z}$ $in$ summands). For any subgroup $G$ of $F$ verify that $2G=\{2u\mid u\in G\}$ is a subgroup of $G$ . Verify that the restriction of the isomorphism $F\cong\mathbf{Z}\oplus\cdots\oplus\mathbf{Z}$ to $2F$ is an isomorphism $2F\cong2\mathbf{Z}\oplus\cdots\oplus2\mathbf{Z}$ ，whence $F/2F\cong\mathbf{Z}/2\mathbf{Z}\oplus\cdots\oplus\mathbf{Z}/2\mathbf{Z}\cong Z_2\oplus\cdots\oplus Z_2$ (n summands) by Corollary I.8.11. Therefore $|F/2F|=2^{n}$ .If $Y$ is another basis of $F$ and $r$ any integer such that $|Y|\geq r$ then a similar argument shows that $|F/2F|\geq2^r$ ,whence $2^r\leq2^n$ and $r\leq n$ It follows that $|Y|=m\leq n$ and $|F/2F|=2^{m}$ . Therefore $2^{m}=2^{n}$ and $|X|=n=m=|Y|$

If one basis of $F$ is infnite, then all bases are infinite by the previous paragraph. Consequently, in order to complete the proof it suffices to show that $|X|=|F|$ , if $X$ is any infinite basis of $F$ . Clearly $|X|\leq|F|$ .Let S = U xr, where $X^{n}=X\times\cdots\times X$ $S=\bigcup_{n\in\mathbb{N}^*}X^n$ nEN* $\bigcup_{n\in\mathbf{N}^*}.$ $n$ factors). For each $s=(x_{1},\ldots,x_{n})\varepsilon S$ let $G_{s}$ be the subgroup $\langle x_{1},\ldots,x_{n}\rangle$ . Then $G_{s}\cong\mathbf{Z}y_{1}\oplus\cdots\oplus\mathbf{Z}y_{t}$ where $y_1, \ldots , y_t$ $( t\leq n)$ (1 ≤ n) $(1\leq n)$ are the distinct elements of $\{x_{1},\ldots,x_{n}\}$ . Therefore, $|G_s|=|\mathbf{Z}^t|=|\mathbf{Z}|=\mathbf{N}_0$ by Introduction, Theorem 8.12. Since $F=\bigcup_{s\in S}G_{s}$, we have $|F|=|\bigcup_{s\in S}G_{s}|\leq|S|\aleph_{o}$ by Introduction, Exercise 8.12. But by Introduction, Theorems 8.11 and 8.12, $|S|=|X|$ , whence $|F|\leq|X|\aleph_0=|X|$ Therefore $|F|=|X|$ by the Schroeder-Bernstein Theorem.

------------------------------------------------------------------

Proposition 1.3. Let $F_{1}$ be the free abelian group on the set. $X_1$ and $F_2$ the free abeliar. group on theset $\mathbf{X}_2$ .Then $\mathbf{F}_{1}\cong\mathbf{F}_{2}$ ifand only ifF,and $F_2$ have the same rank (that is $|\mathbf{X}_{1}|=|\mathbf{X}_{2}|)$

REMARK. Proposition 1.3 is also true for arbitrary nonabelian free groups (as in Section I.9); see Exercise 12.

SKETCH OF PROOF OF 1.3. If $\alpha:F_{1}\cong F_{2}$, then $\alpha(X_1)$ is a basis of $F_{2}$ whence $|X_{1}|=|\alpha(X_{1})|=|X_{2}|$ by Theorem 1.2. The converse is Theorem I.7.8.

Theorem 1.4. Euery abelian group G is the homomorphic image of a free abelian. group of rank $|\mathbf{x}|$ , where $X$ is a set of generators of G

PROOF. Let $F$ be the freeabelian group on the set $X$ Then $F=\sum_{x\in X}\mathbf{Z}x$ and rank $F=|X|$ .By Theorem 1.1 the inclusion map $X\to G$ induces a homomorphisr $\bar{f}:F\to G$ such that $1x\vdash x\in G$ , whence $X\subset\operatorname{Im}\bar{f}$ Since $X$ generates $G$ we must have Im $\bar{f}=G$ .■

We now prove a theorem that will be extremely useful in analyzing the structure of finitely generated abelian groups (Section 2). We shall need

Lemma 1.5. $If\{\mathbf{x}_1,\ldots,\mathbf{x}_n\}$ is a basis ofa free abelian groupF and a E $\mathbf{Z}$ then for all. i$\neq$j$\left \{ x_{1}, \ldots , x_{i- 1}, x_{j}+ ax_{i}, x_{j+ 1}, \ldots , x_{n}\right \}$ is also a basis ofF

PROOF. Since $x_{j}=-ax_{i}+(x_{j}+ax_{i})$ , it follows that $F=\langle x_{1},\ldots,x_{j-1},x_{j}+$ $ax_{i},x_{j+1},\ldots,x_{n}\rangle$ . If $k_{1}x_{1}+ \cdots + k_{j}( x_{j}+ ax_{i}) + \cdots + k_{n}x_{n}= 0$ $( k_{i}\varepsilon \mathbf{Z} )$ ，then $k_{1}x_{1}+\cdots+(k_{i}+k_{j}a)x_{i}+\cdots+k_{j}x_{j}+\cdots+k_{n}x_{n}=0$ ,which implies that $k_t=0$ forall 1 .■

Theorem 1.6. If F is a free abelian group of finite rank nandG is a nonzero subgroup ofF,then there exists a basis $\{\mathbf{x}_{1},\ldots,\mathbf{x}_{\mathrm{n}}\}$ ofF,an integerr $(1\leq$r$\leq$n) and positive integers $d_1$ ...., $\mathbf{d}_{r}$ such that $d_1\mid d_2\mid\cdots\mid d_r$ and G isfree abelian with basis $\left\{\mathbf{d}_{\mathrm{l}}\mathbf{x}_{\mathrm{l}},\ldots,\mathbf{d}_{\mathrm{r}}\mathbf{x}_{\mathrm{r}}\right\}$

 REMARKS. Every subgroup of a free abelian group of (possibly infinite) rank $\alpha$ is free of rank at most $\alpha$ ; see Theorem IV.6.1. The notation *d $l_{1}\mid d_{2}\mid\ldots\mid d$, 'means $“d_1$ divides $d_2,d_2$ d2 $d_2$ divides $d_3$, etc."

PROOF OF 1.6.If $n=1$ , then $F=\langle x_{1}\rangle\cong\mathbf{Z}$ and $G=\left\langle d_{1}x_{1}\right\rangle\cong\mathbf{Z}\left(d_{i}\varepsilon\mathbf{N}^{*}\right)$ by Theorems I.3.5, I.3.1, and 1.3.2. Proceeding inductively, assume the theorem is true for all free abelian groups of rank less than n. Let $S$ be the set of all those integers $s$ such that there exists a basis $\{y_1,\ldots,y_n\}$ of $F$ and an element in $G$ of the form $sy_{1}+k_{2}y_{2}+\cdots+k_{n}y_{n}\left(k_{i}\varepsilon\mathbf{Z}\right)$ $(k_i\in\mathbf{Z})$ (ki e Z) . Note that in this case $\{y_2,y_1,y_3,\ldots,y_n\}$ is also a basis of $F$ whence $k_2\varepsilon S$ ; similarly $k_j\varepsilon S$ for $j=3,4,\ldots,n$ Since $G\neq0$ ,wehave $S\neq\varnothing$ . Hence $S$ contains a least positive integer $d_1$ and for some basis $\{y_1,\ldots,y_n\}$

------------------------------------------------------------------



------------------------------------------------------------------

(c) If $F$ is free abelian, it is nor true that every linearly independent subset of $F$ maybe extended to a basis of $F$ (d) If $F$ is free abelian, it is nor true that every generating set of $F$ contains a basis of $F.$ .However, if $F$ is also finitely generated by $n$ elements, $F$ has rank $m\leq n$

3. Let $X=\{a_{i}\mid i\varepsilon I\}$ be a set. Then the free abelian group on $X$ is (isomorphic to) the group defined by the generators $X$ and the relations (in multiplicative notation) $\{a_{i}a_{j}a_{i}^{-1}a_{j}^{-1}=e\mid i,j\varepsilon I\}$

4. A free abelian group is a free group (Section I.9) if and only if it is cyclic.

5.The direct sum of a family of free abelian groups is a free abelian group.(A direct product of free abelian groups need not be free abelian; see L. Fuchs [13, p. 168].)

6. If $F=\sum_{x\epsilon X}\mathbf{Z}x$ is a free abelian group, and $G$ is the subgroup with basis $X^{\prime}=X-\{x_0\}$ for some $x_0\varepsilon X$ ,then $F/G\cong\mathbf{Z}x_0$ Generalize thisresult to arbitrary subsets $X^{\prime}$ of $X$

7.A nonzero free abelian grouphas a subgroup of index $n$ for every positive integer $n$

8. Let $G$ be h utipicaive roup enered y he ea matices $a=\begin{pmatrix}2&0\\0&1\end{pmatrix}$ and $b=\begin{pmatrix}1&1\\0&1\end{pmatrix}.$ If $H$ is the set of all matrices in $G$ whose (main) diagonal entries are 1, then $H$ is a subgroup that is nor finitely generated

9. Let $G$ be a finitely generated abelian group in which no element (except O) has fnite order. Then $G$ is a free abelian group.[Hinr:Theorem 1.6.]

10. (a) Show that the additive group of rationals $\mathbf{Q}$ is not finitely generated (b) Show that $\mathbf{Q}$ is not free. (c) Conclude that Exercise 9 is false if the hypothesis “finitely generated" is omitted.

11. (a) Let $G$ be the additive group of all polynomials in $x$ with integer coefficients Show that $G$ is isomorphic to the group $Q^*$ of all positive rationals (under multiplication). (Hinr: Use the Fundamental Theorem of Arithmetic to construct an isomorphism. (b) The group $Q^*$ is free abelian with basis $\{p|p$ is prime in $\mathbf{Z}\}$

12. Let $F$ be the free (not necessarily abelian) group on a set $X$ (as in Section I.9) and $G$ the free group on a set $Y$ . Let $F^{\prime}$ be the subgroup of $F$ generated by $\left\{aba^{-1}b^{-1}\right|a,b\varepsilon F\}$ and similarly for $G^{\prime}$ (a) $F^{\prime}\triangleleft F_{j}$ $G^{\prime}\triangleleft G$ and $F/F^{\prime}$ $G/G^{\prime}$ are abelian [see Theorem 7.8 below]. (b) $F/F^{\prime}$ [resp. $G/G^{\prime}]$ is a free abelian group of rank $|X|$ [resp. [Y]. [Hint: $\{xF^{\prime}\mid x\in X\}$ is a basis of $F/F^{\prime}$ 小(c) $F\cong G$ if and only if $|X|=|Y|$ . [Hint: if $\varphi:F\cong G$ , then $\varphi$ induces an isomorphism $F/F^{\prime}\cong G/G^{\prime}$ .Apply Proposition 1.3 and (b). The converse is Theorem 1.7.8.]

------------------------------------------------------------------

1

1

## 2. FINITELY GENERATED ABELIAN GROUPS

We begin by proving two different structure theorems for finitely generated abelian groups. A uniqueness theorem (2.6) then shows that each structure theorem provides a set of numerical invariants for a given group (that is, two groups have the same invariants if and only if they are isomorphic). Thus each structure theorem leads to a complete classification(up to isomorphism) of all finitely generated abelian groups. As in Section 1, all groups are written additively. Many of the results (though not the proofs) in this section may be extended to certain abelian groups that are not finitely generated; see L. Fuchs [13] or I. Kaplansky [17]. All of the structure theorems tobe proved here are special cases of corresponding

theorems for finitely generated modules over a principal ideal domain (Section IV.6) Some readers may prefer the method of proof used in Section IV.6 to the one used here, which depends heavily on Theorem 1.6.

1

1

Theorem 2.1. Every finitely generated abelian group G is (isomorphic to) a finite. direct sum of cyclic groups in which the finite cyclic summands (if any) are of orders $\mathbf{m}_1,\ldots,\mathbf{m}_t$ $m_{t}$ mt ,where $m_1>1$ and $\mathbf{m}_{\mathrm{l}}\mid\mathbf{m}_{2}\mid\cdots\mid\mathbf{m}_{\mathrm{t}}$

PROOF. If $G\neq0$ and $G$ is generated by $n$ elements, then there is a free abelian group $F$ of rank $n$ and an epimorphism $\pi:F\to G$ by Theorem 1.4. If $\pi$ is an isomorphism, then $G\cong F\cong\mathbf{Z}\oplus\cdots\oplus\mathbf{Z}$ (n summands). If not, then by Theorem 1.6 there is a basis $\{x_{1},\ldots,x_{n}\}$ of $F$ and positive integers $d_1,\ldots,d_r$ such that $1\leq r\leq n$ $d_1\mid d_2\mid\cdots\mid d_r$ and $\{d_1x_1,\ldots,d_rx_r\}$ is a basis of $K=$ Ker $\pi$ Now F = (x) and $K=\sum_{i=1}^r\left\langle d_ix_i\right\rangle$ , where $\langle x_{i}\rangle\cong\mathbf{Z}$ and under the same isomorphism $\langle d_ix_i\rangle\cong d_i\mathbf{Z}$ $=\left\{d_{i}u\mid u\in\mathbf{Z}\right\}$ . For i=r+1 $i=r+1$ $i= r+ 1$, $r+ 2, \ldots , n$ let $d_i=0$ so that K = ≥(dix) Then by Corollaries I.5.7, 1.5.8, and I.8.11

$$G\cong F/K=\sum_{i=1}^{n}\langle x_{i}\rangle\left/\sum_{i=1}^{n}\langle d_{i}x_{i}\rangle\cong\sum_{i=1}^{n}\langle x_{i}\rangle/\langle d_{i}x_{i}\rangle\cong\sum_{i=1}^{n}\mathbf{Z}/d_{i}\mathbf{Z}.\right.$$

If $d_i=1$ , then $\mathbf{Z}/d_i\mathbf{Z}=\mathbf{Z}/\mathbf{Z}=0$ ; if $d_i>1$ , then $\mathbf{Z}/d_i\mathbf{Z}\cong Z_{d_i}$ ;if $d_i=0$ , then $\mathbf{Z}/d_i\mathbf{Z}=\mathbf{Z}/0\cong\mathbf{Z}$ .Let $m_1.$ m1 $m_{1},\ldots,m_{t}$ be those $d_i$ (in order)such that $d_i\neq0$ ,1 andlet s be the number of $d_i$ such that $d_i=0$ . Then

$$G\cong\mathbb{Z}_{m_1}\oplus\cdots\oplus\mathbb{Z}_{m_t}\oplus(\mathbb{Z}\oplus\cdots\oplus\mathbb{Z}),$$

where m > 1 $m_1>1$ $m_{1}>1,m_{1}\mid m_{2}\mid\cdots\mid m_{1}$ and $(\mathbf{Z}\oplus\cdots\oplus\mathbf{Z})$ has rank s.

1

1

Theorem 2.2. Every finitely generated abelian group G is (isomorphic to) a finite direct sum ofcyclic groups, each of which is either infinite or of order a power o fa prime

SKETCH OF PROOF. The theorem is an immediate consequence of Theorem 2.1 and the following lemma.Another proof is sketched in Exercise 4.

------------------------------------------------------------------

Lemma 2.3. If m is a positive integer and $\mathbf{m} = \mathbf{p} _{1}^{\mathrm{n} _{1}}\mathbf{p} _{2}^{\mathrm{n} _{2}}\cdots \mathbf{p} _{\mathrm{t} }^{\mathrm{n} _{\mathrm{t} }}\left ( \mathbf{p} _{\mathrm{l} }, \ldots , \mathbf{p} _{\mathrm{t} }\right )$ distinc primes and each $n_i>0$ ),then $\mathbb{Z}_{\mathfrak{m}}\cong\mathbb{Z}_{\mathfrak{pl}}^{\mathfrak{n}_1}\oplus\mathbb{Z}_{\mathfrak{pl}}^{\mathfrak{n}_1}\oplus\cdots\oplus\mathbb{Z}_{\mathfrak{pl}}^{\mathfrak{n}_1}$

SKETCH OF PROOF.Useinduction on the number 1 of primes in the prime decomposition of $m$ and the fact that

$$Z_{r_n}\cong Z_r\oplus Z_n\quad\mathrm{whenever}\quad(r,n)=1,$$

which we now prove. The element $n=n1\varepsilon Z_{rn}$ has order $r$ (Theorem I.3.4 (vi), whence $Z_r\cong\langle n1\rangle<Z_{rn}$ and the map $\psi_1{:}Z_r\to Z_m$ given by $k\mapsto nk$ is a monomorphism. Similarly the map $\psi_2{:}Z_n\to Z_{rn}$ given by $k\vdash rk$ is a monomorphism. By the proof of Theorem I.8.5 the map $\psi:Z_r\oplus Z_n\to Z_{rn}$ given by $(x,y)\vdash\psi_{1}(x)+\psi_{2}(y)=$ $nx+ry$ is a well-defined homomorphism. Since $(r,n)=1$ ， $ra+nb=1$ for some $a,b\in\mathbf{Z}$ (Introduction, Theorem 6.5). Hence $k=rak+nbk=\psi(bk,ak)$ for all $k\varepsilon Z_m$ and $\psi$ is an epimorphism. Since $|Z,\oplus Z_n|=rn=|Z_{rn}|,\psi$ must also be a monomorphism.

Corollary 2.4. IfG is a finite abelian group oforder n, then G has a subgroup oforder m for every positive integer m that divides n

SKETCH OF PRF Uus Theorem2 an beretht $G\cong\sum_{i=1}^kG_i$ implies that $|G|=|G_{1}||G_{2}|\cdots|G_{k}|$ and for $i\leq r,p^{r-i}Z_{p^{r}}\cong Z_{p^{i}}$ by Lemma 2.5 (v) below.

REMARK.Corollary2.4 may be false if $G$ is not abelian (Exercise I.6.8)

InTheorem 2.6 belowwe shall show that theorders of the cyclic summands in the decompositions of Theorems 2.1 and 2.2 are in fact uniquely determined by the group G. First we collect a number of miscellaneous facts about abelian groups that will be used in the proof.

Lemma 2.5.Ler G bean abelian group,m an integer and paprime integer.Then each of the following is a subgroup of G:

$$\text{mG = \{mu|u G\} ;}$$
(i) $\mathbf{G[m]}=\{u\varepsilon G|mu=0\}$ ; (i) $\mathbf{G} ( \mathbf{p} ) = \{ \mathbf{u} \varepsilon \mathbf{G} | | \mathbf{u} | = \mathbf{p} ^{\mathbf{n} }$ for some $\mathbf{n} \geq 0$ n≥0 $n\geq0$ ； (iv) $\mathbf{G}_{\mathbf{t}}=\{\mathbf{u}\varepsilon\mathbf{G}\mid|\mathbf{u}|$ is finite}. In particular there are isomorphisms

() $\mathbb{Z}_{p^n}[p]\cong\mathbb{Z}_p$ (n$\geq1)$ and $\mathbf{p}^{m}\mathbf{Z}_{p^{n}}\cong\mathbf{Z}_{p^{n-m}}(\mathfrak{m}<\mathfrak{n})$ Let $H$ and $\mathbf{G}_{\mathbf{i}}$ (i e I) be abelian groups. (vi) $If\mathbf{g} : \mathbf{G} \to \sum _{i\in I}\mathbf{G} _{\mathrm{i} }$ is an isomorphism, then therestrictions of g to mG and G[m]

respectively are isomorphisms $\mathbf{mG}\cong \sum _{i= I}\mathrm{mG}_{i}$ and $\mathbf{G} [ \mathfrak{m} ] \cong \sum _{i\in I}G_{\mathrm{i} }[ \mathfrak{m} ] .$

(vii) $If\mathbf{f}:\mathbf{G}\to\mathbf{H}$ is an isomorphism, then the restrictions of f to. $\mathbf{G}_{t}$ and $G(p)$ re spectively are isomorphisms $\mathbf{G}_{t}\cong\mathbf{H}_{t}$ and $\mathbf{G}(\mathbf{p})\cong\mathbf{H}(\mathbf{p})$

------------------------------------------------------------------

1

1

SKETCH OF PROOF. (i)-(iv) are exercises; the hypothesis that $G$ is abelian is essential $(S_3$ provides counterexamples for (i)-(ii) and Exercise I.3.5 for (iv)). (v) $P^{n-1}\varepsilon Z_{p^n}$ has order $P$ by Theorem I.3.4 (vi), whence $\langle p^{n-1}\rangle\cong Z_{p}$ and $\langle p^{n-1}\rangle$ $<Z_{pn}[p]$ .If $u\in Z_{p^n}[P]$, then $pu=0$ in $Z_{p^n}$ so that $pu\equiv0$ (mod $P^{n}$ in $\mathbf{Z}$ .But $P^n\mid pu$ implies $\cdot P^{n-1}\mid u.$ Therefore, $\sin Z_{p^n,u\in\langle p^{n-1}\rangle}$ and $Z_{p^n}[p]<\langle p^{n-1}\rangle$ . For the second statement note that $P^m\varepsilon Z_{p^n}$ has order $p^{n-m}$ by Theorem I.3.4 (vii). Therefore $P^mZ_{p^n}$ $=\langle p^{m}\rangle\cong Z_{p^{n-m}}$ (vi) is an exercise. (vii) If $f{:}G\to H$ is a homomorphism and $x\in G(p)$ has order $p^n$ ，then $p^{n}f(x)=f(p^{n}x)=f(0)=0$ . Therefore $f(x)\in H(p)$ .Hence $f:G(p)\to H(p)$ . If $f$ is an isomorphism then the same argument shows that $f^{-1}:H(p)\to G(p)$ .Since $ff^{-1}=1_{H(p)}$ and $f^{-1}f=1_{G(p)},G(p)\cong H(p)$ .The other conclusion of (vi) is proved similarly.

If $G$ is an abelian group, then the subgroup $G_{t}$ defined in Lemma 2.5 is called the torsion subgroup of $G$ .If $G=G_{t}$ then $G$ is said to be a torsion group. If $G_i=0$ ,then $G$ is said tobe torsion-free.For a complete classification of all denumerable torsion groups, see I. Kaplansky [17].

1

1

1

1

## Theorem 2.6.Let G be a finitely generated abelian group.

(i) There is a unique nonnegative integer s such that the number of infinite cyclic summands in any decomposition of G as a direct sum of cyclic groups is precisely s; (ii) either G is free abelian or there is a unique list of (not necessarily distinct)

positive integers $m_{\mathrm{l}}$ ..... $m_t$ such that $m_1>1$ ， $m_{1}\mid m_{2}\mid\cdots\mid m_{t}$ and

$$\mathrm{G\cong Z_{m_1}\oplus\cdots\oplus Z_{m_t}\oplus F}$$

with F free abelian;

(ii) either G is free abelian or there is a list of positive integers $\mathbf{p}_{1}^{81},\ldots,\mathbf{p}_{\mathbf{k}}^{8k}$ which is unique except for the order of its members,such that $\mathbf{p}_1,\ldots,\mathbf{p}_k$ are(not necessarily distinct) primes, $\mathbf{s}_{\mathrm{l}},\ldots,\mathbf{s}_{\mathrm{k}}$ Sk $S_k$ are (not necessarily distinct) positive integers and

$$\mathrm{G\cong Z_{pl}^{sl}\bigoplus...\textcircled{+}Z_{pk}^{s_k}\textcircled{+}F}$$

with F free abelian.

PROOF. (i) Any decomposition of $G$ as a direct sum ofcyclicgroups(and thereis at least one by Theorem 2.1) yields an isomorphism $G\cong H\oplus F$ ,where $H$ is a direct sum of finite cyclic groups (possibly O) and $F$ is a free abelian group whose rank is precisely the number $s$ of infinite cyclic summands in the decomposition. If $\iota:H\to H\oplus F$ is the canonical injection $(h|\mapsto(h,0))$ ,then clearly $\iota(H)$ is the torsion subgroup of $H\oplus F$ .By Lemma 2.5, $G_t\cong\iota(H)$ under the isomorphism $G\cong H\oplus F$ Consequently by Corollary I.5.8, $G/G_t\cong(F\oplus H)/\iota(H)\cong F$ Therefore, any decomposition of $G$ leads to the conclusion that $G/G_i$ is a free abelian group whose rank is the number $s$ of infinite cyclic summands in the decomposition. Since $G/G_t$ does not depend on the particular decomposition and the rank of $G/G_t$ is an invariant by Theorem 1.2, $s$ is uniquely determined. (ii) Suppose $G$ has two decompositions, say

$$G\cong\sum_{i=1}^rZ_{n_i}\oplus F\quad\mathrm{and}\quad G=\sum_{j=1}^dZ_{k_j}\oplus F^{\prime},$$

1

[

------------------------------------------------------------------

with each $n_i,k_j$ a power of a prime (different primes may occur) and $F,F^{\prime}$ free abelian; (there is at least one such decomposition by Theorem 2.2). We must show that $r=d$ and (after reordering) $\eta_{i}=k_{i}$ for every i.It iseasy tosee that the torsion subgroup of $\sum Z_{n_i}\oplus F$ is (isomorphic to) $\sum Z_{n_i}$ and similarly for the other decomposition. Hence $\sum_{i=1}^{\overline{r}}Z_{n_i}\cong G_{l}\cong\sum_{j=1}^{d}Z_{k}$, by Lemma 2.5.Fo eah prime $P$ $(\sum Z_{n_i})(p)$ is obvi ously (isomorphic to) the direct sum of those $Z_{n_i}$ such that $n_{i}$ is a power of $p$ and similarly for the other decomposition. Since $(\sum Z_{n_i})(p)\cong(\sum Z_{k_i})(p)$ for each prime $p$ by Lemma 2.5, it suffces to assume that $G=G_{t}$ and each $n_i,k_j$ is a power of a fixed prime $p$ (so that $G=G(p)$ .Hencewe have

$$\sum_{i=1}^rZ_{p^{a_i}}\cong G\cong\sum_{j=1}^dZ_{p^cj}(1\leq a_1\leq a_2\leq\cdots\leq a_r;1\leq c_1\leq c_2\leq\cdots\leq c_d).$$

We first show that in any two such decompositions of a group we must have $r=d.$ Lemma 2.5 and the first decomposition of $G$ show that

$$G[p]\cong\sum_{i=1}^rZ_{p^{a_i}}[p]\cong Z_p\oplus\cdots\oplus Z_p\text{(r summands),}$$

whence $|G[p]|=p^{r}$ . A similar argument with the second decomposition shows that $|G[p]|=p^{d}$ . Therefore, $p^{r}=p^{d}$ and $r=d$ Let $\nu\left(1\leq\nu\leq r\right)$ be thefirst integer such that $a_{i}=c_{i}$ for all $i<\nu$ and $a_v\neq c_v$

We may assume that $a_v<c_v$ . Since $P^{a_v}Z_{p^{a_i}}=0$ for $a_i\leq a_v$ , the first decomposition and Lemma 2.5 imply that

$$p^{a_v}G\cong\sum_{i=1}^rp^{a_v}Z_{p^a_i}\cong\sum_{i=v+1}^rZ_{p^{a_i-a_v}},$$

with $a_{v+1}-a_{v}\leq a_{v+2}-a_{v}\leq\cdots\leq a_{r}-a_{v}.$ Clearly, there are at most $r-(v+1)+$ $1=r-v$ nonzero summands. Similarly since $a_{i}=c_{i}$ for $i<v$ and $a_v<c_v$ the second decomposition implies that

$$p^{a_v}G\cong\sum_{i=v}^rZ_{p^{c_i-a_v}},$$

with $1\leq c_{v}-a_{v}\leq c_{v+1}-a_{v}\leq\cdots\leq c_{r}-a_{v}$ Obviously there are at least $r-v+1$ nonzero summands. Therefore, we have two decompositions of the group $P^{av}G$ as a direct sum of cyclic groups of prime power order and the number of summands in the frst decomposition is less than the numter of summands in the second. This contradicts the part of the Theorem proved in the previous paragraph (and appliec here to $p^{av}G$ 0. Hence we must have $a_{i}=c_{i}$ for all i. (ii) Suppose $G$ has two decompositions, say

$$G\cong Z_{m_1}\oplus\cdots\oplus Z_{m_t}\oplus F\mathrm{~and~}G\cong Z_{k_1}\oplus\cdots\oplus Z_{k_d}\oplus F^{\prime}$$

with m > 1 $m_1>1$ $m_1>1,m_1\mid m_2\mid\cdots\mid m_t,k_1>1,k_1\mid k_2\mid\cdots\mid k_d$ and k1| k2|...| kd $k_1\mid k_2\mid\cdots\mid k_d$ $F$ $F^{\prime}$ free abelian; (one such decomposition exists by Theorem 2.1). Each. $m_i,k_j$ has a prime decomposition and by inserting factors of the form $p^{0}$ wemay assume that the same (distinct) primes $p_1,\ldots,p_r$ occur in all the factorizations, say

------------------------------------------------------------------

1

1

1

k=pip..p m1 = Pp2.. .P" K2=Pp.p m=pipa..p
$$m_{t}\:=\:p_{1}^{a_{t1}}p_{2}^{a_{t2}}\cdots p_{r}^{a_{tr}}\quad k_{d}=p_{1}^{c_{d1}}p_{2}^{c_{d2}}\cdots p_{r}^{c_{dr}}.$$

Since $m_{1}\mid m_{2}\mid\cdots\mid m_{l}$ , we must have for each j, $0\leq a_{1j}\leq a_{2j}\leq\cdots\leq a_{tj}$ . Similarly $0\leq c_{1j}\leq c_{2j}\leq\cdots\leq c_{dj}$ for each $j.$ .By Lemmas 2.3 and 2.5

$$\sum_{i,j}Z_{p_{j}}^{a_{ij}}\cong\sum_{i=1}^{t}Z_{m_{i}}\cong G_{t}\cong\sum_{i=1}^{d}Z_{k_{i}}\cong\sum_{i,j}Z_{p_{j}}^{c_{ij}},$$

where some summands may be zero. It follows that for each $j=1,2,\ldots,r$

$$\sum_{i=1}^tZ_{p_j}{}^{a_{ij}}\cong G(p_i)\cong\sum_{i=1}^dZ_{p_j}{}^{c_{ij}}.$$

Since $m_1>1$ , there is some $p_{i}$ such that $1\leq a_{1j}\leq\cdots\leq a_{tj}$ whence Z,μas has nonzero summands. By (ii) ≥Z,;:s has exactly 1 nonzero summands, whencee $t\leq d$ . Similarly $k_1>1$ implies that $d\leq t$ and hence $d=t.\mathbf{By}$ (ii) we now must have $a_{ij}=c_{ij}$ for all $i,j$ , which implies that $m_i=k_i$ for i = 1,2 $i=1,2$ $i=1,2,\ldots,t.$

If $G$ is a finitely generated abelian group, then the uniquely determined integers $m_1,\ldots,m_t$ mt $m_i$ as in Theorem 2.6 (i) are called the invariant factors of $G.$ The uniquely determined prime powers as in Theorem 2.6 (ii) are called the elementary divisors of $G$

1

1

1

Corollary 2.7. Two finitely generated abelian groups G and H are isomorphic if and. only $if\mathbf{G}/\mathbf{G}_{t}$ and $H/H_t$ have the same rank and G and H have the same invariant. factors [resp. elementary divisors].

PROOF. Exercise

EXAMPLE.All finite abelian groups of order 1500 may be determined up to isomorphism as follows. Since the product of the elementary divisors of a finite group $G$ must be $|G|$ and $1500=2^2\cdot3\cdot5^3$ ,the only possible families of elementary divisors are $\{2,2,3,5^{3}\}$ ， $\{2,2,3,5,5^{2}\}$ ,{2,2,3,5,5,5}, $\{2^2,3,5^8\}$ , {22,3,5,52} and {22,3,5,5,5} Each of these six families determines an abelian group of order 1500 (for example, $\{2,2,3,5^3\}$ determines $Z_2\oplus Z_2\oplus Z_3\oplus Z_{125})$ . By Theorem 2.2 every abelian group of order 1500 is isomorphic to one of these six groups and no two of the six are isomorphic by Corollary 2.7.

If the invariant factors $m_1,\ldots,m_t$ of a finitely generated abelian group $G$ are known, then the proof of Theorem 2.6 shows that the elementary divisors of $G$ are the prime powers $P^n(n>0)$ which appear in the prime factorizations of $m_1,\ldots,m_t$ Conversely if the elementary divisors of $G$ are known, they may be arranged in the following way (after the insertion of some terms of the form $p^0$ if necessary):

1

1

------------------------------------------------------------------

Pr", Pn,..., Pnur P,pm,...,Pr
$$p_{1}^{n_{t1}},p_{2}^{n_{t2}},\ldots,p_{r}^{n_{tr}}.$$

where $p_{1},\ldots,p_{r}$ are distinct primes; for each $j=1,2,\ldots,r,0\leq n_{1i}\leq n_{2i}\leq\cdots\leq n_{tj}$ with some $n_{ij}\neq0$ ; and finally $n_{1j}\neq0$ for some $j$ .By the definition of elementary diviors (Thorem 2.6(i), $G\cong\sum_{i=1}^t\sum_{j=1}^rZ_{p_jn_ij}\oplus F$ where $F$ is freabelan and ome finite summands are O, namely those with $P_{i}^{n_{ij}}=p_{i}^{0}=1$ 0. For each $i=1,2,\ldots,t$ let $m_{i}=p_{1}^{n_{i1}}p_{2}^{n_{i2}}\cdots p_{r}^{n_{ir}}$ (that is, $m_i$ is the product of the ith row in the array above). Since some $n_{1j}\neq0$ ， $m_{1}>1$ and by construction $m_{1}\mid m_{2}\mid\cdots\mid m_{t}$ .By Lenma 2.3 $G\cong\sum_{i=1}^{i}\left(\sum_{j=1}^{i}Z_{p_jn_{ij}}\right)\oplus F\cong\sum_{i=1}^{i}Z_{m_i}\oplus F$ . Therefore, $m_1,\ldots,m_t$ are he invarian factors of $G$ by Theorem 2.6 (ii).

EXAMPLE. If $G$ is the group $Z_5\oplus Z_{15}\oplus Z_{25}\oplus Z_{36}\oplus Z_{54}$, then by Lemma 2.3 $G\cong Z_5\oplus(Z_5\oplus Z_3\oplus Z_5\oplus(Z_4\oplus Z_4)\oplus(Z_7\oplus Z_2)$ .Hence the elementary divi sors of $G$ are $2,2^2,3,3^2,3^3,5,5^2$ which may be arranged as explained above:

$$\begin{array}{ll}2^0,&3,&5\\2,&3^2,&5\\2^2,&3^3,&5^2.\end{array}$$

Consequently the invariant factors of $G$ are $1\cdot3\cdot5=15$ $1\cdot3\cdot5=15$ $1\cdot3\cdot5=15,2\cdot3^2\cdot5=90$ $2\cdot3^2\cdot5=90$ $2\cdot3^2\cdot5=90$ and $2^2\cdot3^3\cdot5^2=2700$ so that $G\cong Z_{15}\oplus Z_{90}\oplus Z_{2700}$

A topic that would fitnaturally into this section is the determination of the structure of a finitely generated abelian group which is described by generators and relations. However, since certain matrix techniques are probably the best way to handle this question, it will be treated in the Appendix to Section Vli.2. The interested reader should have little or no difficulty in reading that material at the present time.

## EXERCISES

1. Show that a finite abelian group that is not cyclic contains a subgroup which is isomorphic to $Z_{p}\oplus Z_{p}$ for some prime $P$

2. Let $G$ be a finite abelian group and $x$ an element of maximal order. Show that $\langle x\rangle$ is a direct summand of $G$ . Use this to obtain another proof of Theorem 2.1.

3. Suppose $G$ is a finite abelian $P$ -group (Exercise 7) and $x\varepsilon G$ G $G$ has maximal order. If $y\in G/(x)$ has order $p^r$ , then there is a representative $y\in G$ G $G$ of the coset $y$ such that $|y|=p^{r}$ . [Note that if $|x|=p^{t}$ ,then $P^{\prime}G=0.$

4. Use Exercises 3 and 7 to obtain a proof of Theorem 2.2 which is independent of Theorem 2.1. [Hint: If $G$ is a $P$ group, let $x$ E $G$ have maximal order; $G/\langle x\rangle$ is a direct sum of cyclics by induction, $G/\langle x\rangle\:=\:\langle\bar{x}_{1}\rangle\:\oplus\cdots\oplus\:\langle\bar{x}_{n}\rangle$ ,with $\left|\bar{x}_i\right|\:=p^{ri}$

------------------------------------------------------------------

]

and $1\leq r_{1}\leq r_{2}\leq\cdots\leq r_{n}$ . Choose representatives $x_i$ of $\bar{x}_i$ such that $|x_{i}|=|\bar{x}_{i}|$ Show that $G=\langle x_{1}\rangle\oplus\cdots\oplus\langle x_{n}\rangle\oplus\langle x\rangle$ is the desired decomposition.]

5.If $G$ is a finitely generated abelian group such that $G/G_t$ has rank $n$ , and $H$ is a subgroup of $G$ such that $H/H_i$ has rank $m$ , then $m\leq n$ and $(G/H)/(G/H)$ has rank $n-m$

6. Let $k$ k $k,m\in\mathbf{N}^{*}$ .If $(k,m)=1$ , then $kZ_{m}=Z_{m}$ and Zm[k] = 0 $Z_m[k]=0$ $Z_{m}[k]=0.$If$k\mid m$,say$m=kd$, then $kZ_{m}\cong Z_{d}$ and $Z_m[k]\cong Z_k$

7. A (sub)group in which every element has order a power of a fixed prime $p$ is called a $p$ -(sub)group (note: $|0|=1=p^{0})$ . Let $G$ be an abelian torsion group. (a) $G(p)$ is the unique maximum $p$ -subgroup of $G$ (that is, every $p$ -subgroup of $G$ is contained in $G(p)$ (b) $G=\sum G(p)$ , where the sum is over all primes $p$ such that $G(p)\neq0$ $[Hint:$If$|u|=p_1^{n1}\cdots p_t^{nt}$ ,let $m_{i}=|u|/p_{i}^{n_{i}}$ .There exist $c_i$ ε Zsuch that $c_1m_1+\cdots$ $+c_{l}m_{t}=1$ ,whence $u=c_1n_1u+\cdots+cm_tu$ but $c_im_iu\in G(p_i)$ $G(p_i)$ G(pi) (c) If $H$ is another abelian torsion group, then $G\cong H$ if and only if $G(p)\cong H(p)$ for all primes $P$

8. A finite abelian $P$ -group (Exercise 7) is generated by its elements of maximal order.

9. How many subgroups of order $p^2$ does the abelian group $Z_{p^3}\oplus Z_{p^2}$ have?

10. (a) Let $G$ be a finite abelian $P$ -group (Exercise 7). Show that for each $n\geq0$ $p^{n+1}G\cap G[p]$ is a subgroup of $p^nG\cap G[p]$ (b) Show that $(p^{n}G\cap G[p])/(p^{n+1}G\cap G[p])$ is a direct sum of copies of $Z_p$ ; let $k$ be the number of copies. (c) Write $G$ as a direct sum of cyclics; show that the number $k$ of part (b) is the number of summands of order $p^{n+1}$

11. Let $G,H.$ and $K$ be finitely generated abelian groups. (a) If $G\oplus G\cong H\oplus H$, then $G\cong H$

(b) If $G\oplus H\cong G\oplus K$ ,then $H\cong K$ (c) If $G_{1}$ is a free abelian group of rank $\aleph_0$ , then $G_1\oplus\mathbf{Z}\oplus\mathbf{Z}\cong G_1\oplus\mathbf{Z}$, but $\mathbf{Z}\oplus\mathbf{Z}\not\cong\mathbf{Z}$ Note: there exists an infinitely generated denumerable torsion-free abelian group. $G$ such that $G\cong G\oplus G\oplus G$ but $G\not\cong G\oplus G$ , whence (a) fails to hold with $H=G\oplus G$ . See A.L.S. Corner [60]. Also see Exercises 3.11, 3.12, and IV.3.12.

12. (a) What are the elementary divisors of the group $Z_2\oplus Z_9\oplus Z_{35}$ ; what are its invariant factors? Do the same for $Z_{26}\oplus Z_{42}\oplus Z_{49}\oplus\bar{Z}_{200}\oplus Z_{1000}$ (b) Determine up to isomorphism all abelian groups of order 64; do the same for order 96. (c) Determine all abelian groups of order $n$ for $n\leq20$

13. Show that the invariant factors of $Z_m\oplus Z_n$ are $(m,n)$ and $[m,n]$ (the greatest common divisor and the least common multiple) if $(m,n)>$ 1 andmnif $(m,n)=1$

14.If $H$ is a subgroup of a fnite abelian group $G$ , then $G$ has a subgroup that is isomorphic to $G/H$

15. Every finite subgroup of $\mathbf{Q}/\mathbf{Z}$ is cyclic [see Exercises I.3.7 and 7]

1

1

1

------------------------------------------------------------------

## 3. THE KRULL-SCHMIDT THEOREM

The groups $\mathbf{Z}$ and $Z_{p^n}$ $P$ prime) are indecomposable, in the sense that neither is a direct sum of two of its proper subgroups (Exercise I.8.1). Consequently, Theorems 2.2 and 2.6(ii) may be rephrased as: every finitely generated abelian group is the direct sum of a finite number of indecomposable groups and these indecomposable summands are uniquely determined up to isomorphism.We shall now extend this result to a large class of (not necessarily abelian) groups.

For theremainder of this chapter wereturn to the use of multiplicative notation for an arbitrary group.

Definition 3.1. A group G is-indecomposable $ifG\neq\langle e\rangle$ and G is not the (internal) direct product of two of its proper subgroups.

Thus $G$ is indecomposable if and only if $G\neq\langle e\rangle$ and $G\cong H\times K$ implies $H=\langle e\rangle$ or $K=\langle e\rangle$ (Exercise 1).

EXAMPLES. Every simple group (for example, An $A_n$ $A_n,n\neq4$ ) is indecomposable However indecomposable groups need not be simple: Z $,Z_{p^n}(p$ prime) and $S_n$ are indecomposable but not simple (Exercises 2 and I.8.1).

Definition 3.2. A group G is said to satisfy the ascending chain condition (ACC) on [normal] subgroups if for every chain $\mathbf{G}_1<\mathbf{G}_2<\cdots$ of[normal] subgroups ofG there is an integern suchthat $\mathbf{G_{i}}=\mathbf{G_{rr}}$ for all i ≥n. G is said to satisfy the descending chain condition (DCC) on [normal] subgroups if for every chain $G_{1}>G_{2}>\cdots$ of [normal] subgroups ofG there is an integer n such that $\mathbf{G}_{\mathrm{i}}=G_{\mathrm{n}}$ for all $i\geq n$

EXAMPLES. Every finite group satisfies both chain conditions. $\mathbf{Z}$ satisfies the ascending but not the descending chain condition (Exercise 5) and $Z(p^{\infty})$ satisfies the descending but not the ascending chain condition (Exercise 13).

Theorem 3.3.Ifa group G sarisfies either the ascending ordescending chain condition on normal subgroups, then G is the direct product ofa finite number of indecomposable subgroups.

SKETCH OF PROOF. Suppose $G$ is not a fnite direct product of indecomposable subgroups. Let $S$ be the set of all normal subgroups $H$ of $G$ such that $H$ is a direct factor of $G$ (that is, $G=H\times T_{H}$ for some subgroup $T_{H}$ of $G$ ) and $H$ is not a finite direct product of indecomposable subgroups. Clearly $G\varepsilon S$ . If $H\varepsilon S$ ,then $H$ is not indecomposable, whence there must exist proper subgroups $K_{H}$ and $J_{H}$ of $H$ such that $H=K_{H}\times J_{H}$ $(=J_{H}\times K_{H})$ .Furthermore, one of these groups, say $K_{H}$ , must lie in $S$ (in particular, $K_{H}$ is normal in $G$ by Exercise I.8.12). Let $f{:}S\to S$ be the map

------------------------------------------------------------------



------------------------------------------------------------------

PROOF. Since $f$ is a normal endomorphism each Im $f^k(k\geq1)$ is normal in $G$ Hence we have two chains of normal subgroups:

$$G>\operatorname{Im}f>\operatorname{Im}f^2>\cdots\quad\mathrm{and}\quad\langle e\rangle<\operatorname{Ker}f<\operatorname{Ker}f^2<\cdots.$$

By hypothesis there is an $n$ such that Im $f^{k}=$Im$f^n$ and Ker $f^k=$Ker $f^n$ for all $k\geq n$ . Suppose a e Ker $f^n\cap$ Im $f^n$ . Then $a=f^{n}(b)$ for some $b\varepsilon G$ and $f^{2n}(b)$ $=f^{n}(f^{n}(b))=f^{n}(a)=e.$ Consequently, $b$ ε Ker $f^{2n}=$Ker$f^n$ so that $a=f^{n}(b)=e$ Therefore, Ker $f^{n}\cap$Im$f^n=\langle e\rangle$ . For an $f^n(c)$ fr(c) $\mathbf{y}$ $c\in G, f^{n}( c) \varepsilon$Im$f^{n}=$Im$f^{2n}$ $f^{n}=\operatorname{Im}f^{2n}$ fn = Im f2n ，whence $f^n(c)=f^{2n}(d)$ for some $d\varepsilon G$ . Thus $f^{n}(cf^{n}(d^{-1}))=f^{n}(c)f^{2n}(d^{-1})=f^{n}(c)f^{2n}(d)^{-1}$ $=f^n(c)f^n(c)^{-1}=e$ and hence $cf^n(d^{-1})$ ∈ Ker $f^n$ . Since $c=(cf^n(d^{-1}))f^n(d)$ ，we conclude that $G=($Ker $f^n)($Im $f^n)$ . Therefore $G=\mathbf{Ker}$ $f^n\times$Im $f^n$ by Definition 1.8.8.

An endomorphism fof a group $G$ is said to be nilpotent if there exists a positive integer $n$ such that $f^{n}(g)=e$ for all $g\varepsilon G$

Corollary 3.6.IfG is an indecomposable group that satisfies both the ascending and descending chain conditions on normal subgroups and f is a normal endomor phism of G,. then either f is nilpotent or f is an automorphism..

PROOF. For some $n\geq1$ ， $G=\operatorname{Ker}f^{n}\times\operatorname{Im}f^{n}$ by Fitting's Lemma. Since $G$ is indecomposable either Ker. $f^{n}=\langle e\rangle$ or $\mathbf{Im}f^{n}=\langle e\rangle$ . The latter implies that $f$ is nilpotent. If Ker $f^{n}=\langle e\rangle$ , then Ker $f=\langle e\rangle$ and $f$ is a monomorphism. Therefore, fis an automorphism by Lemma 3.4.

If $G$ is a group and f, g are functions from G to $G$ ,then $f+g$ denotes the function $G\to G$ given by a $\mapsto$f(a)g(a) . Verify that the set of all functions from $G$ to $G$ is a group under + (with identity the map $0_{\mathrm{G} }{: }\mathbf{G} \to \mathbf{G}$ given by a $\mapsto$e for all a ε G). When f and $g$ are endomorphisms of G, $f+g$ need not be an endomorphism (Exercise 7). So the subset of endomorphisms is not in general a subgroup.

Corollary 3.7. Let G $i(\neq\langle e\rangle)$ be an indecomposable group that satisfies both the ascending and descending chain conditions on normal subgroups. $If\mathbf{f}_{1},\ldots,\mathbf{f}_{\mathrm{n}}$ are normal nilpotent endomorphisms ofG such that every $\mathbf{f} _{\mathrm{i} 1}+ \cdots + \mathbf{f} _{\mathrm{i} _{\mathrm{r} }}( 1\leq \mathbf{i} _{\mathrm{l} }< \mathbf{i} _{2}< \cdots < \mathbf{i} _{\mathrm{r} }\leq \mathbf{n} )$ is an endomorphism,then $\mathbf{f}_{1}+\mathbf{f}_{2}+\cdots+\mathbf{f}_{\mathrm{n}}$ is nilpotent.

SKETCH OF PROOF. Since each $f_{i_1}+\cdots+f_{i_r}$ is an endomorphism that is normal (Exercise 8(c)), the proof will follow by induction once the case $n=2$ is established. If $f_1+f_2$ is not nilpotent, it is an automorphism by Corollary 3.6. Verify that the inverse $g$ of $f_1+f_2$ is a normal automorphism. If $g_{1}=f_{1}g$ and $g_{2}=f_{28}$ ,then $\mathbf{l}_{G}=g_{1}+g_{2}$ and for all $x\in G$ ， $x^{-1}=(g_{1}+g_{2})(x^{-1})=g_{1}(x^{-1})g_{2}(x^{-1})$ .Hence $x=[g_{1}(x^{-1})g_{2}(x^{-1})]^{-1}=g_{2}(x)g_{1}(x)=(g_{2}+g_{1})(x)$ ）and $\mathbf{l}_{G}=g_{2}+g_{1}$ . Therefore,. $g_{1}+g_{2}=g_{2}+g_{1}$ and $g_{1}(g_{1}+g_{2})=g_{1}l_{G}=1_{G}g_{1}=(g_{1}+g_{2})g_{1}$ ,which implies that $g_{1}g_{2}=g_{2}g_{1}$ . A separate inductive argument now shows that for each $m\geq1$

$$(g_1+g_2)^m=\sum_{i=0}^mc_ig_1^ig_2^{m-i}(c_i\varepsilon\mathbf{Z}),$$

------------------------------------------------------------------

[

where the $c_i$ are the binomial coefficients(see Theorem Ill.1.6) and $c_ih$ means $h+h+\cdots+h$ $c_i$ summands). Since each $f_i$ is nilpotent, $g_{i}=f_{i}g$ has a nontrivial kernel, whence $g_i$ is nilpotent by Corollary 3.6.Therefore for large enough $m$ and all aeG, $(g_{1}+g_{2})^{m}(a)=\sum_{i=0}^{m}c_{i}g_{1}^{i}g_{2}^{m-i}(a)=\prod_{i=0}^{m}e^{c_{i}}=e.$ But this conradiesthe faets that $g_{1}+g_{2}=1_{G}$ and $G\neq\langle e\rangle$ .

The next theorem will make use of the following facts. If a group $G$ is the internal direct product of its subgroups $G_1,\ldots,G_s$ then by the proof of Theorem I.8.6 there is an isomorphism $\varphi:G_1\times\cdots\times G_s\cong G$ given by $(g_1,\ldots,g_s)\vdash g_1g_2\cdots g_s$ .Consequently, every element of $G$ may be written uniquely as a product $g_{1}g_{2}\cdots g_{s}(g_{i}\varepsilon G_{i})$ For each $i$ the map $\pi_i:G\to G_i$ given by $g_1g_2\cdots g_s\vdash g_i$ is a well-defined epimorphism; (it is the composition of $\varphi^{-1}$ with the canonical projection $G_1\times\cdots\times$ $G_{s}\to G_{i}$ ) We shall refer to the maps $\pi_{i}$ as the canonical epimorphisms associated with the internal direct product $G=G_{1}\times\cdots\times G$,

Theorem 3.8. (Krull-Schmidt) Let G be a group that satisfies both the ascending and descending chain conditions on normal subgroups. If $\mathbf{G}=\mathbf{G}_{1}\times\mathbf{G}_{2}\times\cdots\times\mathbf{G}_{8}$ and $\mathbf{G}=\mathbf{H}_{1}\times\mathbf{H}_{2}\times\cdots\times\mathbf{H}_{t}$ with each $G_i,H_j$ indecomposable, then $s=t$ and after reindexing $\mathbf{G}_{\mathrm{i}}\cong\mathbf{H}_{\mathrm{i}}$ for every i and for each 1 $<t$

$$G=G_1\times\cdots\times G_r\times H_{r+1}\times\cdots\times H_t.$$

REMARKS. $G$ has at least one such decomposition by Theorem 3.3. The unique ness statement here is stronger than simply saying that the indecomposable factors are determined up to isomorphism

SKETCH OF PROOF OF 3.8. Let $P(0)$ be the statement $G=H_{1}\times\cdots\times H_{t}$ For $1\leq r\leq\min{(s,t)}$ (s,1) $(s,t)$ let $P(r)$ be the statement: there is a reindexing of $H_{1},\ldots,H_{t}$ such that $G_{i}\cong H_{i}$ for $i=1,2,\ldots,r$ r $r$ and $G=G_1\times\cdots\times G_r\times H_{r+1}\times\cdots\times H_t$ (or $G=G_{1}\times\cdots\times G_{t}$ if $r=t$ ). We shall show inductively that. $P(r)$ is true for all r such that $0\leq r\leq \min$ $( s, t) .$ $P( 0)$ $( s, t) .$ $P( 0)$ $( s, t) .$ $P( 0)$ is true by hypothesis,and so we assume that $P(r-1)$ is true: after some reindexing $G_{i}\cong H_{i}$ for $i=1,\ldots,r-1$ and $G=G_{\mathrm{l}}\times\cdots\times G_{r-1}\times H_{r}\times\cdots\times H_{t}$ Let $\pi_1,\ldots,\pi_s$ [resp. $\pi_1^{\prime},\ldots,\pi_t^{\prime}]$ be the canonical epimorphisms associated with the internal direct product

$$G=G_1\times\cdots\times G_s[\mathrm{resp.}G=G_1\times\cdots\times G_{r-1}\times H_r\times\cdots\times H_t]$$

as in the paragraph preceding the statement of the Theorem.Let $\lambda_i$ [resp. $\lambda_i^{\prime}]$ be the inclusion maps sending the ith factor into $G$ . For each $i$ let $\varphi_{i}=\lambda_{i}\pi_{i}:G\to G$ and let $\psi_{i}=\lambda_{i}^{\prime}\pi_{i}^{\prime}:G\to G$ .Verif y that the following identities hold.

$$\varphi_{i}\mid G_{i}=1_{G_{i}};\varphi_{i}\varphi_{i}=\varphi_{i};\varphi_{i}\varphi_{j}=0_{G}\:(i\neq j)^{2};\\\psi_{1}+\cdots+\psi_{i}=1_{G};\psi_{i}\psi_{i}=\psi_{i};\psi_{i}\psi_{j}=0_{G}\:(i\neq j);\\\mathrm{Im}\:\varphi_{i}=G_{i};\mathrm{Im}\:\psi_{i}=G_{i}\:(i<r);\mathrm{Im}\:\psi_{i}=H_{i}\:(i\geq r).$$

It follows that $\varphi_{r}\psi_{i}=0_{C}$ for all $i<r$ (since $\psi_i(x)\varepsilon G_i$ so that $\varphi_{\tau}\psi_{i}(x)=\varphi_{r}\mathbf{l}_{G_{i}}\psi_{i}(x)$ $=\varphi_{r}\varphi_{i}\psi_{i}(x)=e)$

1

------------------------------------------------------------------

The preceding identities show that $\varphi_{r}=\varphi_{r}\mathbf{l}_{G}=\varphi_{r}(\psi_{1}+\cdots+\psi_{t})=\varphi_{r}\psi_{r}+\cdots$ $+\varphi_r\psi_t$ . Every “"sum" of distinct $\varphi_r\psi_i$ is a normal endomorphism (Exercises 8, 9). Since $\varphi_{\tau}\mid G_{r}=\mathbf{1}_{G_{r}}$ is a (normal) automorphism of $G$, and $G_r$ satisfies both chain conditions on normal subgroups (Exercise 6), Corollaries 3.6 and 3.7 imply that $\varphi_r\psi_i|G_r$ is an automorphism of $G_r\neq\langle e\rangle$ for some $j(r\leq j\leq t)$ . Therefore, for every $n\geq1$ $(\varphi_r\psi_i)^{n+1}$ is also an automorphism of $G$ . Consequently, since $G_r\neq\langle e\rangle$ and $(\varphi_{r}\psi_{i})^{n+1}$ $=\varphi_{r}(\psi_{i}\varphi_{r})^{n}\psi_{i}$ for all $n\geq1$ , the normal endomorphism $\psi_{i}\varphi_{r}\mid H_{j}:H_{i}\rightarrow H_{j}$ cannot be nilpotent. Since $H_{j}$ satisfies both chain conditions (Exercise 6), $\psi_{i}\varphi_{r}\mid H_{j}$ must be an automorphism of $H_{i}$ by Corollary 3.7. Therefore $\psi_i\mid G_r:G_r\to H_j$ is an isomor phism and so is $\varphi_{r}\mid H_{j}:H_{j}\rightarrow G_{r}$ .Reindex the $H_{k}$ so that we may assume $j=r$ and $G_{r}\cong H_{r}$ .We have proved the first half of statement $P(r)$ Since $G=G_{1}\times\cdots\times G_{r-1}\times H_{r}\times\cdots\times H_{t}$ by the induction hypothesis the

subgroup $G_1G_2\cdots G_{r-1}H_{r+1}\cdots H_t$ is the internal direct product $G_1\times\cdots G_{r-1}\times$ $H_{r+1}\times\cdots\times H_{l}$ . Observe that for $j<r,\psi_{r}(G_{j})=\psi_{r}\psi_{j}(G)=\langle e\rangle$ and for $j>r.$ $\psi_{r}(H_{j})=\psi_{r}\psi_{i}(G)=\langle e\rangle$ whence $\psi_{r}(G_{1}\cdots G_{r-1}H_{r+1}\cdots H_{t})=\langle e\rangle$ . Since $\psi_r\mid G_r$ is an isomorphism, we must have $G_r$ G, $G_{r}\cap(G_{1}\cdots G_{r-1}H_{r+1}\cdots H_{l})=\langle e\rangle$ . It follows that the group $G^{*}=G_{1}\cdots G_{r-1}G_{r}H_{r+1}\cdots H_{t}$ is the internal direct product

$$G^*=G_1\times\cdots\times G_r\times H_{r+1}\times\cdots\times H_t.$$

Define a map $\theta:G\to G$ as follows. Every element $g\varepsilon G$ G $G$ may be written $g=g_{1}\cdots$ $g_{r-1}h_r\cdots h_t$ with $g_i\varepsilon G_i$ and $h_j\varepsilon H_j$ .Let $\theta(g)=g_{1}\cdots g_{r-1}\varphi_{r}(h_{r})h_{r+1}\cdots h_{t}$ . Clearly $\mathbf{Im}\theta=G^{*}$ $\theta$ is a monomorphism (see Theorem I.8.10) that is easily seen to be normal. Therefore $\theta$ is an automorphism by Lemma 3.4 so that $G=$Im$\theta=G^*$ $=G_{1}\times\cdots G_{r}\times H_{r+1}\times\cdots\times H_{t}$ . This proves the second part of $P(r)$ and com pletes the inductive argument. Therefore,after reindexing $G_i\cong H_i$for$0\leq i\leq\min(s,t)$ If min $(s,t)=s$ ，then $G_1\times\cdots\times G_s=G=G_1\times\cdots\times G_s\times H_{s+1}\times\cdots\times H_t$, and if min $(s,t)=t$ ，then $G_1\times\cdots\times G_s=G=G_1\times\cdots\times G_t$ . Since $G_{i}\neq\langle e\rangle$ $H_{i}\neq\langle e\rangle$ for all $i,j$ ,we must have $s=t$ in either case.

### EXERCISES

1. A group $G$ is indecomposable if and only if $G\neq\langle e\rangle$ and $G\cong H\times K$ implies $H=\langle e\rangle$ or $K=\langle e\rangle$

2. $S_n$ is indecomposable for all $n\geq 2. [ Hint:$If$n\geq 5$ n≥5 $n\geq5$ Theorems I.6.8 and 1.6.10 and Exercise I.8.7 may be helpful.]

 3. The additive group $\mathbf{Q}$ is indecomposable.

4. A nontrivial homomorphic image of an indecomposable group need not be indecomposable.

5. (a) $\mathbf{Z}$ satisfies the ACC but not the DCC on subgroups. (b) Every fnitely generated abelian group satisfies the ACC on subgroups. 6. Let $H,K$ be normal subgroups of a group $G$ such that $G=H\times K$ (a) If $N$ is a normal subgroup of $H$ , then $N$ is normal in $G$ (compare Exercise 1.5.10). (b) If $G$ satisfies the ACC or DCC on normal subgroups, then so do $H$ and $K$

------------------------------------------------------------------

7. If $f$ and $g$ are endomorphisms of a group $G$ , then $f+g$ need not be an endomorphism. [Hint: Let $a=(123)$ ， $b=(132)\varepsilon S_3$ and define $f(x)=axa^{-1}$ $g(x)=bxb^{-1}.$

8. Let $f$ and $g$ be normal endomorphisms of a group $G$ (a) $fg$ is a normal endomorphism.

(b) $H\lhd G$ implies $f(H)\lhd G$ (c) If $f+g$ is an endomorphism, then it is normal.

9. Let $G=G_{1}\times\cdots\times G_{n}$ .For each $i$ let $\lambda_i:G_i\to G$ be the inclusion map and $\pi_i:G\to G_i$ the canonical projection (see page 59). Let $\varphi_{i}=\lambda_{i}\pi_{i}$ .Then the "sum" $\varphi_{i_{1}}+\cdots+\varphi_{i_{k}}$ of any $k\left(1\leq k\leq n\right)$ distinct $\varphi_i$ is a normal endomorphism of $G$

10. Use the Krull-Schmidt Theorem to prove Theorems 2.2 and 2.6 (i) for finite abelian groups.

11. If $G$ and $H$ are groups such that $G\times G\cong H\times H$ and $G$ satisfies both the ACC and DCC on normal subgroups, then $G\cong H$ [see Exercise 2.11],

12. If $G,H,K$ and $J$ are groups such that $G\cong H\times K$ and $G\cong H\times J$ and $G$ satis fies both the ACC and DCC on normal subgroups, then $K\cong J$ [see Exercise 2.11]

13. For each prime $p$ the group $Z(p^{\infty})$ satisfies the descending but not the ascending chain condition on subgroups [see Exercise I.3.7].

## 4.THE ACTION OF A GROUP ON A SET

The techniques developed in this section will be used in the following sections to develop structure theorems for (nonabelian finite) groups.

Definition 4.1. An action of a group $G$ on a set S is a function $G\times S\to S$ (usually denoted by $(\mathbf{g},\mathbf{x})\vdash\mathbf{g}\mathbf{x}]$ )such that for all x eS and $\mathbf{g}_1,\mathbf{g}_2\in\mathbf{G}$

$$\mathrm{ex~=~x\quad and\quad(g_{1}g_{2})x~=~g_{1}(g_{2}x).}$$
When such an action is given,we say that $G$ acts on the set S.

Since there may be many different actions of a group $G$ on a given set $S$ ,the nota tion $gx$ is ambiguous. In context, however, this will not cause any difficulty.

EXAMPLE. An action of the symmetric group $S_n$ on the set $I_{n}$ = $\{ 1, 2\ldots , n\}$ is given by $(\sigma,x)\to\sigma(x)$

EXAMPLES. Let $G$ be a group and $H$ a subgroup. An action of the group $H$ on the set $G$ is given by $(h,x)\vdash hx$ ,where $hx$ is the product in $G$ .The action of he H on $G$ is called a (left) translation. If $K$ is another subgroup of $G$ and $S$ is the set of all left cosets of $K$ in $G$ ,then $H$ acts on $S$ by translation: $(h,xK)\vdash hxK$

EXAMPLES. Let $H$ be a subgroup of a group $G$ . An action of $H$ on the set $G$ is givenby $(h,x)|\mapsto hxh^{-1}$ ; to avoid confusion with the product in $G$ , this action of h e $H$ is always denoted hxh-1 and nor $hx$ . This action of $h\varepsilon H$ on $G$ is called conjugation by

1

1

------------------------------------------------------------------



------------------------------------------------------------------

$$|\mathrm{G}|=\sum_{i=1}^n[\mathrm{G:C_G(x_i)}];$$

(ii) the number of subgroups of G conjugate toK is $[G:\mathbb{N}_{\mathbb{G}}(K)]$ ,which divides $|\mathbf{G}|$

PROOF.(i) and (i) follow immediately from the preceding Theorem and Lagrange's Theorem I.4.6. Since conjugacy is an equivalence relation on $G$ (Theorem 4.2), $G$ is the disjoint union of the conjugacy classes $\bar{x}_{1},\ldots,\bar{x}_{n}$, Xn $\bar{x}_n.$ whence (ii) follows from (i).

The eqution $|G|=\sum_{i=1}^n\left[G:C_G(x_i)\right]$ as in Corolary 4 i is alled the clas equation of the finite group $G$

Theorem 4.5. Ifa group $G$ acts on a set S, then this action induces a homomorphisn $\mathbf{G}\to\mathbf{A}($S) , where A(S) is the group of all permutations of S.

PROOF. If $g\varepsilon G$ ,define $\tau_{a}:\mathcal{S}\to\mathcal{S}$ by $x|\mapsto gx$ . Since $x=g(g^{-1}x)$ for all $x\varepsilon S$ $\tau_{a}$ is surjective. Similarly $gx=gy\:(x,y\:\varepsilon S)$ $(x,y^{\prime}\in S)$ (x,y eS) implies $x=g^{-1}(gx)=g^{-1}(gy)=y$ whence $\tau_{\varrho}$ is injective and therefore a bijection (permutation of S). Since $\tau_{UD^{\prime}}=\tau_{U}\tau_{U^{\prime}}$ ： $S\to S$ for all $g,g^{\prime}\in G$ , the map $G\to A(S)$ given by $g|\mapsto\tau_a$ is a homomorphism. 

Corollary 4.6. (Cayley) IfG is a group, then there is a monomorphism $\mathbf{G}\to\mathbf{A}(\mathbf{G})$ Hence every group is isomorphic to a group of permutations. In particular every finite group is isomorphic to a subgroup of $\mathrm{S_n}$ with $\mathbf{n}=|\mathbf{G}|$

PROOF. Let $G$ act on itself by left translation and apply Theorem 4.5 to obtain a homomorphism $\tau:G\to A(G)$ .If $\tau(g)=\tau_{g}=\mathbf{l}_{G}$ ,then $gx=\tau_{d}(x)=x$ for all $x\varepsilon G$ In particular $ge=e$ , whence $g=e$ and $\tau$ is a monomorphism. To prove the last statement note if $|G|=n$ , then $A(G)\cong S_n$ .■

Recall that if $G$ is a group, then the set Aut $G$ of all automorphisms of $G$ is a group with composition of functions as binary operation (Exercise I.2.15)

1

## Corollary 4.7.Let G be a group

(i) For each g e G, conjugation by g induces an automorphism of G. (i) There is a homomorphism $\mathbf{G}\to Aut$G whose kernel is $\mathbf{C}(\mathbf{G})=\{\mathbf{g}\varepsilon\mathbf{G}\mid\mathbf{g}\mathbf{x}=$

xg for all x e G}.

PROOF. (1) If $G$ acts on itself by conjugation, then for each $g\varepsilon G$ , the map $\tau_{a}:G\to G$ given by $\tau_{a}(x)=gxg^{-1}$ is a bijection by the proof of Theorem 4.5. It is easy to see that $\tau_{a}$ is also a homomorphism and hence an automorphism. (i) Let $G$ act on itself by conjugation. By (i) the image of the homomorphism $\tau:G\to A(G)$ of Theorem 4.5 is contained in Aut $G.$ Clearly

for all $x\varepsilon G.$
$$g\varepsilon Ker\tau\Leftrightarrow\tau_{o}=1_{G}\Leftrightarrow gxg^{-1}=\tau_{o}(x)=x$$

But $\wp xg^{-1}=x$ if and only if $gx=xg$ ,whence Ker $\tau=C(G)$ .

------------------------------------------------------------------

The automorphism $\tau_0$ of Corollary 4.7(i) is called the inner automorphism induced by $g$ . The normal subgroup $C(G)=$Ker $\tau$ is called the center of $G$ . An element $g\varepsilon G$ is in $C(G)$ if and only if the conjugacy class of $g$ consists of $g$ alone. Thus if $G$ is finite and $x\in C(G)$ ,then $[G:C_G(x)]=1$ (Corollary 4.4). Consequently the class equation of $G$ (Corollary 4.4(i)) may be written

$$|G|=|C(G)|+\sum_{i=1}^m[G:C_G(x_i)],$$

where X1,..., Xm $\bar{x}_{1},\ldots,\bar{x}_{m}$ $\bar{x}_{1},\ldots,\bar{x}_{m}\left(x_{i}\varepsilon G-C(G)\right)$ are distinct conjugacy classes of $G$ andeach $[G:C_G(x_i)]>1$

Proposition 4.8. Let H be a subgroup of a group G and let G act on the set S of all left cosets of H in G by left translation. Then the kernel of the induced homomorphism $\mathbf{G}\to\mathbf{A}($S) is contained in H

PROOF. The induced homomorphism $G\to A(S)$ is given by $g|\mapsto\tau_0$, where $\tau_0:S\to S$ and $\tau_{u}(xH)=gxH.$ If $g$ is in the kernel, then $\tau_{0}=1_{S}$ and $gxH=xH$ for all $x$ x $x\in G$ G $G$ ; in particular for $x=e$ x=e $x=e,geH=eH=H$, which implies $g$ E $H$ .■

Corollary 4.9.If H is a subgroup of index n in a group G and no nontrivial normal subgroup ofG is contained in H,then G is isomorphic to a subgroup of $S_n$

PROOF. Apply Proposition 4.8 to $H$ ; the kernel of $G\to A(S)$ is a normal subgroup of $G$ contained in $H$ and must therefore be $\langle e\rangle$ by hypothesis. Hence, $G\to A(S)$ is a monomorphism. Therefore $G$ is isomorphic to a subgroup of thegroup of all permutations of the $n$ left cosets of $H_{:}$ and this latter group is clearly isomorphic to $S_n$ .■

Corollary 4.10. If H is a subgroup ofa finite group G of index p, where p is the smallest prime dividing the order of G, then H is normal in G.

PROOF. Let $S$ be the set of all left cosets of $H$ in $G$ . Then $A(S)\cong S_p$ since $[G:H]=p$ . If $K$ is the kernel of the homomorphism $G\to A(S)$ of Proposition 4.8, then $K$ is normal in $G$ and contained in $H.$ Furthermore $G/K$ is isomorphic to a subgroup of $S_{n}$ . Hence $|G/K|$ divides $|S_p|^\cdot=p$ ! But every divisor of $|G/K|=[G:K]$ must divide $\left|G\right|=\left|K\right|\left[G:K\right]$ $[G:K]$ $[G:K]$ . Since no number smaller than $p$ (except 1) can divide $|G|$ ,we must have $|G/K|=p$ or 1. However $|G/K|=[G:K]=[G:H][H:K]$ $=p[H:K]\geq p.$ Therefore $|G/K|=p$ and $[H:K]=1$ ,whence $H=K$ . But $K$ is normal in $G$ .■

## EXERCISES

1. Let $G$ be a group and $A$ a normal abelian subgroup. Show that $G/A$ operates on $A$ by conjugation and obtain a homomorphism $G/A\to$Aut $A$

2.If $H,K$ are subgroups of $G$ such that $H\lhd K$ ,show that $K<N_G(H)$

------------------------------------------------------------------

3. If a group $G$ contains an element a having exactly two conjugates, then $G$ has a proper normal subgroup $N\neq\langle e\rangle$

4. Let Hbea subgroup of $G$ . Thecentralizer of His the set $C_{G}(H)=\left\{g\varepsilon G\mid hg=gh\mathrm{for}\right\}$ or all $h\varepsilon H\}$ . Show that $C_G(H)$ is a subgroup of $N_G(H)$

5.If $H$ is a subgroup of $G$ , the factor group $N_G(H)/C_G(H)$ (see Exercise 4) is isomorphic to a subgroup of Aut $H$

6. Let $G$ be a group acting on a set $S$ containing at least two elements. Assume that $G$ is transitive; that is, given any $x,y\varepsilon S$ , there exists $g\varepsilon G$ such that $gx=y$ Prove (a) for $x\varepsilon S$ , the orbit $\bar{x}$ of $x$ is $S$

(b) all the stabilizers $G_x$ (for $x\varepsilon S)$ are conjugate; (c) if $G$ has the property: $\{g\varepsilon G\mid gx=x$ for all $x\in S|=\langle e\rangle$ (which is the case if $G<S_n$ for some $n$ and $S=\{1,2,\ldots,n\}$ and if $N\lhd G$ and $N<G_{x}$ for some $x\varepsilon S$ , then $N=\langle e\rangle$ (d) for $x\varepsilon S$ ， $|S|=[G:G_{x}]$ ; hence $|S|$ divides $|G|$

7. Let $G$ be a group and let In $G$ be the set of all inner automorphisms of $G$ .Show that In $G$ is a normal subgroup of Aut $G$

8. Exhibit an automorphism of $Z_6$ that is nor an inner automorphism

9.If $G/C(G)$ is cyclic, then $G$ is abelian.

10. Show that the center of $S_4$ is $\langle e\rangle$ ; conclude that $S_4$ is isomorphic to the group of all inner automorphisms of $S_4$

11.Let $G$ be a group containing an element a not of order 1 or 2. Show that $G$ has a nonidentity automorphism. [Hint: Exercise I.2.2 and Corollary 4.7.]

12. Any finite group is isomorphic to a subgroup of $A_n$ for some $n$

13. If a group $G$ contains a subgroup $(\neq G)$ of finite index, it contains a normal subgroup $(\neq G$, offinite index.

14. If $|G|=pn$ ,with $p>n,p$ prime, and $H$ is a subgroup of order $p$ , then $H$ is normal in $G$

15. If a normal subgroup $N$ oforder p $p$ $p\left(p\right.$ p $p$ prime) is contained in a group $G$ of order $p^n$ , then $N$ is in the center of $G$

## 5. THE SYLOW THEOREMS

------------------------------------------------------------------

discussion of subgroups of maximal prime power order (second and third Sylow Theorems).

Lemma 5.1. If a group H of order $p^n$ (p prime) acts on a finite set S and if $S_{0}$= $\{$x$\varepsilon$S| hx= x for all h ε H), then $|\mathcal{S}|\equiv|\mathcal{S}_0|$ (mod p)

REMARK.This lemma (and the notation $S_{0.}$ ）will be used frequently in the sequel.4

PROOF OF 5.1. An orbit $\bar{x}$ contains exactly one element if and only if $x\varepsilon S_0$ Hence $S$ can be written as a disjoint union S = So $S=S_0$ $S=S_{0}\cup\bar{x}_{1}\cup\bar{x}_{2}\cup\cdots\cup\bar{x}_{n}$ ,with $|\bar{x}_i|>1$ for all i. Hence $|S|=|S_{0}|+|\bar{x}_{1}|+|\bar{x}_{2}|+\cdots+|\bar{x}_{n}|$ .Now $p\mid|\bar{x}_i|$ for eachi since $|\bar{x}_i|>1$ and $|\bar{x}_{i}|=[H:H_{x_{i}}]$ divides $|H|=p^{n}$ . Therefore $|S|\equiv|S_0|$ (mod p).

Theorem 5.2.(Cauchy) IfG is a finite group whose order is divisible by a prime p, then G contains an element of order p.

PROOF. (J. H. McKay) Let $S$ be the set of $P$ -tuples of group elements $\left\{(a_1,a_2,\ldots,a_p)\mid a_i\varepsilon G\right.$ and $a_1a_2\cdots a_p=e\}$ . Since $a_p$ is uniquely determined as $(a_{1}a_{2}\cdots a_{p-1})^{-1}$ , it follows that $|S|=n^{p-1}$ ,where $|G|=n$ Since $p\mid n,|S|\equiv0({\mathrm{mod~}}p)$ Let the group $Z_p$ act on $S$ by cyclic permutation; that is, for $k\in Z_p,k(a_1,a_2,\ldots,a_p)$ $=(a_{k+1},a_{k+2},\ldots,a_{p},a_{1},\ldots,a_{k})$ $a_{p},a_{1},\ldots,a_{k})$ apa1,... ,ak) .Verify that $(a_{k+1},a_{k+2},\ldots,a_{k})\varepsilon S$ S $S$ (use the fact that in a group $ab=e$ implies $ba=(a^{-1}a)(ba)=a^{-1}(ab)a=e)$ .Verify that for $0,k,k^{\prime}\varepsilon Z_p$ and $x\varepsilon S$ $0x=x$ and $(k+k^{\prime})x=k(k^{\prime}x)$ (additive notation for a group action on a set !). Therefore the action of $Z_{p}$ on $S$ is well defined.

Now $(a_{1},\ldots,a_{p})\varepsilon S_{0}$ if and only if $a_{1}=a_{2}=\cdots=a_{p}$ ; clearly $(e,e,\ldots,e)\varepsilon S_0$ and hence $|S_0|\neq0$ .By Lemma 5.1, $0\equiv|S|\equiv|S_{0}|$ (mod $p.$ 0.Since $|S_0|\neq0$ there must be at least $P$ elements in $S_0;$ that is, there is $a\neq e$ such that $(a,a,\ldots,a)\varepsilon S_0$ and hence $a^{p}=e.$ Since $p$ is prime, $|a|=p$ .■

A group in which every element has order a power $(\geq0)$ of some fixed prime $P$ is called a p-group. If $H$ is a subgroup of a group $G$ and $H$ is a $P$ -group, $H$ is said to be a $p$ -subgroup of $G$ . In particular $\langle e\rangle$ is a $p$ -subgroup of $G$ for every prime $P$ since $|\langle e\rangle|=1=p^{0}$

Corollary 5.3. A finite group G is a p-group if and only $if|G|$ is a power of p.

PROOF. If $G$ is a $P$ -group and $q$ a prime which divides $|G|$ , then $G$ contains an element of order $q$ by Cauchy's Theorem. Since every element of $G$ has order a power of $p,q=p$ . Hence $|G|$ is a power of $p$ .The converse is an immediate consequence of Lagrange's Theorem I.4.6.

*1 am indebted to R. J. Nunke for suggesting this line of proof

------------------------------------------------------------------

Corollary 5.4. The center C(G) of a nontrivial finite p-group G contains more than one element.

PROoF.Consider the class equation of $G$ (see page 91):

$$|G|=|C(G)|+\sum[G:C_G(x_i)].$$

Since each $[G:C_G(x_i)]>1$ and divides $|G|=p^n\left(n\geq1\right),p$ $p$ p divides each $[G:C_G(x_i)]$ and $|G|$ and therefore divides $|C(G)|$ . Since $|C(G)|\geq1$ ， $C(G)$ has at least $P$ ele ments.

Lemma 5.5.If H is a p-subgroup of a finite group G, then $[\mathbf{N}_{\mathbf{G}}(\mathbf{H}):\mathbf{H}]\equiv[\mathbf{G}:\mathbf{H}]$ (mod p).

PROOF. Let $S$ be the set of left cosets of $H$ in $G$ and let $H$ act on $S$ by (left translation. Then $|S|=[G:H]$ .Also

$$xH\varepsilon S_{0}\Leftrightarrow hxH=xH\quad\mathrm{for~all}\quad h\varepsilon H\\\Leftrightarrow x^{-1}hxH=H\quad\mathrm{for~all}\quad h\varepsilon H\Leftrightarrow x^{-1}hx\varepsilon H\quad\mathrm{for~all}\quad h\varepsilon H\\\Leftrightarrow x^{-1}Hx=H\Leftrightarrow xHx^{-1}=H\Leftrightarrow x\varepsilon N_{G}(H).$$

Therefore $|S_0|$ is the number of cosets $xH$ with x E $N_G(H)$ ; that is, $|S_0|=[N_G(H):H]$ By Lemma 5.1 $[N_G(H):H]=|S_0|\equiv|S|=[G:H]$ (mod $p$ 0.

Corollary 5.6. If H is p-subgroup ofa finite group G such that p divides $[G:H]$ ,ther $\mathbf{N} _{\mathrm{G} }( \mathbf{H} ) \neq \mathbf{H}$

PROOF. $0\equiv[G:H]\equiv[N_{G}(H):H]$ (mod $p$ ). Since $[N_G(H):H]\geq1$ in any case, we must have $[N_G(H):H]>1$ . Therefore $N_G(H)\neq H$ .

Theorem 5.7. (First Sylow Theorem) Ler G be a group of order $p^nm$ ,with $n\geq1$ ,p prime, and $(p,m)=1$ .Then G contains a subgroup oforder $p^i$ for each $1\leq i\leq$ nand every subgroup of G of order $p^i$ (i< n) is normal in some subgroup of order $p^{i+1}$

PROOF. Since $p\mid|G|$ $G$ contains an element $a$ , and theref ore, a subgroup $\langle a\rangle$ of order $p$ by Cauchy's Theorem. Proceeding by induction assume $H$ is a subgroup of $G$ of order $p^i$ $(1\leq i<n)$ . Then $P\mid[G:H]$ and by Lemma 5.5 and Corollary $5.6H$ is normal in $N_G(H)$ ， $H\neq N_G(H)$ and $1<|N_G(H)/H|=[N_G(H):H]\equiv[G:H]\equiv0$ (mod $p.$ ).Hence $p\mid|N_G(H)/H|$ and $N_G(H)/H$ contains a subgroup of order $p$ as above. By Corollary I.5.12 this group is of the form $H_1/H$ where $H_{1}$ is a subgroup of $N_G(H)$ containing $H.$ Since $H$ is normal in $N_G(H)$ ， $H$ is necessarily normal in $H_{1}$ Finally $|H_{1}|=|H||H_{1}/H|=p^{i}p=p^{i+1}$ .

A subgroup $P$ of a group $G$ is said to be a Sylow $p$ -subgroup $ip$ prime) if $P$ is a maximal $p$ -subgroup of $G$ (that is, $P<H<G$ with $H$ a $p$ -group implies $P=H$ ). Sylow $P$ -subgroups always exist, though they may be trivial, and every $P$ -subgroup is contained in a Sylow $p$ -subgroup(Zom's Lemma is needed to show thisfor infinite

1

------------------------------------------------------------------

groups). Theorem 5.7 shows that a finite group $G$ has a nontrivial Sylow $P$ -subgroup for every prime $p$ that divides $|G|$ . Furthermore, we have

Corollary 5.8. Ler G be a group oforder p"m with p prime, $n\geq1$ and $(\mathbf{m},\mathbf{p})=1.L$ et H be ap-subgroup ofG.

(i) H is a Sylow p-subgroup of G if and only if $|\mathbf{H}|=\mathbf{p}^{n}$ (i)Every conjugate of a Sylow p-subgroup is a Sylow p-subgroup. (ii) If there is only one Sylow p-subgroup P, then P is normal in G.

SKETCH OF PROOF. (i) Corollaries I.4.6 and 5.3 and Theorem 5.7. (i) Exer cise I.5.6 and (i). (i) follows from (i).

As a converse to Corollary 5.8 (i) we have

Theorem 5.9.(Second Sylow Theorem) IfH is a p-subgroup ofa finite group G ,and P is any Sylow p-subgroup of G, then there exists x e G such that $\mathbf{H}<\mathbf{xPx^{-1}}$ .Inpar ticular, any two Sylow p-subgroups of G are conjugate.

PROOF. Let $S$ be the set of left cosets of $P$ in $G$ and let $H$ act on $S$ by (left) trans lation. $|S_0|\equiv|S|=[G:P]$ (mod $p.$ ）by Lemma 5.1.But $p\nmid[G:P]$ ; therefore $|S_0|\neq0$ and there exists $xP\in S_0$

$$xP\varepsilon S_0\Leftrightarrow hxP=xP\quad\mathrm{for~all}\quad h\varepsilon H$$

$$\Leftrightarrow x^{-1}hxP=P\quad\text{for all}\quad h\varepsilon H\Leftrightarrow x^{-1}Hx<P\Leftrightarrow H<xPx^{-1}.$$

If $H$ is a Sylow $P$ -subgroup $|H|=|P|=|xPx^{-1}|$ and hence $H=xPx^{-1}$ .

Theorem 5.10. (Third Sylow Theorem) IfG is a finite group and p a prime, then the number of Sylow p-subgroups of G divides $|\mathbf{G}|$ and is of the form $kp+1$ for some $k\geq0$

PROOF. By the second Sylow Theorem the number of Sylow $p$ -subgroups is the number of conjugates of any one of them, say $P$ . But this number is $[G:N_G(P)]$, a divisor of $|G|$ , by Corollary 4.4. LetS be the set of all Sylow $P$ -subgroups of $G$ and let $P$ act on $S$ by conjugation. Then $Q\varepsilon S_0$ if and only if $xQx^{-1}=Q$ for all $x\varepsilon P$ . The latter condition holds if and only if $P<N_{G}(Q)$ .Both $P$ and $Q$ are Sylow $p$ -subgroups of $G$ and hence of $N_G(Q)$ and are therefore conjugate in $N_G(Q)$ .But since $Q$ is normal in $N_G(Q)$ , this can only occur if $Q=P$ . Therefore, $S_0=\{P\}$ and by Lemma 5.1, $|S|\equiv|S_0|=1$ (mod $p.$ ).Hence $|S|=k_{P}+1$ .

Theorem 5.11. If $P$ is a Sylow p-subgroup of a finite group G, then $\mathbf{N}_{\mathbf{G}}(\mathbf{N}_{\mathbf{G}}(\mathbf{P}))$ $=\mathbf{N}_{\mathrm{G}}(\mathbf{P})$

PROOF. Every conjugate of $P$ is a Sylow $P$ -subgroup of $G$ and of any subgroup of $G$ that contains it. Since $P$ is normal in $N=N_{G}(P)$, $P$ is the onlySylow $P$ -subgroup of $N$ by Theorem 5.9. Therefore.

------------------------------------------------------------------

$$x\varepsilon N_{G}(N)\Rightarrow xNx^{-1}=N\Rightarrow xPx^{-1}<N\Rightarrow xPx^{-1}=P\Rightarrow x\varepsilon N.$$

Hence $N_G(N_G(P))<N$ ; the other inclusion is obvious.

## EXERCISES

1. If $N\lhd G$ and $N,G/N$ are both $P$ -groups, then $G$ is a $P$ -group.

2. If $G$ is a finite $P$ -group, $H\lhd G$ and $H\neq\langle e\rangle$ , then $H\cap C(G)\neq\langle e\rangle$

3. Let $|G|=p^n$ . For each $k$ ， $0\leq k\leq n$, $G$ has a normal subgroup of order $p^k$

4.If $G$ is an infinite $P$ -group( $p$ prime), then either $G$ has a subgroup of order $p^n$ for each $n\geq1$ or there exists $m$ m $m\in\mathbb{N}^{*}$ N* $N^*$ such that every finite subgroup of $G$ has order $\leq p^m$

5.If $P$ is a normal Sylow $D$ -subgroup of a finite group $G$ and $f:G\to G$ is an endo morphism, then $f(P)<P$

6. If $H$ is a normal subgroup of order $p^k$ of a finite group $G$ , then $H$ is contained in every Sylow $P$ -subgroup of $G$

 7. Find the Sylow 2-subgroups and Sylow 3-subgroups of $S_3,S_4,S_5$ 8. If every Sylow $p$ -subgroup of a finite group $G$ is normal for every prime $P$ , then $G$ is the direct product of its Sylow subgroups. 9.If $|G|=p^n\psi$ ,with $p>y$ primes, then $G$ contains a unique normal subgroup of index $q$ 10. Every group of order 12,28,56,and 200 must contain a normalSylow subgroup and hence is not simple. 11. How many elements of order 7 are there in a simple group of order 168? 12. Show that every automorphism of $S_4$ is an inner automorphism, and hence $S_4\cong$Aut $S_4$ $S_4$ S4 .[Hint: see Exercise 4.10. Every automorphism of $S_4$ induces a permutation of the set $\{P_{1},P_{2},P_{3},P_{4}\}$ of Sylow 3-subgroups of $S_{4.}$ If $f\varepsilon$ Aut $S_4$ has $f(P_{i})=P_{i}$ for all $i$ , then $f=1_{S_{4}}.$ 13.Every group $G$ of order $p^2(p$ prime) is abelian [Hinr: Exercise 4.9 and Corollary 5.4].

## 6. CLASSIFICATION OF FINITE GROUPS

We shall classify up to isomorphism all groups of order pq ( $.p,q$ primes) and all groups of small order $(n\leq15)$ .Admittedly, these are not very far reaching results; but even the effort involved in doing this much will indicate the diffculty in determining the structure of an arbitrary (finite) group. The results of this section are not needed in the sequel.

------------------------------------------------------------------

t0 isornorphism) exactly two distinct groups oforder pq: the cyclic group $Z_{\mathrm{pq}}$ and anon abelian group K generated by elements c and d such that

$$|\mathrm{c}|=\mathrm{p};\quad|\mathrm{d}|=\mathrm{q};\quad\mathrm{dc}=\mathrm{c}^{\mathrm{s}}\mathrm{d},$$

where $s\not\equiv1$ (mod p) and $s^{\mathfrak{q}}\equiv1$ (mod p)

SKETCH OF PROOF. A nonabelian group $K$ of order $pq$ as described in the proposition does exist (Exercise 2). Given $G$ of order $pq$ ， $G$ contains elements $a,b$ with $|a|=p,|b|=q$ by Cauchy's Theorem 5.2. Furthermore, $S=\langle a\rangle$ is normal in $G$ (by Corollary 4.10 or by counting Sylow $P$ -subgroups, as below). The coset $bS$ has order 4 in the group $G/S$ . Since $|G/S|=q$ $G/S$ is cyclic with generator $bS$ $G/S=\langle bS\rangle$ . Therefore every element of $G$ can be written in the form biai and $G=\langle a,b\rangle$

The number of Sylow 4 -subgroups is $kq+1$ and divides pq. Hence it is 1 or $p$ .Ifit is 1 (as it must be if $q+p-1)$ , then $\langle b\rangle$ is also normal in $G$ . Lagrange's Theorem I.4.6 shows that $\langle a\rangle\cap\langle b\rangle=\langle e\rangle$ .Thus by Theorems I.3.2, 1.8.6, 1.8.10 and Exercise I.8.5, $G=\langle a\rangle\times\langle b\rangle\cong Z_p\oplus Z_q\cong Z_{pq}$ . If the number is $p$ , (which can only occur if $p\mid q-1)$ , then $bab^{-1}=a^r$ (since $\langle a\rangle\triangleleft G)$ and $r\not\equiv1$ r1 $r\not\equiv1({\mathrm{mod~}}p)$ p) $p)$ (otherwise) $G$ would be abelian by Theorem $\mathbf{I}.3.4(\mathbf{v})$ and hence have a unique Sylow $q$ -subgroup). Since $bab^{-1}=a^r$ , it follows by induction that $b^iab^{-i}=a^{ri}$ In particular for $j=q$ $a=a^{rq}$ which implies $r^q\equiv1$ r= 1 $r^{q}\equiv1({\mathrm{mod~}}p)$ P $p$ by Theorem I.3.4 (v). In order to complete the proof we must show that if $q|_{P}-1$ and $G$ is the non-

abelian group described in the preceding paragraph, then $G$ is isomorphic to $K$ .We shall need some results from number theory. The congruence $x^q\equiv1$ x=1 $x^{q}\equiv1\pmod{p}$ P $p$ has exactly $q$ distinct solutions modulo $p$ (see J. E. Shockley [51; Corollary 6.1, p. 67]). If $r$ is a solution and $k$ is the least positive integer such that $r^k\equiv1$ r*= 1 $r^k\equiv1({\mathrm{mod~}}p)$ , then $k\mid q$ (see J.E. Shockley [51; Theorem 8, p. 70]). In our case $r\not\equiv1$ (mod $p.$ ,whence $k=$ $q$ . It follows that $1,r,r^2,\ldots,r^{q-1}$ are all the distinct solutions modulo $p$ of $x^q\equiv1$ (mod $p$ ). Consequently, $s\equiv r^t$ S=rt $s\equiv r^t({\mathrm{mod~}}p)$ $p$ P for some 1 $(1\leq1\leq q-1)$ . If $b_{1}=b^{t}\varepsilon G$ then $|b_1|=q$ . Our work above (with $b_1$ in place of $b$ )shows that $G=\langle a,b_1\rangle$ ; that every element of $G$ can be written $b_1ia^i$ ; that $|a|=p$ ; and that $b_1ab_1^{-1}=b^lab^{-\iota}$ $=a^{r^{l}}=a^{s}$ (Theorem I.3.4(v)). Therefore, $b_1a=a^sb_1$ .Verify that the map $G\to K$ given by $a\vdash c$ and $b_1\vdash d$ is an isomorphism.

Corollary 6.2. Ifp is an odd prime, then every group oforder $2p$ is isomorphic either. t0 the cyclic group $\mathbf{Z}_{2\boldsymbol{\jmath}}$ or the dihedral group $\mathbf{D}_{\mathrm{p}}$

PROOF. Apply Proposition 6.1 with $q=2$ .If $G$ is not cyclic, the conditions on s imply $s\equiv-1$ (mod $p$ ).Hence G = (c,d) $G=\langle c,d\rangle$ $G=\langle c,d\rangle,\:|d|=2,\:|c|=$ ldl = 2 $|d|=2$ lcl= $|c|=p$ , and $dc=c^{-1}d$ by Theorem I.3.4(v). Therefore, $G\cong D_p$ by Theorem I.6.13.

Proposition 6.3. There are (up to isomorphism) exacily rwo distinct nonabelian groups of order 8: the quaternion group Qs and the dihedral group $\mathcal{D}_4$

REMARK. The quaternion group $Q_8$ is described in Exercise I.2.3.

------------------------------------------------------------------

SKETCH OF PROOF OF 6.3. Verify that $D_4\not\cong Q_8$ (Exercise 10). If a group $G$ of order 8 is nonabelian, then it cannot contain an element of order 8 or have every nonidentity element of order 2 (Exercise I.1.13). Hence $G$ contains an element a of order 4. The group $\langle a\rangle$ of index 2 is normal. Choose $b\notin\langle a\rangle$ . Then $b^2\varepsilon\langle a\rangle$ since $|G/\langle a\rangle|=2.$ . Show that the only possibilities are $b^2=a^2$ or $b^2=e$ . Since $\langle a\rangle$ is normal in $G,bab^{-1}\varepsilon\langle a\rangle$ ; the only possibility is $bab^{-1}=a^{3}=a^{-1}$ . It follows that every element of $G$ can be written $b^ia^j$ .Hence $G=\langle a,b\rangle$ . In one case we have $|a|=4$ $b^2=a^2$ ， $ba=a^{-1}b$ ,and $G\cong Q_8$ by Exercise I.4.14.; in the other case, $|a|=4$ $|b|=2$ ， $ba=a^{-1}b$ and $G\cong D_{4}$ by Theorem 1.6.13.

Proposition 6.4. There are (up to isomorphism) exactly three distinct nonabeliar groups of order 12: the dihedral group $\mathbf{D}_{6}$ ,the alternating group $\mathbf{A}_{4}$ , and a group T generated by elements a,b such that |a|=6 $\mathbf{b}^{2}=\mathbf{a}^{3}$ ,and b $\mathbf{a}=\mathbf{a}^{-1}\mathbf{b}$

SKETCH OF PROOF.Verify that there is a group $T$ of order 12 as stated (Exercise 5) and that no two of $D_6,A_4,T$ are isomorphic (Exercise 6). If $G$ is a nonabelian group of order 12, let $P$ be a Sylow 3-subgroup of $G$ . Then $|P|=3$ and $[G:P]=4$ . By Proposition 4.8 there is a homomorphism $f:G\to S_4$ whose kernel $K$ is contained in $P$ ,whence $K=P$ or $\langle e\rangle$ .If $K=\langle e\rangle$ , fis a monomorphism and $G$ is isomorphic to a subgroup of order 12 of $S_4$, which must be $A_4$ by Theorem I.6.8. Otherwise $K=P$ and $P$ is normal in $G$ . In this case $P$ is the unique Sylow 3-subgroup Hence $G$ contains only two elements of order 3.If $c$ is one of these, then $[G:C_G(c)]=1$ or2 since $[G:C_G(c)]$ is the number of conjugates of $c$ and every conjugate of $c$ has order 3.Hence $C_G(c)$ is a group of order 12 or 6. In either case there is de $C_G(c)$ of order 2 by Cauchy's Theorem. Verify that $|cd|=6$

Let $a=cd$ ;then $\langle a\rangle$ is normal in $G$ and $|G/\langle a\rangle|=2$ . Hence there is an element $b\varepsilon G$ such that $b\notin\langle a\rangle$ b#(a) b≠e $b\neq e$ $b\notin\langle a\rangle,b\neq e,b^2\varepsilon\langle a\rangle$ $b^2\varepsilon\langle a\rangle$ b2 ∈(a) ,and $bab^{-1}\varepsilon\langle a\rangle$ .Since $G$ is nonabelian and $|a|=6$ $|a|=6$ $|a|=6,bab^{-1}=a^{5}=a^{-1}$ is the only possibility; that is, $ba=a^{-1}b$ . There are six possibilities for $b^2\varepsilon\langle a\rangle$ $b^{2}=a^{2}$ or $b^{2}=a^{4}$ lead to contradictions; $b^2=a$ or $b^2=a^5$ imply $|b|=12$ and $G$ abelian. Therefore, the only possibilities are

(i) $|a|=6$ $b^2=e;$ b² = e $b^{2}=e;ba=a^{-1}b$ ,whence $G\cong D_6$ by Theorem I.6.13; (i) $|a|=6$ $b^{2}=a^{3}$ ; $ba=a^{-1}b$ ,whence $G\cong T$ by Exercise 5(b).

The table below lists (up to isomorphism) all distinct groups of small order. There are 14 distinct groups of order 16 and 51 of order 32; see M. Hall and J.K. Senio1 [16]. There is no known formula giving the number of distinct groups of order $n$ for every $n$

Order

Distinct Groups
$$\begin{aligned}&\langle e\rangle\\&Z_{2}\\&Z_{3}\\&Z_{2}\oplus Z_{2},Z_{4}\\&Z_{6},D_{3}\\&Z_{7}\end{aligned}$$

Reference Exercise I.4.3 Exercise I.4.3 Exercise I.4.5 Exercise I.4.3 Corollary 6.2 Exercise I.4.3

------------------------------------------------------------------

Order Distinct Groups Reference 8 Z④ZZ, $Z_2\oplus Z_4$ $Z_8$ ,Qs, Da Theorem 2.1 and Proposition 6.39 ZaZ, Zg Exercise 5.13 and Theorem 2.1 Corollary 6.2 Z10, Ds 1 Exercise I.4.3 Zi Theorem 2.1 and ZZ6, Z12, A4, D6,T Proposition 6.4 Exercise I.4.313 Corollary 6.2
$$\begin{array}{c}Z_{13}\\Z_{14},\\Z_{15}\end{array}D_7$$
Proposition 6.1

### EXERCISES

1. Let $G$ and $H$ be groups and $\theta:H\to$Aut $G$ a homomorphism. Let $G\times_{\theta}H$ be the set $G\times H$ with the following binary operation: $(g,h)(g^{\prime},h^{\prime})=(g[\theta(h)(g^{\prime})],hh^{\prime})$ Show that $G\times_\theta H$ is a group with identity element $(e,e)$ and $(g,h)^{-1}=$ $(\theta(h^{-1})(g^{-1}),h^{-1})$ . $G\times_\theta H$ is called the semidirect product of $G$ and $H$

2. Let $C_{p}=\langle a\rangle$ and $C_{q}=\langle b\rangle$ be (multiplicative) cyclic groups of prime orders $p$ and $q$ respectively such that $p>q$ and $q\mid p-1$ Let $s$ be an integer such that $s\neq1$ (mod $\dot{p}$ )and $s^q\equiv1$ s= 1 $s^{q}\equiv1\pmod{p}$ P $p.$ which implies $s\not\equiv0$ (mod $p.$ ). Elementary number theory shows that such an $s$ exists (see J.E. Shockley [51; Corollary 6.1, p. 67]). (a) The map $\alpha:C_p\to C_p$ given by $a^i|\mapsto a^{si}$ is an automorphism. (b) The map $\boldsymbol{\theta}:\boldsymbol{C}_0\to$Aut C $C_p$ given by $\theta(b^i)=\alpha^i$ $\alpha$ as in part (a) is a homo-

morphism $(\alpha^{0}=1c_{p})$ (c) If we write $a$ for $(a,e)$ and $b$ for $(e,b)$ , then the group $C_p\times_\theta C_q$ (see Exer-

cise 1) is a group of order $pq$ , generated by $a$ and $b$ subject to the relations $|a|=p,|b|=q,ba=a^{s}b$ ,where $s\not\equiv1({\mathrm{mod}}p)$ ,and $s^q\equiv1$ s=1 $\dot{s}^{q}\equiv1({\mathrm{mod~}}p)$ .The group $C_p\times_\theta C_q$ is called the metacyclic group.

3. Consider the set $G=\{\pm1,\pm i,\pm j,\pm k\}$ with multiplication given by $i^{2}=j^{2}=k^{2}$ =-1 ; $ij=k;jk=i$ ki=j;ji=-k $ki=j;ji=-k$ $ki=j;ji=-k,kj=-i,ik=-j$, $kj=-i$ $kj=-i$ ik=-j $ik=-j$ and the usualrules for multiplying by $\pm1$ . Show that $G$ is a group isomorphic to the quaternion group $Q_{8}$

4. What is the center of the quaternion group $Q_8?$ Show that $Q_8/C(Q_8)$ is abelian.

 5. (a) Show that there is a nonabelian subgroup $T$ of $S_3\times Z_4$ of order12 generated by elements $a,b$ such that [al = 6 $|a|=6.$ $a^3=b^2$ a² = b2 $|a|=6,a^{3}=b^{2},ba=a^{-1}b$ ba = a-1b $ba=a^{-1}b$ (b) Any group of order 12 with generators $a,b$ such that $|a|=6$ lal = 6 $|a|=6,\:a^{8}=\:b^{2}$ a = b2 $a^8=b^2$ $ba=a^{-1}b$ is isomorphic to $T$

6. No two of $D_6,A_4$ , and $T$ are isomorphic, where $T$ is the group of order 12 described in Proposition 6.4 and Exercise 5.

7. If $G$ is a nonabeliangroup of order $p^8(p$ prime), then the center of $G$ is the subgroup generated by all elements of the form aba $^{\cdot1}b^{-1}$ $(a,b\in G)$

8. Let $p$ be an odd prime. Prove that there are, at most, two nonabelian groups of order $p^8$ . [One has generators $a,b$ satisfying $|a|=p^{2}$ ; $|b|=p$ ； $b^{-1}ab=a^{1+p}$

------------------------------------------------------------------

the other has generators $a,b,c$ satisfying $|a|=|b|=|c|=p$ ； $c=a^{-1}b^{-1}ab$ ca = ac $ca=ac$ $ca=ac;cb=bc.]$ cb = bc $cb=bc$

9. Classify up to isomorphism all groups of order 18. Do the same for orders 20 and 30.

10. Show that $D_4$ is not isomorphic to $Q_{8}$ . [Hint: Count elements of order 2.]

## 7. NILPOTENT AND SOLVABLE GROUPS

Consider the following conditions on a finite group $G$

(i) G is the direct product of its Sylow subgroups. (i) Ifm divides $|G|$ ,then G has a subgroup of order m. (ii) $If|\mathbf{G}|=$mn with $(m,n)=1$ ,then G has a subgroup oforder m.

Conditions (i) and (i) may be considered as modifications of the First Sylow Theorem. It is not difficult to show that $(\mathrm{i})\Longrightarrow(\mathrm{ii})$ and obviously (ii) $\Longrightarrow$ (ii). The fact that every finite abelian group satisfies (i) is an easy corollary of Theorem 2.2. Every $P$ · group satisfies (i) trivially. On the other hand, $A_4$ satisfies (i) but not (ii), and $S_3$ satisfies (ii) but not (i) (Exercise 1). Given the rather striking results.achieved thus far with finite abelian and $p$ -groups, the classes of groups satisfying (i), (ii), and (ii) respectively would appear to be excellent candidates for investigation. We shall restrict our attention to those groups that satisfy (i) or (ii). We shall first define nilpotent and solvable groups in terms of certain “normal

series"of subgroups. In the case of finite groups, nilpotent groups are characterized by condition (i) (Proposition 7.5) and solvable ones by condition (i) (Proposition 7.14). This approach will also demonstrate that there is a connection between nil. potent and solvable groups and commutativity. Other characterizations of nilpotent and solvable groups are given in Section 8 Our treatment of solvable groups is purely group theoretical. Historically, how.

ever, solvable groups first occurred in connection with the problem of determining the roots of a polynomial with coefficients in a field (see Section V.9).

Let $G$ be a group. The center $C(G)$ of $G$ is a normal subgroup (Corollary 4.7). Let $C_2(G)$ be the inverse image of $C(G/C(G))$ under the canonical projectior $G\to G/C(G)$ .Then by (the proof of) Theorem I.5.11 $C_2(G)$ is normal in $G$ and contains $C(G)$ . Continue this process by defining inductively: $C_1(G)=C(G)$ and $C_i(G)$ is the inverse image of $C(G/C_{i-1}(G))$ under the canonical projection $G\to G/C_{i-1}(G)$ Thus we obtain a sequence of normal subgroups of $G$ , called the ascending central series of $G{:}\left\langle e\right\rangle<C_1(G)<C_2(G)<\cdots$

Definition 7.1. A group G is nilpotent $if\mathbf{C}_n(\mathbf{G})=\mathbf{G}$ for some n.

Every abelian group $G$ is nilpotent since $G=C(G)=C_{\mathrm{i}}(G)$

------------------------------------------------------------------

PROOF. $G$ and all its nontrivial quotients are $P$ -groups, and therefore, have nontrivial centers by Corollary 5.4.This implies that if $G\neq C_i(G)$ , then $C_i(G)$ is strictly contained in $C_{i+1}(G)$ . Since $G$ is finite, $C_n(G)$ must be $G$ for some n.

Theorem 7.3. The direct product of a finite number of nilpotent groups is nilpotent

PROOF. Suppose for convenience that $G=H\times K$ ,the proof for more than two factors being similar. Assume inductively that $C_{i}(G)=C_{i}(H)\times C_{i}(K)$ (the case $i=1$ is obvious). Let $\pi_{H}$ be the canonical epimorphism $H\to H/C_i(H)$ and similarly for $\pi_{K}$ .Verify that the canonical epimorphism $\varphi:G\to G/C_i(G)$ isthe composition

$$G=H\times K\stackrel{\pi}{\rightarrow}H/C_{i}(H)\times K/C_{i}(K)\stackrel{\psi}{\rightarrow}\frac{H\times K}{C_{i}(H)\times C_{i}(K)}=\frac{H\times K}{C_{i}(H\times K)}=G/C_{i}(G),$$

where $\pi=\pi_{H}\times\pi_{K}$ (Theorem I.8.10), and $\psi$ is the isomorphism of Corollary I.8.11. Consequently,

$$\begin{aligned}
C_{i+1}(G)& =\varphi^{-1}[C(G/C_{i}(G))]=\pi^{-1}\psi^{-1}[C(G/C_{i}(G))] \\
&=\pi^{-1}[C(H/C_{i}(H)\times K/C_{i}(K))] \\
&=\pi^{-1}[C(H/C_{i}(H))\times C(K/C_{i}(K))] \\
&=\pi_{H}^{-1}[C(H/C_{i}(H))]\times\pi_{K}^{-1}[C(K/C_{i}(K))] \\
&=C_{i+1}(H)\times C_{i+1}(K).
\end{aligned}$$

Thus the inductive step isproved and $C_i(G)=C_i(H)\times C_i(K)$ for all i. Since $H,K$ are nilpotent, there exists $n\varepsilon N^*$ such that $C_{n}(H)=H$ and $C_n(K)=K$ ，whence $C_n(G)=H\times K=G$ . Therefore, $G$ is nilpotent.

Lemma 7.4. If H is a proper subgroup of a nilpotent group G, then H is a proper subgroup of its normalizer $N_G(H)$

PROOF. Let $C_{0}(G)=\langle e\rangle$ and let $n$ be the largest index such that $C_n(G)<H$ (there is such an $n$ since $G$ is nilpotent and $H$ a proper subgroup). Choose a e $C_{n+1}(G)$ with $a\notin H.$ .Then for every he H, $C_nah=(C_na)(C_nh)=(C_nh)(C_na)=C_nh$la in $G/C_n(G)$ since $C_na$ is in the center by the definition of $C_{n+1}(G)$ . Thus $ah=h^{\prime}ha$ where $h^{\prime}\in C_n(G)<H$ Hence aha-' e H and ae $N_G(H)$ . Since $a\neq H$ ,H is a proper subgroup of $N_G(H)$ .

Proposition 7.5. A finite group is nilpotent if and only if it is the direct product of it. Sylow subgroups.

PROOF. If $G$ is the direct product of its Sylow $P$ -subgroups, then $G$ is nilpotent by Theorems 7.2 and 7.3. If $G$ is nilpotent and $P$ is a Sylow $P$ -subgroup of $G$ for some prime $p$ , then either $P=G$ (and we are done) or $P$ is a proper subgroup of $G$ .In the latter case $P$ is a proper subgroup of $N_G(P)$ by Lemma 7.4. Since $N_G(P)$ is its own normalizer by Theorem 5.1l, we must have $N_G(P)=G$ by Lemma 7.4. Thus $P$ is normal in $G$ ,and hence the unique Sylow $P$ -subgroup of $G$ by Theorem 5.9. Let

------------------------------------------------------------------

$|G|=p_1^{n_1}\cdots p_k^{n_k}$ $(p_i$ distinct primes, $n_i>0$ ）and let $P_1,P_2,\ldots,P_k$ be the corre sponding (proper normal) Sylow subgroups of $G$ . Since $|P_{i}|=p_{i}^{n_{i}}$ for each $i.$ $P_{i}\cap P_{i}=\langle e\rangle$ for $i\neq j.$ By Theorem $\mathbf{I}.5.3\:xy=\:yx$ for every $x\in P_{i,\:y\:\varepsilon}P_{j}\left(i\neq j\right)$ (i≠j) $(i\neq j)$ It follows that for each i, $P_{1}P_{2}\cdots P_{i-1}P_{i+1}\cdots P_{k}$ is a subgroup in which every element has order dividing $p_{1}^{n_{1}}\cdots p_{i-1}^{n_{i-1}}p_{i+1}^{n_{i+1}}\cdots p_{k}^{n_{k}}$ . Consequently, $P_{i}\cap(P_{1}\cdots P_{i-1}P_{i+1}\cdots P_{k})$ $=\langle e\rangle$ and $P_1P_2\cdots P_k=P_1\times\cdots\times P_k$ . Since $|G|=p_{1}^{n1}\cdots p_{k}^{nk}=|P_{1}\times\cdots\times P_{k}|$ $=|P_{1}\cdots P_{k}|$ we must have $G=P_{1}P_{2}\cdots P_{k}=P_{1}\times\cdots\times P_{k}$

Corollary 7.6. IfG is a finite nilpotent group and m divides $|\mathbf{G}|$ ,then G has a sub group of order m.

PROOF. Exercise.

Definition 7.7. Let G be a group. The subgroup of $^{\prime}\mathbf{G}$ generated by the set $\{aba^{-1}b^{-1}\mid a,b\varepsilon G\}$ is called the commutator subgroup of G and denoted $\mathbf{G^{\prime}}$

The elements $aba^{-1}b^{-1}$ $(a,b\in G)$ are called commutators. The commutators only generate $G^{\prime}$ ,so that $G^{\prime}$ may well contain elements that are not commutators. $G$ is abelian if and only if $G^{\prime}=\langle e\rangle$ . In a sense, $G^{\prime}$ provides a measure of how much $G$ differs from an abelian group.

Theorem 7.8. IfG is a group, then $\mathbf{G^{\prime}}$ isa normal subgroup ofG and $G/G^{\prime}$ is abelian IfN is a normal subgroup ofG, then $G/N$ is abelian if and only if N contains $\mathbf{G^{\prime}}$

PROOF. Let $f:G\to G$ be any automorphism. Then

$$f(aba^{-1}b^{-1})=f(a)f(b)f(a)^{-1}f(b)^{-1}\varepsilon\:G^{\prime}.$$

 It follows that $f(G^{\prime})<G^{\prime}$ . In particular, if $f$ is the automorphism given by conjugation by a e $G$ ,then $aG^{\prime}a^{-1}=f(G^{\prime})<G^{\prime}$ , whence $G^{\prime}$ is normal in $G$ by Theorem I.5.1. Since $(ab)(ba)^{-1}=aba^{-1}b^{-1}\varepsilon\:G^{\prime}$ $abG^{\prime}=baG^{\prime}$ and hence $G/G^{\prime}$ is abelian. If $G/N$ is abelian, then $abN=baN$ for all $a,b\in G$ ,whence $ab(ba)^{-1}=aba^{-1}b^{-1}\varepsilon N$ . There fore, $N$ contains all commutators and $G^{\prime}<N$ . The converse is easy.

Let $G$ be a group and let $G^{(1)}$ be $G^{\prime}$ . Then for $i\geq1$ , define $G^{(i)}$ by $G^{(i)}\:=\:(G^{(i-1)})^{\prime}$ $G^{(i)}$ is called ith derived subgroup of $G$ . This gives a sequence of subgroups of $G$ each normal in the preceding one: $G>G^{(1)}>G^{(2)}>\cdots$ . Actually each $G^{(i)}$ is a normal subgroup of $G$ (Exercise 13).

Definition 7.9. A group G is said to be solvable $ifG^{(\mathrm{n})}=\langle e\rangle$ for some n.

Every abelian group is trivially solvable. More generally, we have

Proposition 7.10. Euery nilpotent group is soluable.

------------------------------------------------------------------

PROOF. Since by the definition of $C_i(G)$ $C_i(G)/C_{i-1}(G)=C(G/C_{i-1}(G))$ is abelian, $C_i(G)^{\prime}<C_{i-1}(G)$ for all $i>1$ and $C_{\mathrm{i}}(G)^{\prime}=C(G)^{\prime}=\langle e\rangle.$ For some $n$ $G=C_{n}(G)$ . Therefore, $C(G/C_{n-1}(G))=C_{n}(G)/C_{n-1}(G)=G/C_{n-1}$ (G) is abelian and hence $G^{(1)}\:=\:G^{\prime}\:<\:C_{n-1}(G)$ . Therefore, $G^{(2)}=\:G^{(1)\prime}<C_{n-1}(G)^{\prime}<C_{n-2}(G)$ similarly $G^{(3)}<C_{n-2}(G)^{\prime}<C_{n-3}(C_{n-1})$ G);..., ${\mathcal G}^{(n-1)}<C_{2}(G)^{\prime}<C_{\mathrm{i}}(G)$ ; $G^{(n)}<C_1(G)^{\prime}$ $=\langle e\rangle$ . Hence $G$ is solvable.

Theorem 7.11.(i) Every subgroup and every homomorphic image ofa solvable group is solvable. (ii) 1fN is a normal subgroup ofa group G such that N and. $G/N$ are solvable, then.

G is solvable..

SKETCH OF PROOF. (i) If $f:G\to H$ is a homomorphism [epimorphism] verify that $f(G^{(i)})<H^{(i)}[f(G^{(i)})=H^{(i)}]$ for all i. Suppose $f$ is an epimorphism, and $G$ is solvable. Then for some $n$ $\langle e\rangle=f(e)=f(G^{(n)})=H^{(n)}$ ,whence $H$ is solvable The proof for a subgroup is similar.

(i) Let $f:G\to G/N$ be the canonical epimorphism. Since $G/N$ is solvable,for some $n\:f(G^{(n)})=(G/N)^{(n)}=\langle e\rangle$ .Hence $G^{(n)}<$Ke $f=N$ Since $G^{(n)}$ is solvable by (i), there exists $k$ k $k\in\mathbf{N}^*$ such that $G^{(n+k)}\:=\:(G^{(n)})^{(k)}\:=\:\langle e\rangle$ . Therefore, $G$ is solvable.

Corollary 7.12. $If$n $\geq5$ , then the symmetric group $S_{\mathrm{n}}$ is not solvable.

PROOF. If $S_n$ were solvable, then $A_n$ would be solvable.Since $A_n$ is nonabelian $A_{n}^{\prime}\neq(1)$ . Since $A_n^{\prime}$ is normal in $A_n$ (Theorem 7.8) and $A_n$ is simple (Theorem 1.6.10), we must have $A_n^{\prime}=A_n$ . Therefore $A_{n}^{(i)}=A_{n}\neq(1)$ for all $i\geq1$ ,whence $A_n$ is not solvable. 

NOTE. The remainder of this section is not needed in the sequel

In order to prove a generalization of the Sylow theorems for finite solvable groups (as mentioned in the first paragraph of this section) we need some definitions and a lemma. A subgroup $H$ of a group $G$ is said to be characteristic [resp. fully invariant] if $f(H)<H$ for every automorphism [resp. endomorphism] $f:G\to G$ Clearly every fully invariant subgroup is characteristic and every characteristic subgroup is normal (since conjugation is an automorphism). A minimal normal subgroup of a group $G$ is a nontrivial normal subgroup that contains no proper subgroup which is normal in $G$

Lemma 7.13. Let N be a normal subgroup of a finite group G and H any subgroup ofG.

(i)IfH is a characteristic subgroup ofN,then H is normal in G.

------------------------------------------------------------------

(i) Every norinal Sylow p-subgroup ofG is fully incariant (ii)IfG is solcable and $N$ is a mininal normal subgroup, then $N$ is an abelian p group for some prime p.

PROOF. (i) Since $aNa^{-1}=N$ for all $a\epsilon G$ , conjugation by $a$ is an automorphism of $N$ .Since $H$ is characteristic in N $N$ $N,aHa^{-1}<H$ 1<H $-1<H$ for all $a\epsilon G$ .Hence $H$ is normal in $G$ by Theorem I.5.1.

(ii) is an exercise.(ii) It is easy to see that $N^{\prime}$ is fully invariant in $N$ ,whence $N^{\prime}$ is normal in $G$ by (i). Since $N$ is a minimal normal subgroup, either $N^{\prime}=\langle e\rangle$ or $N^{\prime}=N$ Since $N$ is solvable (Theorem 7.11), $N^{\prime}\neq N$ Hence $N^{\prime}=\langle e\rangle$ and $N$ is a nontrivial abelian group. Let $P$ be a nontrivial Sylow. $p$ -subgroup of $N$ forsome prime $P$ . Since $N$ is abelian, $P$ is normal in $N$ and hence fully invariant in $N$ by (ii). Consequently $P$ is normal in $G$ by (i). Since $N$ is minimal and $P$ nontrivial we must have $P=N$ .

Proposition 7.14. (P. Hall) Ler G be a finite solrable group of order mn, witli $(m,n)=1$ .Then

(i) G contains a subgroup oforder m; (i) any rwo subgroups of G of order m are conjugate:

(i) any subgroup of G of order k, where $k|m$ ,is contained in a subgroup of

order m.

REMARKS. If m is a prime power, this theorem merely restates several results contained in the Sylow theorens. P. Hall has also proved the converse of (i): if $G$ isa finite group such that whenever $|G|=$ mn with $(m,n)=1$ $G$ has a subgroup of order $m$ , then $G$ is solvable. The proof is beyond the scope of this book (see M. Hall [15; p. 143]).

PROOF OF 7.14. The proof proceeds by induction on $|G|$ , the orders $\leq5$ being trivial. There are two cases.

CASE 1. There is a proper normal subgroup $H$ of $G$ whose order is not divisible by $n$

(i) $|H|=m_1n_1$ , where m! $|m,n_1|n$ ,and $n_{1}<n.G/H$ G/H $G/H$ is a solvablegroupof order $(m/m_1)(n/n_1)<mn$ ,with $(m/m_{1},n/n_{1})=1$ . Therefore by induction $G/H$ contains a subgroup $A/H$ oforder $(m/m_1)$ (where $A$ is a subgroup of $G$ - see Corollary I.5.12). Then $|A|=|H|[A:H]=(m_{1}n_{1})(m/m_{1})=mn_{1}<mn.A$ A $A$ is solvable (Theorem 7.11) and by induction contains a subgroup of order 1111 (ii) Suppose $B,C$ are subgroups of $G$ of order m. Since $H$ is normal in $G$ G $G,HB$ is a

subgroup (Theorem I.5.3), whose order $k$ necessarily divides $|G|=111n$ . Since $k=|HB|=|H||B|/|H\cap B|=m_1n_1m/|H\cap B|$ ， we have $k|H\cap B|=m_1n_1m$ whence $k\mid m_1n_1m$ .Since $(m_{1,n})=1$ , there are integers $x,y$ such that $m_{1}x+ny=1$ and hence $mn_1m_1x+mn_1ny=mn_1$ . Consequently $k\mid mn_1$ . By Lagrange's Theorem $\mathbf{I} . 4. 6$ $m= | B|$ and $m_{1}n_{1}=|H|$ divide $k$ . Thus $(m,n)=1$ implies $mn_1\mid k$ . Therefore $k$ $= mn_{1}$ ; similarly $|HC|=mn_1$ . Thus $HB/H$ and $HC/H$ are subgroups of $G/H$ of

------------------------------------------------------------------

order $m/m_1$ . By induction they are conjugate: for some $\bar{x}\in G/H$ (where $\bar{x}$ is the coset of $x\in G)$ ， $\bar{x}(HB/H)\bar{x}^{-1}=HC/H$ .It follows that $xHBx^{-1}=HC$ . Consequently $xBx^{-1}$ and $C$ are subgroups of $HC$ of order $m$ and are therefore conjugate in HC by induction. Hence $B$ and $C$ are conjugate in $G$ (i) If a subgroup $K$ of $G$ has order $k$ dividing $m$ , then $HK/H\cong K/H\cap K$ K $K$ has

order dividing $k$ . Since $HK/H$ is a subgroup of $G/H$ , its order also divides $|G/H|$ $=(m/m_1)(n/n_1).(k,n)=1$ (k,n) = 1 $(k,n)=1$ implies that the order of $HK/H$ divides $m/m_1$ . By induction there is a subgroup $A/H$ of $G/H$ of order $m/m_1$ which contains $HK/H$ (where $A<G$ as above). Clearly $K$ is a subgroup of $A$ . Since $|A|=|H||A/H|=m_{1}n_{1}(m/m_{1})$ $=mn_1<nn,R$ $K$ is contained in a subgroup of $A$ (and hence of $G$ ) of order $m$ by induction.

CASE 2. Every proper normal subgroup of $G$ has order divisible by $n$ . If $H$ is a minimal normal subgroup (such groups exist since $G$ is finite), then $|H|=p^{r}$ for some prime $p$ by Lemma 7.13 (ii). Since $(m,n)=1$ and $n\mid|H|$ , it follows that $n=p^r$ and hence that $H$ is a Sylow $P$ -subgroup of $G$ .Since $H$ is normal in $G$ $H$ is the unique Sylow $p$ -subgroup of $G$ . This argument shows that $H$ is the only minimal normal subgroup of $G$ (otherwise $n=p^r$ and $n=q^s$ for distinct primes $p,q)$ 0. In particular, every nontrivial normal subgroup of G contains $H$

(i) Let $K$ be a normal subgroup of $G$ such that $K/H$ is a minimal normal subgroup of $G/H$ (Corollary I.5.12). By Lemma 7.13 (ii) $|K/H|=q^{s}$ $iq$ prime, $q\neq p$ ) so that $|K|=p^{r}q^{s}$ . Let $S$ bea Sylow $q$ -subgroup of $K$ and let $M$ be the normalizer of $S$ in $G$ .We shall show that $|M|=m.$ Since $H$ is normal in $K$ K $K,HS$ is a subgroup of $K$ Clearly $H\cap S=\langle e\rangle$ so that $|HS|=|H||S|/|H\cap S|=p^{r}q^{s}=|K|$ ,whence $K=HS$ Since $K$ is normal in $G$ and $S<K$ ,every conjugate of $S$ in $G$ lies in $K$ .Since

$S$ is a Sylow subgroup of $K$ ,all these subgroups are already conjugate in $K$ .Let $N=N_{\kappa}(S)$ ; then the number $c$ of conjugates of $S$ in $G$ is $[G:M]=[K:N]$ by Corollary 4.4. Since $S<N<K$, V<K $\mathbf{v}<K,\:K>HN>HS=K$ ，So that $K=HN$ and $c=[G:M]=[K:N]=[HN:N]=[H:H\cap N]$ (Corollary I.5.9). We shall show that $H\cap N=\langle e\rangle$ , which implies $c=|H|=p^{r}$ and hence $|M|=|G|/[G:M]$ $=mp^r/p^r=m$ .We do this by showing first that $H\cap N<C(K)$ and second that $C(K)=\langle e\rangle$ Let $x\in H\cap N$ and $k\varepsilon K$ . Since K=HS $K=HS$ $k=hs$ k=hs $K=HS,k=hs(h\varepsilon H,s\varepsilon S)$ (he H, seS) $(h\in H,s\in S)$ . Since $H$ is

abelian (Lemma 7.13 (ii)) and $x\in H$ , we need only show $xs=sx$ in order to have $xk=kx$ and $x$ E $C(K)$ .Now $(xsx^{-1})s^{-1}\varepsilon S$ since $x\in N=N_{K}(S)$ .But $x(sx^{-1}s^{-1})$ E $H$ since $x\varepsilon H$ and $H$ is normal in $G$ . Thus $xsx^{-1}s^{-1}\varepsilon H\cap S=\langle e\rangle$ ,，which implies $xs=sx$ It is easy to see that $C(K)$ is a characteristic subgroup of $K$ . Since $K$ is normal in

$G,C(K)$ is normal in $G$ by Lemma 7.13 (i). If $C(K)\neq\langle e\rangle$ , then $C(K)$ necessarily concontains $H$ .This together with $K=HS$ implies that $S$ is normal in $K$ . By Lemma 7.13 (ii) and (i) $S$ is fully invariant in $K$ and hence normal in $G$ (since $K\lhd G$ ).This implies $H<S$ which is a contradiction. Hence $C(K)=\langle e\rangle$ (ii) Let $M$ be as in (i) and suppose $B$ is a subgroup of $G$ of order m. Now $|BK|$ is

divisible by $|B|=m$ and $|K|=p^{r}q^{s}$ . Since $(m,p)=1$ $|BK|$ is divisible by $p^rm=nm$ $=|G|$ . Hence ${\mathcal G}=BK$ Consequently $G/K=BK/K\cong B/B\cap K$ K $K$ (Corollary 1.5.9), which implies that $|B\cap K|=|B|/|G/K|=q^{s}$ .By the Second Sylow Theorem $B\cap K$ K $K$ is conjugate to $S$ in $K$ . Furthermore $B$ n $K$ is normal in $B$ (since $K\lhd G$ )and hence $B$ is contained in $N_G(B\cap K)$ . Verify that conjugate subgroups have conjugate

------------------------------------------------------------------

normalizers. Hence $N_G(B\cap K)$ and $N_G(S)=M$ are conjugate in $G.$ Thus $|N_{G}(B\cap K)|=|M|=m$ .But $|B|=m$ ; therefore $B<N_G(B\cap K)$ implies $B=N_{G}(B\cap K)$ . Hence $B$ and $M$ are conjugate. (ii) Let $D<G$ , where $|D|=k$ and $k\mid m$ . Let $M$ (of order $m$ ) and $H$ (of order

$p^r$ ,with $(p,m)=1]$ ) be as in (i). Then $D\cap H=\langle e\rangle$ and $|DH|=|D\|H|/|D\cap H|$ $=kp^r$ .We also have $| G|$ = $mp^{r}$ ， $M\cap H=\langle e\rangle$ and $MH$ = $G$ (since $|MH|=|M||H|/|M\cap H|=mp^{r}=|G|)$ ．Hence $M(DH)=G$ and therefore $|M\cap DH|=|M||DH|/|MDH|=m(kp^{r})/mp^{r}=k$ . Let $M^{*}=M\cap DH$ ;then $M^*$ and $D$ are conjugate (by (i) applied to the group $DH$ ).For some a E $G$ $aM^{*}a^{-1}=D$ Since $M^*<M,D$ D $D$ is contained in $aMa^{-1}$ , a conjugate of $M$ , and thus a subgroup of order $m$ .

We close this sectionby mentioning a longstanding conjecture of Burnside: every finite group of odd order is solvable. This remarkable result was first proved by W. Feit and J. Thompson [61] in 1963.

## EXERCISES

1. (a) $A_4$ is not the direct product of its Sylow subgroups, but $A_4$ does have the property: $mn=12$ and $(m,n)=1$ imply there is a subgroup of order $m$ (b) $S_3$ has subgroups of orders 1, 2, 3, and 6 but is not the direct product of its Sylow subgroups.

2. Let $G$ be a group and $a,b\in G$ .Denote the commutator ab $a^{-1}b^{-1}\varepsilon G$ G $G$ by $[a,b]$ Show that for any a,b, G $G$ $c, \varepsilon$ $G$, $[ ab, c]$ = $a[ b, c] a^{- 1}[ a, c]$

3.If $H$ and $K$ are subgroups of a group $G$ ,let $(H,K)$ be the subgroup of $G$ zenerated by the elements $\{hkh^{-1}k^{-1}\mid h\varepsilon H,k\varepsilon K\}$ . Show that (a) $(H,K)$ is normal in $H\vee K$

(b) If $(H,G^{\prime})=\langle e\rangle$ , then $(H^{\prime},G)=\langle e\rangle$ (c) $H\triangleleft G$ if and only if $(H,G)<H$ (d) Let $K\lhd G$ and $K<H$ ; then $H/K<C(G/K)$ if and only if $(H,G)<K$

4. Define a chain of subgroups $\gamma_i(G)$ of a group $G$ as follows: $\gamma_1(G)=G$ 2(G) = (G,G) $\gamma_2(G)=(G,G)$ $\gamma_2(G)=(G,G),\gamma_i(G)=(\gamma_{i-1}(G),G)$ (see Exercise 3). Show that $G$ is nilpotent if and only if $\gamma_{m}(G)=\langle e\rangle$ for some $m$

 5. Every subgroup and every quotient group of a nilpotent group is nilpotent. [Hint: Theorem 7.5 or Exercise 4.].

6. (Wielandt) Prove that a fnite group $G$ is nilpotent if and only if every maximal proper subgroup of $G$ is normal. Conclude that every maximal proper subgroup has prime index. [Hinr : if $P$ is a Sylow $P$ -subgroup of $G$ , show that any subgroup containinge $N_G(P)$ is its own normalizer; see Theorem 5.11.]

7. If Nis a nontrivial normal subgroup of a nilpotent group $G$ ,then $N\cap C(G)\neq\langle e\rangle$

8.If $D_n$ is the dihedral group with generators $a$ of order $n$ and $b$ of order 2, then (a) $a^{2}\in D_{n}^{\prime}$ (b) If $n$ is odd, $D_n^{\prime}\cong Z_n$

(c) If $n$ is even, $D_n^{\prime}\cong Z_m$ ,where $2m=n$ (d) $D_n$ is nilpotent if and only if $n$ is a power of 2.

------------------------------------------------------------------

9. Show that the commutator subgroup of $S_4$ is $A_4$ .What is the commutaton group of $A_4$

10. $S_n$ is solvable for $n\leq4$ , but $S_3$ and $S_4$ are not nilpotent.

11. A nontrivial fnite solvable group $G$ contains a normal abelian subgroup $H\neq\langle e\rangle$ . If $G$ is not solvable then $G$ contains a normal subgroup $H$ such that $H^{\prime}=H$

12. There is no group $G$ such that $G^{\prime}=S_{4}$ .[Hint: Exercises 9 and 5.12 may be helpful.]

13.If $G$ is a group, then the ith derived subgroup $G^{(i)}$ is a fully invariant subgroup whence $G^{(i)}$ is normal.

14. If $N\lhd G$ and $N\cap G^{\prime}=\langle e\rangle$ ,then $N<C(G)$ 15. If $H$ is a maximal proper subgroup of a finite solvable group $G$ , then $[G:H]$ is a prime power. 16. For any group $G,C(G)$ is characteristic, but not necessarily fully invariant 17.If $G$ is an abelian $P$ -group, then the subgroup $G[p]$ (see Lemma 2.5) is fully invariant in $G$ 18. If $G$ is a finite nilpotent group, then every minimal normal subgroup of $G$ is contained in $C(G)$ and has prime order.

## 8. NORMAL AND SUBNORMAL SERIES

The usefulness of the ascending central series and the series of derived subgroups of a group suggests that other such series of subgroups should be investigated. We do this next and obtain still other characterizations of nilpotent and solvable groups, as well as the famous theorem of Jordan-Holder

Definition 8.1. A subnormal series of a group G is a chain of subgroups $\mathbf{G}=\mathbf{G}_0>$ $\mathbf{G}_{1}>\cdots>\mathbf{G}_{n}$ such that $G_{i+1}$ is normal in $\mathbf{G}_{\mathbf{i}}$ for $0\leq$i<n .The factors of the series are the yuotient groups. $\mathbf{G}_{\mathrm{i}}/\mathbf{G}_{\mathrm{i}+1}$ . The length of the series is the number of strict inclusions (or alternatively, the number ofnonidentity factors). A subnormal series such that $G_{\mathrm{i}}$ is normal in G for all i is said to be normal.

A subnormal series need not be normal (Exercise I.5.10)

EXAMPLES. The derived series $G>G^{(1)}>\cdots>G^{(n)}$ is a normal series for any group $G$ (see Exercise 7.13). If $G$ is nilpotent, the ascending central series $C_1(G)<\cdots<C_n(G)=G$ is a normal series for $G$

Definition 8.2. Let $\mathbf{G} = \mathbf{G} _{0}> \mathbf{G} _{1}> \cdots > \mathbf{G} _{\mathrm{n} }$ be a subnormal series. A one-step re-. finement of this series is any series of the form $\mathbf{G}=\mathbf{G}_{0}>\cdots>\mathbf{G}_{i}>\mathbf{N}>\mathbf{G}_{i+1}>\cdots$

------------------------------------------------------------------

$>G_n$ or $\mathbf{G} = \mathbf{G} _{0}> \cdots > \mathbf{G} _{\mathrm{n} }> \mathbf{N}$ , where N is a normal subgroup oJ $fG_i$ and $(if$i$<n)$ $G_{i+1}$ is normal in N. A refinement of a subnormal series S is any subnormal series obtained from S by a finite sequence of one-step refinements. A refinement ofS is said to be proper if its length is larger than the length of'S.

Definition 8.3. A subnormal series $\mathbf{G} = \mathbf{G} _{0}> \mathbf{G} _{\mathrm{l} }> \cdots > \mathbf{G} _{\mathrm{n} }= \langle \mathbf{e} \rangle$ is a composi tion series if each factor $\mathbf{G}_i/\mathbf{G}_{i+1}$ is simple. A subnormal series $\mathbf{G} = \mathbf{G} _{0}> \mathbf{G} _{\mathrm{l} }> \cdots >$ $\mathbf{G} _{\mathrm{n} }= \langle \mathbf{e} \rangle$ is a solvable series if each factor is abelian

The following fact is used frequently when dealing with composition series: if $N$ is a normal subgroup of a group $G$ , then every normal subgroup of $G/N$ is of theform $H/N$ where $H$ is a normal subgroup of $G$ which contains $N$ (Corollary I.5.12). Therefore, when $G\neq N$ ， $G/N$ is simple if and only if $N$ is a maximal in the set of all normal subgroups $M$ of $G$ with $M\neq G$ (such a subgroup $N$ is called a maximal normal subgroup of $G$ ).

Theorem 8.4.(i) Every finite group $G$ has a composition series. (i)Every refinement ofa soluable series is a solvable series.

(ii)A subnormal series is a composition series if and only ifit has noproper re finements.

PROOF. (i) Let $G_{1}$ be amaximal normal subgroupof $G$ ; then $G/G_1$ is simple by Corollary I.5.12. Let $G_2$ be a maximal normal subgroup of $G_{1}$, and so on. Since $G$ is finite, this process must end with $G_n=\langle e\rangle$ . Thus $G>G_1>\cdots>G_n=\langle e\rangle$ is a composition series. (ii) If $G_i/G_{i+1}$ is abelian and $G_{i+1}\lhd H\lhd G_{i}$, then $H/G_{i+1}$ is abelian since it is a

subgroup of $G_{i}/G_{i+1}$ and $G_i/H$ is abelian since it is isomorphic to the quotient $(G_i/G_{i+1})/(H/G_{i+1})$ by the Third Isomorphism Theorem I.5.10. The conclusion now follows immediately. (i) If $G_{i+1}\subsetneq H\unlhd G_{i}$ are groups, then $H/G_{i+1}$ is a proper normal subgroup of

$G_i/G_{i+1}$ and every proper normal subgroup of $G_i/G_{i+1}$ has this form by Corollary I.5.12. The conclusion now follows from the observation that a subnormal series $G=G_0>G_1>\cdots>G_n=\langle e\rangle$ has a proper refinement if -and only if there is a subgroupe $H$ such that for some i, $G_{i+1}\trianglelefteq_{\not=}H\trianglelefteq_{\not=}G_{i}$

1

Theorem 8.5.A group G is solvable if and only if it has a solvable series.

PROOF. If $G$ is solvable, then the derived series $G>G^{(1)}>G^{(2)}>\cdots>G^{(n)}$ $=\langle e\rangle$ is a solvable series by Theorem 7.8. If $G=G_0>G_1>\cdots>G_n=\langle e\rangle$ is a solvable series for $G$ , then $G/G_1$ abelian implies that $G_{1}>G^{(1)}$ by Theorem 7.8; $G_1/G_2$ abelian implies $G_2>G_1^{\prime}>G^{(2)}$ . Continue by induction and conclude that $G_{1}>G^{(i)}$ for all $i;$ in particular $\langle e\rangle=G_{n}>G^{(n)}$ and $G$ is solvable.

EXAMPLES. The dihedral group $D_n$ is solvable since $D_n>\langle a\rangle>\langle e\rangle$ is a solvable series, where $a$ is the generator of order $n$ (so that $D_n/\langle a\rangle\cong Z_2)$ .Similarly if

1

------------------------------------------------------------------



------------------------------------------------------------------

(i) $\mathbf{A}^*(\mathbf{A}\cap\mathbf{B}^*)$ is a normal subgroup of A $\iota^{*}(A\cap B)$ (i) $\mathbf{B}^*(\mathbf{A}^*\cap\mathbf{B})$ is a normal subgroup of $\mathbf{B}^*(\mathbf{A}\cap\mathbf{B})$ (ii) $\mathbf{A}^*(\mathbf{A}\cap\mathbf{B})/\mathbf{A}^*(\mathbf{A}\cap\mathbf{B}^*)\cong\mathbf{B}^*(\mathbf{A}\cap\mathbf{B})/\mathbf{B}^*(\mathbf{A}^*\cap\mathbf{B})$

PROOF. Since $B^*$ is normal in B $B$ $B,A\cap B^*=(A\cap B)\cap B^*$ is a normal subgroup of $A\cap B$ (Theorem I.5.3 (i); similarly $A^*\cap B$ is normal in A M B. Consequently $D=(A^{*}\cap B)(A\cap B^{*})$ is a normal subgroup of $A\cap B$ (Theorem I.5.3 iii) and Exercise I.5.13). Theorem 1.5.3 (ii) also implies that $A^*(A\cap B)$ and $B^*(A\cap B)$ are subgroups of $A$ and $B$ respectively.We shall define an epimorphism $f:A^*(A\cap B)\to(A\cap B)/D$ with kernel $A^*(A\cap B^*)$ . This will imply that $A^*(A\cap B^*)$ is normal in $A^*(A\cap B)$ (Theorem 1.5.5) and that $A^*(A\cap B)/A^*(A\cap B^*)\cong(A\cap B)/D$ (Corollary I.5.7).

Define $f:A^*(A\cap B)\to(A\cap B)/D$ as follows. If ae $A^*$ ，C∈ $A\cap B$ ，let $f(ac)=Dc$ . Then $f$ is well defined since $ac=a_{1}c_{1}(a,a_{1}\varepsilon A^{*};c,c_{1}\varepsilon A\cap B)$ implies $c_{1}c^{-1}=a_{1}^{-1}a_{\epsilon}(A\cap B)\cap A^{*}=A^{*}\cap B<D$ , whence $Dc_{1}=Dc.f$ is clearly surjective. $f$ is an epimorphism since $f[(a_1c_1)(a_2c_2)]=f(a_1a_3c_1c_2)=Dc_1c_2=Dc_1Dc_2$ $=f(a_1c_1)f(a_2c_2)$ ,where $a_i\varepsilon A^*$ $c_i\in A\cap B$ , and $c_1a_2=a_3c_1$ since $A^*$ is normal in $A$ Finally ac ε Ker $f$ ifand onlyifce $D$ ,that is,if and onlyif $c=a_{1}c_{1}$ , with $a_1\in A^*\cap B$ and $c_1\varepsilon A\cap B^*$ . Hence ac e Ker $f$ if and only if $ac=(aa_1)c_1$ E $A^*(A\cap B^*)$ .Therefore, Ker $f=A^{*}(A\cap B^{*})$ A symmetric argument shows that $B^*(A^*\cap B)$ is normal in $B^*(A\cap B)$ and

$B^*(A\cap B)/B^*(A^*\cap B)\cong(A\cap B)/D$ , whence (ii) follows immediately.

Theorem 8.10.(Schreier)Any two subnormal [resp.normal] series ofa group G have subnormal [resp. normal] refinements that are equivalent.

PROOF. Let $G=G_{0}>G_{1}>\cdots>G_{n}$ and $G=H_{0}>H_{1}>\cdots>H_{m}$ be subnormal [resp. normal] series. Let $G_{n+1}=\langle e\rangle=H_{m+1}$ and for each $0\leq i\leq n$ consider the groups

$$G_{i}=G_{i+1}(G_{i}\cap H_{0})>G_{i+1}(G_{i}\cap H_{i})>\cdots>G_{i+1}(G_{i}\cap H_{i})>G_{i+1}(G_{i}\cap H_{i+1})\\>\cdots>G_{i+1}(G_{i}\cap H_{m})>G_{i+1}(G_{i}\cap H_{m+1})=G_{i+1}.$$

For each $0\leq j\leq m$ , the Zassenhaus Lemma (applied to $G_{i+1},G_{i},H_{j+1}$, and $H_i)$ shows that $G_{i+1}(G_i\cap H_{j+1})$ is normal in $G_{i+1}(G_i\cap H_i)$ . [If the original series were both normal, then each $G_{i+1}(G_i\cap H_j)$ is normal in $G$ by Theorem I.5.3 (ii) and Exercises I.5.2 and I.5.13.] Inserting these groups between each $G_i$ and $G_{i+1}$ ,and denoting $G_{i+1}(G_i\cap H_j)$ by $G(i,j)$ thus gives a subnormal [resp. normal] refinement of the series $G_{0}>G_{1}>\cdots>G_{n}$

$$G=G(0,0)>G(0,1)>\cdots>G(0,m)>G(1,0)>G(1,1)>\\G(1,2)>\cdots>G(1,m)>G(2,0)>\cdots>G(n-1,m)>G(n,0)>\cdots>G(n,m),$$

where $G(i,0)=G_{i}$ Note that this refinement has $(n+1)(m+1)$ (not necessarily distinct) terms. A symmetric argument shows that there is a refinement of $G=H_{0}>$ $H_{1}>\cdots>H_{m}$ (where $H(i,j)=H_{i+1}(G_{i}\cap H_{j})$ and $H(0,j)=H_{i}$ ：

$$G=H(0,0)>H(1,0)>\cdots>H(n,0)>H(0,1)>H(1,1)>H(2,1)>\\H(n,1)>H(0,2)>\cdots>H(n,m-1)>H(0,m)>\cdots>H(n,m).$$

1

------------------------------------------------------------------



------------------------------------------------------------------

8.If $H$ and $K$ are solvable subgroups of $G$ with $H\lhd G$ , then $HK$ is a solvable sub group of $G$

10. A group $G$ is nilpotent if and only if there is a normal series $G=G_{0}>G_{1}>\cdots$ $>G_{n}=\langle e\rangle$ such that $G_{i}/G_{i+1}<C(G/G_{i+1})$ for every i.

5. An abelian group has a composition series if and only if it is finite. 6.If $H\lhd G$ ,where $G$ has a composition series, then $G$ has a composition series one of whose terms is $H$ 7. A solvable group with a composition series is finite. 9. Any group of order $p^2q\left(p,q\right)$ primes) is solvable. 11. (a) Show that the analogue of Theorem 7.11 is false for nilpotent groups [Consider $S_3]$ (b) If $H<C(G)$ and $G/H$ is nilpotent, then $G$ is nilpotent. 12. Prove the Fundamental Theorem of Arithmetic, Introduction, Theorem 6.7, by applying the Jordan-Holder Theorem to the group $Z_n$ 13. Any simple group $G$ of order 60 is isomorphic to $A_5$ . [Hinr: use Corollary 4.9; if $H<G$ ，then $[G:H]\geq5$ (since $|S_n|<60$ for $n\leq4)$ ;if $[G:H]=5$ then $G\cong A_{5}$ by Theorem I.6.8. The assumption that there is no subgroup of index 5 leads to a contradiction.] 14. There are no nonabelian simple groups of order <6015. Let $G$ be the subgroup of $S_7$ generated by (1234567) and (26)(34).Show that $|G|=168$

Exercises 16-20 outline a proof of the fact that the group $G$ of Exercise 15 is simple. We consider $G$ as acting on the set $S=\{1,2,3,4,5,6,7\}$ as in the first example after Definition 4.1 and make use of Exercise 4.6.

16. The group $G$ is transitive (see Exercise 4.6).

17. For each $x\varepsilon S$ $G_{x}$ is a maximal (proper) subgroup of $G$ . The proof of this fact proceeds in several steps: (a) A block of $G$ is a subset $T$ of $S$ such that for each $g\varepsilon G$ $G$ G either $gT$ n $T=\varnothing$ or $gT=T$ where $gT=\{gx\mid x\in T\}$ . Show that if $T$ is a block, then $|T|$ divides 7. [Hint: let $H=(g\varepsilon G|gT=T)$ and show that for $x$ $T$, $G_x<H$ and $[H{:}G_x]$ $=|T|$ .Hence $|T|$ divides $[G:G_z]=[G:H][H:G_z]$ .But $[G:G_z]=7$ by Exercise 4.6(a) and Theorem 4.3.] (b) If $G_{x}$ is not maximal, then there is a block $T$ of $G$ such that $|T|+7$ ,contradicting part (a). [Hint: If $G_{x}\lneq H<G$ , show that $H$ is not transitive on $S$ (since $1\leq[H:G_{z}]<|S|$ , which contradicts Exercise 4.6.(d)). Let $T=\{hx\mid h\varepsilon H\}$ Since $H$ is not transitive, $|T|<|S|=7$ and since $H\neq G_x,|T|>1$ . Show that $T$ is a block.]

18. If $(1)\neq N\lhd G$ , then 7 divides $|N|$ . [Hint : Exercise $4.6\left(\mathrm{c}\right)\Rightarrow G_{z}\lneq NG_{x}$ for all x $\varepsilon S\Rightarrow NG_{x}=G$ for all $x\varepsilon S$ by Exercise $17\Longrightarrow N$ is transitive on $S\Rightarrow7$ divides $|N|$ by Exercise 4.6 (d).]

------------------------------------------------------------------



------------------------------------------------------------------



------------------------------------------------------------------



------------------------------------------------------------------



------------------------------------------------------------------



------------------------------------------------------------------



------------------------------------------------------------------

morphism of rings which is an injective [resp. surjective, bijective] map. A monomorphism of rings $R\to S$ is sometimes called an embedding of $R$ in $S$ .An isomorphism $R\to R$ is called an automorphism of $R$ The kernel of a homomorphism of rings $f:R\to S$ is its kernel as a map of addi-

tive groups; that is, Ker $f=\{r\varepsilon R\mid f(r)=0\}$ . Similarly the image of $f$, denoted $Imf$, is $\{s\in S\mid s=f(r)$ for some r e $R$ 1.If $R$ and $S$ both have identities $1_{R}$ and $\mathbf{l}_{S:}$ we do nor require that a homomorphism of rings map $1_{R}$ to $1s$ (see Exercises 15, 16).

EXAMPLES. The canonical map $\mathbf{Z}\to\mathbf{Z}_m$ given by $k\vdash\bar{k}$ is an epimorphism of rings. The map $\mathbb{Z}_3\to\mathbb{Z}_6$ given by $\bar{k}\mapsto\overline{4k}$ is a well-defined monomorphism of rings.

EXAMPLE. Let $G$ and $H$ be multiplicative groups and $f:G\to H$ a homomorphism of groups. Let $R$ be a ring and define a map on the group rings $\bar{f}:R(G)\to R(H)$ by:

$$\bar{f}\biggl(\sum_{i=1}^{n}r_{i}g_{i}\biggr)=\sum_{i=1}^{n}r_{i}f(g_{i}).$$

Then $\bar{f}$ is a homomorphism of rings.

Definition 1.8. Ler R be a ring. If there is a least positive integer n such that na =0 for all a e R, then R is said to have characteristic n. If no such n exisis R is said to have characteristic zero. (Notation: char $\mathbf{R}=\mathbf{n}$

Theorem1.9.LerR be a ring with identity $1_{\mathbf{R}}$ and characteristic $n>0$

(i) $If\varphi:\mathbf{Z}\to\mathbf{R}$ is the mapgiven by $m\mapsto ml_{R}$ ,then 4 is a homomorphism of rings with kernel $\langle n\rangle=|kn|k\varepsilon Z\}$ (ii) n is the least positire integer such that $n1_{R}=0$ (ii)If R has no zero divisors (in particular ifR is an integral domain),then n is prine.

SKETCH OF PROOF. (ii) If $k$ is the least positive integer such that $k1_{R}=0$ then for all a ε $R:kQ=k(1_{R}a)=(k1_{R})a=0\cdot a=0$ by Theorem 1.2. (ii) If $n=kr$ with $1<k<n$ ， $1<r<n$ ,then $0=n1_{R}=(kr)1_{R}1_{R}=(k1_{R})(r1_{R})$ implies that $k1_{R}=0$ or $r1_{R}=0$ , which contradicts (ii).

Theorem 1.10.Euery ringR may be embedded in a ringSwithidentity.Thering S (which is not unique) may be chosen tobe either of characteristiczero or of the same characteristic as R.

SKETCH OF PROOF. Let S.be the additive abelian group $R\oplus\mathbf{Z}$ and define multiplication in $S$ by

$$(r_1,k_1)(r_2,k_2)=(r_1r_2+k_2r_1+k_1r_2,k_1k_2),(r_i\in R;k_i\in\mathbf{Z}).$$

------------------------------------------------------------------

Verify that $S$ is a ring with identity (O,1) and characteristic zero and that the map $R\to S$ given by $r\vdash(r,0)$ is a ring monomorphism (embedding). If char $R=n>0$ use a similar proof with $S=R\oplus Z_{n}$ and multiplication defined by

$$(r_{1},\bar{k}_{1})(r_{2},\bar{k}_{2})=(r_{1}r_{2}+k_{2}r_{1}+k_{1}r_{2},\bar{k}_{1}\bar{k}_{2}),$$

where $r_i\varepsilon R$ and $\bar{k}_i\varepsilon Z_n$ is the image of ki $k_i$ $k_i\varepsilon Z$ under the canonical map. Then char $S=n$ .

## EXERCISES

1. (a) Let $G$ be an (additive) abelian group. Define an operation of multiplicatior in $G$ by $ab=0$ (for all $a,b$ ε $G$ .Then $G$ is a ring

(b) Let $S$ be the set of all subsets of some fixed set $U$ .For $A,B\in S$ ,define $A+B=(A-B)\cup(B-A)$ (B - A) $(B-A)$ and $AB=A\cap B.$ Then $S$ is a ring. Is $S$ com mutative? Does it have an identity?.

2. Let $\{R_{i}\mid i\in I\}$ bea family of rings with identity.Make thedirect sum of abelian groups $\sum_{iel}R_i$ into a ring by defhning multiplication coordinatewise Does $\sum_{iel}R_i$ have an identity?

3. A ring $R$ such that $a^{2}=a$ for all a ε $R$ is called a Boolean ring. Prove that every Boolean ring. $R$ is commutative and $a+a=0$ for all a e. $R$ .[For anexampleof a Boolean ring, see Exercise 1(b).].

4. Let $R$ be a ring and $S$ a nonempty set. Then the group $M(S,R)$ (Exercise I.1.2) is a ring with multiplication defined as follows: the product of $f,g$ E $M(S,R)$ is the function $S\to R$ given by $s\vdash f(s)g(s)$

5.If $A$ is the abelian group $\mathbf{Z}\oplus\mathbf{Z}$, then End $A$ is a noncommutative ring (see page 116).

6. A finite ring with more than one element and no zero divisors is a division ring (Special case: a finite integral domain is a field.)

7. Let $R$ be a ring with more than one element such thatfor each nonzero a e $R$ there is a unique $b\varepsilon R$ such that aba $=a$ .Prove:

(a) $R$ has no zero divisors. (b) $bab=b$ (c) $R$ has an identity. (d) $R$ is a division ring.

8. Let $R$ be the set of all $2\times2$ matrices over the complex field $\mathbf{C}$ of theform

$$\binom z{-\bar{w}},$$

where $\bar{z},\overline{w}$ are the complex conjugates of $z$ and $w$ respectively (that is. $c=a+b\sqrt{-1}\Leftrightarrow\bar{c}=a-b\sqrt{-1})$ . Then $R$ is a division ring that is isomorphic to the divisionring $K$ of real quaternions. [Hint: Define an isomorphism $K\to R$ by letting the images of $1,i,j,k$ E $K$ be respectively the matrices

$$\begin{pmatrix}1&0\\0&1\end{pmatrix},\begin{pmatrix}\sqrt{-1}&0\\0&-\sqrt{-1}\end{pmatrix},\begin{pmatrix}0&1\\-1&0\end{pmatrix},\begin{pmatrix}0&\sqrt{-1}\\\sqrt{-1}&0\end{pmatrix}.$$

!

------------------------------------------------------------------

9.(a) The subset $G$ = $\{$ $1, - 1, i, - i, j, - j, k, - k\}$ of the division ring $K$ ofreal quaternions forms a group under nultiplication (b) $G$ is isomorphic to the quaternion group (Exercises I.4.14 and I.2.3) (c)What is the difference between the ring $K$ and the group ring $\mathbf{R}(G)$ $\mathbf{R}$ the feld of real numbers)?

10. Let $k,n$ be integers such that $0\leq k\leq n$ and () the binomial coeffcien $n!/(n-k)!k!$ ，where 0!=1 and for $n>0$ ， $n!=n(n-1)(n-2)\cdots2\cdot1$ (a) $\binom nk=\binom n{n-k}$ (b) $\binom nk<\binom n{k+1}$ for $k+1\leq n/2$ () $\binom nk+\binom n{k+1}=\binom{n+1}{k+1}$ for k<n. (d) $\binom nk$ is an integer. (e) if $p$ is prime and $1\leq k\leq p^n-1$ . then $\binom{p^n}k$ is disible by $p$ [Hins (b) observe hat $\binom n{k+1}=\binom nk\frac{n-k}{k+1}$ (d noe hat $\binom m0=\binom mm=1$ and use induction on $n$ in part (c).]

11. (The Freshman's Dream'). Let $R$ be a commutative ring with identity of prime. characteristic $P$ .If $a,b\in R$ R $R$ , then $(a\pm b)^{\prime\prime\prime}=a^{\prime\prime\prime}\pm b^{\prime\prime^n}$ for all integers $n\geq0$ [see Theorem 1.6 and Exercise 10; note that $b=-b$ if $p=2]$

12. An element of a ring is nilpotent if $u^{n_1}=0$ for some 111 . Prove that in a commutative ring $a+b$ is nilpotent if $u$ and $b$ are. Show that this result may be false if $R$ is not commutative.

13. In a ring $R$ the following conditions are equivalent..

(a) $R$ has no nonzero nilpotent elements (see Exercise 12). (b) If $a\varepsilon R$ $R$ R and $u^2=0$ ,then $u=0$

14. Let $R$ be a commutative ring with identity and prime characteristic $P$ .The map $R\to R$ given by $r\vdash r^{\prime}$ is a homomorphism of rings called the Frobenius homo morphism [see Exercise 11].

15. (a) Give an example of a nonzero homomorphism $f:R\to S$ of rings with identity such that $f(1_R)\neq1_S$ (b) If $f:R\to S$ is an epimorphism of rings with identity, then $f(\mathbf{l}_{R})=\mathbf{l}_{S}$

(c) If $f:R\to S$ is a homomorphism of rings with identity and $u$ is a unit in $R$ such that $f(u)$ is a unit in $S$ ,then $f(1_{n})=1_{s}$ and $f(u^{-1})=f(u)^{-1}$ . [Note: there are easy examples which show that $f(u)$ need not be a unit in $S$ even though $u$ is a unit in $R$ -J]

16. Let $f:R\to S$ be a homomorphisn of rings such that $f(r)\neq0$ for some nonzero $r\varepsilon R$ . If $R$ has an identity and $S$ has no zero divisors, then $S$ is a ring with identity $f(1_R)$

'Terminology due to V. O. McBrien..

------------------------------------------------------------------

17. (a) If $R$ is a ring. then so is $R^{\cdots_{1}}$ .where $R^{\cdots1}$ is defined as follows. The underlying set of $R^{\prime\prime}l$ is precisely $R$ and addition in $R^{\prime\prime}$ coincides with addition in $R$ . Multiplication in $R^{(\prime)}$ , denoted o, is defined by $(10h=bcu)$ .where $ba$ is the product in $R$ $R^{\prime\prime}l$, is called the opposite ring of $R$ (b) $R$ has an identity if and only if $R^{\cdots}$ does.

(c) $R$ is a division ring if and only if $R^{\prime\prime\prime}$ is. (d) $(R^{\prime\prime\prime})^{\prime\prime\prime\prime}=R$ (e) If $S$ is a ring, then $R\cong S$ if and only if $R^{\cdots_{\prime}}\cong S^{\cdots_{1}}$

18. Let Q be the field of rational numbers and $R$ any ring. If $f,g:\mathbf{Q}\to R$ are homomorphisms of rings such that $f|\mathbf{Z}=g|\mathbf{Z}$ then $f=g$ . [Hinr: show that for neZ $(n\neq0)$ . $f(1/n)g(n)=g(1)$ ,whence $f(1,n)=g(1/n).$

## 2. IDEALS

Just as normal subgroups played a crucial role in the theory of groups, so ideals play an analogous role in the study of rings. The basic properties of ideals are developed, including a characterization of principal ideals (Theorem 2.5) and the various isomorphism theorems (2.9-2.13; these correspond to the isomorphism theorems. for groups). Prime and maximal ideals are characterized in several ways. Direct products in the category of rings are discussed and the Chinese Remainder Theorem is proved.

Definition 2.1.Ler R be a ring and S a nonempry subset ofR that is closed under the operations ofaddition and multiplication in R. If S is itself a ring under these operations. then S is called a subring of R. A subring I of a ring R is. $a$ left ideal prorided

reR and xεI = rx e I;

I is a right ideal prorided

reR and xel xI e I; ！

I is an ideal if it is both a left and right ideal.

Whenever a statement is made about left ideals it is to be understood that the analogous statement holds for right ideals..

EXAMPLE. If $R$ is any ring, then the center of $R$ is the set $C=\{c\varepsilon R\mid cr=rc$ for all $r\varepsilon R\}$ . $C$ is easily seen to be a subring of $R$ . but may not be an ideal (Exer cise 6).

EXAMPLE. If $f:R\to S$ is a homomorphisn of rings, then Ker fis an ideal in $R$ (Theorem 2.8 below) and Im $f$ is a subring of $S$ . Im $f$ need not be an ideal in $S$

EXAMPLE. For each integer 11 the cyclic subgroup $\langle n\rangle=\{kn\mid k\varepsilon\mathbf{Z}\}$ is an ideal in Z.

EXAMIPLE. In the ring $R$ of $n\times n$ matrices over a division ring $D$ , let $I_k$ be the set of all matrices that have nonzero entries only in column. $k$ . Then $I_{k}$ is aleft ideal.

------------------------------------------------------------------



------------------------------------------------------------------



------------------------------------------------------------------

Theorem 2.7. Ler R be a ring and I an ideal ofR. Then the additive quotient group R/I is a ring with multiplication given by

$$\mathrm{(a+I)(b+I)=ab+I.}$$

If R is commutative or has an identity, then the same is true of R/I

SKETCH OF PROOF OF 2.7. Once we have shown that multiplication in $R/I$ is well defined, the proof that $R/I$ is a ring is routine. (For example, if $R$ has identity $1_{R:}$ then $1_R+I$ is the identity in $R/I.)$ Suppose $a+I=a^{\prime}+I$ and $b+I=b^{\prime}+I$ Wemust showthat $ab+I=a^{\prime}b^{\prime}+I.$ Since $a^{\prime}\varepsilon a^{\prime}+I=a+I$, $a^{\prime}=a+i$ for someiε I. Similarly $b^{\prime }$ = $b+ j$ with $j$ j $j\in I.$ Consequently $a^{\prime}b^{\prime}=(a+i)(b+j)=ab+ib+aj+ij$ Since $I$ is an ideal,

$$a'b'-ab=ib+aj+ij\varepsilon I.$$

Therefore $a^{\prime}b^{\prime}+I=ab+I$ by Corollary I.4.3, whence multiplication in $R/I$ is well defined.

As one might suspect from the analogy with groups,ideals and homomorphisms of rings are closelyrelated.

Theorem 2.8. $If\mathbf{f}:\mathbf{R}\to\mathbf{S}$ is a homomorphism ofrings, then the kernel off is an idea. in R. Conversely ifI is an ideal in. $R$ , then the map $\pi:\mathbb{R}\to\mathbb{R}/\mathbb{I}$ given by $r\vdash r+I$ is an epimorphism of rings with kernel I.

The map $\pi$ is called the canonical epimorphism (or projection).

PROOF OF 2.8. Ker fis an additive subgroup of $R$ .If $x\varepsilon$ Ker fand r e R, then $f(rx)=f(r)f(x)=f(r)0=0$ ,whence $rx$ εKer $f.$ . Similarly, $xr$ Ker $f.$ .Therefore, Ker $f$ is an ideal. By Theorem I.5.5 the map $\pi$ is an epimorphism of groups with kernel I. Since $\pi(ab)=ab+I=(a+I)(b+I)=\pi(a)\pi(b)$ for all $a,b\in R$ R $R$ $\pi$ is also an epimorphism of rings. 

In view of the preceding results it is not surprising that the various isomorphism theorems for groups(Theorems I.5.6-I.5.12) carry over to rings with normal subgroups and groups replaced by ideals and rings respectively. In each case the desired isomorphism is known to existfor additive abelian groups.If the groups involved are, in fact, rings and the normal subgroups ideals, then one need only verify that the known isomorphism of groups is also a homomorphism and hence an isomor. phism of rings.Caution:in the proofs of the isomorphism theorems for groups all groups and cosets are written multiplicatively, whereas the additive group of a ring and the cosets of an ideal are written additively.

Theorem 2.9. Iff : $\mathbb{R}\to\mathbb{S}$ is a homomorphism of rings andIis anideal of Rwhich is contained in the kernel off,then there is a unique homomorphism of rings $\mathbf{\bar{f}}:\mathbf{R}/\mathbf{I}\to\mathbf{S}$ such that $\bar{\mathbf{f}}(\mathbf{a}+\mathbf{I})=$f$(\mathbf{a})$ for all a ε R. Im $\bar{\mathbf{f}}=Im$ f and Ker $\bar{\mathbf{f} } = ( Ker$ f$) / \mathbf{I} .$ f is an iso morphism if and only iffis an epimorphismand $\mathbf{I}=Ker$f

------------------------------------------------------------------

### PROOF. Exercise; see Theorem I.5.6.

Corollary 2.10. (First Isomorphism Theorem) If $\mathbf{f}:\mathbf{R}\to\mathbf{S}$ is a homomorphism of. rings, then f induces an isomorphism of rings. $\mathbf{R}/Ker$ f$\cong Im$ f.

PROOF. Exercise; see Corollary I.5.7.

Corollary 2.11. Iff: $\mathbb{R}\to\mathbb{S}$ is a homomorphism of rings, Iis an ideal in R and J is an ideal in S such that. $\mathbf{f}(\mathbf{I})\subset\mathbf{J}$ , then f induces a homomorphism of rings. $\mathbf{\bar{f}}:\mathbf{R}/\mathbf{I}\to\mathbf{S}/\mathbf{J}$ given by a $1+\mathbf{I}\mapsto\mathbf{f}(\mathbf{a})+\mathbf{J}$ fis an isomorphism if and only ifIm $\mathbf{f}+\mathbf{J}=\mathbf{S}$ and $\mathbf{f}^{-1}(\mathbf{J})\subset\mathbf{I}.$ In particular, if f is an epimorphism such that. $\mathbf{f(I)}=\mathbf{J}$ and Ker f C I, then f is an isomorphism.

PROOF. Exercise; see Corollary I.5.8..

Theorem2.12.LetI and J be ideals in a ring R.

(i) (Second Isomorphism Theorem) There is an isomorphisms ofrings I/(I J) = $(\mathbf{I}+\mathbf{J})/\mathbf{J}$ (ii) (Third Isomorphism Theorem) if I C J, then. $\mathbf{J}/\mathbf{I}$ is an ideal in R/I and there is. an isomorphism ofrings $(\mathbf{R}/\mathbf{I})/(\mathbf{J}/\mathbf{I})\cong\mathbf{R}/\mathbf{J}$

PROOF. Exercise; see Corollaries I.5.9 and I.5.10.

1

Theorem 2.13. If I is an ideal in a ring R, then there is a one-to-one correspondence between the set ofall ideals of R which contain I and the set of all idealsof R/I, given $by$ J$\vdash\mathbf{J}/\mathbf{I}$ .Hence every ideal in R/Iis oftheform $\mathbf{J}/\mathbf{I}$ ,whereJis an ideal ofRwhich contains I.

PROOF. Exercise; see Theorem 1.5.11, Corollary 1.5.12 and Exercise 13.

Nextwe shall characterize in several ways twokinds of ideals(prime and maximal), which are frequently of interest

1

Definition 2.14. An ideal P in a ring R is said to be prime $ifP\neq\mathbf{R}$ andfor any ideals A,BinR

$$AB\subset P\Rightarrow A\subset PorB\subset P.$$

The definition of prime ideal excludes the ideal $R$ for both historical and technica reasons. Here is a very useful characterization of prime ideals; other characteriza tions aregiven inExercise 14.

1

------------------------------------------------------------------

Theorem 2.15. If P is an ideal in a ring R such that $P\neq\mathbb{R}$ and for all a,b ε R

ab εP $\Longrightarrow$ aεＰ or bεP,

then P is prime. Conversely ifP is prime and R is commutative, then P satisfies condition (1).

REMARK. Commutativity is necessary for the converse (Exercise 9 (b)).

PROOF OF 2.15. If $A$ and $B$ are ideals such that $AB\subset P$ and $A\not\subset P$ ,then there exists an element $a\in A-P$ .For every $b\varepsilon B$ ，ab ε $AB\subset P$ ,whence ae $P$ or $b\varepsilon P.$ .Since a 中$P$ ,we must have $b\varepsilon P$ for all $b\varepsilon B$ ; that is, $B\subset P$ . Therefore, $P$ is prime. Conversely, if $P$ is any ideal and ab e $P$ , then the principal ideal $(ab)$ is contained in $P$ by Definition 2.4. If $R$ is commutative, then Theorem 2.5 implies that $(a)(b)\subset(ab)$ ，whence $(a)(b)\subset P$ .If $P$ is prime, then either $(a)\subset P$ or $(b)\subset P$ whence ae $P$ or $b\varepsilon P$ .

EXAMPLES. The zero ideal in any integral domain is prime since $ab=0$ if and only if $a=0$ or $b=0$ . If $p$ is a prime integer, then the principal ideal $(p)$ in $\mathbf{Z}$ is prime since

$$ab\varepsilon(p)\quad\Rightarrow\quad p|ab\quad\Rightarrow\quad p|a\quad\mathrm{or}\quad p|b\quad\Rightarrow\quad a\varepsilon(p)\quad\mathrm{or}\quad b\varepsilon(p).$$

Theorem 2.16. In a commutative ring R with identity $\mathbf{l}_{\mathbb{R}}\neq0$ an ideal P is prime $if$ and only if thequotient ring $R/P$ is an integral domain.

PROOF. $R/P$ is a commutative ring with identity $1_R+P$ and zero element $0+P=P$ by Theorem 2.7. If $P$ is prime, then $1_{R}+P\neq P$ since $P\neq R.$ Furthermore, $R/P$ has no zero divisors since

$$(a+P)(b+P)=P\quad\Rightarrow\quad ab+P=P\quad\Rightarrow\quad ab\varepsilon P\quad\Rightarrow\quad a\varepsilon P\quad\mathrm{or}\\b\varepsilon P\quad\Rightarrow\quad a+P=P\quad\mathrm{or}\quad b+P=P.$$

Therefore, $R/P$ is an integral domain. Conversely, if $R/P$ is an integral domain, then $1_{R}+P\neq0+P$ whence $1_R\notin P$ . Therefore, $P\neq R$ .Since $R/P$ has no zero divisors

$$\begin{aligned}ab\varepsilon P\quad\Rightarrow\quad ab+P&=P\quad\Rightarrow\quad(a+P)(b+P)=P\quad\Rightarrow\quad a+P=P\quad\mathrm{or}\\b+P&=P\quad\Rightarrow\quad a\varepsilon P\quad\mathrm{or}\quad b\varepsilon P.\end{aligned}$$

Therefore, $P$ is prime by Theorem 2.15.

Definition 2.17. An ideal [resp. left ideal) M in a ring R is said to be maximal if $M\neq\mathbb{R}$ and for every ideal[resp. left ideal) $N$ such that $\mathbf{M}\subset\mathbb{N}\subset\mathbb{R}$ ,either $\mathbf{N}=\mathbf{M}$ or $\mathbf{N}=\mathbf{R}$

EXAMPLE. The ideal (3) is maximal in $\mathbf{Z}$ ; but the ideal (4) is not since $(4)\subsetneq$

------------------------------------------------------------------

REMARK. If $R$ is a ring and S is the set of allideals Iof $R$ such that $I\neq R$ ,then S is partially ordered by set-theoretic inclusion. $M$ is a maximal ideal (Defnition 2.17) if and only if $M$ is amaximal element in thepartially ordered setS in the sense of Introduction, Section 7. More generally one sometimes speaks of an ideal $I$ that is maximal with respect toa given property,meaning that under thepartial ordering of set theoretic inclusion,. $I$ is maximal in the set of all ideals of $R$ which have the given. property. In this case $I$ need not be maximal in the sense of Definition 2.17.

Theorem 2.18. In a nonzero ring R with identity maximal [left] ideals ulways exist. In fact every [lefi] ideal in R (except R itself) is contained in a maximal[lefi)] ideal.

PROOF. Since O is an ideal and $0\neq R$ , it suffices to prove the second statement The proof is a straightforward application of Zorn's Lemma. If $A$ is a [left] ideal in $R$ such that $A\neq R.$ letSbe theset of all[left] ideals $B$ in $R$ such that $A\subset B\neq R$ .Sis nonempty since $A\varepsilon S$ .Partially order S by set theoretic inclusion (that is, $B_1\leq B_2\Leftrightarrow B_1\subset B_2$ 0. In order to apply Zorn's Lemma we must show that every chain $\mathcal{C}=\{C_{i}\mid i\in I\}$ of [left ideals in S has an uper bound i S. Let $C=\bigcup_{ieI}C_i.$

We claim that $C$ is a [left] ideal. If $a,b\in C$ , then for some $i,j\varepsilon I$ ,ae $C_{i}$ and $h\varepsilon C_i$ Since ୧ is a chain, either $C_i\subset C_i$ or $C_i\subset C_i;$ say the latter.Hence $a,b\in C_i$ $C_i$ Ci .Since $C_i$ is a left ideal, $a-b\varepsilon C_i$ and ra ε $C_{i}$ for all $r\varepsilon R$ (if $C_i$ is an ideal ar e $C_i$ as well). Therefore, $a,b$ E $C$ imply $a-b$ and ra are in $C_i\subset C$ . Consequently, $C$ is a [left] ideal by Theorem 2.2. Since $A\subset C_i$ for every i, $A\subset\cup C_i=C$ .Since each $C_i$ is in S, $C_{i}\neq R$ for all i e I. Consequently, $1_R\notin C_i$ for every $i$ (otherwise $C_{i}=R]$ , whence $1_{R}\notin\bigcup C_{i}=C$ Therefore, $C\neq R$ and hence, $C\varepsilon S.$ Clearly $C$ is an upper bound of. the chain C. Thus the hypotheses of Zorn's Lemma are satisfied and hence S contains a maximalelement. But a maximal element of Sis obviously a maximal[left] ideal in $R$ that contains $A$ .

1

Theorem 2.19. 1fR is acommutatire ring such that $\mathbf{R}^{2}=\mathbf{R}$ (in particular if R has an identity), then every maximal ideal M in R is prine.

REMARK. The converse of Theorem 2.19 is false. For example, 0 is a prime ideal in $\mathbf{Z}$ , but not a maximal ideal. See also Exercise 9.

PROOF OF 2.19. Suppose ab e $M$ but a $\notin M$ and $b\notin M.$ Then each of the ideals $M+(a)$ and $M+(b)$ properly contains $M$ .By maximality $M+(a)=R=M+(b)$ Since $R$ is commutative and ab e $M$ , Theorem 2.5 implies that $(a)(b)\subset(ab)\subset M$ Therefore, $R=R^2=(M+(a))(M+(b))\subset M^2+(a)M+M(b)+(a)(b)\subset M$ This contradicts the fact that $M\neq R$ (since $M$ is maximal). Therefore, a e $M$ or $b\varepsilon M$ ,whence $M$ is prime by Theorem 2.15.

Maximal ideals, like prime ideals, may be characterized in terms of their quotient rings.

1

------------------------------------------------------------------



------------------------------------------------------------------

(iⅡ $R_{\mathrm{i}}$ is a ring with muliplication defined by $\{a_{i}\}_{i,I}\{b_{i}\}_{i,I}=\{a_{i}b_{i}\}_{i,I};$ iel (i)fR; hasanieiy sm f h $\prod_{i\in I}\mathbf{R}_{\mathrm{i}}$ has an

identity [resp. is commutative];

(ii) for each k e I the canonical projection $\pi _{\mathrm{k} }\nobreak {: } \prod _{i\in I}$ $\mathbf{R} _{\mathrm{i} }\to \mathbf{R} _{\mathrm{k} }$ given by $\{a_{\mathrm{i}}\}\vdash a_{\mathrm{k}}$ ,i an epimorphism of rings,. (iv) for each k e I the canonical injection $\iota_{\mathrm{k}}:\mathbf{R}_{\mathrm{k}}\rightarrow\prod_{i\in I}\mathbf{R}_{\mathrm{i}}$ gicen by $a_k\vdash\{a_i\}$

(where $a_{\mathrm{i}}=0$ for $i\neq k$ ),is a monomorphism ofrings

### PROOF. Exercise.

$\prod_{ieI}R_i$ R $R_i$ is calle the exteral diret produet o thefam o rins $\{R_{i}\mid i\in I\}$ If the index set is finite, say $I=\{1,\ldots,n\}$ , then we sometimes write $R_1\times R_2\times\cdots\times R_n$ instead of $\Pi_{R_i}$ If $\{R_{i}\mid i\in I\}$ is a family of rings and for each $i\varepsilon I,A_{i}$ Ai $A_i$ is an ideal in $R_{i}$, then it is

easy to see that $\prod_{i\in I}A_i$ is an idea in $\prod_{ieI}R_{i}.$ If $A_{i}=0$ for all $i\neq k$ ,then the ideal $\prod_{ieI}A_i$ is pecsly $\iota_k(A_k)$ If the inde set $I$ is fnite and each $R_{i}$ has an identity, then every ideal in $\prod_{i\in I}R_i$ is of the form $\prod_{ieI}A_i$ with $A_i$ an ideal in $R_{i}$ (Exercise 22).

Theorem 2.23. Let $\{ \mathbf{R} _{\mathrm{i} }\mid \mathbf{i} \varepsilon \mathbf{I} \}$ be a nonempty family of rings, S a ring and $\{ \varphi _{\mathrm{i} }: \mathcal{S} \to \mathbf{R} _{\mathrm{i} }\mid$ i e I} a family of homomorphisms ofrings. Then there is a unique homomorphism of rings $\varphi : \mathcal{S} \to \prod _{i\in I}\mathcal{R} _{\mathrm{i} }$ such hatr $\pi_{\mathrm{i}}\varphi=\varphi_{\mathrm{i}}$ for ll I. The ing $\prod_{i\in I}\mathbf{R}_{i}$ is uniquely dermined up to isomophisn by thisproprry,In oher words $\prod_{ieI}^{iel}\mathbf{R}_{i}$ is a product in the category of rings.

SKETCH OF PROOF. By Theorem I.8.2 there is a unique homomorphism of groups $\varphi:S\to\prod_{i\in I}R_{i}$ such that $\pi_{i}\varphi=\varphi_{i}$ for all i e I. Verify that $\varphi$ is also a ring homomorphism. Thuse $\prod_{i\in I}R_i$ is product in the categoryo rings Defhnition 1.7.2) and therefore determined up to isomorphism by Theorem I.7.3.

Theorem 2.24. Let $\mathbf{A}_1,\mathbf{A}_2$, .... $\mathbf{A}_{\mathrm{n}}$ be ideals in a ring R such that (i) $\mathbf{A}_{1}+\mathbf{A}_{2}+\cdots+$ $\mathbf{A_{n}}=\mathbf{R}$ and (ii) for each k( $(1\leq\mathbf{k}\leq\mathbf{n})$ $A_k$ $A_k$ $),\mathbf{A}_{k}\cap(\mathbf{A}_{1}+\cdots+\mathbf{A}_{k-1}+\mathbf{A}_{k+1}+\cdots+\mathbf{A}_{n})$ =0 . Then there is a ring isomorphism. $\mathbf{R}\cong\mathbf{A}_{1}\times\mathbf{A}_{2}\times\cdots\times\mathbf{A}_{n}$

PROOF. By the proof of Theorem I.8.6 the map $\varphi:A_1\times A_2\times\cdots\times A_n\to R$ given by $(a_1,\ldots,a_n)\vdash a_1+a_2+\cdots+a_n$ is an isomorphism of additive abeliar. groups. We need only verify that $\varphi$ is a ring homomorphism. Observe that if $i\neq j$ and $a_{i}\in A_{i}$, $a_{j}\in A_{j}$, then by (i) $a_{i}a_{j}\varepsilon A_{i}\cap A_{j}=0$ . Consequently, for all $a_{i},b_{i}\in A_{i}$

$$(a_1+a_2+\cdots+a_n)(b_1+b_2+\cdots+b_n)=a_1b_1+\cdots+a_nb_n,$$

------------------------------------------------------------------

If $R$ is a ring and $A_1,\ldots,A_n$ An $A_n$ are ideals in $R$ that satisfy the hypotheses of Theorem 2.24, then $R$ is said to be the (internal) direct product of the ideals $A_i$ . As in the case of groups, there is a distinction between internal and external direct products If a ring $R$ is the internal direct product of ideals $A_1,\ldots,A_n$, An $A_n.$ then each of the $A_i$ is actually an ideal contained in $R$ and $R$ is isomorphic to the external direct product. $A_1\times\cdots\times A_n$ . However, the external direct product $A_1\times\cdots\times A_n$ does not contain the $A_{i}$, but only isomorphic copies of them (namely the $\iota_i(A_i)$ — see Theorem 2.22). Since this distinction is unimportant in practice, the adjectives “internal" and “external' will be omitted whenever the context is clear and the following notation will be used.

NOTATION. We write $R=\prod A_i$ or $R=A_{1}\times A_{2}\times\cdots\times A_{n}$ to indicate that the ring $R$ is the internal direct product of its ideals $A_1,\ldots,A_n$

Other characterizations of finite direct products are given in Exercise 24. We close this section with a result that will be needed in Chapters VIlI and $IX$

Let $A$ be an ideal in a ring $R$ and $a,b\in R.$ . The element $a$ is said to be congruent to $b$ modulo $A$ (denoted) $a\equiv b$ (mod $A)$ ）if $a-b$ e .1.Thus

$$a\equiv b\:(\mathrm{mod}\:A)\:\Leftrightarrow\:a-b\varepsilon\:A\:\Leftrightarrow\:a+A=b+A.$$

Since $R/A$ is a ring by Theorem 2.7,

$$\begin{aligned}&a_{1}\equiv a_{2}\:(\mathrm{mod}\:A)\quad\mathrm{and}\quad b_{1}\equiv b_{2}\:(\mathrm{mod}\:A)\quad\Rightarrow\\&a_{1}+b_{1}\equiv a_{2}+b_{2}\:(\mathrm{mod}\:A)\quad\mathrm{and}\quad a_{1}b_{1}\equiv a_{2}b_{2}\:(\mathrm{mod}\:A).\end{aligned}$$

Theorem 2.25. (Chinese Remainder Theorem) Let A1, ...,. $\mathbf{A}_n$ be ideals in a ring R such that $\mathbf{R} ^{2}+ \mathbf{A} _{\mathrm{i} }= \mathbf{R}$ for all i and $\mathbf{A} _{\mathrm{i} }+ \mathbf{A} _{\mathrm{j} }= \mathbf{R}$ for all $i\neq$j . Ifbi, ..., $b_n$ ER, then there exists b e R such that.

$$\mathrm{b\equiv b_i\:(mod\:A_i)\quad(i=1,2,\ldots,n).}$$

Furthermore b is uniguely determined up to congruence modulo the ideal

$$\mathrm{A_1\cap A_2\cap\cdots\cap A_n.}$$

REMARK. If $R$ has an identity, then $R^{2}=R$ ，whence $R^{2}+A=R$ for every ideal $A$ of $R$

SKETCH OF PROOF OF 2.25. Since $A_{1}+A_{2}=R$ and $A_{1}+A_{3}=R$

$$\begin{aligned}R^{2}&=(A_{1}+A_{2})(A_{1}+A_{3})=A_{1}^{2}+A_{1}A_{3}+A_{2}A_{1}+A_{2}A_{3}\\&\subset A_{1}+A_{2}A_{3}\subset A_{1}+(A_{2}\cap A_{3}).\end{aligned}$$

Consequently, since $R=A_{1}+R^{2}$

$$R=A_1+R^2\subset A_1+(A_1+(A_2\cap A_3))=A_1+(A_2\cap A_3)\subset R.$$

Therefore,e $R=A_{1}+(A_{2}\cap A_{3})$ . Assume inductively that

$$R=A_1+(A_2\cap A_3\cap\cdots\cap A_{k-1}).$$

------------------------------------------------------------------

$$R^{2}=(A_{1}+(A_{2}\cap\cdots\cap A_{k-1}))(A_{1}+A_{k})\subset A_{1}+(A_{2}\cap A_{3}\cap\cdots\cap A_{k})$$
and hence

$$R=R^2+A_1\subset.A_1+(A_2\cap\cdots\cap A_k)\subset R.$$

Therefore, $R=A_{1}+(A_{2}\cap\ldots\cap A_{k})$ and the induction step is proved. Consequently, $R$ = $A_{1}+ ( A_{2}\cap \cdots \cap A_{n}) =$ $A_{1}+ ( \bigcap _{i\neq 1}A_{i})$ A similar argument shows that for each k = 1,2, ... , n, R = Ak + (M Ai). Consequently for each $k$ $k=1,2,\ldots,n,R=A_{k}+(\bigcap_{i\neq k}A_{i})$ there exist elements $a_k\varepsilon A_k$ and $r_k\in\bigcap_{i\neq k}A_i$ such that $b_{k}=a_{k}+r_{k}$ .Furthermore

$$r_k\equiv b_k\mathrm{~(mod~}A_k)\quad\mathrm{and}\quad r_k\equiv0\mathrm{~(mod~}A_i)\quad\mathrm{for}\quad i\neq k.$$

Let $b=r_{1}+r_{2}+\cdots+r_{n}$ and use the remarks preceding the theorem to verify that $b\equiv b_i$ b=bi $b\equiv b_i\left(\mathrm{mod}A_i\right)$ A $A_i$ for every i. Finally if $c\varepsilon R$ $R$ R is such that $c\equiv b_i$ (mod $A_i$ ) for every $i.$ then $b\equiv c$ b=c $b\equiv c\left(\mathrm{mod}A_{i}\right)$ $A_i$ Ai for each $i$ ,whence $b-c\in A_i$ Ai $A_i$ for all i. Therefore, $b-c\varepsilon\bigcap_{i=1}A_{i}$ and $b\equiv c\left(\mathrm{mod}\bigcap_{i=1}^nA_i\right).$

The Chinese Remainder Theorem is so named because it is a generalization of the following fact from elementary number theory, which was known to Chinese mathematicians in the first century A.D.

Corollary 2.26. Let $\mathbf{m}_1,\mathbf{m}_2,\ldots,\mathbf{m}_n$ be positive integers such that. $(\mathbf{m}_{\mathrm{i}},\mathbf{m}_{\mathrm{j}})=1$ for $i\neq\mathbf{j}$ i≠j i$\neq$j. $Ifb_{1}$, $b_{2}$, $\ldots$, $b_{n}$ bn $b_{\mathrm{n}}$ are any integers, then the system of congruences

$$\mathrm{x\equiv b_{1}\:(mod\:m_{1});\:x\equiv b_{2}\:(mod\:m_{2});\:\cdots;\:x\equiv b_{n}\:(mod\:m_{n})}$$

has an integral solution that is uniguely determined modulo $\mathbf{m}=\mathbf{m}_{1}\mathbf{m}_{2}\cdots\mathbf{m}_{n}$

SKETCH OF PROOF. Let $A_{\mathrm{i} }$ = $( m_{i})$ ; then . Ai = (m). Show thal $\bigcap_{i=1}^nA_i=(m)$ $(m_{i},m_{j})=1$ implies $A_{i}+A_{j}=\mathbf{Z}$ and apply Theorem 2.25.

Corollary 2.27. If Ai, .. . , $\mathbf{A}_{\mathrm{n}}$ are ideals in a ring $R$ , then there is a monomorphism. of rings

$$\theta:\mathbb{R}/(\mathbb{A}_1\cap\cdots\cap\mathbb{A}_n)\to\mathbb{R}/\mathbb{A}_1\times\mathbb{R}/\mathbb{A}_2\times\cdots\times\mathbb{R}/\mathbb{A}_n.$$

If $\mathbf{R} ^{2}+ \mathbf{A} _{\mathrm{i} }= \mathbf{R}$ for all i and $\mathbf{A} _{\mathrm{i} }+ \mathbf{A} _{\mathrm{j} }= \mathbf{R}$ for all $i\neq\mathbf{j}$, then $\theta$ is an isomor phism of rings.

SKETCH OF PROOF. By Theorem 2.23 the canonical epimorphisms $\pi_k:R\to$ $R/A_k(k=1,\ldots,n)$ induce a homomorphism of rings $\theta_1:R\to R/A_1\times\cdots\times R/A_n$ with $\theta_{1}(r)=(r+A_{1},\ldots,r+A_{n})$ . Clearly ker $\theta_{1}=A_{1}\cap\ldots\cap A_{n}$ . Therefore, $\theta_1$ induces a monomorphism of rings $\theta:R/(A_1\cap\cdots\cap A_n)\to R/A_1\times\cdots\times R/A_n$ (Theorem 2.9). The map $\theta$ need not be surjective (Exercise 26). However, if the hypotheses of Theorem 2.25 are satisfied and $(b_1+A_1,\ldots,b_n+A_n)\varepsilon R/A_1$ R/A1 $R/A_1$

------------------------------------------------------------------

$\times\cdots\times R/A_n$ , tien there exists $b\varepsilon R$ such that $b\equiv b_i$ (mod $A_i$ ) for all $i.$ Thus $\theta(b+\bigcap_{i}A_{i})=(b+A_{1},\ldots,b+A_{n})=(b_{1}+A_{1},\ldots,b_{n}+A_{n})$ $b_n+A_n)$ bn + An) whence $\theta$ is an epimorphism.

### EXERCISES

1. The set of all nilpotent elements in a commutative ring forms an ideal [see Exercise 1.12].

2. Let $I$ be an ideal in a commutative ring $R$ and let Rad $I=\{r\varepsilon R\mid r^{n}\in I$ for some $n_1^{[}$ . Show that Rad $I$ is an ideal.

3.If $R$ is a ring and ae $R$ ，then $J=\left\{r\varepsilon R\mid ra=0\right\}$ is aleft ideal and $K=\{r\varepsilon R\mid ar=0\}$ is a right ideal in $R$

4. If Iis a left ideal of $R$ ,then $A(I)=\{r\varepsilon R\mid rx=0$ for every $x\in I\}$ is an ideal in $R$

5. If Iis an ideal in a ring $R$ , let $[R:I]=\{r\varepsilon R\mid xr\varepsilon R\}$ for every $x\in R$ 1. Prove that $[R:I]$ is an ideal of $R$ which contains $I$

6. (a) The center of the ring $S$ of all $2\times2$ matrices over a feld $F$ consists of all matrices of the form $\begin{pmatrix}a&0\\0&a\end{pmatrix}$ (b) The center of $S$ is not an ideal in $S$

(c) What is the center of the ring of all $n\times n$ matrices over a division ring?

7. (a) A ring $R$ with identity is a division ring if and only if $R$ has no proper left ideals. [Proposition I.1.3 may be helpful.]

(b) If S is a ring (possibly without identity) with no proper left ideals, then either $S^2=0$ or $S$ is a division ring. [Hinr: show that $\{a\varepsilon S|Sa=0\}$ is an ideal. If $cd\neq0$ ,show that $\{r\varepsilon S\mid rd=0\}=0$ .Findee $S$ such that $ed=d$ andshow that $e$ is a (two-sided) identity.)

8. Let $R$ be a ring with identity and $S$ the ring of all $n\times n$ matrices over $R.J$ is an idealof $S$ if and only if $J$ is the ring of all $n\times n$ matrices over $I$ for someideal in $R$ . [Hinr: Given $J$ ,let I be the set of all those elements of $R$ that appear as the row1-column 1 entry of some matrix in $J.$ Use the matrices. $E_{r,s}$ where $1\leq r\leq n$ $1\leq s\leq n$ and $E_{r,s}$ has $1_{R}$ as the row $r$ -column $s$ entry and O elsewhere. Observe that for a matrix $A=(a_{ij}),E_{p,r}AE_{s,q}$ is the matrix with $a_{rs}$ in the row $P$ -column 4 entry and O elsewhere.]

9. Let $S$ be the ring of all $n\times n$ matrices over a division ring $D$ (a) $S$ has no proper ideals (that is, O is a maximal ideal). [Hint: apply Exercise

8 or argue directly, using the matrices $E_{r,s}$ mentioned there.] (b) $S$ has zero divisors. Consequently, (i) $S\cong S/0$ is not a division ring and (i) 0 is a prime ideal which does not satisfy condition (1) of Theorem 2.15.

10.(a) Show that $\mathbf{Z}$ is a principal ideal ring [see Theorem I.3.1]. (b)Every homomorphic image of a principal ideal ring is also a principal ideal

ring. (c) $Z_{m}$ is a principal ideal ring for every $m>0$

------------------------------------------------------------------

11.If $N$ is the ideal of all nilpotent elements in a commutative ring $R$ (see Exercise 1), then $R/N$ is a ring with no nonzero nilpotent elements.

12. Let $R$ be a ring without identity and with no zero divisors. Let $S$ be thering whose additive group is $R\times\mathbf{Z}$ as in the proof of Theorem 1.10. Let $A$ = $\{ ( r, n)$ $\varepsilon$ $S$ | $rx+ nx$ = 0 for every $x\varepsilon R|$ (a) $A$ is an ideal in $S$ (b) $S/A$ has an identity and contains a subring isomorphic to $R$ (c) $S/A$ has no zero divisors.

13. Let $f:R\to S$ be a homomorphism of rings, I an ideal in $R$ , and $J$ an ideal in $S$ (a) $f^{-1}(J)$ is an ideal in $R$ that contains Ker $f$ (b) If $f$ is an epimorphism, then $f(I)$ is an ideal in $S$ . If $f$ is not sur jective, $f(I)$ need not be an ideal in $S$

14. If $P$ is an ideal in a not necessarily commutative ring $R$ , then the following conditions are equivalent. (a) $P$ is a prime ideal.

(b) $Ifr,s\varepsilon R$ $R$ R are such that $rRs\subset P$ , then $r\varepsilon P$ P $P$ or s e P. [Hint: If(a) holds and $rRs\subset P$ ,then $(RrR)(RsR)\subset P$ ,whence $RrR\subset P$ or $RsR\subset P$ ,say $RrR\subset P$ If $A=(r)$ ,then $A^3\subset RrR\subset P$ , whence r e $A\subset P$ (c) If $(r)$ and $(s)$ are principal ideals of $R$ such that $(r)(s)\subset P$ , then re $P$ Or $s\varepsilon P$ P $P$ (d) If $U$ and $V$ are right ideals in $R$ such that $UV\subset P$ , then $U\subset P$ or $V\subset P$ (e) If $U$ and $V$ are left ideals in $R$ such that $UV\subset P$ , then $U\subset P$ or $V\subset P$

15. The set consisting of zero and all zero divisors in a commutative ring with identity contains at least one prime ideal.

16.Let $R$ be a commutative ring with identity and suppose that the ideal $A$ of $R$ is contained in a finite union of prime ideals $P_1$ P1 $P_1\cup\ldots\cup P_n$ Pn $P_n$ . Show that $A\subset P_i$ for some i. [Hint: otherwise one may assume that $A\cap P_i\not\subset\bigcup_{i\neq j}P_i$ for all $j.$ Let $a_{j}\varepsilon(A\cap P_{i})-(\bigcup_{i\neq j}P_{i})$ Then $a_{1}+a_{2}a_{3}\cdots a_{n}$ is in $A$ but not in $P_1\cup\cdots\cup P_n.]$

17. Let $f:R\to S$ be an epimorphism of rings with kernel $K$

(a) If $P$ is a prime ideal in $R$ that contains $K$ , then $f(P)$ is a prime ideal in $S$ [see Exercise 13]. (b) If $Q$ is a prime ideal in $S$ ,then $f^{-1}(Q)$ is a prime ideal in $R$ that contains $K$ (c) There is a one-to-one correspondence between the set of all prime ideals in $R$ that contain $K$ and the set of all prime ideals in $S$ , given by $P\vdash f(P)$ (d) If Iis an ideal in a ring $R$ , then every prime ideal in $R/I$ is of the form $P/I$ where $P$ is a prime ideal in $R$ that contains $I$

18. An ideal $M\neq R$ in a commutative ring $R$ with identityis maximal if and only if for every $r\varepsilon R-M$ , there exists $x\varepsilon R$ such that $\mathbf{1}_{R}-rx\in M$

19. The ring $E$ of even integers contains a maximal ideal $M$ such that $E/M$ is not a field.

20. In the ring $\mathbf{Z}$ the following conditions on a nonzero ideal I are equivalent: (i) Iis prime; (ii) $I$ is maximal; (i) $I=(p)$ with $p$ prime.

21. Determine all prime and maximal ideals in the ring $Z_m$

------------------------------------------------------------------

22.(a) If $R_{1},\ldots,R_{n}$ $R_n$ Rn are rings with identity and $I$ is an ideal in $R_1\times\cdots\times R_n$ ,then $I=A_{1}\times\cdots\times A_{m}$ , where each. $A_i$ is an ideal in $R_i$ . [Hint: Given I let $A_{k}=\pi_{k}(I)$ where $\pi_k:R_1\times\cdots\times R_n\to R_k$ is the canonical epimorphism.] (b) Show that the conclusion of (a) need not hold if the rings $R_i$ do not have identities.

23. An element $e$ in a ring $R$ is said to be idempotent if $e^{2}=e$ .An element of the center of the ring $R$ is said to be central. If $e$ is a central idempotent in a ring $R$ with identity, then (a) $1_R-e$ is a central idempotent;

(b) $eR$ and $(1_{R}-e)R$ are ideals in $R$ such that $R=eR\times(1_{R}-e)R$

24. Idempotent elements $e_1,\ldots,e_n$ in a ring $R$ [see Exercise 23] are said to be orthogonal if $e_ie_j=0$ for $i\neq j$ If $R,R_{1},\ldots,R_{n}$ are rings with identity, then the following conditions are equivalent : (a) $R\cong R_1\times\cdots\times R_n$

(b) $R$ contains a set of orthogonal central idempotents [Exercise 23] $\{e_1,\ldots,e_n\}$ such that $e_{1}+e_{2}+\cdots+e_{n}=1_{R}$ and $e_iR\cong R_i$ for each $i$ (c) $R$ is the internal direct product $R=A_{1}\times\cdots\times A_{n}$ where each $A_i$ is an ideal of $R$ such that $A_{i}\cong R_{i}$ $[Hint:(\mathfrak{a})\Rightarrow(\mathfrak{b})$ The elements $\bar{e}_{1}=(1_{R_{1}},0,\ldots,0)$ $\bar{e}_{2}=(0,1_{R_{2}},0,\ldots,0),\ldots,\bar{e}_{n}$ $=(0,\ldots,0,1_{R_n})$ are orthogonal central idempotents in $S=R_{1}\times\cdots\times R_{n}$ such that $\bar{e}_{1}+\cdots+\bar{e}_{n}=1_{S}$ and $\bar{e}_iS\cong R_i$ $(\mathbf{b})\Longrightarrow($c) Note that $A_{k}=e_{k}R$ is the principal ideal $(e_k)$ in $R$ and that $e_kR$ is itself a ring with identity $e_k$ ]

25. If $m\varepsilon Z$ has a prime decomposition $m=p_{1}^{k_{1}}\cdots p_{t}^{k_{t}}(k_{i}>0;p_{i})$ Pi $p_i$ distinct primes), then there is an isomorphism of rings $Z_m\cong Z_{p_1}^{k_1}\times\cdots\times Z_{p_t}^{k_l}$ [Hint: Corollary 2.27.]

26. If $R=\mathbf{Z}$, $A_{1}=(6)$ and $A_2=(4)$ , then the map 0 : R/A1 $\theta:R/A_1$ $\theta:R/A_1\cap A_2\to R/A_1\times R/A_2$ of Corollary 2.27 is not surjective.

## 3. FACTORIZATION IN COMMUTATIVE RINGS

In this section we extend the concepts of divisibility, greatest common divisor and primein thering of integers to arbitrary commutative rings and study those integral domains in which an analogue of the Fundamental Theorem of Arithmetic (Introduction, Theorem 6.7) holds. The chief result is that every principal ideal domain is such a unique factorization domain. In addition we study those commutative rings in which an analogue of the division algorithm is valid (Euclidean rings)

Definition 3.1.A nonzero element a of a commutative ring R is said to divide an element b e R (notation: a | b) ifthere exists x e R such that ax = = $:=\mathbf{b}.$ Elements a,b of R are said to be associates ifa I b and b I a.

------------------------------------------------------------------



------------------------------------------------------------------

$c=dx$ .Since $c$ is irreducible either dis a unit(whence $(d)=R)$ or $x$ is a unit (whence $(c)=(d)$ by Theorem 3.2). Hence (c) is maximal in $S$ . Conversely if $(c)$ is maximal in $S$ , then $c$ is a (nonzero) nonunit in $R$ by Theorem 3.2. If $c=ab$ , then $(c)\subset(a)$ whence $(c)=(a)$ or $(a)=R.$ If $(a)=R$, then $a$ is a unit (Theorem 3.2). If $(c)=(a)$ then $a=cy$ and hence $c=ab=cyb$ Since $R$ is an integral domain $1=yb$ ,whence $b$ is a unit. Therefore, $C$ is irreducible. (ii) If $p=ab$ , then $p\mid a$ or $p\mid b$ ; say $p\mid a$ Then $px=a$ and $p=ab=pxb$ , which implies that $1=xb$ . Therefore, $b$ is a unit. (iv) If $p$ is irreducible, use (i), Theorem 2.19 and (i) to show that $p$ is prime. (v) If $c$ is irreducible and $d$ is an associate of $c$ , then $c=du$ with ue $R$ a unit (Theorem 3.2). If $d=ab$ , then $c=abu$ ,whence $a$ is a unit or $bu$ is a unit. But if $bu$ is a unit, so is $b$ Hence $d$ is irreducible. (vi) If $c$ is irreducible and $a\mid c$, then $(c)\subset(a)$ ，whence $(c)=(a)$ or $(a)=R$ by (i). Therefore, $a$ is either an associate of $c$ Or a unit by Theorem 3.2.

Wehave nowdeveloped the analogues in an arbitraryintegraldomain of the concepts of divisibility andprime integers in thering Z.Recall that every element in $\mathbf{Z}$ is a product of a finite number of irreducible elements (prime integers or theii regatives) according to the Fundamental Theorem of Arithmetic (Introduction Theorem 6.7). Furthermore this factorization is essentially unique (except for the order of the irreducible factors). Conseq uently, $\mathbf{Z}$ is an example of:

Definition 3.5. An integral domain R is a unique factorization domain provided that :

(i) every nonzero nonunit element a of R can be written $\mathbf{a}=c_{1}\mathbf{C}_{2}\cdots\mathbf{C}_{n}$ ,with $c_1,\ldots,c_n$ irreducible (i) $If$ a $= c_1c_2\cdots c_n$ and $\mathbf{a} = \mathbf{d} _{1}\mathbf{d} _{2}\cdots \mathbf{d} _{\mathrm{rn}}$ ( $c_i$, $d_i$ irreducible), then $\mathbf{n}=\mathbf{m}$ andfor some permutation $\sigma$ of $\{1,2,\ldots,n\}$ , $c_i$ and $\mathrm{d}_{\sigma(\mathrm{i})}$ are associates for every i.

REMARK. Every irreducible element in a unique factorization domain is necessarily prime by (i). Consequently, irreducible and prime elements coincide by Theorem 3.4 (ii).

Definition 3.5 is nontrivial in the sense that there are integral domains in which every element is a finite product of irreducible elements, but this factorization is not unique (that is, Definition 3.5 (i) fails to hold); see Exercise 4. Indeed one of the historical reasons for introducing the concept of ideal was to obtain some sort of unique factorization theorems (for ideals) in rings of algebraic integers in which factorization of elements was not necessarily unique; see Chapter VIlI. In view of the relationship between irreducible elements and principal ideals

(Theorein 3.4) and the example of the integers, it seems plausible that every principal ideal domain is a unique factorization domain. In order to prove that this is indeed the case we need:

------------------------------------------------------------------

PROOF. Let $A=\bigcup_{i\geq1}\left(a_{i}\right)$ We claim that $A$ is an ideal If $b,c\in A$ , then $b\in(a_i)$ and $c\in(a_i)$ . Either $i\leq j$ or $i\geq j$ ; say $i\geq j$ . Consequently $(a_j)\subset(a_i)$ and $b,c\in(a_i)$ Since $(a_i)$ is an ideal $b-c\in(a_i)\subset A$ .Similarly if $r\varepsilon R$ and $b\varepsilon A$ , then $b\varepsilon(a_i)$, whence $rb\varepsilon(a_i)\subset A$ and $r\in(a_{i})\subset A$ . Therefore, $A$ is an ideal by Theorem 2.2. By hypothesis $A$ is principal, say $A=(a)$ . Since a E $A=\bigcup(a_i)$ ,ae $(a_n)$ for some $n$ By Definition $2.4\left(a\right)\subset\left(a_n\right)$ . Therefore, for every $j\geq n$ ， $(a)\subset(a_n)\subset(a_j)\subset A=$ $(a)$ ,whence $(a_j)=(a_n)$ .■

Theorem 3.7. Every principal ideal domain R is a unigue factorization domain

REMARK. The converse of Theorem 3.7 is false. For example the polynomial ring $\mathbf{Z}[x]$ can be shown to be a unique factorization domain (Theorem 6.14 below), but $\mathbf{Z}[x]$ is not a principal ideal domain (Exercise 6.1). :

SKETCH OF PROOF OF 3.7. Let $S$ be the set of all nonzero nonunit elements of $R$ which cannot be factored as a finite product of irreducible elements We shall first show that $S$ is empty, whence every nonzero nonunit element of. $R$ has at least one factorization as a finite product of irreducibles. Suppose $S$ is not empty and a ε S. Then $(a)$ is a proper ideal by Theorem 3.2(iv) and is contained in a maximal ideal $(c)$ by Theorem 2.18. The element c E $R$ is irreducible by Theorem 3.4(i). Since $(a)\subset(c)$, c divides a. Therefore, it is possible to choose for each a e S an irreducible divisor $c_a$ of $a$ (Axiom of Choice).Since $R$ is an integral domain, $c_a$ uniquely deter- mines a nonzero. Xa $x_a$ $x_a\in R$ R $R$ such that $c_ax_a=a$ . We claim that $x_a\in S.$ For if $x_a$ were a unit, then $a=c_{a}x_{a}$ would be irreducible by Theorems 3.2(vi) and 3.4(v). If $x_a$ is a nonunit and not in $S$ ,then $x_{a}$ has a factorization as a product of irreducibles, whence $a$ also does. Since $a\varepsilon S$ this is a contradiction. Hence $x_a\varepsilon S$ . Furthermore, we claim that the ideal $(a)$ is properly contained in the ideal $(x_a)$ .Since $x_a\mid a,(a)\subset(x_a)$ by Theorem 3.2(i). But $(a)=(x_{a})$ implies that $x_{a}=ay$ for some $y\varepsilon R$ ，whence $a=x_{a}c_{a}=ayc_{a}$ and $1=yc_{a}$ . This contradicts the fact that $c_a$ is irreducible (and hence a nonunit). Therefore $(a)\subseteq(x_a)$

The preceding remarks show that the function $f:\mathcal{S}\to\mathcal{S}$ given by $f(a)=x_a$ is well defined. By the Recursion Theorem 6.2 of the Introduction (with. $f=f_n$ for all $n$ there exists a function $\varphi:\mathbb{N}\to S$ such that

$$\varphi(0)=a\quad\mathrm{and}\quad\varphi(n+1)=f(\varphi(n))=x_{\varphi(n)}\:(n\geq0).$$

If we denote $\varphi(n)$ by $a_n$ , we thus have a sequence ofelements of $S{:}a,a_{1},a_{2}$, ... such that

$$a_{1}=x_{a};a_{2}=x_{a_{1}};\cdots;a_{n+1}=x_{a_{n}};\cdots.$$

Consequently,the preceding paragraph shows that there is an ascending chain of ideals

$$(a)\subsetneq(a_1)\subsetneq(a_2)\subsetneq(a_3)\subsetneq\cdots,$$

contradicting Lemma 3.6. Therefore, the set $S$ must be empty, whence every nonzerc nonunit element in $R$ has a factorization as a finite product of irreducibles

------------------------------------------------------------------

Finally if $c_1c_2\cdots c_n=a=d_1d_2\cdots d_m$ $(c_i,d_i$ irreducible), then $c_1$ divides some $d_i$ by Theorem 3.4(iv). Since $c_{\mathrm{I}}$ is a nonunit, it must be an associate of $d_i$ by Theorem 3.4 (vi). The proof of uniqueness is now completed bya routine inductive argument. 

Several important integral domains that we shall meet frequently have certain properties not shared by all integral domains.

Definition 3.8. Let N be the set of nonnegatice integers and R a commutative ring R is a Euclidean ring if there is a function $\varphi:\mathbf{R}-\left\{0\right\}\to\mathbf{N}$ such that:

(i) ifa,b ε R and $ab\neq0$ ,then $\varphi($a$)\leq\varphi($ab) (ii) ifa,be R and $\mathbf{b\neq0}$ ,then there exist q,r eRsuchthat $\mathbf{a}=\mathbf{qb}+\mathbf{r}with$ r=0 r=0 $r=0$ or $r\neq0$ and $\varphi($r$)<\varphi($b) A Euclidean ing which is an integral domain is called a Euclidean domain

EXAMPLE. The ring $\mathbf{Z}$ of integers with $\varphi(x)=|x|$ is a Euclidean domain.

EXAMPLE. If $F$ is a feld, let $\varphi(x)=1$ for all $x\in F,x\neq0$ . Then $F$ is a Euclidean domain.

EXAMPLE. If $F$ is a field, then the ring of polynomials in one variable $F[x]$ is a Euclidean domain with $\varphi(f)=$ degree of $f;$ see Corollary 6.4 below.

EXAMPLE. Let $Z[i]$ be thefollowing subset of the complex numbers $\mathbf{Z}[i]=\left\{a+bi|a,b\varepsilon\mathbf{Z}|.\mathbf{Z}[i]\right.$ is an integral domain called the domain of Gaussian integers. Defne $\varphi(a+bi)=a^{2}+b^{2}$ . Clearly $\varphi(a+bi)\neq0$ if $a+bi\neq0$ ; it is also easy to show that condition (i) of the definition is satisfied. The proof that 4 satisfies condition (i) is left to the reader (Exercise 6).

Theorem 3.9. Every Euclidean ring R is a principal ideal ring with identity. Conseyuently every Euclidean domain is a unigue factorization domain.

REMARK. The converse of Theorem 3.9 is false since there are principal ideal domains that are not Euclidean domains (Exercise 8).

PROOF OF 3.9.If $I$ is a nonzero ideal in $R$ ,choose aε I such that $\varphi(a)$ is the least integer in the set of nonnegative integers $|\varphi(x)|x\neq0;x\in I|$ . If $b\varepsilon I$ ,then $b=qa+r$ with $r=0$ r=0 $r=0$ or $r\neq0$ and $\varphi(r)<\varphi(a)$ . Since $b$ ε Iand ya e I, $r$ is necessarily in I.Since $\varphi(r)<\varphi(a)$ would contradict thechoice of $a$ ,we must have $r=0$ ,whence $b=qa$ . Consequently, by Theorem $2.5I\subset Ra\subset(a)\subset I.$ . Therefore $I=Ra=(a)$ and $R$ is a principal ideal ring. Since $R$ itself is an ideal, $R=Ra$ for some a e R. Consequently, $a=ea=ae$ for

some $e\varepsilon R$ .If $b\in R=Ra$ ，then $b=xa$ for some $x\varepsilon R$ . Therefore, $be=(xa)e$ $=x(ae)=xa=b$ ，whence $e$ is a multiplicative identity element for $R$ . The last statement of the theorem is now an immediate consequence of Theorem3.7.

We close this section with some further observations on divisibility that will be used occasionally in the sequel (Sections 5, 6 and IV.6).

------------------------------------------------------------------

Definition 3.10. Let $X$ be a nonempty subset ofa commutative ring R.An element d e R is a greatest common divisor of $X$ provided.

(i) d | a for all a εX; (i c la for all a e $\textbf{X }\Rightarrow$ c|d

Greatest common divisors do not always exist. For example, in the ring $E$ of even integers 2 has no divisors at all, whence 2 and 4 have no (greatest) common divisor. Even when a greatest common divisor of $a_1,\ldots,a_n$ exists, it need not be unique. However, any two greatest common divisors of $X$ are clearly associates by (ii). Furthermore any associate of a greatest common divisor of $X$ is easily seen to be a greatest common divisor of $X$ . If $R$ has an identity and $a_1,a_2,\ldots,a_n$ an $a_n$ have $l_{R}$ as a greatest common divisor, then $a_1,a_2,\ldots a_n$ are said to be relatively prime.

Theorem 3.11. Let $a_1$, $\ldots$, $a_n$ be elements of acommutative ring R with identity.

(i) de R is a greatest common divisor of $\{\mathbf{a}_1,\ldots,\mathbf{a}_n\}$ such that $\mathbf{d}=\mathbf{r_{1}a_{1}}$ $+\cdots+r_na_n$ for some $r_i\varepsilon R$ ifand only $if($d)=(a$_1)+($a$_2)+\cdots+($a$_n)$ (ii) if R is a principal ideal ring, then a greatest common divisor $ofa_{1}$, $\ldots$, $a_{n}$ exists and every one is of the form. $r_{1}a_{1}+\cdots+r_{n}a_{n}\left(r_{i}\varepsilon R\right)$ (ili) if R is a unique factorization domain, then there exists a greatest common divisor ofai,..., an

REMARK. Theorem 3.11(i) does not state that every greatest common divisor of $a_{\mathrm{l}},\ldots,a_{n}$ is expressible as a linear combination of $a_1,\ldots,a_n$ . In general this is not the case (Exercise 6.15).See also Exercise 12.

SKETCH OF PROOF OF 3.11. (i) Use Definition 3.10 and Theorem 2.5. (ii)follows from (i). (ii)Each $a_i$ has a factorization: $a_{i}=c_{1}^{m_{i1}}c_{2}^{m_{i2}}\cdots c_{i}^{m_{i}}$with$c_1,\ldots,c_{i}$ distinct irreducible elements and each $m_{ij}\geq0$ .Show that $d=c_{1}^{k_{1}}C_{2}^{k_{2}}\cdots c_{l}^{k_{l}}$ is a greatest common divisor of $a_{1},\ldots,a_{n}$ ,where $k_{j}=\min$ $\{m_{1j},m_{2j},m_{3j},\ldots,m_{nj}\}$ .

### EXERCISES

1.A nonzero ideal in a principal ideal domain is maximal if and only if it is prime.

2. An integral domain $R$ is a unique factorization domain if and only if every nonzero prime ideal in $R$ contains a nonzero principal ideal that is prime.

3. Let $R$ be the subring $\{a+b\sqrt{\mathbf{i}0}\mid a,b\in\mathbf{Z}\}$ of the field of real numbers (a) The map $N:R\to\mathbf{Z}$ given by $a+b\sqrt{10}\mapsto(a+b\sqrt{10})(a-b\sqrt{10})$ $=a^{2}-10b^{2}$ is such that $N(uv)=N(u)N(v)$ for all u,v e $R$ and $N(u)=0$ if and only if $u=0$ (b) $u$ is a unit in $R$ if and only if $N(u)=\pm1$ (c) 2, 3, $4+\sqrt{10}$ and $4-\sqrt{10}$ are irreducible elements of $R$ (d) $2,3,4+\sqrt{10}$ and $4-{\tilde{V}0}$ are not prime elements of . $R.$ $[ Hint: 3\cdot 2= 6$ $=(4+\sqrt{10})(4-\sqrt{10}).$

4. Show that in the integral domain of Exercise 3 every element can be factored into a product of irreducibles, but this factorization need not be unique (in the sense of Definition 3.5 (i)).

------------------------------------------------------------------



------------------------------------------------------------------

Let $r_0=b$ and let $n$ be the least integer such that $r_{n+1}=0$ (such an $n$ exists since the $\varphi(r_k)$ form a strictly decreasing sequence of nonnegative integers). Show that $r_n$ is the greatest common divisor $a$ and $b$

## 4. RINGS OF QUOTIENTS AND LOCALIZATION

In the firstpart of this section the familiar construction of the fiela of rational numbers from the ring of integers is considerably generalized. The rings of quotients so constructed from any commutative ring are characterized by a universal mapping property (Theorem 4.5). The last part of this section, which is referred to only occasionally in the sequel, deals with the(prime)ideal structure of rings of quotients and introduces localization at a prime ideal.

Definition 4.1. A nonempty subset S of a ring $R$ is multiplicative prouided that

a,bεS $\Longrightarrow$ ab e S.

EXAMPLES. The set $S$ of all elements in a nonzero ring with identity that are not zero divisors is multiplicative. In particular, the set of all nonzero elements in an integral domain is multiplicative.The set of units in any ring with identity is a multiplicative set. If $P$ is a prime ideal in a commutative ring $R$ , then both $P$ and $S=R-P$ are multiplicative sets by Theorem 2.15. The motivation for what follows may be seen most easily in the ring $\mathbf{Z}$ of integers

and the field $\mathbf{Q}$ of rational numbers. The set $S$ of all nonzero integers is clearly a multiplicative subset of $\mathbf{Z}.$ Intuitively the field $\mathbf{Q}$ is thought of as consisting of all fractionse $a/b$ with $a\varepsilon Z$ and $b\varepsilon S$ , subject to the requirement

$$a/b=c/d\:\Leftrightarrow\:ad=bc\:(\mathrm{or}\:ad-bc=0).$$

More precisely, $\mathbf{Q}$ may be constructed as follows (details of the proof will be supplied later). The relation on the set $\mathbf{Z}\times\mathbf{S}$ defined by

$$\begin{matrix}(a,b)\sim(c,d)&\Leftrightarrow&ad-bc=0\end{matrix}$$

is easily seen to be an equivalence relation. $\mathbf{Q}$ is defined to be the set of equivalence. classes of $\mathbf{Z}\times\mathbf{S}$ under this equivalence relation. The equivalence class of. $(a,b)$ is denoted $a/b$ and addition and multiplication are defined in the usual way. One verifies that these operations are well defined and that $\mathbf{Q}$ is a field. The map $\mathbf{Z}\to\mathbf{Q}$ given by $a\mapsto a/1$ is easilyseen to be amonomorphism (embedding) We shall now extend the construction just outlined to an arbitrary multiplicative

subset of any commutative ring $R$ (possibly without identity). We shall construct a commutative ring $S^{-1}R$ with identity and a homomorphism $\varphi_{S}:R\to S^{-1}R$ . If $S$ is the set of all nonzero elements in an integral domain $R$ , then $S^{-1}R$ will be a field $(S^{-1}R=\mathbf{Q}$ if $R=\mathbf{Z}$ and $\varphi s$ will be a monomorphism embedding $R$ in $S^{-1}R$

Theorem 4.2. Let S be a multiplicative subset of a commutative ring R. The relation defined on the set $\mathbf{R}\times\mathbf{S}by$

$$\mathrm{(r,s)\sim(r',s')~\Leftrightarrow~s_1(rs'-r's)=0}$$
for some SieS

1

------------------------------------------------------------------



------------------------------------------------------------------

The ring $S^{-1}R$ in Theorem 4.3 is called the ring of quotients or ring of fractions or quotient ring of $R$ by $S$ . An important special case occurs when $S$ is the set of all nonzero elements in an integral domain $R$ . Then $S^{-1}R$ is a field (Theorem 4.3(iii)) which is called the quotient field of the integral domain $R$ . Thus if $R=\mathbf{Z}$ ,the quotient field is precisely the feld $\mathbf{Q}$ of rational numbers. More generally suppose $R$ is any nonzero commutative ring and $S$ is the set of all nonzero elements of $R$ that are not zero divisors. If $S$ is nonempty (as is always the case if $R$ has an identity), then $S^{-1}R$ is called the complete (or full) ring ofquotients (or fractions) of the ring R.s Theorem 4.3 (ii) may be rephrased: if a nonzero ring $R$ has no zero divisors, then the complete ring of quotients of $R$ is a feld.Clearly the complete ring of quotients of an integral domain is just its quotient feld. If $\varphi:\mathbf{Z}\to\mathbf{Q}$ is the map given by $n\vdash n/1$ , then 4 is clearly a monomorphism

that embeds $\mathbf{Z}$ in Q. Furthermore, for every nonzero $n$ $\varphi(n)$ is a unit in Q. More generally, we have:

Theorem 4.4. Let S be amultiplicative subset ofa commutative ring $R$

(i) The map $\varphi _{\mathrm{S} }: \mathbf{R} \to \mathbf{S} ^{- 1}\mathbf{R}$ given by rhers/s (for anyse S)is a well-defined homomorphism of rings such that. $\varphi_{\mathrm{S}}($s) is a unit in $S^{-1}R$ for ecery seS

(i) $If0\notin\mathbf{S}$ and S contains no zero divisors,then 45 is a monomorphism. In par-. ticular, any integral donain may be embedded in its quotient field. (ii)IfR has an identity and S consists ofunits,then $\varphi_\mathrm{S}$ is an isomorphism. In par-. ticular, the complete ring o fquotients ( = quotient field) of a field F is isomorphic to F

SKETCH OF PROOF. (i) If $s,s'\varepsilon S$ , then $rs/s=rs^{\prime}/s^{\prime}$ , whence $\varphi_{S}$ is well defined. Verify that $\varphi_\mathrm{s}$ is a ring homomorphism and that for each s e S, $s/s^2\varepsilon S^{-1}R$ is the multiplicative inverse of $s^2/s=\varphi_S(s)$ . (ii) If $\varphi_s(r)=rs/s=0$ in $S^{-1}R$ , then $rs/s=0/s$ ,whence $rs^2s_1=0$ for some $s_1\varepsilon S$ .Since $s^2s_1\varepsilon S$ $s^2s_1\neq0$ . Since $S$ has no zero divisors, we must have $r=0$ . (ii) $\varphi s$ is a monomorphism by (i). If $r/s\in S^{-1}R$ with $s$ a unit in $R$ , then $r/s=\varphi_{S}(rs^{-1})$ ，whence $\varphi_{\mathbf{s}}$ is an epimorphism.

In view of Theorem 4.4 (ii) it is customary to identify an integral domain $R$ with its image under $\varphi_{\mathrm{S}}$ and to consider $R$ as a subring of its quotient field. Since $1_R\varepsilon S$ in this case, $r\varepsilon R$ $R$ R is thus identifed with $r/1_{R}\varepsilon S^{-1}R$

The next theorem shows that rings of quotients may be completely characterizec by a universal mapping property. This theorem is sometimes used as a definition of thering of quotients.

Theorem 4.5. Let S be a multiplicatice subset of a commutative ring R and let T be any coininutative ring with identity. $If$f$:\mathbf{R}\to\mathbf{T}$ is ahomomorphism ofrings such that f(s) is a unit in T for all s e S,then there exists a unique homomorphism ofrings $\bar{\mathbf{f}}:\mathcal{S}^{-1}\mathbf{R}\to\mathcal{T}$ such that $\tilde{\mathbf{f} } \varphi _{\mathrm{S} }= \mathbf{f} .$ The ring $S^{-1}R$ is completely determined (up to iso morphism) by this property.

SKETCH OF PROOF. Verify that the map $\bar{f}:S^{-1}R\to T$ given by $\bar{f}(r/s)$ $=f(r)f(s)^{-1}$ is a well-defined homomorphism of rings such that $\bar{f}_{\varphi_{S}}=f.$ If

------------------------------------------------------------------

$g:S^{-1}R\to T$ is another homomorphism such that $g\varphi_{S}=f$, then for every $s\varepsilon S$ $g(\varphi_s(s))$ is a unit in $T$ . Consequently, $g(\varphi_{S}(s)^{-1})=g(\varphi_{S}(s))^{-1}$ for every $s\varepsilon S$ by Exercise 1.15. Now for each s e S, $\varphi_{S}(s)=s^{2}/s$ ,whence $\varphi_{s}(s)^{-1}=s/s^{2}\varepsilon S^{-1}R$ .Thus for each $r/s\in S^{-1}R$

$$\begin{aligned}
g(r/s)& =g(\varphi_{S}(r)\varphi_{S}(s)^{-1})=g(\varphi_{S}(r))g(\varphi_{S}(s)^{-1})=g(\varphi_{S}(r))g(\varphi_{S}(s))^{-1} \\
&=\:f(r)\:f(s)^{-1}=\:\overline{f}(r/s). \\
\text{一}
\end{aligned}$$
Therefore, $\bar{f}=g$

To prove the last statement of the theorem let $\mathbb{C}$ be the category whose objects

are all $(f,T)$ ,where $T$ is a commutative ring with identity and $f:R\to T$ a homomorphism of rings such that $f(s)$ is a unit in $T$ for every $s\varepsilon S$ . Define a morphism in ୧ from $(f_1,T_1)$ to $(f_2,T_2)$ to be a homomorphism of rings $g:T_1\to T_2$ such that $gf_{1}=f_{2}$ Verify that ୧ is a category and that a morphism $g$ in $\mathcal{C}\left(f_1,T_1\right)\to\left(f_2,T_2\right)$ is an equiv. alence if and only if $g:T_1\to T_2$ is an isomorphism of rings. The preceding paragraph shows that $(\varphi_{S,S^{-1}R})$ is a universal object in the category ୧ ,whence $S^{-1}R$ is completely determined up to isomorphism by Theorem I.7.10.

Corollary 4.6.LetR be an integral domain considered as a subring of its quotient field F. If E is a field and f : $\mathbf{R}\to\mathbf{E}$ a monomorphism of rings, then there is a unigue monomorphism offields f : $F\to\mathbb{E}$ such that f $\mid\mathbf{R}=\mathbf{f}.$ In particular any field $E_{1}$ con taining R contains an isomorphic copy $F_{1}$ ofF with $\mathbb{R}\subset\mathbb{F_1}\subset\mathbb{E_1}$

SKETCH OF PROOF. Let $S$ be the set of all nonzero elements of $R$ and apply Theorem 4.5 to $f{:}\boldsymbol{R}\to\boldsymbol{E}$ . Then there is a homomorphism $\bar{f}:S^{-1}R=F\to E$ such that $\bar{f}\varphi_{s}=f$ Verify that $\bar{f}$ is a monomorphism. Since $R$ is identified with $\varphi_{\mathbf{S}}(R)$ , this means that $\bar{f}\mid R=f$ .The last statement of the theorem is the special case when $f:R\to E_1$ is the inclusion map.

Theorems 4.7-4.11 deal withthe ideal structure of rings of quotients.This material will be used only in Section VIll.6. Theorem 4.13, which does not depend on Theorems 4.7-4.11, will be referred to in the sequel.

Theorem 4.7.Let S be a multiplicative subset of a commutative ring R.

(i) IfI is an ideal in R, then $S^{- 1}I$ = $\{ a/ s| a\varepsilon I; s\varepsilon S\}$ is an ideal in $S^{-1}R$ (i) ifJ is another ideal in $R$ ,then

$$\begin{gathered}
\mathbf{S^{-1}(I+J)}=\mathbf{S^{-1}I}+\mathbf{S^{-1}J}; \\
\mathrm{S^{-1}(IJ)=(S^{-1}I)(S^{-1}J);} \\
\mathbf{S}^{-1}(\mathbf{I}\cap\mathbf{J})=\mathbf{S}^{-1}\mathbf{I}\cap\mathbf{S}^{-1}\mathbf{J}. 
\end{gathered}$$

REMARKS. $S^{-1}I$ is called the extension of $I$ in $S^{-1}R$ . Note that $r/s\in S^{-1}I$ need not imply that r e I since it is possible to have $a/s=r/s$ with a e $I,r\notin I$

$$\begin{aligned}
&SKETCHOFPROOFOF4.7.UsethefactsthatinS^{-1}R,\sum_{i=1}^{n}(c_{i}/s) \\
&=\left(\sum_{i=1}^{n}c_{i}\right)/s;\sum_{j=1}^{m}\left(a_{i}b_{i}/s\right)=\sum_{j=1}^{m}\left(a_{i}/s\right)(b_{i}s/s);\mathrm{and}
\end{aligned}$$

------------------------------------------------------------------

$$\sum_{k=1}^{t}(c_{k}/s_{k})=\left(\sum_{k=1}^{t}c_{k}s_{1}s_{2}\cdots s_{k-1}s_{k+1}\cdots s_{t}\right)/s_{1}s_{2}\cdots s_{t}.$$

Theorem 4.8.Let S be a multiplicative subset ofa commutative ring Rwith identity and ler I be an ideal of R. Then $S^{-1}\mathbf{I}=\mathbf{S}^{-1}\mathbf{R}$ if and only ifS $\bigcap I\neq\varnothing$

PROOF. If $s\in S\cap I$ ，then $1_{S^{-1}R}=s/s\varepsilon S^{-1}I$ and hence $S^{-1}I=S^{-1}R$ . Conversely, if $S^{-1}I=S^{-1}R$ ,then $\varphi_{S}^{-1}(S^{-1}I)=R$ whence $\varphi_{S}(1_{R})=a/s$ forsomea e I, s ε S Since $\varphi_{s}(1_{R})=1_{R}s/s$ we have $s^{2}s_{1}=ass_{1}$ for some $s_1\varepsilon S$ .But $s^2s_1\varepsilon S$ and assi ∈l imply $S\cap I\neq\varnothing$ .■

In order to characterize the prime ideals in a ring of quotients we need a lemma Recall that if $J$ is an ideal in a ring of quotients $S^{-1}R$ ,then $\varphi_{S}^{-1}(J)$ is an ideal in $R$ (Exercise 2.13). $\varphi_{s}^{-1}(J)$ is sometimes called the contraction of $J$ in $R$

Lemma 4.9.Ler S be a multiplicative subset ofa commutative ring R with identity and let I be an ideal in R.

(i) $I\subset\varphi_{\mathbf{s}^{-1}(\mathrm{S}^{-1}\mathbf{I})}$

(i) $If\mathbf{I}=\varphi_{\mathrm{S}}^{-1}(\mathbf{J})$ for some ideal J in $S^{-1}R$ ,then $S^{-1}\mathbf{I}=\mathbf{J}$ . In other words every idealin $S^{-1}R$ is of theform $S^{-1}I$ for some ideal I in R. (i) IfP is a prime ideal in R and S $\cap\mathbf{P}=\varnothing$ ,then $S^{-1}P$ is a prime ideal in $S^{-1}R$

and $\varphi\mathbf{s}^{-1}(\mathbf{S}^{-1}\mathbf{P})=\mathbf{P}$

PROOF. (i) If ae I,then as e I for every s eS.Consequently, $\varphi_{S}(a)=as/s\varepsilon S^{-1}I$ whencea $\varepsilon\varphi_{s}^{-1}(S^{-1}I)$ . Therefore, $I\subset\varphi_{S}^{-1}(S^{-1}I)$ . (ii) Since $I=\varphi_{S}^{-1}(J)$ every element of $S^{-1}I$ is of the form $r/s$ with $\varphi_S(r)\in J$ Therefore, $r/s=(1_R/s)(rs/s)$ $=(1_{R}/s)\varphi_{S}(r)\in J$, whence $S^{-1}I\subset J$ .Conversely, if $r/s\in J$ ，then $\varphi_{s}(r)=rs/s$ $=(r/s)(s^2/s)\varepsilon\:J$ whence $r\in\varphi_{S}^{-1}(J)=I$ . Thus $r/s\in S^{-1}I$ and hence $J\subset S^{-1}I$ (ii) $S^{-1}P$ is an ideal such that $S^{-1}P\neq S^{-1}R$ by Theorem 4.8. If $(r/s)(r^{\prime}/s^{\prime})\varepsilon S^{-1}P$, then $rr^{\prime}/ss^{\prime}=a/t$ with ae P,1 eS.Consequently, $s_{1}trr^{\prime}=s_{1}ss^{\prime}a\varepsilon P$ for some $s_1\varepsilon S$ Since $s_1t\varepsilon S$ and $S\cap P=\varnothing$ , Theorem 2.15 implies that $rr^{\prime}\varepsilon P$ ,whence $r\varepsilon P$ $P$ P or $r^{\prime}\varepsilon P$ . Thus $r/s\in S^{-1}P$ or $r^{\prime}/s^{\prime}\varepsilon S^{-1}P$ . Therefore, $S^{-1}P$ is prime by Theorem 2.15 Finally $P\subset\varphi_{s}^{-1}(S^{-1}P)$ by (i). Conversely if r $\varepsilon\:\varphi_{S}^{-1}(S^{-1}P)$ ,'then $\varphi_S(r)\varepsilon S^{-1}P$ .Thus $\varphi_{S}(r)=rs/s=a/t$ with ae $P$ and $s,t\in S$ . Consequently, $s_{1}str=s_{1}sa\varepsilon P$ P $P$ for some $s_1\varepsilon S$ .Since $s_{1}st\in S$ and S ∩ $P=\varnothing.$ .re $P$ by Theorem 2.15. Therefore, $\varphi_{S}^{-1}(S^{-1}P)\subset P$ .■

Theorem 4.10. Let S be a multiplicatire subset ofa commuratice ring R with identity Then there is a one-to-one correspondence between the set l ofprime ideals of R which are disjoint from S and the set $ଅ$ of prime ideals of $S^{-1}R$ ,given by $\mathbf{P}\vdash\mathbf{S}^{-1}\mathbf{P}$

PROOF. By Lemma 4.9(ii) the assignment $P\vdash S^{-1}P$ defines an injective map $\mathfrak{u}\to\mathfrak{v}$ . We need only show that it is surjective as well. Let $J$ be a prime ideal of $S^{-1}R$ and let $P=\varphi_{S}^{-1}(J)$ .Since $S^{-1}P=J$ by Lemma 4.9(i), it suffices to show that $P$ is prime. If ab ε $P$ , then $\varphi_{s}(a)\varphi_{s}(b)=\varphi_{s}(ab)\varepsilon J$ since $P=\varphi_{S}^{-1}(J)$ .Since $J$ is prime

------------------------------------------------------------------



------------------------------------------------------------------



------------------------------------------------------------------

(ii) $R$ has a minimal prime ideal which contains all zero divisors, and all nonunits of $R$ are zero divisors.

16. Every nonzero homomorphic image of a local ring is local.

## 5. RINGS OF POLYNOMIALS AND FORMAL POWER SERIES

We begin by defining and developing notation for polynomials in one indeterminate over a ring $R$ . Next the ring of polynomials in $n$ indeterminates over $R$ is defined and its basic properties are developed. The last part of the section, which is not needed in the sequel, is a brief introduction to the ring of formal power series in one indeterminate over $R$

Theorem 5.1. Let R be a ring and let $R[x]$ denote the set of all sequences of element. ofR $(\mathbf{a}_0,\mathbf{a}_1,\ldots)$ such that. $a_{\mathrm{i}}=0$ for all but a finite number of indices i.

(i) $R[x]$ is a ring with addition and multiplication defined by:

$$\mathrm{(a_0,a_1,\ldots)+(b_0,b_1,\ldots)=(a_0+b_0,a_1+b_1,\ldots)}$$

and

$$\mathrm{(a_0,a_1,\ldots)(b_0,b_1,\ldots)=(c_0,c_1,\ldots),}$$

where

$$\mathrm{c_n=\sum_{i=0}^na_{n-i}b_i=a_nb_0+a_{n-1}b_1+\cdots+a_1b_{n-1}+a_0b_n=\sum_{k+j=n}a_kb_j.}$$

(ii) If R is commutative [resp. a ring with identity or a ring with no zero divisors o an integral domain], then so is. $R[x]$

(ii) The map $\mathbf{R}\to\mathbf{R}[\mathbf{x}]$ givenby $\mathbf{r}\vdash(\mathbf{r},0,0,\ldots)$ is a monomorphism of rings.

PROOF. Exercise. If $R$ has an identity $1_{R}$ ,then $(1_{R},0,0,\ldots)$ is an identity in $R[x]$ Observe that if (ao,a1, . . .) $(a_0,a_1,\ldots)$ $(a_0,a_1,\ldots),(b_0,b_1,\ldots)\varepsilon R[x]$ and $k$ [resp. $j]$ is the smallest index such that $a_k\neq0$ [resp. $b_i\neq0.$ ,then

$$(a_0,a_1,\ldots)(b_0,b_1,\ldots)=(0,\ldots,0,a_kb_j,a_{k+1}b_j+a_kb_{j+1},\ldots).\quad\blacksquare $$

The ring $R[x]$ of Theorem 5.1 is called the ring of polynomials over $R$ . Its elements are called polynomials. The notation $R[x]$ is explained below. In view of Theorem 5.1(i) we shall identify $R$ with its isomorphic image in $R[x]$ and write $(r,0,0,\ldots)$ simply as $r$ .Note that $r(a_0,a_1,\ldots)=(ra_0,ra_1,\ldots)$ . We now develop a more familiar notation for polynomials.

Theorem 5.2. Let R be a ring with identity and denote by x the element $(0,1_{\mathbf{R}},0,0,\ldots)$ $of\mathbf{R}[\mathbf{x}]$

(i) $\mathbf{x}^{\mathrm{n}}=(0,0,\ldots,0,\ldots,0,\ldots)$ ,where $1_{\mathbf{R}}$ is the $(\mathbf{n}+1)$st coordinate (i) Ifre R,then for each $n\geq0$ 00, $\mathbf{r} \mathbf{x} ^{\mathrm{n} }= \mathbf{x} ^{\mathrm{n} }\mathbf{r} = ( 0, \ldots , 0, \mathbf{r} , 0, \ldots )$ ,where1 is the $(n+1)$st coordinate.

------------------------------------------------------------------

(i)For every nonzero polynomial f in $R[x]$ there exists an integer n e N and elements $\mathbf{a}_0,\ldots,\mathbf{a}_n\in\mathbf{R}$ such that $\mathbf{f}=\mathbf{a}_{0}\mathbf{x}^{0}+\mathbf{a}_{1}\mathbf{x}^{1}+\cdots+\mathbf{a}_{n}\mathbf{x}^{n}$ .The integer n and elements a; are unique in the sense that $\mathbf{f}=\mathbf{b}_{0}\mathbf{x}^{0}+\mathbf{b}_{1}\mathbf{x}^{1}+\cdots+\mathbf{b}_{m}\mathbf{x}^{m}$ (bi eR) implies $\mathbf{m\geq n;a_{i}=b_{i}}$ a; = bi $a_{i}=b_{i}$ for $\mathbf{i}=1,2,\ldots,\mathbf{n}$ ; and $\mathbf{b_i}=0$ for $n<i\leq m$

SKETCH OF PROOF.Use induction for (i) and straightforward computation for (ii). (i) $\mathbf{If}f= ( a_{0}, a_{1}, \ldots ) \varepsilon$ $R[ x]$ , there must be a largest index $n$ such that $a_n\neq0$ Then $a_0,a_1,\ldots,a_n\in R$ an $a_n$ R $R$ are the desired elements

If $R$ has an identity, then $x^{0}=1_{R}$ (as in any ring with identity) and we write the polynomial $f=a_{0}x^{0}+a_{1}x^{1}+\cdots+a_{n}x^{n}$ as $f=a_{0}+a_{1}x+\cdots+a_{n}x^{n}$ . It will be convenient to extend the notation of Theorem 5.2 to rings without identity as follows. If $R$ is a ring without identity, then $R$ may be embedded in a ring $S$ with identity by Theorem 1.10. Identify $R$ with its image under the embedding map so that $R$ is a subring of $S$ . Then $R[x]$ is clearly a subring of $S[x]$ . Consequently, every polynomial $f= ( a_{0}, a_{1}, \ldots ) \varepsilon$ $R[ x]$ may be written uniquely as$f= a_{0}+ a_{1}x^{1}+ \cdots + a_{n}x^{n}$ where $a_{\mathrm{i}}\varepsilon R\subset S$ ， $a_n\neq0$ ,and $x=(0,1_s,0,0,\ldots)\varepsilon S[x]$ . The only important difference between this and the case when $R$ has an identity is that in this case the element $x$ is not in $R[x]$ Hereafter a polynomial $f$ over a ring $R$ (with or without identity) will always be

written in the form $f=a_{0}+a_{1}x+a_{2}x^{2}+\cdots+a_{n}x^{n}\left(a_{i}\varepsilon R\right)$ . In this notation addition and multiplication in $R[x]$ are given by the familiar rules:.

$$\begin{gathered}
\sum_{i=0}^{n}a_{i}x^{i}+\sum_{i=0}^{n}b_{i}x^{i}=\sum_{i=0}^{n}\:(a_{i}+b_{i})x^{i} \\
\left(\sum_{i=0}^{n}a_{i}x^{i}\right)\left(\sum_{j=0}^{m}b_{j}x^{j}\right)=\sum_{k=0}^{m+n}c_{k}x^{k},\quad\mathrm{where}\quad c_{k}=\sum_{i+j=k}a_{i}b_{j}. 
\end{gathered}$$

If $f=\sum_{i=0}^{n}a_{i}x^{i}\varepsilon R[x]$, then the elements $a_i\varepsilon R$ are called the ceficients of $f.$ The element $a_0$ is called the'constant term. Elements of $R$ , which all have the form $r=(\mathbf{r},0,0,\ldots)=rx^{0}$ are called constant polynomials. If f=>axi = ao + $a_{1}x+\cdots+a_{n}x^{n}=a_{n}x^{n}+\cdots+a_{1}x+a_{0}$ has $a_n\neq0$ ,then $a_n$ is called the leading coefficient of $f.$ If $R$ has an identity and leading coefficient $\cdot1_{R}$ ，then $f$ is said to be a monic polynomial. Let $R$ be a ring (with identity). For historical reasons the element $x=(0,1_{R},0,\ldots)$

of $R[x]$ is called an indeterminate. One speaks of polynomials in the indeterminate $x$ If S is another ring (with identity), then the indeterminate $x\in S[x]$ is nor the same elementas $x\in R[x]$ . In context this ambiguous notation will cause no confusion. If $R$ is any ring, it is sometimes convenient to distinguish one copy of the poly-

nomialring over $R$ from another. In this situation the indeterminate in one copy is denoted by one symbol, say $x$ , and in the other copy by a different symbol, say y. In the latter case the polynomial ring is denoted $R[y]$ and its elements have the form $a_0+a_1y+\cdots+a_ny^n$ We shall now define polynomials in more than one indeterminate. For con-

venience the discussion here is restricted to the case of a finite number of indeter. minates.For the general case see Exercise 4. The definition is motivated by the fact that a polynomial in one indeterminate is by definition a particular kind of sequence

------------------------------------------------------------------

that is, a function $\mathbf{N}\to\boldsymbol{R}$ . For each positive integer $n$ let $\mathbf{N}^{n}=\mathbf{N}\times\cdots\times\mathbf{N}$ (n factors). The elements of $N^n$ are ordered $n$ tuples of elements of N. Nr is clearly an additive abelian monoid under coordinate-wise addition.

Theorem 5.3. Let R be a ring and denote by $\mathbf{R}[\mathbf{x}_1,\ldots,\mathbf{x}_n]$ the set of all functions $\mathbf{f}:\mathbf{N}^{n}\to\mathbf{R}$ such that $\mathbf{f}($u$)\neq0$ for at most a finite number of elements u of $N^n$

(i) $\mathbf{R}[\mathbf{x}_1,\ldots,\mathbf{x}_n]$ is a ring with addition and multiplication defined by
$$\mathrm{(f+g)(u)=f(u)+g(u)}\quad and\quad\mathrm{(fg)(u)=\sum_{\begin{array}{c}v+w=u\\v,weN^n\end{array}}f(v)g(w),}$$

where $\mathbf{f, g}\varepsilon \mathbf{R} [ \mathbf{x} _{1}, \ldots , \mathbf{x} _{\mathrm{n} }]$ andu e $Nn$

(i)IfR is commutative[resp.a ring with identity or a ring without zero divisors on an integral domain], then so is $\mathbf{R}[\mathbf{x}_1,\ldots,\mathbf{x}_n]$ (iii) The map $\mathbf{R}\to\mathbf{R}[\mathbf{x}_1,\ldots,\mathbf{x}_n]$ given by $r\vdash\mathrm{f}_{\mathrm{r}}$, where $\mathbf{f} _{\mathrm{r} }( 0, \ldots , 0) = \mathbf{r}$ and

$\mathbf{f}(\mathbf{u})=0$ for all other u e $Nn$ ,is a monomorphism ofrings.

### PROOF. Exercise.

The ring $R[x_{1},\ldots,x_{n}]$ of Theorem5.3 is called thering ofpolynomials in $n$ in determinates over $R.R$ R $R$ is identified with its isomorphic image under the map of Theorem 5.3(ii) and considered as a subring of $R[x_{1},\ldots,x_{n}]$ .If $n=1$ ,then $R[x_1]$ is precisely the ring of polynomials as inTheorem 5.1.As in the case of polynomials in one indeterminate, there is a more convenient notation for elements of $R[x_{1},\ldots,x_{\underline{n}}]$ Let $n$ be a positive integer and for each $i=1,2,\ldots,n$ ,let

$$\varepsilon_i=(0,\ldots,0,1,0,\ldots,0)\varepsilon\mathbf{N}^n,$$

where 1 is the ith coordinate of $\varepsilon_i$ . If $k\varepsilon N$ ,let $k\varepsilon_{i}=(0,\ldots,0,k,0,\ldots0)$ .Then every element of $N^n$ may be written in the form $k_{1}\varepsilon_{1}+k_{2}\varepsilon_{2}+\cdots+k_{n}\varepsilon_{n}$

Theorem 5.4. Let R be a ring with identity and n a positive integer. For each $\mathbf{i}=1,2,\ldots$, nlet $\mathbf{x} _{\mathrm{i} }\varepsilon \mathbf{R} [ \mathbf{x} _{1}, \ldots , \mathbf{x} _{\mathrm{n} }]$ be defined by $\mathbf{x}_{\mathrm{i}}(\varepsilon_{\mathrm{i}})=\mathbf{1}_{\mathrm{R}}$ and $\mathbf{x} _{\mathrm{i} }( \mathbf{u} ) = 0$ for $u\neq\varepsilon_i$

(i) For each integer k e N, $\mathbf{x} _{\mathrm{i} }^{\mathrm{k} }( \mathbf{k} \varepsilon _{\mathrm{i} }) = \mathbf{1} _{\mathrm{R} }$ and $\mathbf{x} _{\mathrm{i} }^{\mathrm{k} }( \mathbf{u} ) = 0$ for $u\neq k\varepsilon_i$ (i) for each $(\mathbf{k}_{1},\ldots,\mathbf{k}_{n})\varepsilon\mathbf{N}^{n}$ $\mathbf{x_{1}}^{k_{1}}\mathbf{x_{2}}^{k_{2}}\cdots\mathbf{x_{n}}^{k_{n}}(\mathbf{k_{1}\varepsilon_{1}}+\cdots+\mathbf{k_{n}\varepsilon_{n}})=\mathbf{1_{R}}$ and

$\mathbf{x}_{1}^{k_{1}}\mathbf{x}_{2}^{k_{2}}\cdots\mathbf{x}_{n}^{k_{n}}(\mathbf{u})=0$ for $\mathbf{u} \neq \mathbf{k} _{1}\mathbf{\varepsilon } _{1}+ \cdots + \mathbf{k} _{\mathrm{n} \mathbf{\varepsilon } _{\mathrm{n} }}$ (ii) $\mathbf{x}_{i}^{g}\mathbf{x}_{j}^{t}=\mathbf{x}_{j}^{t}\mathbf{x}_{i}^{8}$ for all s,t e N and all $\mathbf{i,j}=1,2,\ldots,n;$

(iv) $x_{\mathrm{i}}tr=rx_{\mathrm{i}}^{\mathrm{t}}$ for allre R andallte N; (v) for every polynomial f in $\mathbf{R} [ \mathbf{x} _{1}, \ldots , \mathbf{x} _{\mathrm{n} }]$ there exist unique elements. $a_{k_1},\ldots,_{k_n}\varepsilon$R

indexed by all $(\mathbf{k}_{1},\ldots,\mathbf{k}_{\mathrm{n}})$ 8 $N^n$ and nonzero for at most a finite number of $(\mathbf{k}_1,\ldots,\mathbf{k}_n)$ E $N^n$ , such that

$$\mathrm{f}\:=\:\sum\:a_{\mathrm{k}_{1}},\ldots,\:\mathrm{k}_{\mathrm{n}}\mathrm{X}_{1}^{\mathrm{k}_{1}}.\:\ldots\:\mathrm{X}_{\mathrm{n}}^{\mathrm{k}_{\mathrm{n}}},$$

where the sum is over all $(\mathbf{k}_{1},\ldots,\mathbf{k}_{n})$ ? $N^n$

------------------------------------------------------------------

If $R$ is a ring with identity, then the elements $x_1, x_2, \ldots , x_n\varepsilon$ $R[ x_1, \ldots , x_n]$ as in Theorem 5.4 are called indeterminates.As in the case of one indeterminate symbols different than $x_{1},\ldots,x_{n}$ Xn $x_n$ may be used to denote indeterminates whenever convenient. The elements $a_0,a_1,\ldots,u_m$ am $u_m$ in Theorem 5.4(v) are called the coefficients of the poly. nomial $f$ .A polynomial of the form $ax_{1}^{k_{1}}x_{2}^{k_{2}}\cdots x_{n}^{k_{n}}\left(a\varepsilon R\right)$ (aε R) $(a\in R)$ is called a monomial in $x_1,x_2,\ldots,x_n$ Theorem 5.4(v) shows that every polynomial is a sum of monomials. It is customary to omit those $x_i$ that appear with exponent zero in a monomial. For example, $a_{0}x_{1}^{0}x_{2}^{0}x_{3}^{0}+a_{1}x_{1}^{2}x_{2}^{0}x_{3}+a_{2}x_{1}x_{2}^{3}x_{3}$ is written $a_0+a_1x_1^2x_3+a_2x_1x_2^3x_3$ . The notation and terminology of Theorem 5.4 is extended to polynomial ring $R[x_{1},\ldots,x_{n}]$ where $R$ has no identity, just as in the·case of one indeterminate. The ring $R$ is embedded in a ringS with identity and $R[x_1,\ldots,x_n]$ is considered as a subring of $S[x_1,\ldots,x_n]$ . If $R$ has no identity then the indeterminates $x_1,x_2,\ldots,x_n$ and the monomials $x_{1}^{k_{1}}x_{2}^{k_{2}}\cdots x_{n}^{k_{n}}(k_{i}\varepsilon\mathbf{N})$ are not elements of $R[x_1,\ldots,x_n]$ If $R$ is any ring, then the map $R[x_1]\to R[x_1,\ldots,x_n]$ defned by $\sum_{i=0}^ma_ix_1^i\vdash$

$\sum_{i=0}^{m}a_{i}x_{1}^{i}x_{2}^{0}\cdots x_{n}^{0}=\sum_{i=0}^{m}a_{i}x_{1}^{i}\varepsilon R[x_{1},...,x_{n}]$ isasiyscn to ea monomorphisnt of rings. Similarly, for any subset $\{i_1,\ldots,i_k\}$ of $\{1,2,\ldots,n\}$ there is a monomorphism $R[x_{i_1},\ldots,x_{i_k}]\to R[x_1,\ldots,x_n]$ . $R[x_{i_1},\ldots,x_{i_k}]$ is usually identified with its isomorphic image and considered to be a subring of $R[x_1,\ldots,x_n]$ Let $\varphi:R\to S$ be a homomorphism of rings, $f\varepsilon$ $R[ x_1, \ldots , x_n]$ and $s_{1},s_{2},\ldots,s_{n}\in S$

By Theorem 5.4 $j= \sum _{i= 0}^{m}a_{i}x_{1}^{k_{i1}}\cdots x_{n}^{k_{in}}$ with $a_i\varepsilon R$ and $k_{ij}$ N. Omit all $x_i$ that appear with xponent zero.Then $\varphi f(s_1,s_2,\ldots,s_n)$ isdeinedto th ${\mathrm{e}}\sum_{i=0}^{m}\varphi(a_{i})s_{1}^{k_{i1}}\cdots s_{n}^{k_{in}}\varepsilon{\mathcal S}$ that is, $\varphi f(s_1,\ldots,s_n)$ is obtained by substituting $\varphi(a_i)$ for $a_i$ and $s_{i}^{k_{ij}}$ for $x_{i}^{k_{ij}}(k_{ij}>0)$ Since the $a_i$ and $k_{ij}$ are uniquely determined (Theorem 5.4), $\varphi f(s_1,\ldots,s_n)$ is a welldefned element of $S$ . If $R$ is a subring of $S$ and 4 is the inclusion map, we write $f(s_1,\ldots,s_n)$ instead of $\varphi f(s_1,\ldots,s_n)$ As is the case with most interesting algebraic constructions, the polynomial ring

$R[x_1,\ldots,x_n]$ can be characterized by a universal mapping property. The following Theorem and its corollaries are true in the noncommutative case if appropriate hypotheses are added (Exercise 5). They are also true for rings of polynomials in an infinite number of indeterminates (Exercise 4).

Theorem 5.5. Let R andS be commutatir:e rings with identity and $\varphi:\mathbf{R}\to\mathbf{S}$ ahomomorphism of rings such that (lr) = 1s $\varphi(1_{\mathrm{R}})=1_{\mathrm{S}}$ $\varphi ( \mathbf{l} _{\mathbf{R} }) = \mathbf{l} _{\mathbf{s} }.$ $If$ $\mathbf{s} _{\mathbf{l} }, \mathbf{s} _{\mathbf{2} }, \ldots , \mathbf{s} _{\mathbf{n} }\varepsilon \mathbf{S}$, then there is a unique homomorphism of rings $\bar{\varphi}:\mathbf{R}[\mathbf{x}_{1},\ldots,\mathbf{x}_{n}]\to\mathbf{S}$ such that $\bar{\varphi}\mid\mathbf{R}=\varphi$ and $\bar{\varphi}(\mathbf{x}_{\mathrm{i}})=\mathbf{s}_{\mathrm{i}}$ for $\mathbf{i}=1,2,\ldots,\mathbf{n}$ .This property completely determines the polynomial ring $\mathbf{R}[\mathbf{x}_1,\ldots,\mathbf{x}_n]$ up to isomorphism.

SKETCH OF PROOF. If $f\varepsilon$ $R[ x_{1}, \ldots , x_{n}]$ , then

$$f=\sum_{i=0}^ma_ix_1^{k_{i1}}\cdot\cdot\cdot x_n^{k_{in}}\left(a_i\:\varepsilon\:R;k_{ij}\:\varepsilon\:\mathbf{N}\right)$$

by Theorem 5.4. The map $\bar{\varphi}$ given by $\bar{\varphi}(f)=\varphi f(s_1,\ldots,s_n)$ is clearly a well-defined map such that $\bar{\varphi}\mid R=\varphi$ and $\bar{\varphi}(x_{i})=s_{i}$ Use the fact that $\varphi$ is a homomorphism, the rules ofexponentiation and the Binomial Theorem 1.6 to verify that $\bar{\varphi}$ is a homomor-

------------------------------------------------------------------

153

phism of rings. Suppose that $\psi:R[x_1,\ldots,x_n]\to S$ is a homomorphism such that $\psi\mid R=\varphi$ and $\psi(x_{i})=s_{i}$ for each i. Ther

$$\begin{aligned}
\psi(f)& =\psi\biggl(\sum_{i=0}^{m}a_{i}x_{1}^{k_{i1}}\cdots x_{n}^{k_{in}}\biggr)_{.}=\sum_{i=0}^{m}\psi(a_{i})\psi(x_{1}^{k_{i1}})\cdots\psi(x_{n}^{k_{in}}) \\
&=\sum_{i=0}^{m}\:\varphi(a_{i})\psi(x_{1})^{ki_{1}}\cdots\psi(x_{n})^{kin} \\
&=\sum_{i=0}^{m}\varphi(a_{i})s_{1}^{k_{i1}}\cdots s_{n}^{k_{in}}=\varphi f(s_{1},s_{2},\ldots,s_{n})=\bar{\varphi}(f);
\end{aligned}$$

whence $\psi=\bar{\varphi}$ and $\bar{\varphi}$ is unique. Finally in order to show that $R[x_1,\ldots,x_n]$ is com pletely determined by this mapping property define a category. ୧ whose objects are all $(n+2)$ -tuples $(\psi,K,s_1,\ldots,s_n)$ where $K$ is a commutative ring with identity, $s_i\varepsilon K$ and $\psi:R\to K$ is a homomorphism with $\psi(1_{R})=1_{K}$ .A morphism in ୧ from $(\psi,K,s_1,\ldots,s_n)$ to $(\theta,T,t_1,\ldots,t_n)$ is a homomorphism of rings $\zeta:K\to T$ such that $\zeta(1_{K})=1_{T},\zeta\psi=\theta$ and $\zeta(s_{i})=t_{i}$ for $i=1,2,\ldots,n$ Verify that 5 is an equivalence in ୧ if and only if 5 is an isomorphism of rings. If $\iota:R\to R[x_1,\ldots,x_n]$ is the inclusion map, then the first part of the proof shows that $(\iota,R[x_{1},\ldots,x_{n}],x_{1},\ldots,x_{n})$ is a universal object in C. Therefore, $R[x_1,\ldots,x_n]$ is completely determined up to isomorphism by Theorem I.7.10.

Corollary 5.6. If $\varphi:\mathbf{R}\to\mathcal{S}$ is $a$ homomorphism of commutative rings and. $s_1,s_2.$ S1,S2 $s_1,s_2,\ldots,s_n\in S$ ,then the map $\mathbf{R}[\mathbf{x}_1,\ldots,\mathbf{x}_n]\to\mathbf{S}$ given by $\mathbf{f}\vdash\varphi$f$(\mathbf{s}_1,\ldots,\mathbf{s}_n)$ is $a$ homomorphism of rings

SKETCH OF PROOF OF 5.6. The proof of Theorem 5.5 showing that the assignment $f\vdash\varphi f(s_1,\ldots,s_n)$ defines a homomorphism is valid even when. $R$ and $S$ do not have identities.

REMARKS. The map $R[x_1,\ldots,x_n]\to S$ of Corollary 5.6 is called the evaluation. Or substitution homomorphism.Corollary 5.6 may be false if $R$ and $S$ are not commutative.This is important since Corollary 5.6 is frequently usedwithout explicit mention. For example, the frequently seen argument that if $f=gh\left(f,g,h\in R[x]\right)$ and $c\varepsilon R$ , then $f(c)=g(c)h(c)$ need not be valid if $R$ is not commutative (Exercise 6). Another consequence of Theorem 5.5 can be illustrated by the following example.

Let $R$ be a commutative ring with identity and consider the polynomial.

$$f=x^2y+x^3y+x^4+xy+y^2+r\varepsilon R[x,y].$$

Observe that $f=y^2+(x^2+x^3+x)y+(x^4+r)$ ，whence $f\varepsilon$ $R[ x] [ y]$ . Similarly $f=x^{4}+yx^{3}+yx^{2}+yx+(y^{2}+r)\varepsilon R[y][x]$ .This suggests that $R[x,y]$ isisomorphic to both $R[x][y]$ and $R[y][x]$ . More generally we have:

Corollary5.7.Let Rbe a commutative ringwith identity and n apositive integer. For each k $(1\leq\mathbf{k}<\mathbf{n})$ there are isomorphisms ofrings $\mathbf{R}[\mathbf{x}_{1},\ldots,\mathbf{x}_{k}][\mathbf{x}_{k+1},\ldots,\mathbf{x}_{n}]\cong$

------------------------------------------------------------------

PROOF. The corollary may be proved by directly constructing the isomorphisms or by using the universal mapping property of Theorem 5.5 as follows. Given a homomorphism $\varphi:R\to S$ of commutative rings with identity and. elements $s_{1},\ldots,s_{n}\in S$ ，there exists a homomorphism $\bar{\varphi}:R[x_1,\ldots,x_k]\to S$ such that $\bar{\varphi}\mid R=\varphi$ and $\bar{\varphi}(x_i)=s_i$ for $i=1,2,\ldots,k$ by Theorem 5.5.Applying Theorem 5.5 with $R[x_1,\ldots,x_k]$ in place of $R$ yields a homomorphism $\bar{\overline{\varphi}}:R[x_1,\ldots,x_k]\left[x_{k+1},\ldots,x_n\right]\to S$ such that $\overline{\overline{\varphi}}\mid R[x_{1},\ldots,x_{k}]=\bar{\varphi}$ and $\overline{\overline{\varphi}}(x_i)=$ $s_i$ for $i=k+1,\ldots,n$ . By construction $\overline{\bar{\varphi}}\mid R=\bar{\varphi}\mid R=\varphi$ and $\bar{\bar{\varphi}}(x_{i})=s_{i}$ for $i=1,2,\ldots,n$ .Suppose that $\psi:R[x_1,\ldots,x_k][x_{k+1},\ldots,x_n]\to S$ is a homo morphism such that $\psi\mid R=\varphi$ and $\psi(x_{i})=s_{i}$ for $i=1,2,\ldots,n$ Then the same ar- gument used in the proof of uniqueness in Theorem 5.5 shows that $\psi\mid R[x_1,\ldots,x_h]$ $=\overline{\varphi}$ .Therefore, the uniqueness statement of Theorem 5.5 (applied to $R[x_{1},\ldots,x_{k}])$ implies that $\psi=\bar{\bar{\varphi}}$ . Consequently, $R[x_{1},\ldots,x_{k}][x_{k+1},\ldots,x_{n}]$ has the desired universal mapping property, whence $R[x_1,\ldots,x_k][x_{k+1},\ldots,x_n]\cong R[x_1,\ldots,x_n]$ by Theorem 5.5. The other isomorphism is proved similarly.

Since $R[x_{1},\ldots,x_{k}]$ is usually considered as a subring of $R[x_{1},\ldots,x_{n}]$ (see page 152) it is customary to identify the various polynomial rings in Corollary 5.6 under the isomorphisms stated there and write, for example, $R[x_1,\ldots,x_k][x_{k+1},\ldots,x_n]$ $=R[x_1,\ldots,x_n]$ We close this section with a brief introduction to rings of formal power series,

which is not needed in the sequel.

Proposition 5.8. Let R be a ring and denore by $R[[x]]$ the set of all sequences of ele. ments ofR $(\mathbf{a}_0,\mathbf{a}_1,\ldots)$

(i) $R[[x]]$ is a ring with addition and multiplication defined by: $(\mathbf{a}_0,\mathbf{a}_1,\ldots)+$ $(b_0,b_1,\ldots)=(a_0+b_0,a_1+b_1,\ldots)$ and $(\mathrm{a}_0,\mathrm{a}_1,\ldots)(\mathrm{b}_0,\mathrm{b}_1,\ldots)=(\mathrm{c}_0,\mathrm{c}_1,\ldots)$ ，where $\mathbf{c}_{\mathrm{n}}=\sum_{i=0}^{n}\mathbf{a}_{\mathrm{i}}\mathbf{b}_{\mathrm{n-i}}=\sum_{k+j=n}^{n}\mathbf{a}_{\mathrm{k}}\mathbf{b}_{\mathrm{j}}$ (ii) The polynomial ring $R[x]$ is a subring of $R[[x]]$ (i)If R is commutative [resp.a ring with identity or a ring with no zero divisors on

an integral domain], then so is $R[[x]]$

PROOF. Exercise; see Theorem 5.1.

The ring $R[[x]]$ ofProposition 5.8 is called thering of formal power series over the ring $R$ . Its elements are called power series. If $R$ has an identity then the polynomial $x=(0,1_{R},0,\ldots)\varepsilon R[[x]]$ is called an indeterminate. It is easy to verify that $x^ir=rx^i$ for all $r\varepsilon R$ R $R$ and i e N. If $( a_0, a_1, \ldots ) \varepsilon$ $R[ [ x] |$ , then for each $n$ ， $(a_{0,}a_{1},\ldots,a_{n},0,0,\ldots)$ is a polynomial, whence $(a_0,\ldots,a_n,0,0,\ldots)=a_0+a_1x+a_2x^2+\cdots+a_nx^n$ by Theorem 5.2. Consequently, we shall adopt the following notation. The power series $(a_0,a_1,\ldots)\varepsilon R[[x]]$ is denoted by the formal sum $\sum_{i=0}^{\infty}a_ix^i.$ The elements $a_i$ are clled coefficients and $a_0$ is called the constant term. Just as in the case of polynomials this notation is used even when $R$ does not have an identity (in which case $x\notin R[[x]])$

------------------------------------------------------------------

Proposio .9 L e R be ig wihideruit andl $\mathbf{f} = \sum _{i= 0}^{\infty }\mathbf{a} _{\mathrm{i} }\mathbf{x} ^{\mathrm{i} }\varepsilon \mathbf{R} [ [ \mathbf{x} ] ] .$

(i) f is a unit in $R[[x]]$ if and only ifits constantterm $a_0$ is a unit in $R$ (i) $Ifa_0$ is irreducible in R, thenf is irreducible in $R[[x]]$

REMARK. If fe $R[[x]]$ is actually a polynomial with irreducible [resp. unit] con stant term then $f$ need not be irreducible[resp. a unit] in the polynomial ring $R[x]$ (Exercise 8).

PROOF OF 5.9. (i) If there exists $g=\sum b_{i}x^{i}\varepsilon R[[x]]$ such that

$$fg=gf=1_{R}\varepsilon R[[x]],$$

 it follows immediately that $a_0b_0=b_0a_0=1_R$ ,whence $a_0$ is a unit in $R$ . Now suppose $a_0$ is a unit in $R$ . If there were an element $g=\sum b_{i}x^{i}\varepsilon R[[x]]$ such that $f_{\mathcal{Q}}=1_{R}$ ,ther the following equations would hold:

$$\begin{matrix}a_0b_0=1_R\\a_0b_1+a_1b_0=0\\.\end{matrix}$$

$$\begin{array}{c}a_0b_n+a_1b_{n-1}+\cdots+a_nb_0=0\\.\\.\\.\end{array}$$

Conversely if a solution $(b_0,b_1,b_2,\ldots)$ for this system of equations in $R$ exists, then $g=\sum_{i=0}^{\infty}b_{i}x^{i}\varepsilon R[[x]]$ clearly has the property that $f_{\mathcal{Q}}=1_{R}$ Since $a_0$ is a unit with multiplicative inverse. $a_0^{-1}$ ),the first equation can be solved: $b_{0}=a_{0}^{-1}$ ; similarly $b_{1}=a_{0}^{-1}(-a_{1}b_{0})=a_{0}^{-1}(-a_{1}a_{0}^{-1})$ .Proceeding inductively, if $b_0,\ldots,b_{n-1}$ are determined in terms of the $a_i$ ，then $a_{0}b_{n}=-a_{1}b_{n-1}-\cdots-a_{n}b_{0}$ implies that $b_{n}=a_{0}^{-1}(-a_{1}b_{n-1}-\cdots-a_{n}b_{0})$ . Thus, if $a_0$ is a unit this system of equations can be solved and there is a $g$ such that $fg=1_{R}\varepsilon R[[x]]$ . A similar argument shows that there exists $h\in R[[x]]$ such that $hf=1_{R}$ . But $h=h\mathbf{1}_{R}=h(fg)=(hf)g=1_{R}g=g$ whence $g$ is a two-sided inverse of $f.$ Therefore $f$ is a unit in $R[[x]]$ . (ii) is an immediate consequence of (i).

Corollary 5.10. If R is a division ring, then the units in $R[[x]]$ are precisely wnose. power series with nonzero constant term. The principal ideal $(\mathbf{x})$ consists precisely of the nonunits in $R[[x]]$ and is the unique maximal ideal of R[[x]]. Thus ifR isa field, R[[x]] is a local ring..

PROOF. The first statement follows from Proposition 5.9 (i) and the fact that every nonzero element of $R$ is a unit. Since $x$ is in the center of $R[[x]]$

$$(x)=\{xf\mid f\varepsilon R[[x]]\}$$

by Theorem 2.5. Consequently, every element $xf$ of $(x)$ has zero constant term,

------------------------------------------------------------------

whence $xf$ is a nonunit.Conversely every nonunit $f_{\varepsilon}R[[x]]$ is necessarily of the form $f=\sum_{i=0}^\infty a_ix^i$ with $a_0=0$ Let $g=\sum_{i=0}^{\infty}b_ix^i$ where $b_{i}=a_{i+1}$ for all . Then $xg=f$, whence $f\varepsilon\left(x\right)$ . Therefore, $(x)$ is .the set of nonunits. Finally, since $1_R\notin(x)$, $(x)\neq R[[x]]$ . Furthermore, every ideal $I$ of $R[[x]]$ with $I\neq R[[x]]$ necessarily consists of nonunits (Remarks, p. 123). Thus every ideal of $R[[x]]$ except $R[[x]]$ is contained in $(x)$ . Therefore, $(x)$ is the unique maximal ideal of $R[[x]]$

## EXERCISES

1. (a) If $\varphi:R\to S$ is a homomorphism of rings, then the map $\bar{\varphi}:R[[x]]\to S[[x]]$ given by $\bar{\varphi}(\sum a_ix^i)=\sum\varphi(a_i)x^i$ is a homomorphism of rings such that $\overline{\varphi}(R[x])\subset$ $S[x].$ (b) $\bar{\varphi}$ is a monomorphism[epimorphism]if and only if 4 is. In this case

$\overline{\varphi}:R[x]\to S[x]$ is also a monomorphism [epimorphism] (c) Extend the results of (a) and (b) to the polynomial rings $R[x_1,\ldots,x_n]$ $S[x_1,\ldots,x_n]$

2. Let $Mat_nR$ be the ring of $n\times n$ matrices over a ring $R$ . Then for each $n\geq1$ (a) $(\mathrm{Mat}_nR)[x]\cong\mathrm{Mat}_nR[x]$ (b) $(\mathrm{Mat}_nR)[[x]]\cong$Mat$_nR[[x]]$

3. Let $R$ be a ring and $G$ an infnite multiplicative cyclic group with generator denoted $x$ . Is the group ring $R(G)$ (see page 117) isomorphic to the polynomial ring in one indeterminate over $R$

4. (a) Let $S$ be a nonempty set and let $Ns$ be the set of all functions $\varphi:S\to\mathbb{N}$ such that $\varphi(s)\neq0$ for at most a finite number of elements $s\varepsilon S$ . Then $Ns$ is a multiplicatire abelian monoid with product defined by

$$(\varphi\psi)(s)=\varphi(s)+\psi(s)\:(\varphi,\psi\:\varepsilon\:\mathbf{N}^{S};s\:\varepsilon S).$$

The identity element in $Ns$ is the zero function.

(b) For each $x\varepsilon S$ and i ε N let $x^i\varepsilon Ns$ be defined by $x^{i}(x)=i$ and $x^{i}(s)=0$ for $s\neq x$ .If $\varphi\varepsilon Ns$ and $x_1,\ldots,x_n$ Xn $x_n$ are the only elements of $S$ such that $\varphi(x_i)\neq0$ then in $Ns$ $\varphi=x_{1}^{i_{1}}x_{2}^{i_{2}}\cdots x_{n}^{i_{n}}$ , where $i_{j}=\varphi(x_{j})$ (c) If $R$ is a ring with identity let $R[S]$ be the set of all functions $f{:}\mathbf{N}^{\mathbf{S}}\to R$ such

that $f(\varphi)\neq0$ for at most a finite number of $\varphi\varepsilon Ns$ . Then $R[S]$ is a ring with identity, where addition and multiplication are defined as follows:

$$(f+g)(\varphi)=f(\varphi)+g(\varphi)\:(\:f,g\:\varepsilon\:R[S];\varphi\:\varepsilon\:\mathbf{N}^{S});\\(fg)(\varphi)\:=\:\sum f(\theta)g(\zeta)\:(\:f,g\:\varepsilon\:R[S];\theta,\zeta,\varphi\:\varepsilon\:\mathbf{N}^{S}),$$

where the sum is over all pairs $(\theta,\zeta)$ such that $\theta\zeta=\varphi.R[S]$ is called the ring of polynomials in S over R. (d) For each $\varphi=x_{1}^{i_{1}}\cdots x_{n}^{i_{n}}\varepsilon\mathbf{N}^{s}$ and each r & $R$ we denote by $r{x_1}^{i_1}\cdots{x_n}^{i_n}$ the

function $\mathbf{N}^{\mathcal{S}}\to R$ which is $r$ at 4 and O elsewhere. Then every nonzero element $f$ $f=\sum_{i=0}^{m}r_{i}x_{1}^{k_{i1}}x_{2}^{k_{i2}}\cdot\cdot\cdot x_{n}^{k_{in}}$ of $R[S]$ can be written in the form ∫= r;xuxb2 . xr with the $r_i\varepsilon R,x_i\varepsilon S$ and $k_{ij}$ kij $k_{ij}\varepsilon N$ all uniquely determined. (e) If $S$ is finite of cardinality $n$ , then $R[S]\cong R[x_1,\ldots,x_n]$ [Hint: if $N^n$ is con

sidered as an additive abelian monoid as in the text, then there is an isomorphism

------------------------------------------------------------------

of monoids $\mathbb{N}^{\mathcal{S}}\cong\mathbb{N}^{n}$ given by $\varphi\vdash(\varphi(s_1),\ldots,\varphi(s_n))$ , where $S=\{s_{1},\ldots,s_{n}\}.]$ (f) State and prove an analogue of Theorem 5.5 for $R[S]$

5. Let $R$ and $S$ be rings with identity, $\varphi:R\to S$ a homomorphism of rings with. $\varphi(1_{R})=\mathbf{l}_{S}$ ,and $s_{1},s_{2},\ldots,s_{n}\in.$ Sn $s_n$ $S$ such that $s_{i}s_{i}=s_{j}s_{i}$ for all $i,j$ and $\varphi(r)s_{i}=s_{i}\varphi(r)$ for all re Randalli. Then there isa unique homomorphism $\bar{\varphi}$ p $\bar{\varphi}{:}R[x_{1},\ldots,x_{n}]{\to}S$such that $\boldsymbol{\varphi}|\boldsymbol{R}=\boldsymbol{\varphi}$ and $\phi(x_{i})=s_{i}$ . This property completely determines $R[x_1,\ldots,x_n]$ up to isomorphism.

6. (a) If $R$ is the ring of all $2\times2$ matrices over $\mathbf{Z}$ , then for any $A\varepsilon R$

$$(x+A)(x-A)=x^2-A^2\varepsilon\:R[x].$$

(b) There exist $C,A\in R$ such that $(C+A)(C-A)\neq C^2-A^2$ .Therefore, Corollary 5.6 is false if the rings involved are not commutative.

7. If $R$ is a commutative ring with identity and $f=a_{n}x^{n}+\cdots+a_{0}$ is a zero divisor in $R[x]$, then there exists a nonzero $b$ E $R$ such that $ba_{n}=ba_{n-1}=\cdots=ba_{0}=0$

8. (a) The polynomial $x+1$ is a unit in the power series ring $\mathbf{Z}[[x]]$, , but is not a unit in $\mathbf{Z}[x]$ (b) $x^2+3x+2$ is irreducible in $\mathbf{Z}[[x]]$, , but not in $\mathbf{Z}[x]$

9. If $F$ is a field, then $(x)$ is a maximal ideal in $F[x]$ ,but it is not the only maximal ideal (compare Corollary 5.10).

10. (a) If $F$ is a field then every nonzero element of $F[[x]]$ is of the form $x^ku$ with $u\in F[[x]]$ a unit. (b) $F[[x]]$ is a principalideal domain whose only ideals are O, $F[[x]]=(1_{F})=(x^{0})$ and $(x^k)$ for each $k\geq1$

11. Let $\mathbb{C}$ be the category with objects all commutative rings with identity and morphisms all ring homomorphisms $f:R\to S$ such that $f(1_{R})=1_{S}$ .Then the polynomial ring $\mathbf{Z}[x_1,\ldots,x_n]$ is a free object on the set $\{x_1,\ldots,x_n\}$ in the category C. [Hinr: for any $R$ in ୧ the map $\mathbf{Z}\to R$ given by $n\mapsto n1_{R}$ is a ring homomorphism; use Theorem 5.5.]

## 6. FACTORIZATION IN POLYNOMIAL RINGS

We now consider the topics introduced in Section 3 (divisibility, irreducibility and unique factorization) in the context of polynomial rings over a commutative ring.We begin with two basic tools: the concept of the degree of a polynomial and the division algorithm. Factors of degree one of a polynomial are then studied finding such factors is equivalent to finding roots of the polynomial. Finally we consider irreducible factors of higher degree: Eisenstein's irreducibility criterion is proved and it is shown that the polynomial domain $D[x_1,\ldots,x_n]$ is a unique factor. ization domain if $D$ is. Let $R$ be a ring. The degree ofa nonzero monomial $ax_{1}^{k_{1}}x_{2}^{k_{2}}\cdots x_{n}^{k_{n}}\varepsilon R[x_{1},\ldots,x_{n}]$

is the nonnegative integer $k_{1}+k_{2}+\cdots+k_{n}$ .If $f$ is a norzero polynomial in $R[x_{1},\ldots,x_{n}]$ ,then $f$ = $\sum _{i= 0}^{m}a, x_{1}^{ki1}$ . . $x_{n}^{kin}$ $x_n^{kin}$ by Thorem 5.4 The toal degre o the polynomial $f$ is the maximum of the degrees of the monomials $a_ix_1^{k_i1}$ ... $x_n^{kin}$ such

------------------------------------------------------------------

that ai≠0 $a_i\neq0$ $a_{i}\neq0\left(i=1,2,\ldots,m\right)$ . The (total) degree of $f$ is denoted deg $f.$ Clearly a nonzero polynomial $f$ has degree zero if and only if $f$ is a constant polynomial $f=a_{0}=a_{0}x_{1}^{0}\cdots x_{n}^{0}$ . A polynomial which is a sum of monomials, each of which has. degree $k$ ,is said to be homogeneous of degree k.Recall that for each $k$ $(1\leq k\leq n)$ $R[x_{1},\ldots,x_{k-1},x_{k+1},\ldots,x_{n}]$ is a subring of $R[x_1,\ldots,x_n]$ (see page 152). The degree of fin $x_k$ is the degree of fconsidered as a polynomial in one indeterminate $x_k$ over the ring $R[x_{1},\ldots,x_{k-1},x_{k+1},\ldots,x_{n}]$

EXAMPLE. The polynomial $3x_1^2x_2^2x_3^2+3x_1x_3^4-6x_2^3x_3\varepsilon\mathbf{Z}[x]$ has degree 2 in $x_1$ ,degree 3 in $x_2$, degree 4 in $x_3$ and total degree 6.

For technical reasons it is convenient to define the degree of the zero polynomial tobe $-\infty$ and to adopt the following conventions about the symbol deg $0=-\infty$ $(-\infty)<n$ and $(-\infty)+n=-\infty=n+(-\infty)$ for every integer n; $(-\infty)+$ $(-\infty)=-\infty$

Theorem 6.1. Ler R be a ring and f $\mathbf{g}\varepsilon\mathbf{R}[\mathbf{x}_{1},\ldots,\mathbf{x}_{n}]$

(i) $deg(f+g)\leq$ max (deg f, deg g). (ii) deg(fg) ≤ deg $f+$ deg g. (ii) $If\mathbf{R}$ has no zero divisors, $deg(fg)=degf+degg$ (iv) $If\mathbf{n}=1$ and the leading coefficient of f or g is not a zero divisor in R (in par. ticular, if it is a unit), then de = = $g(fg)=degf+degg$

REMARK. The theorem is also true if deg fis taken to mean “degree of fin $x_k$ .

SKETCH OF PROOF OF 6.1. Since we shall apply this theorem primarily when $n=1$ we shall prove only that case. (i) is easy (ii) is trivial if $f=0$ or $g=0$ . If $0\neq f=\sum_{i=0}^na_ix^i$ has degree $n$ and $0\neq g=\sum_{i=0}^mb_ix^i$ has degree $m$ ,then $fg=a_0b_0$ $+\cdots+(a_{n-1}b_m+a_nb_{m-1})x^{n+m-1}+a_nb_mx^{m+n}$ has degree at most $m+n$ .Since $a_{n}\neq0\neq b_{m}$, fghas degree $m+n$ if one of $a_n,b_m$ is not a zero divisor.

Theorem 6.2. (The Division Algorithm) Let R be a ring with identity and f,g e R[x nonzero polynomials such that the leading coefficient ofg is a unit in R. Then there exist. unique polynomials q,r e $R[x]$ such thal

$$\mathrm{f=qg+r}\quad and\quad deg\:r<deg\:g.$$

PROO. Ifdeg $g>\deg f$, let $q=0$ and $r=f.$ If deg ~ de ,then $f=\sum_{i=0}^{n}a_{i}x^{i}$, g =∑ bix, with $a_n\neq0$ an ×0 bm ≠ 0 $b_m\neq0$ $a_{n}\neq0,b_{m}\neq0,m\leq n$, m< n $m\leq n$ and $b_{m}$ a unit in $R$ . Proceed by inductior on $n=\deg f$ If $n=0$ , then $m=0$ $f= a_{0}$, $g=$ $b_{0}$ and $b_0$ is a unit. Let $q=a_0b_0^{-1}$ and $r=0$ ; then deg $r<$ deg $g$ and $qg+r=(a_0b_0^{-1})b_0=a_0=f$

Assume that the existence part of the theorem is true for polynomials of degree. less than $n=\deg f$ $f$ s A straightforward calculation shows that the polynomial. $(a_nb_m^{-1}x^{n-m})g$ has degree $n$ and leading coefficient $a_n$ .Hence

------------------------------------------------------------------

$$f-(a_nb_m^{-1}x^{n-m})g=(a_nx^n+\cdots+a_0)-(a_nx^n+\cdots+a_nb_m^{-1}b_0x^{n-m})$$

is a polynomial of degree less than. $n$ . By the induction hypothesis there are poly nomials $q^{\prime}$ and $r$ such that

$$f-(a_nb_m^{-1}x^{n-m})g=q^{\prime}g+r\quad\mathrm{and}\quad\deg r<\deg g.$$

Therefore, if $q=a_{n}b_{m}^{-1}x^{n-m}+q^{\prime}$ ,then

$$f=(a_{n}b_{m}{}^{-1}x^{n-m})g+q^{\prime}g+r=qg+r.$$

(Uniqueness) Suppose $f=q_{1}g+r_{1}$ ,and $f=q_{2}g+r_{2}$ with deg $r_1<$ deg $g$ and deg $r_2<$ deg $g$ . Then $q_{1}g+r_{1}=q_{2}g+r_{2}$ implies

$$(q_1-q_2)g=r_2-r_1.$$

Since the leading coefficient $b_m$ of $g$ is a unit, Theorem 6.1 implies

$$\deg\left(q_1-q_2\right)+\deg g=\deg\left(q_1-q_2\right)g=\deg(r_2-r_1).$$

Since $\deg(r_2-r_1)\leq$ max (deg $r_2$ ,deg $r_1)<$ deg $g$ , the above equality is true onlyif $\deg(y_1-q_2)=(-\infty)=\deg(r_2-r_1)$ .In other words $q_{1}-q_{2}=0$ and $r_{2}-r_{1}=0$ .

Corollary 6.3.(Remainder Theorem) Let R be a ring with identity and

$$\mathrm{f(x)}=\sum_{i=0}^{n}\mathrm{a_{i}x^{i}\varepsilon R[x]}.$$

For any ceR there exists $a$ unique $\mathbf{q(x)\varepsilon R[x]}$ such that $\mathbf{f(x)=q(x)(x-c)+f(c)}$

PROOF. If $f=0$ let $q=0$ . Suppose then that $f\neq0$ . Theorem 6.2 implies that there exist unique polynomials $q(x),r(x)$ in $R[x]$ such that $f(x)=q(x)(x-c)+r(x)$ and deg $r(x)<\deg(x-c)=1.$ Thus $r(x)=r$ is a constant polynomial (possibly 0).
$$(x\quad\mathrm{t})-1.\:\mathrm{Thas}\:r(x)-r\:\mathrm{is}\:\mathrm{a}\:\mathrm{constant}\:\mathrm{poiynoinar}\:(\mathrm{possioly}\:\mathrm{o}).\\\mathrm{hen}\:f(x)=q(x)(x-c)+r=-b_{0}c+\sum_{k=1}^{n-1}\:(-b_{k}c+b_{k-1})x^{k}+$$
If $q(x)=\sum_{j=0}b_{i}x^{i}$ $b_{n-1}x^n+r$ whence

$$\begin{aligned}
f(c)& =\:-b_{0}c+\sum_{k=1}^{n-1}\:(-b_{k}c+b_{k-1})c^{k}+b_{n-1}c^{n}+r \\
&=\:-\sum_{k=0}^{n-1}\:b_{k}c^{k+1}+\sum_{k=1}^{n}b_{k-1}c^{k}+r\:=\:0+r\:=\:,\quad\blacksquare 
\end{aligned}$$

Corollary 6.4.If F is a field, then the polynomial ring $F[x]$ is a Euclidean domain, whence $F[x]$ is a principal ideal domain and a unique factorization domain. The units in. F[x] are precisely the nonzero constant polynomials

SKETCH OF PROOF. $F[x]$ is an integral domain by Theorem 5.1. Defne $\varphi:F[x]-\{0\}\to\mathbf{N}$ by $\varphi(f)=\deg f$ Since everynonzero element of $F$ is a unit, Theorems 6.1(iv) and 6.2 imply that $F[x]$ is a Euclidean domain. Therefore, $F[x]$ is a principal ideal domain and a unique factorization domain (Theorem 3.9). Finally Theorem 6.1 (iv) implies that every unit fin $F[x]$ has degree zero, whence $f$ is a nonzero constant.The converse is obvious.

------------------------------------------------------------------

If $F$ is a field, then $F[x_1,\ldots,x_n]$ is not a principal ideal domain (Exercise 1), but it is a unique factorization domain (Theorem 6.14 below). Before proving this latter fact we shall discuss factors of degree one in polynomial rings.

Definition 6.5. Ler R be a subring of a commutative ring S, $\mathrm{c_1,c_2,\ldots,c_n\varepsilon S}$ and $f=\sum_{i=0}^{m}a_{i}x_{1}^{k_{i1}}\cdots x_{n}^{k_{in}}\varepsilon\:{\mathcal R}[\mathbf{x}_{1},\ldots,\mathbf{x}_{n}]$ a polynomial such that $\mathbf{f}(\mathbf{c}_1,\mathbf{c}_2,\ldots\mathbf{c}_n)=0$ Then $(c_{1},c_{2},\ldots,c_{n})$ is said to be a root or zero of f (or a solution of the polynomial equation $\mathbf{f}(\mathbf{x}_{1},\ldots,\mathbf{x}_{n})=0$ 0.

Theorem 6.6. Let R be a commutative ring with identity and f e $R[x]$ . Then c e R is a root off if and only if x - c divides f

SKETCH OF PROOF. We have $f(x)=q(x)(x-c)+f(c)$ by Corollary 6.3. If $x-c\mid f(x)$ ,then $h(x)(x-c)=f(x)=q(x)(x-c)+f(c)$ with he $R[x]$ whence $(h(x)-q(x))(x-c)=f(c)$ .Since $R$ is commutative, Corollary 5.6 (with $\varphi=1_{R})$ implies $f(c)=(h(c)-q(c))(c-c)=0$ . Commutativity is not required for the converse; use Corollary 6.3.

Theorem 6.7. If D is an integral domain contained in an integral domain E and. fe D[x] has degree n,then f has at most n distinct roots in E.

SKETCH OF PROOF. Let $c_{1,}c_{2},\ldots$ be the distinct roots of fin $E$ . By Theorem $6.6f(x)=q_{1}(x)(x-c_{1})$ whence $0=f(c_{2})=q_{1}(c_{2})(c_{2}-c_{1})$ by Corollary 5.6. Since $c_1\neq c_2$ and $E$ is an integral domain, $q_{1}(c_{2})=0$ . Therefore, $x-c_2$ divides $q_2$ and $f(x)=q_{3}(x)(x-c_{2})(x-c_{1})$ . An inductive argument now shows that whenever $c_{1},\ldots,c_{m}$ are distinct roots of $f$ in $E$ ,then $g_{m}=(x-c_{1})(x-c_{2})\cdots(x-c_{m})$ divides $f.$ But deg $g_m=m$ by Theorem 6.1. Therefore $m\leq n$ by Theorem 6.1 again.

REMARK. Theorem 6.7 may be false without the hypothesis of commutativity. For example, $x^2+1$ has an infinite number of distinct roots in the division ring of real quaternions (including $\pm i,\pm j$ and $\pm k$ ).

If $D$ is a unique factorization domain with quotient field $F$ and $f\varepsilon D[x]$ , then the rootsof $f$ in $F$ may be found via

Proposition 6.8. Let D be a unigue factorization domain with quotient field F and le $\mathbf{f}=\sum_{i=0}^{n}\mathbf{a}_{\mathrm{i}}\mathbf{x}^{\mathrm{i}}\varepsilon\mathbf{D}[\mathbf{x}].If\mathbf{u}=\mathbf{c}/\mathbf{d}\varepsilon\mathbf{F}$ $If\mathbf{u}=$c/d$\varepsilon$ Ifu = c/d e wihe and rlarioel rime ard i ror of then c divides ao and d divides $a_n$

'Commutativity is not essential in the definition provided one distinguishes "left roots' and "right roots" (the latter occur when $f$ is written ${\dot{f}}=\sum x_{1}^{k_{i1}}\cdots x_{n}^{k_{1n}}a_{i})$

------------------------------------------------------------------

SKETCH OF PROOF. $f(u)=0$ implies hat $a_0d^n=c\left(\sum_{i=1}^n(-a_i)c^{i-1}d^{n-i}\right)$ and $-a_nc^n=\left(\sum_{i=0}^{n-1}c^id^{n-i-1}\right)d.$ Consequently, if $(c,d)=1_R$ then $c|a_0$ and $d\mid a_n$ by Exercise 3.10.

EXAMPLE. If$f= x^{4}- 2x^{3}- 7x^{2}- ( 11/ 3) x- 4/ 3\varepsilon \mathbf{Q} ( x]$ , then $f$ has the same roots in $\mathbf{Q}$ as does $3f=3x^{4}-6x^{3}-21x^{2}-11x-4\varepsilon\mathbf{Z}[x]$ .By Proposition 6.8 the only possible rational roots of ±1 $\pm1$ $3f$are$\pm1,\pm2,\pm4,\pm1/3,\pm2/3$ ±2/3 $\pm2/3$ and $\pm4/3$ .Substitution shows that 4 is the only rational root. Let $D$ be an integral domain and $f_{\varepsilon}D[x].$ If c $c$ $c\in D$ D $D$ and $c$ is a root of $f$, thenre

peated application of Theorem 6.6 together with Theorem 6.7 shows that there is a greatest integer $m$ $(0\leq m\leq\deg f)$ such that

$$f(x)=(x-c)^mg(x),$$

where $g(x)\in R[x]$ and $x-c$ Y$g(x)$ (that is, $g(c)\neq0$ ).The integer $m$ is called the multiplicity of the root $c$ of $f$ If $c$ has multiplicity 1, $c$ is said to be a simple root. If $c$ has multiplicity $m>1,c$ C $c$ is called a multiple root. In order to determine when a poly. nomial has multiple roots we need:

$$\mathbf{9.}\:Let\:\mathbf{D}\:be\:an\:integral\:domain\:and\:\mathbf{f}\:=\:\sum_{i=0}^{n}\:\mathbf{a_{i}x^{i}}\:\varepsilon\:\mathbf{D}[\mathbf{x}].\:Let\\\mathbf{f}^{\prime}=\sum_{k=1}^{n}\mathrm{ka_{k}x^{k-1}=a_{1}+2a_{2}x+3a_{3}x^{2}+\cdots+na_{n}x^{n-1}.}$$
polynomial f f,ge D[x] and c e D:

(i $(\mathbf{cf})^{\prime}=\mathbf{cf}^{\prime}$ (ii) $(\mathbf{f}+\mathbf{g})^{\prime}=\mathbf{f}^{\prime}+\mathbf{g}^{\prime}$ (ii) $(\mathbf{fg})^{\prime}=\mathbf{f'g}+\mathbf{fg'}$ (iv) $(\mathbf{g}^{n})^{\prime}=\mathbf{n}\mathbf{g}^{n-1}\mathbf{g}^{\prime}$

PROOF. Exercise.

The polynomial $f^{\prime}$ is called the formal derivative of $f.$ The word "formal" emphasizes the fact that the definition of $f^{\prime}$ does not involve the concept of limits. According to Definition 3.3 a nonzero polynomial $f\varepsilon R[x]$ is irreducible pro-

vided fis not a unit and in every factorization $f=gh$ , either $g$ or $h$ is a unit in $R[x]$

Theorem 6.10. Let D be an integral domain which is a subring ofan integral domain E.Ler feD[x] and cεE.

(i) c is a multiple root off if and only $iff(c)=0$ and $\mathbf{f}^{\prime}(c)=0$ (ii) 1fD is a field and f is relatively prime to $f'$ ,thenf hasno multipleroots inE (ii)ifD is afield,fis irreducible in $D[x]$ and E contains a rootoff,then f has no multiple roors in E if and only $if\mathbf{f}^{\prime}\neq0$

PROOF. (i) $f(x)=(x-c)^mg(x)$ where $m$ is the multiplicity of $f(m\geq0)$ and $g(c)\neq0$ . By Lemma 6.9 $f^{\prime }( x) = m( x- c) ^{m- 1}g( x) + ( x- c) ^{m}g^{\prime }( x)$ If $c$ is a multiple

------------------------------------------------------------------

root of $f$, then $m>1$ ,whence $f^{\prime}(c)=0$ Conversely, if $f(c)=0$ , then $m\geq1$ (Theorem 6.6). If $m=1$ ,then $f^{\prime}(x)=g(x)+(x-c)g^{\prime}(x)$ . Consequently, if $f^{\prime}(c)=0$ then $0=f^{\prime}(c)=g(c)$ by Corollary 5.6, which is a contradiction. Therefore, $m>1$ (ii) By Corollary 6.4 and Theorem $3.11kf+hf^{\prime}=1_D$ for some k,h e $D[x]\subset E[x]$

If $c$ is a multiple root of $f$, then by Corollary 5.6 and (i) $\mathbf{1}_{D}=k(c)f(c)+h(c)f^{\prime}(c)=0$, which is a contradiction. Hence $c$ is simple root. (ii) If fis irreducible and $f^{\prime}\neq0$ , then fand $f^{\prime}$ are relatively prime since deg $f^{\prime}<$

deg $f.$ .Therefore, $f$ has no multiple roots in $E$ by (i). Conversely, suppose fhas no multiple roots in $E$ and $b$ is a root of fin $E$ .If $f^{\prime}=0$ , then $b$ is a multiple root by (i), which is a contradiction. Hence $f^{\prime}\neq0$ .■

This completes the discussion of linear factors of polynomials. We now consider the more general question of determining the units and irreducible elements in the polynomial ring $D[x]$, where $D$ is an integral domain. In general this is quite difficult, but certain facts are easily established: (i) The units in $D[x]$ are precisely the constant polynomials that are units in $D$

[see the proof of Corollary 6.4]. (ii) Ifc e $D$ and $c$ is irreducible in $D$ , then the constant polynomial $c$ is irreducible

in $D[x]$ [use Theorem 6.1 and (i)]. (ii) Every first degree polynomial whose leading coefficient is a unit in $D$ is irre-

ducible in $D[x]$ In particular, every frst degree polynomial over a field is irreducible. (iv) Suppose $D$ is a subring of an integral domain $E$ and $f\varepsilon$ $D[ x] \subset E[ x]$ Then $f$

may be irreducible in $E[x]$ but not in $D[x]$ and vice versa, as is seen in the following examples.

EXAMPLES. $2x+2$ is irreducible in $\mathbf{Q}[x]$ by (ii) above. However, $2x+2$ $=2(x+1)$ and neither 2 nor $x+1$ is a unit in $\mathbf{Z}[x]$ by(i), whence $2x+2$ is reducible in $\mathbf{Z}[x]$ $x^2+1$ is irreducible over the real field, but factors over the complex feld as $(x+i)(x-i)$ .Since $x+i$ and $x-i$ are not units in $\mathbf{C}[x]$ by (i), $x^2+1$ is reducible in $\mathbf{C}[x]$ In order to obtain what few general results there are in this area the rest of the

discussion will be restricted to polynomials ovet a unique factorization domain $D$ We shall eventually prove that $D[x_1,\ldots,x_n]$ is also a unique factorization domain The proof requires some preliminaries,which will also provide a criterion for irreducibility in $D[x]$

Let $D$ be a unique factorization domain and $f=\sum_{i=0}^na_ix^i$ a nonzero polynomial in $D[x]$ . A greatest common divisor of the coefficients $a_0,a_1,\ldots,a_n$ an $a_n$ is called a content of fand is denoted $C(f)$ . Strictly speaking, the notation $C(f)$ is ambiguous since greatest common divisors are not unique. But any two contents of $f$ are necessarily associates and any associate of a contentof $f$ is also a content of $f.$ We shall write $b=c$ whenever $b$ and $c$ are associates in D. Now $\approx$ is an equivalence relation on $D$ and since $D$ is an integral domain, $b\approx c$ if and only if $b=cu$ for some unit $u\in D$ D $D$ by Theorem 3.2 (vi). If a E $D$ and $f\varepsilon D[x]$, then $C(af)=aC(f)$ (Exercise 4). If $f\varepsilon D[x]$ and $C(f)$ is a unit in $D$ , then $f$ is said to be primitive. Clearly for any polynomial $g\varepsilon D[x],g=C(g)g_1$ with $g_1$ primitive

Lemma 6.11.(Gauss) If D is a unique factorization domain and $\mathbf{f},\mathbf{g}\in\mathbf{D}[\mathbf{x}]$ ,，then $\mathbf{C}(\mathbf{f}\mathbf{g})=\mathbf{C}(\mathbf{f})\mathbf{C}(\mathbf{g})$ . In particular, the product of primitive polynomials is primitive.

------------------------------------------------------------------

PROOF. $f=C(f)f_1$ and $g=C(g)g_{1}$ with $f_1,g_1$ primitive. Consequently $C(fg)=C(C(f)f_{\mathrm{i}}C(g)g_{\mathrm{i}})=C(f)C(g)C(f_{\mathrm{i}}g_{\mathrm{i}})$ . Hence it suffices to prove that $f_{1}g_{1}$ is primitive (that is, $C(f_{1}g_{1})$ is a unit). If $f_1=\sum_{i=0}^na_ix^i$ and 81 = ≥ b;x, thern $f_{1}g_{1}=\sum_{k=0}^{m+n}c_{k}x^{k}$ wih $c_{k}=\sum_{i+j=k}a_{i}b_{i}$ $f_{1}g_{1}$ is o riethentherecist anire ducible element $P$ in $R$ such that $p\mid c_k$ for all $k$ .Since $C(f_1)$ is a unit $p\nmid C(f_1)$ ,whence there is a least integer $s$ such that

$$p\mid a_i\quad\mathrm{for}\quad i<s\quad\mathrm{and}\quad p\nmid a_s.$$

Similarly there is a least integer 1 such that

$$p\mid b_i\quad\mathrm{for}\quad j<t\quad\mathrm{and}\quad p\nmid b_t.$$

Since $P$ divides $c_{s+t}=a_{0}b_{s+t}+\cdots+a_{s-1}b_{t+1}+a_{s}b_{t}+a_{s+1}b_{t-1}+\cdots+a_{s+t}b_{0}$, $P$ must divide $a_sb_t$ . Since every irreducible element in $D$ is prime, $p\mid a_s$ or $p\mid b_t$ $p\mid b_t$ p|be . This is a contradiction. Therefore $f_{\mathrm{l}}g_{\mathrm{l}}$ is primitive.

Lemma 6.12.Let D be a unique factorization domain with quotient field F and let f and g be primitive polynomials in $D[x]$ .Then f and g are associates in $D[x]$ ifand only if they are associates in $F[x]$

PROOF. If $f$ and $g$ are associates in the integral domain $F[x]$, then $f=gu$ for some unit $u\in F[x]$ (Theorem 3.2 (vi)). By Corollary $6.4u\varepsilon F$ ,whence $u=b/c$ with $b,c\in D$ D $D$ and $c\neq0$ . Therefore, $cf=b\boldsymbol{g}$ .Since $C(f)$ and $C(g)$ are units in $D$

$$c=cC(f)=C(cf)=C(bg)=bC(g)=b.$$

Therefore, $b=cv$ for some unit $\upsilon\varepsilon D$ and $cf=bg=vcg$ . Consequently, $f=vg$ (since $c\neq0$ , whence $f$ and $g$ are associates in $D[x]$ . The converse is trivial.

Lemma 6.13. Let D be a unigue factorization domain with quotient field F and f a primitive polynomial of positive degree in $D[x]$ .Thenfis irreducible in $D[x]$ if and only iffis irreducible in $F[x]$

SKETCH OF PROOF. Suppose $f$ is irreducible in $D[x]$ and $f=gh$ with $g,h\in F[x]$ and deg $g\geq1$ , deg $h\geq1$ . Then g = ≥ (a/b:)xt and h = ≥ (ci/d)xi with $a_i,b_{i,C},d_j\in D$ and bi≠0 $b_i\neq0$ $b_i\neq0,\:d_i\neq0$ di≠0 $d_i\neq0$ .Let $b\:=\:b_0b_1\cdots b_n$ and for each $i$ let $b_{i}^{*}=b_{0}b_{1}\cdots b_{i-1}b_{i+1}\cdots b_{n}$ . If gi = ∑ ab;*xi e D[x], then $g_{1}=ag_{2}$ with $a=C(g_{1})$ $g_2\varepsilon D[x]$ and $g_{2}$ primitive. Verify that $g=(1_{D}/b)g_{1}=(a/b)g_{2}$ and deg $g=\deg g_{2}$ Similarly $h=(c/d)h_{2}$ with $c,d\in D,h_2\varepsilon D[x],h_2$ $h_2$ h2 primitive and deg h = deg h2. Consequently, $f=gh=(a/b)(c/d)g_{2}h_{2}$ ,whence = = $bdf=acg_2h_2$ . Since $f$ is primitive by hypothesis and $g_2h_2$ is primitive by Lemma 6.11,

$$bd=bdC(f)=C(bdf)=C(acg_2h_2)=acC(g_2h_2)=ac.$$

As in the proof of Lemma 6.12, bd and ac associates in $D$ imply that $f$ and g2h2 are

------------------------------------------------------------------

associates in $D[x]$ . Consequently, $f$ is reducible in $D[x].$ .which is a contradiction Therefore, $f$ is irreducible in $F[x]$

Conversely if $f$ is irreducible in $F[x]$ and $f=gh$ with $g,h\in D[x]$ then one of $g,h$ (say $g.$ ) is a constant by Corollary 6.4. Thus $C(f)=gC(h)$ . Since $f$ is primitive, $g$ must be a unit in $D$ and hence in $D[x].$ Therefore, $f$ is irreducible in $D[x]$ .

Theorem 6.14. IfD is a unigue factorization domain, then so is the polynomial ring $\mathbf{D}[\mathbf{x}_1,\ldots,\mathbf{x}_n]$

REMARK.Since a field $F$ is trivially a unique factorization domain, $F[x_1,\ldots,x_n]$ is a unique factorization domain.

SKETCH OF PROOF OF 6.14. We shall prove only that $D[x]$ is a unique factorization domain. Sincee $D[x_1,\ldots,x_n]=D[x_1,\ldots,x_{n-1}][x_n]$ by Corollary 5.7, a routine inductive argument then completes the proof. If $f\varepsilon D[x]$ has positive degree then $f=C(f)f_{1}$ with $f_1$ a primitive polynomial in $D[x]$ of positive degree. Since $D$ is a unique factorization domain, either $C(f)$ is a unit or $C(f)=c_1c_2\cdots c_m$ with each $c_i$ irreducible in $D$ and hence in $D[x]$ . Let $F$ be the quotient field of $D$ . Since $F[x]$ is a unique factorization domain (Corollary 6.4) which contains. $D[x],f_1=p_1{}^*p_2^*\cdots p_n{}^*$ with each $p_i^*$ an irreducible polynomial in $F[x]$ . The proof of Lemma 6.13 shows that. for each i, $p_{i}^{*}=(a_{i}/b_{i})p_{i}$ with ai,bi e D $a_{i,b_{i}\in D}$ bi≠0 $b_i\neq0$ $a_{i},b_{i}\varepsilon D,b_{i}\neq0,a_{i}/b_{i}\varepsilon F,p_{i}\varepsilon D[x]$ $a_{i}/b_{i}\in F$ ai/bieF and $p_i$ primitive. Clearly each $p_i$ is irreducible in $F[x]$ , whence each $p_i$ is irreducible in $D[x]$ by Lemma 6.13. If $a=a_{1}a_{2}\cdots a_{n}$ and $b=b_1b_2\cdots b_n$ , then $f_1=(a/b)p_1p_2\cdots p_n$ . Consequently, $bf_{1}=ap_{1}p_{2}\cdots p_{n}$ Since $f_{1}$ and $p_{1}p_{2}\cdots p_{n}$ are primitive (Lemma 6.11), it follows (as in theproofof Lemma 6.12) that $a$ and $b$ are associates in $D$ . Thus $a/b=u$ with $u$ a unit in $D$ . Therefore, if $C(f)$ is a nonunit, $f=C(f)f_{1}=c_{1}c_{2}\cdots c_{m}(up_{1})p_{2}\cdots p_{n}$ with each $c_i,p_i$ , and $up_1$ irreducible in $D[x]$ . Similarly, if $C(f)$ is a unit, $f$ is a product of irreducible elements in $D[x]$

(Uniqueness) Suppose $f$ is a nonprimitivepolynomial in $D[x]$ of positive degree. Verify that any factorization of fas a product of irreducible elements may be written $f=c_{1}c_{2}\cdots c_{m}p_{1}\cdots p_{n}$ with each $c_i$ irreducible in $D,C(f)=c_{1}\cdots c_{m}$ and each $p_i$ irre- ducible (and hence primitive) in $D[x]$ of positive degree. Suppose $f=d_{1}\cdots d_{r}q_{1}\cdots q_{s}$ with each $d_j$ irreducible in $D,C(f)=d_1\cdots d_r$ and each $q_i$ irreducible primitive in $D[x]$ of positive degree. Then $c_1c_2\cdots c_n$ and $d_1d_2\cdots d_r$ are associates in $D$ . Unique factorization in $D$ implies that $n=r.$ and (after reindexing) each $c_i$ is an associate of $d_i$ . Consequently, $p_1p_2\cdots p_n$ and $\zeta_1\zeta_2\cdots q_s$ are associates in $D[x]$ and hence in $F[x]$ Since each $p_i$ [resp. $q_i]$ is irreducible in $F[x]$ by Lemma 6.13, unique factorization in $F[x]$ (Corollary 6.4) implies that $n=s$ and (after reindexing) each $p_i$ is an associate of $q_i$ in $F[x].$ By Lemma 6.12 each $p_i$ is an associate of $q_i$ in $D[x]$ .

Theorem 6.15. (Eisenstein's Criterion). Let D be a unigue factorization domain with. quotien feld F. $If$f$= \sum _i= 0^n$ $a_ix^i\varepsilon$D[ x] , deg 2 and is a ireduibl elemen o D such that

$$p\nmid a_n;p|a_ifori=0,1,\ldots,n-1;p^2\nmid a_0,$$

------------------------------------------------------------------

thenf is irreducible inF[x]. Iff is primitive,thenf is irreducible in $D[x]$

PROOF. $f=C(f)f_{1}$ with $f_1$ primitive in $D[x]$ and $C(f)\in D$ ;(in particular $f_{1}=f$ if fis primitive). Since $C(f)$ is a unit in $F$ (Corollary 6.4), it suffices to show that $f_{\mathrm{i}}$ is irreducible in $F[x].$ By Lemma 6.13 we need only prove that $f_1$ is irreducible in $D[x]$ Suppose on the contrary that $f_1=gh$ with

and
$$g=b_{r}x^{r}+\cdots+b_{0}\varepsilon D[x],\deg g=r\geq1;\\h=c_{s}x^{s}+\cdots+c_{0}\varepsilon D[x],\deg h=s\geq1.$$

Now $P$ does not divide $C(f)$ (since $p\nmid a_n)$ , whence the coeffcents of f = a*x satisfy the same divisibility conditions with respect to $P$ as do the coeffcients of $f.$ Since $p$ divides $a_{0}^{*}=b_{0}c_{0}$ and every irreducible in $D$ is prime, either $p\mid b_0$ or $p\mid c_0$, say $p\mid b_0$ Since $p^2Ya_0^*$ $c_{\mathrm{n}}$ is nor divisible by $P$ . Now some coefficient $b_k$ of $g$ is not divisible by $p$ (otherwise $p$ would divide every coefficient of $gh=f_{\mathbf{l}}$ ,which would be a contradiction). Let $k$ be the least integer such that

$$p\mid b_i\quad\mathrm{for}\quad i<k\quad\mathrm{and}\quad p\nmid b_k.$$

Then $1\leq k\leq r<n$ Since $a_{k}{}^{*}=b_{0}c_{k}+b_{1}c_{k-1}+\cdots+b_{k-1}c_{1}+b_{k}c_{0}$ and $p\mid a_k^*,p$ must divide $b_kc_0$ whence $p$ divides $b_k$ or $c_0$ . Since this is a contradiction, $f_1$ must be irreducible in $D[x]$

EXAMPLE. If $f=2x^{5}-6x^{3}+9x^{2}-15\varepsilon\mathbf{Z}[x]$, then the Eisenstein Criterion with $p=3$ shows that $f$ is irreducible in both $\mathbf{Q}[x]$ and $\mathbf{Z}[x]$

EXAMPLE. Let $f=y^{3}+x^{2}y^{2}+x^{3}y+x\varepsilon R[x,y]$ with $R$ a unique factorization domain. Then $x$ is irreducible in $R[x]$ and $f$ considered as an element of $(R[x])[y]$ is primitive. Therefore,. $f$ is irreducible in $R[x][y]=R[x,y]$ by Theorem 6.14 and Eisenstein's Criterion (with.) $p=x$ and $D=R[x]$

For another application of Eisenstein's Criterion see Exercise 10. There is a lengthy method, due to Kronecker, for finding all the irreducible factors of a poly. nomial over a unique factorization domain,which has only a finite number of units, such as $\mathbf{Z}$ (Exercise 13). Other examples and techniques appear in Exercises 6-9

## EXERCISES

1. (a) If $D$ is an integral domain and $c$ is an irreducible element in $D$ ,then $D[x]$ is not a principal ideal domain. [Hinr: consider the ideal $(x,c)$ generated by $x$ and $c$ (b) $\mathbf{Z}[x]$ is not a principal ideal domain. (c) If $F$ is a field and $n\geq2$ , then $F[x_1,\ldots,x_n]$ is not a principal ideal domain. [Hinr: show that $x_1$ is irreducible in $F[x_{1},\ldots,x_{n-1}].$

2. If $F$ is a feld and $f,g\in F[x]$ withdeg $g\geq1$ , then there exist unique polynomials $f_0,f_1,\ldots,f_r\in F[x]$ such that deg $f_i<$ deg $g$ for all $i$ and

$$f=f_0+f_1g+f_2g^2+\cdots+f_rg^r.$$

3. Let $f$ be apolynomial ofpositivedegree over an integral domain $D$ (a)If char $D=0$ ,then $f^{\prime}\neq0$

------------------------------------------------------------------

(b) If char $D=p\neq0$ , then $f^{\prime}=0$ if and only if $f$ is a polynomial in $x^p$ (that is, $f=a_{0}+a_{p}x^{p}+a_{2p}x^{2p}+\cdots+a_{ip}x^{ip})$

4. If $D$ is a unique factorization domain, a E $D$ and $f\varepsilon D[x]$, then $C(af)$ and $aC(f)$ are associates in $D$

5. Let $R$ be a comutaive ring wihidenity and $f=\sum_{i=0}^na_ix^i\varepsilon R[x]$ .Then $f$ is unit in $R[x]$ if and only if $a_{0}$ is a unit in $R$ and $a_{1}$ a1 $a_1,\ldots,a_n$ $a_n$ an are nilpotent elements of $R$ (Exercise 1.12).

6. [Probably impossible with the tools at hand.] Let $p$ ? $\mathbf{Z}$ be a prime; let $F$ be a field and let $c\epsilon F$ . Then $x^p-c$ is irreducible in $F[x]$ if and only if $x^{p}-c$ has no root in $F$ . [Hint: consider two cases: char $F=p$ and char $F\neq p$ ]

7. If $f=\sum a_{i}x^{i}\varepsilon\mathbb{Z}[x]$ and $p$ is prime, let $\bar{f}=\sum\bar{a}_ix^i\varepsilon Z_p[x]$ , where $\bar{a}$ is the image of $a$ under the canonical epimorphism $\mathbf{Z}\to\mathbf{Z}_p$ (a) If $f$ is monic and $\bar{f}$ is irreducible in $Z_p[x]$ for some prime $p$ , then $f$ is irre-

ducible in $\mathbf{Z}[x]$ (b) Give an example to show that (a) may be falseif $f$ is not monic. (c) Extend (a) to polynomials over a unique factorization domain.

8. [Probably impossible with the tools at hand.] (a) Let c E $F$ , where $F$ is a field of characteristic p $p$ $p\left(p\right.$ prime). Then $x^{p}-x-c$ is irreducible in $F[x]$ if and only if $x^{p}-x-c$ has no root in $F$ (b) If char $F=0$ , part (a) is false. 9. Let $f=\sum_{i=0}a_{i}x^{i}\varepsilon\mathbf{Z}[x]$ have degree $n$ Suppos that for some $k$ $(0<k<n)$ and

some prime $p:p\nmid a_n;p\nmid a_k;p\mid a_i$ for all $0\leq i\leq k-1$ ; and $p^2Xa_0$ .Show that f has a factor $g$ of degree at least $k$ that is irreducible in $\mathbf{Z}[x]$

10. (a) Let $D$ be an integral domain and $c\varepsilon D$ . Let $f(x)=\sum_{i=0}^na_ix^i\varepsilon D[x]$ and f(x - c) = ≥ a(x - c) e D[x]. Then $f(x)$ is irreducible in $D[x]$ if and only if $f(x-c)$ is irreducible.

(b) For each prime $P$ , the cyclotomic polynomial $f=x^{p-1}+x^{p-2}+\cdots+x+1$ is irreducible in $\mathbf{Z}[x]$ .[Hinr: observe that $f=(x^{p}-1)/(x-1)$ ，whence $f(x+1)=((x+1)^p-1)/x.$ Use the Binomial Theorem 1.6 and Eisenstein's Criterion to show that $f(x+1)$ is irreducible in $\mathbf{Z}[x]$ ]

11.If $c_0,c_1,\ldots,c_n$ are distinct elements of an integral domain $D$ and $d_0,\ldots,d_n$ are any elements of $D$ , then there is at most one polynomial $f$ of degree $\leq n$ in $D[x]$ such that $f(c_{i})=d_{i}$ for $i=0,1,\ldots,n$ . [For the existence of $f$ , see Exercise 12]

12. Lagrange's Interpolation Formula. If $F$ is a feld, $a_0,a_1,\ldots,a_n$ are distinct ele ments of $F$ and $c_0,c_1,\ldots,c_n$ are any elements of $F$ ,then

$$f(x)=\sum_{i=0}^{n}\frac{(x-a_{0})\cdots(x-a_{i-1})(x-a_{i+1})\cdots(x-a_{n})}{(a_{i}-a_{0})\cdots(a_{i}-a_{i-1})(a_{i}-a_{i+1})\cdots(a_{i}-a_{n})}c_{i}$$

is the unique polynomial of degree $\leq n$ in $F[x]$ such that $f(a_i)=c_i$ for all $i$ [see Exercise I1].

13. Let $D$ be a unique factorization domain with a finite number of units and quotient field $F$ . If $f\varepsilon D[x]$ has degree $n$ and $c_0,c_1,\ldots,c_n$ are $n+1$ distinct ele

1

1

------------------------------------------------------------------

ments of $D$ , then $f$ is completely determined by $f(c_0),f(c_1),\ldots,f(c_n)$ according to Exercise 11. Here is Kronecker's Method for finding all the irreducible factors of $f$ in $D[x]$ (a) It suffices to find only those factors $g$ of degree at most $n/2$

(b) If $g$ is a factor of $f$, then $g(c)$ is a factor of $f(c)$ for all $c\varepsilon D$

(c) Let $m$ be the largest integer $\leq n/2$ and choose distinct elements $c_0,c_1$ Co,C1 $c_0,c_1,\ldots$,

$c_{m}$ E $D$ . Choose $d_0,d_1$ do,d, $d_0,d_1,\ldots,d_m\in D$ $d_m$ dm such that $d_i$ is a factor of $f(c_i)$ in $D$ for all i. Use

Exercise 12 to construct a polynomial $g\dot{\varepsilon}F[x]$ such that $g(c_{i})=d_{i}$ for all $i;$ it is unique by Exercise 11. (d) Check to see if the polynomial $g$ of part (c) is a factor of $f$in $F[x]$ . If not,

make a new choice of $d_0,\ldots,d_m$ dm $d_m$ and repeat part (c). (Since $\boldsymbol{D}$ is a unique factorization domain with only finitely many units there are only a finite number of possible choices for $d_0,\ldots,d_m.$ ) If $g$ is a factor of $f$, say $f=gh$ , then repeat the entire process on $g$ and $h$ (e) After a finite number of steps, all the (irreducible) factors of fin $F[x]$ will

have been found. If $g\varepsilon F[x]$ is such a factor (of positive degree) then choose r E $D$ such that $rg\varepsilon D[x]$ (for example, let $r$ be the product of the denominators of the coeffcients of $g$ ). Then $r^{-1}(rg)$ and hence $rg$ is a factor of $f.$ Then $rg=C(rg)g_{1}$ with $g_1\varepsilon D[x]$ primitive and irreducible in $F[x]$ .By Lemma 6.13, $g_1$ is an irreducible factor of $f$in $D[x]$ . Proceed in this manner to obtain all the nonconstant irreducible factors of $f;$ the constants are then easily found.

14. Let $R$ be a commutative ring with identity and $c,b\varepsilon R$ $R$ R with $c$ a unit. (a) Show that the assignment $x\vdash cx+b$ induces a unique automorphism of

$R[x]$ that is the identity of $R$ . What is its inverse? (b) If $D$ is an integral domain, then show that every automorphism of $D[x]$ that is the identity on $D$ is of the type described in (a).

15.If $F$ is a feld, then $x$ and $y$ are relatively prime in the polynomial domain $F[x,y]$ but $F[x,y]=(1_{F})\sum_{\not=}(x)+(y)$ [compare Theorem 3.11 (i)].

16. Let $f=a_nx^n+\cdots+a_0$ be a polynomial over the field R of real numbers and Jet $\varphi=|a_{n}|x^{n}+\cdots+|a_{0}|\varepsilon\mathbf{R}[x]$ (a) If $|u|\:\leqslant d$ , then $\left|f(u)\right|\leq\varphi(d)$ . [Recall that $|a+b|\leqslant|a|+|b|$ and

that $|a|\leqslant a^{\prime}$ ， $|b|\:\leqslant b^{\prime}\Rightarrow\:|ab|\:\leqslant a^{\prime}b^{\prime}.$ (b) Given a,c ε R with $c>0$ there exists $M\varepsilon R$ such that $|f(a+h)-f(a)|\leq$ $M|h|$ for all h ε R with $|h|\leq c$ . [Hinr: use part (a).] (c) (Intermediate Value Theorem) If $a<b$ and $f(a)<d<f(b)$ then there exists $c\varepsilon R$ such that $a<c<b$ and $f(c)=d$ . [Hint: Let $c$ be the least upper bound of $S=\{x\mid a<x<b\}$ and $f(x)\leq d\}$ . Use part (b).) (d) Every polynomial $g$ of odd degree in $R[x]$ has areal root. [Hint : for suitable a,b ε R, $g(a)<0$ and $g(b)>0$ ; use part (c).]

------------------------------------------------------------------

# MODULES

Modules over a ring are a generalization of abelian groups (which are modules over $\mathbf{Z}_{j}$ 0. They are basic in the further study of algebra. Section 1 is mostly devoted to carrying over to modules various concepts and results of group theory.Although the classification (up to isomorphism) of modules over an arbitrary ring is quite difficult, we do have substantially complete results for free modules over a ring (Section 2) and finitely generated modules over a principal ideal domain (Section 6). Free modules, of whichvector spaces over a divisionring are a special case,have widespread applica tions and are studied thoroughly in Section 2. Projective modules (a generalization of free modules) are considered in Section 3; this material is needed only in Section VIll.6 and Chapter IX. With the exception of Sections 2 and 6, we shall concentrate on external struc-

tures involving modules rather than on the internal structure of modules. Of particular interest are certain categorical aspects of the theory of modules: exact sequences (Section 1) and module homomorphisms (Section 4). In addition we shall study various constructions involving modules such as the tensor product (Section 5). Algebras over a commutative ring $K$ with identity are introduced in'Section 7. The approximate interdependence of the sections of this chapter is as follows:

![](https://storage.simpletex.cn/view/fsQc8YCg5EKRtcTMtqDx1OslzQoPG2q0U)

------------------------------------------------------------------

1.

# 1. MODULES, HOMOMORPHISMS AND EXACT SEQUENCES

Modules over a ring are a generalization of abelian groups (which are modules over $\mathbf{Z}$ ). Consequently, the first part of this section is primarily concerned with carrying over to modules various concepts and results of group theory. The remainder of the section presents the basic facts about exact sequences

Definition 1.1.Ler R be a ring. A (left) R-module is an addirice abelian group A together with a function. $\mathbf{R}\times\mathbf{A}\to\mathbf{A}$ (theimageof(r,a) being denoted by ra) such that for all r,s e R and a,b ε A:

(i)
$$\mathrm{r(a+b)=ra+rb.}$$

$$\mathrm{(r+s)a=ra+sa.}$$
(ii) $\mathrm{r(sa)}=(\mathbf{rs})$a If R has an identity element. $1_{R}$ and (iv) $\mathbf{1}_{\mathrm{R}}\mathbf{a}=\mathbf{a}$ for all a ε A,

then A is said to be a unitary R-module. If R is a division ring, then a unitary R-module is called a(left)vector space.

A (unitary) right $R$ -module is defined similarly via a function. $A\times R\to A$ de noted $(a,r)\vdash ar$ and satisfying the obvious analogues of (i)-(iv).From now on,unless specified otherwise, "R-module" means "left $R$ -module" and it is understood that all theorems aboutleft $R$ -modules also hold, mutatis mutandis, for right $R$ modules. A given group $A$ may have many different $R$ -module structures (both left and

right). If $R$ is commutative, it is easy to verify that every left $R$ -module $A$ can be given the structure of a right $R$ -module by defining $ar=ra$ for r E $R$ , a e A (commutativit) is needed for (ii); for a generalization of this idea to arbitrary rings, see Exercise 16) Unless specified otherwise, every module. $A$ over a commutativering $R$ is assumed to be both a left and a right module with $ar=ra$ for all $r\varepsilon R$ aEA

If $A$ is a module with additive identity element $0_{A}$ over a ring $R$ with additive identity $0_{R}$, then it is easy to show that for all r e $R$ aeA:

$$r0_{A}=0_{A}\quad\mathrm{and}\quad0_{R}a=0_{A}.$$

In the sequel $0_{A},0_{R},0_{\varepsilon}\mathbf{Z}$ and the trivial module {O} will all be denoted 0. It also is easy to verify that for all r e $R$ ,neZand ae $A$

$$(-r)a=-(ra)=r(-a)\quad\mathrm{and}\quad n(ra)=r(na),$$

where na has its usual meaning for groups (Definition I.1.8, additive notation)

EXAMPLE. Every additive abelian group $G$ is a unitary Z-module, with na $(n\in\mathbf{Z},a\in G)$ given by Definition I.1.8

EXAMPLE. If $S$ is a ring and $R$ is a subring, then $S$ is an $R$ -module (but not vice versa!) with ra $(r\varepsilon R,a\varepsilon S)$ being multiplication in $S$ .In particular, the rings $R[x_1,\ldots,x_m]$ and $R[[x]]$ are $R$ -modules

------------------------------------------------------------------

1

EXAMPLES. If $I$ is a lefr ideal of a ring $R$ , then $I$ is a left $R$ -module with $ra\left(r\varepsilon R,a\in I\right)$ being the ordinary product in $R$ . In particular, O and $R$ are $R$ -modules. Furthermore, sincee $I$ is an additive subgroup of $R,R/I$ is an (abelian) group. $R/I$ is an $R$ -module with $r(r_1+I)=rr_1+I.R/I$ need not be a ring, however, unless $I$ is a two-sided ideal.

EXAMPLE. Let $R$ and $S$ be rings and $\varphi:R\to S$ a ring homomorphism. Then every $S$ -module $A$ can be made into an $R$ -module by defining $rx\left(x\in A\right)$ to be $\varphi(r)x$ One says that the $R$ -module structure of $A$ is given by pullback along $\varphi$

EXAMPLE. Let $A$ be an abelian group and End $A$ its endomorphism ring (see p. 116). Then $A$ is a unitary (End $A$ )-module, with $fa$ defined to be $f(a)$ (for $a\varepsilon A$ A $A$ feEnd $A$ ）.

EXAMPLE. If $R$ is a ring, every abelian group can be made into an $R$ -module with trivial module structure by defining $ra=0$ for all $r\varepsilon R$ $R$ R and a ε $A$

[

|

Definition 1.2.Let A andB be modules over a ring R.A functionf $:\mathbf{A}\to\mathbf{B}$ isar R-module homomorphism provided that for all a,c ε A and r ε R:

$$\mathrm{f(a+c)=f(a)+f(c)\quad and\quad f(ra)=rf(a).}$$

IfR is a division ring,then an R-module homomorphism is called $a$ linear transformation.

When the context is clear $R$ -module homomorphisms are called simply homomorphisms. Observe that an $R$ -module homomorphism $f{:}A\to B$ is necessarily a homomorphism of additive abelian groups. Consequently the same terminology is used: $f$ is an R-module monomorphism [resp. epimorphism, isomorphism] if it is injective [resp. surjective, bijective] as a map of sets. The kernel of. $f$ is its kernel as a homomorphism of abelian groups, namely Ker $f=\{a\in A\mid f(a)=0\}$ . Similarly the image of $f$ is the set Im $f=\left\{b\in B\mid b\right.=f(a)$ for some a e $A$ . Finally, Theorem 1.2.3 implies: (i $f$ is an $R$ -module monomorphism if and only if Ker $f=0$

(ii) $f:A\to B$ is an $R$ -module isomorphism if and only if there is an $R$ -module homomorphism $g:B\to A$ such that $gf=1_{iA}$ and $f_{\mathcal{K}}=1_{B}$

EXAMPLES. For any modules the zero map $0:A\dashrightarrow B$ given by $a\vdash0(a\in A)$ is a module homomorphism. Every homomorphism of abelian groups is a $\mathbf{Z}$ -module homomorphism. If $R$ is a ring, the map $R[x]\to R[x]$ given by $f\vdash xf$ (for example $(x^{2}+1)\vdash x(x^{2}+1))$ is an $R$ -module homomorphism, but not a ring homomorphism.

REMARK. For a given ring $R$ the class of all $R$ -modules [resp. unitary $R$ -modules] and $R$ -module homomorphisms clearly forms a (concrete) category. In fact, one can define epimorphisms and monomorphisms strictly in categorical terms (objects and morphisms only — no elements); see Exercise 2.

------------------------------------------------------------------

Definition 1.3. Let R be a ring, A an R-module and B a nonempty subset ofA. B is a submodule of A provided that B is an additive subgroup of A and rb e B for all r e R, b eB.A submodule ofa vector space over a division ring is called a subspace

Note that a submodule is itself a module. Also a submodule of a unitary module over a ring with identity is necessarily unitary..

EXAMPLES. If $R$ is a ring and $:A\to B$ is an $R$ -module homomorphism, then Ker $f$ is a submodule of $A$ and Im $f$ is a submodule of $B$ . If $C$ is any submodule of $B$ then $f^{-1}(C)=\{a\varepsilon A\mid f(a)\varepsilon C\}$ is a submodule of $A$

EXAMPLE. Let I be a left ideal of the ring. $R$ $A$ an $R$ -module and $S$ a nonempty subset of $A$ Then IS = ra ;:e I; a; eS; n e N* is a submodule of $A$ (Exercise 3). Similarly if a e $A$ , then $Ia=\{ra\mid r\varepsilon I\}$ is a submodule of $A$

EXAMPLE. If $\{B_{\mathrm{i}}\mid i\in I\}$ is a family of submodules of a module $A$ , then $\bigcap B_i$ is easily seen to be a submodule of $A$

Definition 1.4. IfX is a subset ofa module A over a ring R, then the intersection of all submodules of A containing $X$ is called the submodule generated by $x$ (or spanned by $X$ ).

If $X$ is finite, and $X$ generates the module B $B$ $B,B$ $B$ B is said to be finitely generated. If $X=\varnothing$ , then $X$ clearly generates the zero module. If $X$ consists of a single element, $X=\{a\}$ , then the submodule generated by $X$ is called the cyclic (sub)module generated by $a$ . Finally, if $\{B_i\mid i\in I\}$ is a family of submodules of $A$ , then the submodule generated by $X=\bigcup_{i\in I}B_i$ is called the sum of the modules $B_i$ . If the index set $I$ is finite, the sum of $B_{1},\ldots,B_{n}$ is denoted $B_1+B_2+\cdots+B_n$

Theorem 1.5. Let R be a ring, A an R-module, $X$ a subset ofA,{B;|iεI}a family of submodules of A and a ε A. Let $\mathbf{Ra}=\{$ra|r$\varepsilon\mathbf{R}\}$

(i)Ra is a submodule of A and the map $\mathbf{R}\to\mathbf{R}$ givenby rh ra is anR-module epimorphism. (ii) The cyclic submodule C generated by a is $\{$ra+na|r$\varepsilon$R;n$\varepsilon\mathbf{Z}\}$ .IfR has an

identity and C is unitary, then $\mathbf{C}=\mathbf{R}$a (iii) The submodule D generated by $X$ is

$$\left\{\sum_{i=1}^s\mathrm{r_ia_i+\sum_{j=1}^{\prime}n_jb_j\mid s,t\in N^*;a_i,b_j\varepsilon X;r_i\varepsilon R;n_j\varepsilon Z}\right\}.$$

If R has an identity and A is unitary, ther.

$$\mathrm{D=RX=\left\{\sum_{i=1}^{s}r_{i}a_{i}\mid s\varepsilon N^{*};a_{i}\varepsilon X;r_{i}\varepsilon R\right\}.}$$

------------------------------------------------------------------

[

(iv) The sum of the family {B, |i e I} consists ofall finite sums $\mathbf{b}_{i_{l}}+\cdots+\mathbf{b}_{i_{n}}$ with $b_{ik}\varepsilon B_{ik}$

PROOF. Exercise; note that if $R$ has an identity $1_{R}$ and $A$ is unitary, then $n1_R\varepsilon R$ for all $n\varepsilon Z$ Z $\mathbf{Z}$ and $na=(n1_R)a$ for all a e $A$ .

1

|

1

Theorem 1.6. Let B be a submodule ofa module A over a ring R. Then the quotieni group $\mathbf{A}/\mathbf{B}$ is an R-module with the action of R on A/B given by.

$$\mathrm{r(a+B)=ra+B\quad for~all\quad r\varepsilon R,a\varepsilon A.}$$

The map $\pi:\mathbf{A}\to\mathbf{A}/\mathbf{B}$ given by a I- a + Bis an R-module epimorphism with kernel B.

The map $\pi$ is called the canonical epimorphism (or projection)

SKETCH OF PROOF OF 1.6. Since $A$ is an additive abelian group, $B$ is a normal subgroup, and $A/B$ is a well-defined abelian group. If $a+B=a^{\prime}+B$ then $a-a^{\prime}\varepsilon B$ . Since $B$ is a submodulei $ra-ra^{\prime}=r(a-a^{\prime})\varepsilon B$ for all r e R. Thus $ra+B=ra^{\prime}+B$ by Corollary I.4.3 and the action of $R$ on $A/B$ is well defined. The remainder of the proof is now easy. 

In view of the preceding results it is not surprising that the various isomorphism theorems for groups (Theorems I.5.6-I.5.12) are valid, mutatis mutandis, for modules One need only check at each stage of the proof to see that every subgroup or homomorphism is in fact a submodule or module homomorphism. For convenience we list these results here.

Theorem 1.7. If R is a ring andf : $\mathbf{A}\to\mathbf{B}$ is an R-module homomorphism andC is a submodule of Ker f, then there is a unique R-module homomorphism $\bar{\mathbf{f}}:\mathbf{A}/\mathbf{C}\to\mathbf{B}$ such that $\bar{\mathbf{f}}(\mathbf{a}+\mathbf{C})=\mathbf{f}(\mathbf{a})$ for all a ε A; Im = $\bar{\mathbf{f}}=$ $\bar{\mathbf{f}}=Im$ f and Ker = = $\bar{\mathbf{f}}=Ker$ f/C .Fis an R-module isomorphism if and only iff is an R-module epimor phism and = = $\mathbf{C}=Ker$ f.In particular A/Ker f Im f.

PROOF. See Theorem I.5.6 and Corollary I.5.7.

Corollary 1.8. IfR is a ring and $\mathbf{A^{\prime}}$ is a submodule of the R-module A and $\mathbf{B^{\prime}}$ usubmodule of the R-module B and $\mathbf{f}:\mathbf{A}\to\mathbf{B}$ is an R-module homomorphism such that $\mathbf{f}(\mathbf{A}^{\prime})\subset\mathbf{B}^{\prime}$ , then f induces an R-module homomorphism $\bar{\mathbf{f}}:\mathbf{A}/\mathbf{A}^{\prime}\to\mathbf{B}/\mathbf{B}^{\prime}$ givenby $\mathbf{a}+\mathbf{A}^{\prime}\vdash\mathbf{f}(\mathbf{a})+\mathbf{B}^{\prime}$ . is an R-module isomorphism if and only ifIm $\mathbf{f}+\mathbf{B}^{\prime}=\mathbf{B}$ and $\mathbf{f}^{-1}(\mathbf{B}^{\prime})\subset\mathbf{A}^{\prime}$ . In particular i ff is an epimorphism such that $\mathbf{f}(\mathbf{A}^{\prime})=\mathbf{B}^{\prime}$ and Ker f $\subset A^{\prime}$ then f is an R-module isomorphism

PROOF. See Corollary 1.5.8.

------------------------------------------------------------------



------------------------------------------------------------------

[

1

1

1

module homomorphism, $\varphi(rc)=\left\{\varphi_{i}(rc)\right\}_{iu}=\left\{r\varphi_{i}(c)\right\}_{iuI}=r\left\{\varphi_{i}(c)\right\}_{i,I}=r\varphi(c)$ and $\varphi$ is an $R$ -module homomorphism. Thus $\prod A_i$ is a product in the category of $R$ -modules (Definition I.7.2) and therefore determined up to isomorphism by Theorem I.7.3.

Theorem 1.13. If R is a ring, $\{\mathbf{A}_{\mathrm{i}}$ |ie I} a family of R-modules, Dan R-module, and $\{\psi_i:\mathbf{A}_i\to\mathbf{D}$ |ieI} a family ofR-module homomorphisms,then there is a unique R-module homomorphism $\psi:\sum_{ieI}\:\mathbf{A}_{\mathrm{i}}\rightarrow\mathbf{D}$ such that $\psi_{i_i}=\psi_{i}$ for all ie I. $\sum_{ieI}\mathbf{A_i}$ is uriquely determinedup to somorphsm by his prpery. Inothr wods, $\sum_{ieI}\mathbf{A}_{\mathrm{i}}$ isaco product in the category of R-modules

PROOF. By Theorem I.8.5 there is a unique abelian group homomorphism. $\psi:\sum A_i\to D$ with the desired property, given by $\psi(\{a_{i}\})=\tilde{\sum}_{i}\psi_{i}(a_{i})$ , where the sum is taken over the finite set of indices i such that $a_i\neq0$ . It is easy to see that $\psi$ is an $R$ -module map. Hence $\sum A_i$ is a coproduct in the category of $R$ -modules (Definition) I.7.4), and therefore, determined up to isomorphism by Theorem I.7.5.

Finite direct sums occur so frequently that a further description of them will be useful. We first observe that if $f$ and $g$ are $R$ -module homomorphisms from an. $R$ module $A$ to an $R$ -module $B$ , then the map $f+g:A\to B$ given by $a\mapsto f(a)+g(a)$ is also an $R$ -module homomorphism. It is easy to verify that the set $\mathrm{Hom_{R}(A,B)}$ of all $R$ -module homomorphisms $A\to B$ is an abelian group under this addition (Exercise 7). Furthermore addition of module homomorphisms is distributive with respec to composition of functions; that is,

$$h(f+g)=hf+hg\quad\mathrm{and}\quad(f+g)k=fk+gk,$$

where $f,g:A\to B$ $f,g:A\to B$ $f,g:A\to B,h:B\to C,k:D\to A$ $h:B\to C$ $h:B\to C$ $k:D\to A$ k:D→A

Theorem 1.14. Ler R be a ring and $\mathbf{A},\mathbf{A}_{1},\mathbf{A}_{2}$, .... $\mathbf{A}_{\mathrm{n}}$ R-modules. Then $\mathbf{A}\cong\mathbf{A}_{\mathrm{I}}\oplus$ $\mathbf{A}_{2}\oplus\cdots\oplus\mathbf{A}_{\mathrm{n}}$ if and only if for each $\mathbf{i}=1,2$, ...., n there are $R$ -module homomorphisms $\pi_{\mathrm{i}}:\mathbf{A}\to\mathbf{A}_{\mathrm{i}}$ and $\iota_{\mathrm{i}}:\mathbf{A}_{\mathrm{i}}\to\mathbf{A}$ such that

(i) $\pi_{\mathrm{i}l_{\mathrm{i}}}=1_{\mathrm{A}_{\mathrm{i}}}$ for $i=1,2$, ...,n; (i) $\pi_{\mathrm{j}}\iota_{\mathrm{i}}=0$ for $i\neq j$
$$\iota_1\pi_1+\iota_2\pi_2+\cdots+\iota_n\pi_n=1_A.$$

PROOF. $(\Rightarrow)$ If $A$ is the module $A_1\oplus A_2\oplus\cdots\oplus A_n$ , then the canonical injections $L_i$ and projections $\pi_i$ satisfy (i)-(iii) as the reader may easily verify. Likewise. if $A\cong A_1\oplus\cdots\oplus A_n$ ,under an isomorphism $f{:}A\to A_1\oplus\cdots\oplus A_n$ , then the homomorphismse $\pi_{i}f\colon A\to A_{i}$ and $f^{-1}\iota_i:A_i\to A$ satisfy (i)-(ii) $(\Leftarrow)$ Let $\pi_i:A\to A_i$ and $u:A_{i}\to A$ $(i=1,2,\ldots,n)$ satisfy (i)-(ii). Let

$\pi_i^{\prime}:A_1\oplus\cdots\oplus A_n\to A_i$ and $\iota_{i}^{\prime}:A_{i}\to A_{1}\oplus\cdots\oplus A_{n}$ be the canonical projections and injections. Let $\varphi:A_{1}\oplus\cdots\oplus A_{n}\to A$ be given by $\varphi=\iota_{1}\pi_{1}^{\prime}+\iota_{2}\pi_{2}^{\prime}+\cdots+\iota_{n}\pi_{n}^{\prime}$ and $\psi:A\to A_1\oplus\cdots\oplus A_n$ by $=\iota_1^{\prime}\pi_1+\iota_2^{\prime}\pi_2+\cdots+\iota_n^{\prime}\pi_n$ . Ther

$$\varphi\psi\:=\:\left(\sum_{i=1}^{n}\:\iota_{i}\pi_{i}'\right)\:\left(\sum_{j=1}^{n}\:\iota_{j}'\pi_{j}\right)=\sum_{i=1}^{n}\:\sum_{j=1}^{n}\:\iota_{i}\pi_{i}'\:\iota_{j}'\pi_{j}\:=\:\sum_{i=1}^{n}\:\iota_{i}\pi_{i}'\:\iota_{i}'\pi_{i}$$

------------------------------------------------------------------

$$=\sum_{i=1}^{n}\iota_{i}\mathbf{1}_{A_{i}}\pi_{i}=\sum_{i=1}^{n}\iota_{i}\pi_{i}=\mathbf{1}_{A}.$$

Simlaly $\psi\varphi=\sum_{i=1}^{n}\sum_{j=1}^{n}\iota_{i}^{\prime}\pi_{i}\iota_{j}\pi_{i}^{\prime}=\sum_{i=1}^{n}\iota_{i}^{\prime}\pi_{i}^{\prime}=1_{A_{1}}\oplus\cdots\oplus A_{n}$ Therefore, $\varphi$ is an isomorphism by Theorem I.2.3.

Theorem 1.15. Let R be a ring and $\left\{\mathbf{A}_{\mathrm{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\right\}a$ family of submodules ofan R-module A such that

(i) A is the sum of the family $\{\mathbf{A}_{\mathrm{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\}$ (i) for each k e I, $A_k$ n $\mathbf{A}_{\mathrm{k}}^{*}=0$ ,where $\mathbf{A}_{k}^{*}$ is the sum of the family. $\{\mathbf{A}_{\mathrm{i}}|\mathbf{i}\neq\mathbf{k}\}$ Then there is an isomor phism $\mathbf{A}\cong\sum_{ieI}\mathbf{A}_{\mathrm{i}}$

PROOF. Exercise; see Theorem I.8.6.

A module $A$ is said to be the (internal)direct sum of a family of submodules $\{A_i\mid i\in I\}$ provided that $A$ and $\{A_i\}$ satisfy the hypotheses of Theorem 1.15. As in the case of groups, there is a distinction between internal and external direct sums. If a module $A$ is the internal direct sum of modules $A_i$ , then by definition each of the. $A_i$ isactually a submodule of $A$ and $A$ isisomorphic to the external diret sum $\sum_{i\in I}A_i$ However the external direct sum $\sum_{i\in I}A_i$ does nor contain the modules $A_i$, but only isomorphic copies of them(namely the $\iota_i(A_i)$ Li(Ai) $\iota_{\mathrm{i}}(A_{i})-$see Theorem 1.11 and Exercise 1.8.10). Since this distinction is unimportant in practice, the adjectives “internal and “external' will be omitted whenever the context is clear and the following notation will be used.

NOTATION. We write $A=\sum_{ieI}A_i$ to indicate that the module $A$ is the internal direct sum of the family of submodules $\{A_i\mid i\in I\}$

Definition 1.16. A pair of module homomorphisms, $\mathbf{A}\overset{\mathbf{f}}{\operatorname*{\to}}\mathbf{B}\overset{\mathbf{g}}{\operatorname*{\to}}\mathbf{C}$ , is said to be exact at B provided Im f $\dot{}=$ Ker g. A finite sequence ofmodule homomorphisms, $\mathbf{A}_{0}\stackrel{\mathbf{f}_{1}}{\rightarrow}\mathbf{A}_{1}\stackrel{\mathbf{f}_{2}}{\rightarrow}$ $\mathbf{A}_{2}\stackrel{\mathrm{f}_{3}}{\operatorname*{\longrightarrow}}\ldots\stackrel{\mathrm{f}_{n-1}}{\operatorname*{\longrightarrow}}\mathbf{A}_{n-1}\stackrel{\mathrm{f}_{n}}{\operatorname*{\longrightarrow}}\mathbf{A}_{n}$ , isexact provided Im f; = Ker $f_{i+1}$ fori = 1,2, ...,n - 1. An infinite sequence of module homomorphisms, ..i! Ai-1 $A_{\mathrm{i-1}}$ $\mathbf{A_{i-1}\overset{f_{i}}{\operatorname*{\operatorname*{\longrightarrow}}}A_{i}\overset{f_{i+1}}{\operatorname*{\operatorname*{\longrightarrow}}}A_{i+1}\overset{f_{i+2}}{\operatorname*{\operatorname*{\longrightarrow}}}}.$ .· is exact provided Im $\mathbf{f_{i}}=Ker\:\mathbf{f_{i+1}}$ $f_{i+1}$ $f_{i+1}$ for allieZ

When convenient we shall abuse the language slightly and refer to an exact se quence of modules rather than an exact sequence of module homomorphisms

EXAMPLES. Note frst that for any module $A.$ , there are unique module homomorphisms $0\to A$ and $A\to0$ . If $A$ and $B$ are any modules then the sequences $0\to A\overset{!}{\operatorname*{\rightarrow}}A\oplus B\overset{\pi}{\operatorname*{\rightarrow}}B\to0$ and $0\to B\overset{\leftarrow}{\operatorname*{\rightarrow}}A\oplus B\overset{\pi}{\operatorname*{\rightarrow}}A\to0$ are exact, where the t's and $\pi$ 's are the canonical injections and projections respectively. Similarly, if $C$ is a submodule of $D$ , then the sequence $0\to C\overset{i}{\operatorname*{\rightarrow}}D\overset{p}{\operatorname*{\rightarrow}}D/C\to0$ is exact, where $i$ is the

------------------------------------------------------------------



------------------------------------------------------------------

Thus $g^{\prime}[\beta(b)-b^{\prime}]=0$ and $\beta(b)-b^{\prime}$ εKer $g^{\prime}=$Im $f^\prime$ by exactness, say $f^{\prime}(a^{\prime})=\beta(b)-b^{\prime}$ $a^{\prime}\varepsilon A^{\prime}$ . Since $\alpha$ is an epimorphism, $a^{\prime}=\alpha(a)$ for some a E $A$ Consider $b-f(a)\varepsilon B$

$$\beta[b-f(a)]=\beta(b)-\beta f(a).$$

By commutativity, $\beta f(a)=f^{\prime}\alpha(a)=f^{\prime}(a^{\prime})=\beta(b)-b^{\prime}$ ;hence

$$\beta[b-f(a)]=\beta(b)-\beta f(a)=\beta(b)-(\beta(b)-b')=b'$$

and $\beta$ is an epimorphism.

(ii) is an immediate consequence of (i) and (i)

Two short exact sequences are said to be isomorphic if there is a commutative diagram of module homomorphisms

$$\overset{0\rightarrow A\rightarrow B\rightarrow C\rightarrow0}{\operatorname*{\underset{0\rightarrow A^{\prime}\rightarrow B^{\prime}\rightarrow C^{\prime}\rightarrow0}{\operatorname*{\underset{0\rightarrow A^{\prime}\rightarrow B^{\prime}\rightarrow C^{\prime}\rightarrow0}{\operatorname*{\longrightarrow}}}}}}$$

such that $f,g:$ and $h$ are isomorphisms. In this case, it is easy to verify that the diagram

$$0\to A\to B\to C\to0\\0\to A^{\prime}\to B^{\prime}\to C^{\prime}\to0$$

(with the same horizontal maps) is also commutative.In fact,isomorphism of shor exact sequences is an equivalence relation (Exercise 14).

Theorem 1.18. Ler R be a ring and $0\to\mathbf{A}_{1}\overset{\mathrm{f}}{\operatorname*{\rightarrow}}\mathbf{B}\xrightarrow{\mathrm{g}}\mathbf{A}_{2}\to0$ a short exact sequence of R-module homomorphisms. Then the following conditions are equivalent.

(i) There is an R-module homomorphism $\mathbf{h}:\mathbf{A}_2\to\mathbf{B}$ with $\mathbf{gh}=\mathbf{1}_{A2}$ iT hereis anR-modle homomorhtsm $\mathbf{k}:\mathbf{B}\to\mathbf{A}_{\mathrm{l}}$ withs $\mathbf{kf}=\mathbf{1}_{\mathbf{A}_{1}}$ A. $\mathbf{A}_{\mathbf{l}}$ $\mathbf{A}_{2}$ tothe

direct sum short exact sequence $0\to\mathbf{A}_1\overset{\leftarrow1}{\operatorname*{\rightarrow}}\mathbf{A}_1\oplus\mathbf{A}_2\overset{\pi_2}{\operatorname*{\rightarrow}}\mathbf{A}_2\to0$ ;in particular $\mathbf{B}\cong\mathbf{A}_{1}\oplus\mathbf{A}_{2}$

A short exact sequence that satisfies the equivalent conditions of Theorem 1.18 is said to be split or a split exact sequence

SKETCH OFPROOF OF 1.18. = $\Rightarrow$ $(\mathrm{i})\Rightarrow(\mathrm{ii}$i) By Theorem 1.13 the homomorphisms $f$ and $h$ induce a module homomorphism. $\varphi:A_1\oplus A_2\to B$ ，given by $(a_1,a_2)\vdash f(a_1)+h(a_2)$ .Verify that the diagram

------------------------------------------------------------------

1

$$\begin{array}{c}0\to A_1\overset{t_1}{\to}A_1\bigoplus A_2\overset{\pi_2}{\to}A_2\to0\\1_{A_1}\\0\to A_1\overset{f}{\longrightarrow}B\overset{g}{\longrightarrow}A_2\overset{g}{\to}0\end{array}$$

is commutative (use the fact that $gf=0$ and $gh\:=\:1_{A_2})$ . By the Short Five. Lemma $\varphi$ is an isomorphism. = $\Longrightarrow$ $(\mathrm{ii})\Rightarrow(\mathrm{iii})$ The diagram

$$\begin{array}{c}0\to A_1\xrightarrow{f}B\xrightarrow{g}A_2\xrightarrow{g}0\\1_{A_1}\\1_{A_1}\\0\to A_1\overset{\iota_1}{\to}A_1\bigoplus A_2\overset{\pi_2}{\to}A_2\overset{\star}{\to}0\end{array}$$

is commutative, where. $\psi$ is the module homomorphism given by $\psi(b)=(k(b),g(b))$ (see Theorem 1.12). Hence the short Five Lemma implies $\psi$ is an isomorphism. $(\mathrm{iii})\Rightarrow(\mathrm{i})$ , (ii) Given a commutative diagram with exact rows and $\varphi$ an isomor-

phism:

$$\begin{array}{c}0\to A_1\xrightarrow{\iota_1}A_1\oplus A_2\xrightarrow{\pi_2}A_2\to0\\1_{A_1}\\0\to A_1\xrightarrow{f}B\xrightarrow{g}A_2\to0,\end{array}$$

define $h:A_2\to B$ to be $\varphi\iota_2$ and $k:B\to A_1$ to be $\pi_1\varphi^{-1}$ . Use the commutativity of the diagram and the facts Tili = 1Ai $\pi_{i}\iota_{i}=1_{A_{i}}$ $\pi_{i}\iota_{i}=1_{A_{i}},\varphi^{-1}\varphi=1_{A_{1}\oplus A_{2}}$ to show that $kf=1_{A_{1}}$ and $gh=1_{A_2}$

### EXERCISES

Note: $R$ is a ring.

1. If $A$ is an abelian group and $n>0$ an integer such that $na=0$ for all a ε $A$ then $A$ is a unitary $Z_n$ -module, with the action of $Z_n$ on $A$ given by $\bar{k}a=ka$ where $k\varepsilon Z$ and $k\vdash\bar{k}\in Z_n$ under the canonical projection $\mathbf{Z}\to\mathbf{Z}_n$

2. Let $f{:}A\to B$ be an $R$ -module homomorphism. (a) $f$ is a monomorphism if and only if for every pair of $R$ -module homomor-

phisms $g,h:D\to A$ such that $fg=fh$ ,we have $g=h$ . [Hint: to prove $(\Leftarrow)$ ,let $D=$Ker $f$, f $f$, with $g$ the inclusion map and $h$ the zero map.] (b) $f$ is an epimorphism if and only if for every pair of $R$ -module homomor-.

phisms $k,t:B\to C$ such that $kf=tf$, we have $k=1$ . [Hint: to prove $(\Leftarrow)$ ,let $k$ be the canonical epimorphism $B\to B/\mathbf{Im}$ fand $t$ the zero map.]

3. Let $I$ be a left ideal of a ring $R$ and $A$ an $R$ -module

(a) If $S$ is a nonempty subset of $A$ , then $IS=\left\{\sum_{i=1}^{n}r_{i}a_{i}\mid n\in\mathbf{N}^{*};r_{i}\varepsilon I;a_{i}\varepsilon S\right\}$ is a submodule of $A$ . Note that if $S=\{a\}$ ,then $IS=Ia=\{ra\mid r\varepsilon I\}$

1

1

1

1

------------------------------------------------------------------



------------------------------------------------------------------

12. (The Five Lemma). Let

$$\begin{gathered}
A_{1}\rightarrow A_{2}\rightarrow A_{3}\rightarrow A_{4}\rightarrow A_{5} \\
\begin{array}{c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c}&&&&&&&&&&&&&&&\\&\alpha_1&&&&&&&&&&&&&&\\&&&&&&&&&&&&&&\end{array} \\
B_1\to B_2\to B_3\to B_4\to B_5 
\end{gathered}$$

be a commutative diagram of $R$ -modules and $R$ -module homomorphisms, with exact rows. Prove that:

(a) $\alpha_1$ an epimorphism and $\alpha_2,\alpha_4$ monomorphisms $\Rightarrow\alpha_3$ is a monomorphism (b) $\alpha_5$ a monomorphism and $\alpha_2,\alpha_4$ epimorphisms $\Rightarrow\alpha_3$ is an epimorphism.

13. (a) If $0\to A\to B\xrightarrow{f}C\to0$ and $0\to C\overset{g}{\operatorname*{\rightarrow}}D\to E\to0$ are short exact sequences of modules, then the sequence $0\to A\to B\overset{of}{\operatorname*{\rightarrow}}D\to E\to0$ is exact. (b) Show that every exact sequence may be obtained by splicing together suitable short exact sequences as in (a).

14. Show that isomorphism of short exact sequences is an equivalence relation.

15. If $f:A\to B$ and $g:B\to A$ are $R$ -module homomorphisms such that $gf=1_{A}$ then $B=$Im$f\oplus$Ker g

16. Let $R$ be a ring and $R^{op}$ its opposite ring (Exercise II1.1.17). If $A$ is a left [resp. right] $R$ -module, then $A$ is a right [resp. left] $R^{op}$ -module such that $ra=ar$ for all $a\varepsilon A,r\varepsilon R,r\varepsilon R^{op}$

17. (a) If $R$ has an identity and $A$ is an $R$ -module, then there are submodules $B$ and $C$ of $A$ such that $B$ is unitary, $RC=0$ and $A=B\oplus C$ . [Hint: let $B=\{1_{R}a\mid a\in A\}$ and $C=\{a\varepsilon A|1_{R}a=0\}$ and observe that for all ae $A$ $a-1_{R}a\varepsilon C.$ (b) Let $A_1$ be another $R$ -module, with $A_{1}=B_{1}\oplus C_{1}$ ${:}B_{1}$ unitary, $RC_{1}=0$ 0.If

$f:A\to A_1$ is an $R$ -module homomorphism then $f(B)\subset B_1$ and $f(C)\subset C_{\mathbf{i}}$ (c) If the map $f$ of part (b) is an epimorphism [resp. isomorphism], then so are $f\mid B:B\to B_1$ and $f\mid C:C\to C_{\mathbf{l}}$

18. Let $R$ be a ring without identity. Embed $R$ in a ring $S$ with identity and characteristic zero as in the proof of Theorem IIl.1.10. Identify $R$ with its image in $S$ (a) Show that every element of $S$ may be uniquely expressed in the form $r1_{s}+n1_{S}\left(r\varepsilon R,n\varepsilon\mathbf{Z}\right)$

(b) If $A$ is an $R$ -module and $a\epsilon A.$ ,show that there is a unique $R$ -module

homomorphism $f{:}S{\rightarrow}A$ such that $f(\mathbf{l}_{s})=a$ . [Hinr: Let $f(r|_S+n|_S)=ra+$ na.]

1

1

1

## 2. FREE MODULES AND VECTOR SPACES

In this section we study free objects in the category of modules over a ring. Such free modules, the most important examples of which are vector spaces over a division ring (Theorem 2.4), have widespread applications in many areas of mathematics. The special case of free abelian groups . $\mathbf{Z}$ modules) will serve as a model for the first part of this section. The remainder of the section consists of a discussion of the dimension (or rank) of a free module (Theorems 2.6-2.12) and an investigation of

1

1

------------------------------------------------------------------

the special properties of the dimension of a vector space (Theorems and Corollaries 2.13-2.16).

A subset $X$ of an $R$ -module $A$ is said to be linearly independent provided that for distinct $x_1,\ldots,x_n\in X$ and $r_i\varepsilon R$

$$r_1x_1+r_2x_2+\cdots+r_nx_n=0\quad\Rightarrow\quad r_i=0\quad\mathrm{for~e}$$
everyi

A set that is not linearly independent is said to be linearly dependent. If $A$ is generated as an $R$ -module by a set $Y.$ then we say that $Y$ spans $A$ . If $R$ has an identity and $A$ is unitary, $Y$ spans $A$ if and only if every element of $A$ may be written as a linear combination: $r_1y_1+r_2y_2+\cdots+r_ny_n(r_i\varepsilon R,y_i\varepsilon Y)$ ; see Theorem 1.5. A linearly inde-. pendent subset of $A$ that spans $A$ is called a basis of $A.$ Observe that the empty sel is (vacuously) linearly independent and is a basis of the zero module (see Definition 1.4).

Theorem 2.1.Let R be a ring with identity. The following conditions on a unitary R-module F are equivalent:

(i) F has a nonempty basis; (ii) F is the internal direct sum of a family ofcyclic R-modules, each of which is.

isomorphic as a left R-module to R; (ii)Fis R-module isomorphic to a direct sum ofcopies of the left R-module R;

(iv) there exists a nonempty set $X$ and a function $\iota:\mathbf{X}\to\mathbf{F}$ with the following

property: given any unitary R-module A and function f. $:\mathbf{X}\to\mathbf{A}$ , there exists a unique. R-module homomorphism $\mathbf{\bar{f}}:\mathbf{F}\to\mathbf{A}$ such that $\bar{\mathbf{f}}\iota=\mathbf{f}.$ In other words, F is a free object. in the category of unitary R-modules.

The theorem is proved below. A unitary module $F$ over a ring $R$ with identity which satisfies the equivalent conditions of Theorem 2.1, is called a free R-module on the set $X.$ By Theorem 2.1 (iv), $F$ is a free object in the category of all unitary left $R$ -modules. But such an $F$ is not a free object in the category of all left $R$ -modules (Exercise 15). By definition the zero module is the free module on the empty set. It is possible to define free modules in the category of all left $R$ -modules over an

arbitrary ring $R$ (possibly without identity); see Exercise 2. Such a free module is not isomorphic to a direct sum of copies of $R$ ,even when $R$ does have an identity (Exercise 2). In a few carefully noted instances below, certain results are also valid for these free modules in the category of all left $R$ -modules. However, unless stated otherwise, the term “free module" will always mean a unitary free module in the sense of Theorem 2.1.

SKETCH OF PROOF OF 2.1. $(\mathrm{i})\Rightarrow$ (i) Let $X$ be a basis of $F$ and $x\in X.$ The map $R\to Rx$ ,given by $r\mapsto rx$ , is an $R$ -module epimorphism by Theorem 1.5. If $rx=0$ , then $r=0$ by linear independence,whence themap is a monomorphism and $R\cong Rx$ as left $R$ -modules. Verify that $F$ is the internal direct sumof the cyclic modules $Rx\left(x\in X\right)$

$\Longrightarrow$ = $(\mathrm{ii})\Rightarrow(\mathrm{iii})$ Theorem 1.15 and Exercise 1.8. $(\mathrm{iii})\Rightarrow(\mathrm{i})$ Suppose $F\cong\sum R$ and the copies of $R$ are indexed by a set $X$ .For each

$x\varepsilon X$ let $\theta_x$ be the element $\{r_i\}$ of $\sum R$ ,where $r_i=0$ for $i\neq x$ and $r_{x}=1_{R}$ . Verify that $\{\theta_x\mid x\in X\}$ is a basis of $\sum_{\boldsymbol{R}}$ and use the isomorphism $F\cong\sum_{\boldsymbol{R}}$ to obtain a basis of $F$ $(\mathrm{i})\Rightarrow($iv) Let $X$ be a basis of $F$ andt : $X\to F$ the inclusion map. Suppose we are

------------------------------------------------------------------

given a map $f:X\to A$ If $u\in F.$ then $u=\sum_{i=1}^{n}r_{i}x_{i}\left(r_{i}\varepsilon R,x_{i}\:\varepsilon X\right)$ since $X$ spans $F.$ If = ∑ six: (si e R), then ∑ (r: - si)x; = O, whence $r_{i}=s_{i}$ for every $i$ by linear independence. Consequently, the map $\bar{f}:F\to A$ given by

$$\bar{f}(u)=\bar{f}\biggl(\sum_{i=1}^nr_ix_i\biggr)=\sum_{i=1}^nr_if(x_i)$$

is a well-defined function such that $\bar{f}_{\iota}=f.$ Verify that $\bar{f}$ is an $R$ -module homomorphism. Since $X$ generates $F$ any $R$ -module homomorphism $F\to A$ is uniquely deter-. mined by its action on $X$ . Thus, if $g:F\to A$ is an $R$ -module homomorphism such that $g\iota=f$, then for every $x$ $\varepsilon X, g( x) =$ $g( u( x) ) =$ $f( x) = \bar{f} ( x)$ whence $g=\bar{f}$ and $\bar{f}$ is unique. Therefore, by Defnition $\mathbf{I.7.7}\boldsymbol{F}$ F $F$ is a free object on the set $X$ in the cate gory of unitary $R$ -modules. (iv$) \Rightarrow ($iii) Given t: $:X\to F$ construct the direct sum $\sum_{R}$ , with one copy of $R$ for

each $x\varepsilon X.$ Let $Y=\left\{\theta_{x}\mid x\in X\right\}$ be the basis of the (unitary) $R$ -module $\sum R$ as in the proof of (iii$) \Rightarrow ($i) . The proof of ( ( iii) $\Rightarrow$( i) $\Rightarrow$( iv) shows that $\sum_{\boldsymbol{R}}$ is a free object on the set $Y$ in the category of $R$ -modules (with $\dot{Y}\to\sum\boldsymbol{R}$ the inclusion map). Since $|X|=|Y|$ , the proof of Theorem I.7.8 implies that there is an $R$ -module isomorphism $f:F\cong\sum R$ such that $f(u(X))=Y$ .■

REMARKS. (a) If $F$ is a free $R$ -module on a set $X(\iota:X\to F)$ ,then the proof of (iv$) \Rightarrow ($iii) of Theorem 2.1 implies that $\iota(X)$ is actually a basis of $F$

(b) Conversely, the proof of $(\mathbf{i})\Rightarrow(\mathbf{i}\mathbf{v})$ of Theorem 2.1 shows that if $X$ is a basis of a unitary module $F$ over a ring $R$ with identity, then $F$ is free on $X$ ,with: $:X\to F$ the inclusion map. (c) If $X$ is any nonempty set and $R$ is a ring with identity, then the proof of

Theorem 2.1 shows how to construct a free $R$ -module on the set $X$ .Simply let $F$ be the direct sum $\sum_{R}$ , with the copies of $R$ indexed by the set $X$ In the notation of the proof, $\{\theta_x\mid x\in X\}$ is a basis of $F$ so that $F=\sum_{x\in X}R\theta_{x}$ Since the map $\iota:X\to F$ given by $x|\mapsto\theta_x$ ,is injective it follows easily that $F$ is free on $X$ in the sense of condition (iv) of Theorem 2.1. In this situation we shall usually identify $X$ with its image under $\iota$ writing $x$ in place of $\theta_x$ So that $X\subset F$ In this notation $F=\sum_{x\in X}R\theta_{x}$ is writen as $\sum_{x\in X}Rx$ and a typical element of $F$ has the form $r_1x_1+\cdots+r_nx_n$ Frx $r_nX_n$ $( r_{i}\varepsilon$ $R; x_{i}$ $\varepsilon$ $X)$ In particular, $X=\iota(X)$ is a basis of $F$ (d) The existence of free modules on a given set in the category of all modules

over an arbitrary ring (possibly without identity) is proved in Exercise 2.

i

1

一

1

1

Corollary 2.2. Every (unitary) module A over a ring R (with identity) is the homomor phic image ofa free R-module F. IfA is finitely generated, then F may be chosen to be finitely generated.

REMARK.Corollary 2.2 and itsproof are valid if the words inparentheses are deleted and “free module'' is taken to mean a free module in the category of all leff modules over an arbitrary ring (as defined in Exercise 2).

1

1

------------------------------------------------------------------

SKETCH OF PROOF OF 2.2. Let $X$ be a set of generators of $A$ and $F$ thefree $R$ -module on the set $X.$ .Then the inclusion map $X\to A$ induces an $R$ -module homomorphism $\bar{f}:F\to A$ such that $X\subset Im$ $\bar{f}$ (Theorem 2.1 (iv)). Since $X$ generates $A$ we must have Im $\bar{f}=A$ .

REMARK. Unlike the situation with free abelian groups, a submodule of a free module over an arbitrary ring need not be free. For instance {0,2,4} is a submodule of $Z_{6}$, but is clearly not a free $Z_6$ -module; compare Theorem I1.1.6 and Theorem 6.1 below.

Vector spaces over a division ring $D$ (Definition 1.1) are important, among other reasons, because every vector space over $D$ is in fact a free $D$ -module. To prove this we need

Lemma 2.3.A maximal linearly independent subset $\mathbf{X}$ ofa vector spaceV overa division ringDis a basis ofV

PROOF. Let $W$ be the subspace of $V$ spanned by the set $X$ .Since $X$ is linearly independent and spans $W,X$ is a basis of $W$ . If $W=V$ ,we are done. If not, then there exists a nonzero a e $V$ with $a\notin W$ . Consider the set $X\cup\{a\}$ . If $ra+r_{1}x_{1}+\cdots+$ $r_{n}x_{n}=0\left(r,r_{i}\varepsilon D,x_{i}\varepsilon X\right)$ and $r\neq0$ , then $a=r^{-1}(ra)=-r^{-1}r_{1}x_{1}-\cdots-r^{-1}r_{n}x_{n}\varepsilon W$ which contradicts the choice of a.Hence $r=0$ ,which implies $r_i=0$ for allisince $X$ is linearly independent. Consequently $X\cup|a\}$ is a linearly independent subset of $V$ contradicting the maximality of $X.$ . Therefore $W=V$ and $X$ is a basis.

Theorem 2.4. Every vector space V over a division ring D has a basis and is therefore. a free D-module. More generally every linearly independent subsetof V is contained in. a basis of V.

The converse of Theorem 2.4 is also true, namely, if every unitary module over a ring $D$ with identity is free, then $D$ is a division ring (Exercise 3.14).

SKETCH OF PROOF OF 2.4. The first statement is an immediate consequence of the second since the null set is a linearly independent subset of every vector space. Consequently, we assume that $X$ is any linearly independent subset of $V$ and letSbe theset of all linearly independent subsets of $V$ that contain $X$ Since $X\in S,S\neq\varnothing$ . Partially order S by set theoretic inclusion. If $\left\{C_i\mid i\in I\right\}$ is a chain in S verify that the set $C=\bigcup_{i\epsilon l}C_{i}$ is linearly independent and hence an lement of S. Clearly $C$ is an upper bound for the chain $\left\{C_i\mid i\in I\right\}$ . By Zorn's Lemma S contains a maximal element $B$ that contains $X$ and is necessarily a maximal linearly independent subset of $V$ .By Lemma $2.3B$ is a basis of $V$ .

------------------------------------------------------------------

SKETCH OF PROOF. Partially order the set S of all linearly independent subsets of $X$ by inclusion. Zorn's Lemma implies the existence of a maximal linearly independent subset $Y$ of $X$ . Every element of $X$ is a linear combination of elements of $Y$ (otherwise, as in Lemma 2.3, we could construct a linearly independent subset of $X$ that properly contained $Y$ , contradicting maximality). Since $X$ spans $V$ ,so does $Y$ Hence $Y$ is a basis of $V$ .■

In the case of free abelian groups $\mathbf{Z}$ -modules) we know that any two bases of a free $\mathbf{Z}$ -module have the same cardinality (Theorem II.1.2). Unfortunately, this is not true for free modules over arbitrary rings with identity (Exercise 13).We shall now show that vector spaces over a divisionring and free modules over a commutative ring with identity have this property.

1

1

Theorem 2.6.Let R be a ring with identity and F a free R-module with an infinite basis $X$ .Then every basis ofF has the same cardinality as $X$

PROOF. If $Y$ is another basis of $F$ ,then we claim that $Y$ is infinite. Suppose on the contrary that $Y$ were finite. Since $Y$ generates $F$ and every element of $Y$ is a linear combination of a finite number of elements of $X$ , it follows that there is a finite subset $\{x_{1},\ldots,x_{m}\}$ of $X$ , which generates $F$ . Since $X$ is infnite, there exists

$$x\in X-\{x_1,\ldots,x_m\}.$$

Then for some $r_i\varepsilon R$ iER $_{i}\varepsilon\:R,\:x=r_{1}x_{1}+\cdots+r_{m}x_{m}$ , which contradicts the linear inde pendence of $X$ . Therefore, $Y$ is infinite.

Let $K(Y)$ be the set of all finite subsets of $Y$ . Define a map $f:X\to K(Y)$ by $x\mapsto\{y_{1},\ldots,y_{n}\}$ , where $x=r_{1}y_{1}+\cdots+r_{n}y_{n}$ and $r_i\neq0$ for all i. Since $Y$ is a basis, the $y_i$ are uniquely determined and $f$ is a well-defined function,(which need not be injective). If Im $f$ were finite, then U S would be a finite subset of $Y$ that would $\bigcup_{\text{Sє}Im}S$ ? generate $X$ and hence $F$ . This leads to a contradiction of the linear independence of $Y$ as in the preceding paragraph. Hence Im $f$ is infnite. Next we show that $f^{-1}(T)$ is a finite subset of $X$ for every $T\varepsilon\operatorname{Im}f\subset K(Y)$ . If

$x\in f^{-1}(T)$ ,then $x$ is contained in the submodule $F_T$ of $F$ generated by $T$ ; that is, $f^{-1}(T)\subset F_{T}$ (see Theorem 1.5). Since $T$ is finite and each $y\varepsilon T$ is a linear combination of a finite number of elements of $X$ , there is a finite subset $S$ of $X$ such that $F_T$ is contained in the submodule $F_s$ of $F$ generated by $S$ . Thus $x\in f^{-1}(T)$ implies $x\in F_S$ and $x$ is a linear combination of elements of. $S$ (Theorem 1.5). Since $x\in X$ and $S\subset X$ this contradicts the linear independence of $X$ unless $x\in S.$ .Therefore, $f^{-1}(T)\subset S$ whence $f^{-1}(T)$ is finite. For each $T\varepsilon$Im $f$, order the elements of $f^{-1}(T)$ ,say $x_1,\ldots,x_n$, Xn $x_n$, and define an in-

jective map $g_T:f^{-1}(T)\to\operatorname{Im}f\times\mathbf{N}$ fXN $f\times\mathbb{N}$ by $x_{k}|\to(T,k)$ .Verify that the sets $f^{-1}(T)$ $(T\varepsilon$Im $f)$ form a partition of $X$ . It follows that the map $X\to\operatorname{Im}f\times\mathbb{N}$ defined by $x\mapsto g_T(x)$ ，where $x\in f^{-1}(T)$ ,is a welldefined injective function, whence $|X|\leq|$Im $f\times\mathbb{N}|$ . Therefore by Defnition 8.3, Theorem 8.11, and Corollary 8.13 of the Introduction:

$$|X|\leq|\operatorname{Im}f\times\mathbf{N}|=|\operatorname{Im}f|\:\mathbf{K}_0=|\operatorname{Im}f|\leq|K(Y)|=|Y|.$$

1

1

1

------------------------------------------------------------------

Interchanging $X$ and $Y$ in the preceding argument shows that $|Y|\leq|X|$ . Therefore $|Y|=|X|$ by the Schroeder-Bernstein Theorem.

Theorem 2.7. If $V$ is a vector space over a division ring D, then any two bases of V have the same cardinality.

PROOF. Let $X$ and $Y$ be bases of $V$ . If either $X$ or $Y$ is infinite, then $|X|=|Y|$ by Theorem 2.6. Hence we assume $X$ and $Y$ are fnite, say $X=\{x_1,\ldots,x_n\}$ ,and $Y=\{y_{1},\ldots,y_{m}\}$ . Since $X$ and $Y$ are bases, $0\neq y_{m}=r_{1}x_{1}+\cdots+r_{n}x_{n}$ for some $r_i\varepsilon D$ .If $r_k$ is the frst nonzero $r_{i}$, then $x_{k}=r_{k}^{-1}y_{m}-r_{k}^{-1}r_{k+1}x_{k+1}-\cdots-r_{k}^{-1}r_{n}x_{n}$ Therefore, the set $X^{\prime}=|y_{m},x_{1},\ldots,x_{k-1},x_{k+1},\ldots,x_{n}|$ xnt $x_n\}$ spans $V$ (since $X$ does). In particular

$$y_{m-1}=s_{m}y_{m}+t_{1}x_{1}+\cdots+t_{k-1}x_{k-1}+t_{k+1}x_{k+1}+\cdots+t_{n}x_{n}\:(s_{m},t_{i}\:\varepsilon\:D).$$

Not all of the $t_i$ are zero (otherwise $y_{m-1}-s_{m}y_{m}=0$ , which contradicts the linear independence of $Y$ 0.If $t_i$ is the first nonzero $l_i$ ,then $x_i$ is a linear combination of $y_{m-1},y_{m}$ and those $x_i$ with $i\neq j,k$ . Consequently, the set $\{y_{m-1},y_m\}\cup\{x_i\mid i\neq j,k\}$ spans $V$ (since $X^{\prime}$ does). In particular, $y_{m-2}$ is a linear combination of $y_{m-1},y_{m}$ and the $x_i$ with $i\neq j,k$ . The above process of adding a $y$ and eliminating an $x$ may therefore be repeated. At the end of the kth step we have a set consisting of $y_{m},y_{m-1},\ldots,y_{m-k+1}$ and $n-k$ of the $x_i$ ,which spans $V$ . If $n<m$ , then at the end of $n$ steps we would conclude that $\{y_m,\ldots,y_{m-n+1}\}$ spans $V.$ Since $m-n+1\geq2$ $y_1$ would be a linear combination of $y_{m},\ldots,y_{m-n+1}$, which would contradict the linear independence of Y.Therefore, we must have $m\leq n$ . A similar argument with the roles of $X$ and $Y$ reversed shows that $n\leq m$ and hence $m=n$

Definition 2.8. Let R be a ring with identity such that for every free R-module F, any two bases of F have the same cardinality. Then R is said to have the invariant dimension property and the cardinal number of any basis of F is called the dimension (or rank) of F over R.

Theorem 2.7 states that every division ring has the invariant dimension property. We shall follow the widespread (but not universal) practice of using“dimension' whenreferring to vector spaces over a division ring and"rank"when referringto free modules over other rings. The dimension of a vector space $V$ over a division ring $D$ will be denoted here by $\dim_DV$ . The properties of $\dim_DV$ will be investigated after Corollary 2.12. Results 2.9-2.12 are not needed in the sequel, except in Sections IV.6 and VII.5.

Proposition 2.9. Let E and F be free modules over a ring R that has the invarian dimension property. Then $E\cong F$ if and only if E and F have the same rank

PROOF. Exercise; see Proposition II.1.3.

Lemma 2.10.Let R be a ring with identity, $\mathcal{I}(\neq\mathbf{R})$ an ideal of R, F a free R-module with basis $X$ and $\pi:\mathcal{F}\to\mathcal{F}/\mathbf{IF}$ the canonical epimorphism. Then F/IF is a free R/I-. module with basis $\pi(\mathbf{X})$ and $|\pi(\mathbf{X})|=|\mathbf{X}|$

------------------------------------------------------------------

Recal that IF =ra|eI,a:eF, neN* and that the action of $R/I$ on $F/IF$ is given by $(r+I)(a+IF)=ra+IF$ (Exercise 1.3)

PROOF CF 2.10. If $u+IF\varepsilon F/IF$ then $u=\sum_{j=1}^nr_jx_j$ with $r_{j}\in R$, $x_{j}\varepsilon X$ since ue $F$ and $X$ is a basis of $F.$ Consequently, $u+IF=(\sum_{j}^{-1}r_{i}x_{j})+IF=\sum_{i}\left(r_{i}x_{i}+IF\right)$ =∑(r; + I)(x; + IF) = ∑(r, + I)π(xi), whence $\pi(X)$ generates $F/IF$ as an $R/I$ module. On the other hand, if $\sum_{k=1}^{m}(r_{k}+I)\pi(x_{k})=0$ with $r_k\varepsilon R$ R $R$ and $x_1,\ldots,x_m$ distinct elements of $X$ then $0= \sum _{k}$ $( r_{k}+ I) \pi ( x_{k}) = \sum _{k}$ $( r_{k}+ I) ( x_{k}+ IF)$ $=\sum_{k}r_{k}x_{k}+IF$ whence $\sum_kr_kx_k\varepsilon IF$ Thus $\sum_{k}r_{k}x_{k}=\sum_{j}s_{j}u_{j}$ wih $s, \varepsilon I$, $u_{j}\varepsilon F$ Sinee $u_j$ Baa $X$ deaee $X$ m $I.$ $I$ Ceane $\sum_js_ju_j$ $\sum_{k=1}^mr_kx_k$ $=\sum_{j}s_{j}u_{j}=\sum_{t=1}^{d}c_{i}y_{i}$ with $c_{l}\varepsilon I,y_{l}\varepsilon X$ The linear independence of $X$ impies that (after reindexing and inserting terms $0x_k$ Oxk $0x_k,0y_i$ Oye $0y_{i}$ if necessary) $m=d$ ， $x_k=y_k$ and $r_{k}=c_{k}\varepsilon I$ for every $k$ .Hence $r_{k}+I=0$ in $R/I$ for every $k$ and $\pi(X)$ is linearly independent over $R/I.$ Thus $F/IF$ is a free $R/I$ -module with basis $\pi(X)$ (Theorem 2.1). Finally if $x$ $x^{\prime}\varepsilon X$ and $\pi(x)=\pi(x^{\prime})$ in $F/IF$ , then $(1_R+I)\pi(x)-(1_R+I)\pi(x^{\prime})=0$ If $x\neq x^{\prime}$ , the preceding argument implies that $1_{R}\varepsilon I$, which contradicts the fact that. $I\neq R$ .Therefore, $x=x^{\prime}$ and the map $\pi:X\to\pi(X)$ is a bijection,whence $|X|=|\pi(X)|$

Proposition 2.11. Ler $\mathbf{f}:\mathbf{R}\to\mathbf{S}$ be a nonzero epimorphism ofrings with identity. If. S has the invariant dimension property, then so does R.

PROOF. Let $I=\ker f;$ then $S\cong R/I$ (Corollary II1.2.10). Let $X$ and Y be bases of the free $R$ -module $F$ and $\pi:F\to F/IF$ the canonical epimorphism. By Lemma $2.10F/IF$ is a free $R/I$ module (and hence a free $S$ -module) with bases $\pi(X)$ and $\pi(Y)$ such that $|X|=|\pi(X)|$ $|Y|=|\pi(Y)|$ . Since $S$ has the invariant dimension property, $|\pi(X)|=|\pi(Y)|$ . Therefore, $|X|=|Y|$ and $R$ has the invariant dimension property.

Corollary 2.12. If R is a ring with identity that has a homomorphic image which is a division ring, then R has the invariant dimension property. In particular, every commutative ring with identity has the invariant dimension property..

PROOF.The first statement follows from Theorem 2.7 and Proposition 2.11. If $R$ is commutative with identity, then $R$ contains a maximal ideal $M$ (Theorem II1.2.18) and $R/M$ is a field (Theorem I1.2.20). Thus the second statement is a special case of the first.

We return now to vector spaces over a division ring and investigate the properties of dimension. A vector space $V$ over a division ring $D$ is said to be fnite dimensional if $\dim_DV$ is finite.

1

------------------------------------------------------------------

Theorem 2.13. Ler W be a subspace of a pector space $V$ over a division ring D.

(i) $dim_{\mathrm{D} }\mathbf{W} \leq dim_{\mathrm{D} }\mathbf{V}$ (i) $ifdim_{\mathrm{D} }\mathbf{W} = dim_{\mathrm{D} }\mathbf{V}$ and dimpV is finite, then $W=V$ (ii) $dim_{\mathrm{D} }\mathbf{V} = dim_{\mathrm{D} }\mathbf{W} + dim_{\mathrm{D} }( \mathbf{V} / \mathbf{W} )$

SKETCH OF PROOF. (i) Let $Y$ be a basis of $W$ By Theorem 2.4 there is a basis $X$ of $V$ containing Y. Therefore, $\dim_{D}W=|Y|\leq|X|=\dim_{D}V.$ (ii)If $|Y|=|X|$ and $|X|$ is finite, then since $Y\subset X$ we must have $Y=X$ ,whence $W=V$ . (iii) We shall show that $U=\{x+W|x\varepsilon X-Y\}$ is a basis of $V/W$ . This will imply (by Definition 8.3 of the Introduction） that $\dim_{D}V=|X|=|Y|+|X-Y|=|Y|+|U|$ $=\dim_DW+\dim_D(V/W)$ If $v\varepsilon V_{:}$ then $v=\sum_{i}r_{i}y_{i}+\sum_{j}s_{i}x_{i}$ $(r_{i},s_{i}\in D$ ;yeY; $x_{i}\varepsilon X-Y)$ so that u + W = ∑ s(x; + W). Therefore, $U$ spans $V/W$ . If $\sum r_{i}(x_{j}+W)=0\left(r_{j}\varepsilon D;x_{j}\varepsilon X-Y\right)$ ,then $\sum_jr_ix_i\varepsilon W$ , whence $\sum_jr_jx_j=\sum_ks_ky_k$ $(s_{k}\varepsilon D;y_{k}\varepsilon Y)$ . This contradicts the linear independence of X = Y $X=Y$ $X=Y\cup(X-Y)$ (x - Y) $(X-Y)$ unless $r_{j}=0,s_{k}=0$ Sk= 0 $s_k=0$ for all $j,k$ . Therefore, $U$ is linearly independent and $|U|=|X-Y|$ .

Corollary 2.14. Iff $:\mathbf{V}\to\mathbf{V^{\prime}}$ is a linear transformation of vector spaces over a division ring D,then there existsa basis $X$ of V such that $X\cap$ Ker f is a basis o f Ker f and $|f(x)|f(x)\neq0,x\varepsilon X|$ is a basis ofIm f. Inparticular

$$dim_{\mathrm{D}}\mathrm{V}=dim_{\mathrm{D}}(\mathrm{Ker~f})+dim_{\mathrm{D}}(\mathrm{Im~f}).$$

SKETCH OF PROOF. To prove the first statement let $W=K$ er fand let $Y,X$ be as in the proof of Theorem 2.13. The second statement follows from Theorem 2.13 (ii) since $V/W\cong\operatorname{Im}f$ by Theorem 1.7.

Corollary 2.15. If V and W are finite dimensional subspaces ofa tector space over c division ring D, then

$$dim_\mathrm{D}\mathrm{V}+dim_\mathrm{D}\mathrm{W}=dim_\mathrm{D}(\mathrm{V}\cap\mathrm{W})+dim_\mathrm{D}(\mathrm{V}+\mathrm{W}).$$

SKETCH OF PROOF. Let $X$ be a basis of $V\cap W$ ,Ya (finite) basis of $V$ that contains $X$ ,and $Z$ a (fnite) basis of $W$ that contains $X$ (Theorem 2.4). Show tha $X\cup(Y-X)\cup(Z-X)$ (Z - x) $(Z-X)$ is a basis of $V+W$ ,whence

$$\begin{gathered}
\dim_{D}(V+W) =|X|+|Y-X|+|Z-X|=\dim_{D}(V\cap W) \\
+(\mathrm{dim}_{i},V-\mathrm{dim}_{D}(V\cap W)) \\
+(\dim_{I}W-\dim_{D}(V\cap W)).\quad\blacksquare 
\end{gathered}$$

Recall that if a divisionring $R$ is containedin a divisionring $S$ ,then $S$ is a vector space over $R$ with $rs\left(s\in S,r\varepsilon R\right)$ the ordinary product in $S.$ The following theorerr will be needed for the study of field extensions in Chapter $V$

------------------------------------------------------------------

Theorem 2.16.Ler R,S,T be division rings such that $\mathbb{R}\subset S\subset\mathcal{T}$ .Then

$$dim_{\mathrm{R}}\mathrm{T}=(dim_{\mathrm{S}}\mathrm{T})(dim_{\mathrm{R}}\mathrm{S}).$$

Furthermore, dimnT is finite if and only if dim $sT$ anddim $RS$ are finite.

PROOF. Let $U$ be a basis of $T$ over $S$ , and let $V$ a basis of $S$ over $R$ .It suffices to show that $\{vu\mid v\in V,u\in U\}$ is a basis of $T$ over $R$ .For the elements $vu$ are all distinct by the linear independence of $U$ over $S$ .Consequently, we may conclude that $\dim_RT=|U||V|=(\dim_ST)(\dim_RS)$ . The last statement of the theorem then follows immediately since the product of two finite cardinal numbers is finite and the product of an infinite with a finite cardinal number is infinite (Introduction, Theorem 8.11).

If u e T, then $u=\sum_{i=1}^{n}s_{i}u_{i}\left(s_{i}\in S,u_{i}\:\varepsilon U\right)$ since $U$ spans $T$ as a vector space over $S$ Since $S$ is a vector space over $R$ each $s_i$ may be written as s; = r:;p;(r; e R,p,; e V) Thus $u=\sum_{i}s_{i}u_{i}=\sum_{i}\left(\sum_{j}r_{ij}v_{j}\right)u_{i}=\sum_{i}\sum_{j}r_{ij}v_{j}u_{i}$ . Therefore, $\{\boldsymbol{v}u|\boldsymbol{v}\in V,\boldsymbol{u}\in\boldsymbol{\varepsilon}U\}$ spans $T$ as a vector space over $R$ Suppose hat $\sum _{i= 1}^{n}\sum _{j= 1}^{m}r_{i, j}( v_{j}u_{i}) = 0$ $( r_{i, j}\varepsilon R, v_{i}\varepsilon V, u_{i}\varepsilon U)$ . For cach i, Iet

$s_{i}=\sum_{j=1}^{m}r_{ij}v_{i}\in S$ Then $0=\sum_{i}\sum_{j}r_{ij}(v_{i}u_{i})=\sum_{i}(\sum_{j}r_{ij}v_{i})u_{i}=\sum_{i}s_{i}u_{i}$ The linar independence of $U$ over $S$ implies that for each i, $0=s_{i}=\sum_{j}r_{ii}v_{i}.$ The linear inde pendence of $V$ over $R$ implies that $r_{ij}=0$ for all $i,j$ . Therefore, $\{vu\mid v\in V,u\in U\}$ is linearly independent over $R$ and hence a basis.

### EXERCISES

1. (a) A set of vectors $\{x_1,\ldots,x_n\}$ in a vector space $V$ over a division ring $R$ is linearly dependent if and only if some $x_k$ is a linear combination of the preceding $x_i$ (b) If $\{x_1,x_2,x_3\}$ is a linearly independent subset of $V$ , then the set $\{x_1+x_2$,

$x_{2}+x_{3},x_{3}+x_{1}\}$ is linearly independent if and only if Char $R\neq2$ . [See Definition I11.1.8].

2. Let $R$ be any ring (possibly without identity) and $X$ a nonempty set. In this exercise an $R$ -module $F$ is called a free module on $X$ if $F$ is a free object on $X$ in the category of all left $R$ -modules. Thus by Definition I.7.7, $F$ is the free module on $X$ if there is a function t : $X\to F$ such that for any left $R$ -module $A$ and function $f:X\to A$ there is a unique $R$ -module homomorphism $\bar{f}:F\to A$ with $\bar{f}_{l}=f.$ (a) Let $\{X_i\mid i\in I\}$ be a collection of mutually disjoint sets and for each $i\varepsilon I$, suppose $F_{i}$ is afree module on $X_i$ with $\iota_i:X_i\to F_i$ Let $X=\bigcup_{i\epsilon I}X_i$ and $F=\sum_{i\epsilon T}^{i}$ $F_i$ , with $\phi_i:F_i\to F$ the canonical injection. Define t : $X\to F$ by $\iota(x)=\phi_{i}\iota_{i}(x)$ fon $x\in X_i$ ; ( is well defined since the $X_i$ are disjoint). Prove that $F$ is a free module on $X$ .[Hint: Theorem 1.13 may be useful.] (b) Assume $R$ has an identity. Let the abelian group $\mathbf{Z}$ be given the trivial $R$ module structure ( $(rm=0$ for all $r\in R,m\in\mathbf{Z})$ , so that $R\oplus\mathbf{Z}$ is an $R$ -module with $r(r^{\prime},m)=(rr^{\prime},0)$ for all $r,r^{\prime}\in R,m\in\mathbf{Z}$ If $X$ is any one element set, $X=\{t\}$

------------------------------------------------------------------

let $\iota:X\to R\oplus\mathbf{Z}$ be given by $\iota(t)=(1_{R},1)$ . Prove that $R\oplus\mathbf{Z}$ is a free module on $X$ . [Hinr: given $f:X\to A$ , let $A=B\oplus C$ as in Exercise 1.17, so that $f(t)=b+c\left(b\varepsilon B,c\varepsilon C\right)$ . Define $f(r,m)=rb+mc.$ (c) If $R$ is an arbitrary ring and $X$ is any set, then there exists a free module

on $X$ . [Hint. Since $X$ is the disjoint union of the sets $\{t\}$ with $\iota\varepsilon X$ ,it suffices by (a) to assume $X$ has only one element. If $R$ has an identity, use (b). If $R$ has no identity,embed $R$ in a ring $S$ with identity and characteristic O as in the proof of Theorem Il1.1.10. Use Exercise 1.18 to show that $S$ is a free $R$ -module on $X$ ] 3. Let $R$ be any ring (possibly without identity) and $F$ a free $R$ -module on the set

$X$ ,with $\iota:X\to F$ ,as in Exercise 2.Show that $\iota(X)$ is a set of generators of the $R$ -module $F$ . [Hint: let $G$ be the submodule of $F$ generated by $\iota(X)$ and use the definition of "free module" to show that there is a module homomorphism $\varphi$ such that

![](https://storage.simpletex.cn/view/f8GTfW5ftC8wIRigSfKp39amTqqAPSr22)

is commutative. Conclude that $\varphi=1_{F}$ ]

4. Let $R$ be a principal ideal domain, $A$ a unitary left $R$ -module, and $p\varepsilon R$ a prime ( = irreducible). Let $pA=\{pa\mid a\in A\}$ and $A[p]=\{a\varepsilon A\mid pa=0\}$

(a) $R/(p)$ is a field (Theorems I1.2.20 and II1.3.4). (b) $pA$ and $A[p]$ are submodules of $A$ (c) $A/pA$ is a vector space over $R/(p)$ , with $(r+(p))(a+pA)=ra+pA$ (d) $A[p]$ is a vector space over $R/(p)$ ,with $(r+(p))a=ra$

5. Let $V$ be a vector space over a division ring $D$ and $S$ the set of all subspaces of $V$ partially ordered by set theoretic inclusion (a) $S$ is a complete lattice (see Introduction, Exercise 7.2; the 1.u.b. of $V_1,V_2$ is

$V_{1}+V_{2}$ and the g.l.b. $V_1\cap V_2)$ (b) $S$ is a complemented lattice; that is, for each V $V_{1}$ $V_1\varepsilon S$ there exists $V_2\varepsilon S$ such that $V=V_{1}+V_{2}$ and $V_1\cap V_2=0$ , so that $V=V_1\oplus V_2$ (c) $S$ is a modular lattice; that is, if $V_{1},V_{2},V_{3}\in S$ and $V_3\subset V_1$, then

$$V_1\cap(V_2+V_3)=(V_1\cap V_2)+V_3.$$

6. Let $R$ and $\mathbf{C}$ be the fields ofreal and complex numbers respectively (a) $\dim_{\mathbf{R}}\mathbf{C}=2$ and $\dim_{\mathbb{R}}\mathbb{R}=1$

(b) There is no field $K$ such that $\mathbb{R}\subset K\subset\mathbf{C}$

7.If $G$ is a nontrivial group that is not cyclic of order 2, then $G$ has a nonidentity automorphism. [Hint: Exercise II.4.11 and Exercise 4(d) above.

8. If $V$ is a finite dimensional vector space and $V^{m}$ is the vector space

$$V\oplus V\oplus\cdots\oplus V\quad(m\mathrm{~summands}),$$

then for each $m\geq1$ ， $V^m$ is finite dimensional and dim $V^{m}=m(\dim V)$

------------------------------------------------------------------

9. If $F_{1}$ and $F_2$ are free modules over a ring with the invariant dimension property, then rank $(F_{1}\oplus F_{2})=$ $(F_{1}\oplus F_{2})=$ $(F_1\oplus F_2)=$rank $F_1+$rank $F_2.$ F+ $F_1+$ F2 $F_2$

10. Let $R$ be a ring with no zerc divisors such that for all $r,s\varepsilon R$ there exist $a,b\in R$ not both zero, with $ar+bs=0$ (a) If $R=K\oplus L$ (module direct sum), then $K=0$ or $L=0$

(b) If $R$ has an identity, then $R$ has the invariant dimension property

11. Let $F$ be a free module of infinite rank $\alpha$ over a ring $R$ that has the invariant dimension property. For each cardinal $\beta$ such that $0\leq\beta\leq\alpha$, $F$ has infnitely many proper free submodules of rank $\beta$

12.If $F$ is a free module over a ring with identity such that $F$ has a basis of finite cardinality $n\geq1$ and another basis of cardinality $n+1$ ,then $F$ has a basis of cardinality $m$ for every $m\geq n\left(m\varepsilon\mathbf{N}^{*}\right)$

13.Let $K$ be a ring with identity and $F$ a free $K.$ -module with an infinite denumerable basis $\{e_1,e_2,\ldots\}$ . Then $R=\operatorname{Hom}_{K}(F,F)$ is a ring by Exercise 1.7(b). If $n$ is any positive integer, then the free left $R$ -module $R$ has a basis of $n$ elements; that is, as an $R$ -module, $R\cong R\oplus\cdots\oplus R$ for any finite number of summands. $[Hint:\{1_R\}$ {lR! $\{1_R\}$ is a basis of one element; $\{f_1,f_2\}$ is a basis of two elements, where fi(e2n) = en $f_{1}(e_{2n})=e_{n}$ $f_{1}(e_{2n})=e_{n},f_{1}(e_{2n-1})=0,f_{2}(e_{2n})=0$ fi(e2n-1) = 0 $f_{\mathrm{i}}(e_{2n-1})=0$ f(e2n) = 0 $f_{2}(e_{2n})=0$ and $f_{2}(e_{2n-1})=e_{n}$ . Note that for any $g\varepsilon R$ $g=g_{1}f_{1}+g_{2}f_{2}$ ,where $g_1(e_n)=g(e_{2n})$ and $g_2(e_n)=g(e_{2n-1}).$

14. Let $f:V\to V^{\prime}$ be a linear transformation of finite dimensional vector spaces $V$ and $V^{\prime}$ such that dim $V=\dim V^{\prime}$ . Then the following conditions are equivalent: (i $f$ is an isomorphism; (ii) $f$ is an epimorphism; (i) $f$ is a monomorphism. [Hint: Corollary 2.14.]

15.Let $R$ be a ring with identity. Show that $R$ is not a free module on any set in the category of all $R$ -modules (as defined in Exercise 2). [Hint. Consider a nonzero abelian group $A$ with the trivial $R$ -module structure $(ra=0$ for all $r\varepsilon R$ R $R$ $a\varepsilon A)$ A $A$ . Observe that the only module homomorphism $R\to A$ is the zero map.]

## 3. PROJECTIVE AND INJECTIVE MODULES

Every free module is projective and arbitraryprojective modules(which need not be free) have some of the same properties as free modules.Projective modules are especially useful in a categoricai setting since they are defined solely in terms of modules and homomorphisms. Injectivity, which is also studied here, is the dual notion to projectivity.

Definition 3.1. A module P over a ring R is said to be projective ifgiven any diagram of R-module homomorphisms

$$A\overset{g}{\operatorname*{\to}}\overset{g}{\operatorname*{\to}}\overset{P}{\operatorname*{\to}}f$$

------------------------------------------------------------------

with bottom row exact(that is,g an epimorphism),there exists an R-module homomorphism $\mathbf{h}:\mathbf{P}\to\mathbf{A}$ such that the diagram

$$\prod_{A\overset{g}{\operatorname*{\to}}\overset{g}{\operatorname*{\to}}\overset{g}{\operatorname*{\to}}\overset{f}{\operatorname*{\to}}0}^{P}$$

is commutative (that is, $\mathbf{gh}=\mathbf{f}.$

The theorems below will provide several examples of projective modules. We note first that if $R$ has an identity and $P$ is unitary, then $P$ is projective if and only if for every pair of unitary modules $A,B$ B $B$ and diagram of $R$ -module homomorphisms

$$\lim_{A\overset{g}{\operatorname*{\to}}\overset{g}{\operatorname*{\to}}\overset{g}{\operatorname*{\to}}\overset{f}{\operatorname*{\to}}0}$$

with $g$ an epimorphism, there exists a homomorphism $h:P\to A$ with $gh=f.$ For by Exercise 1.17, $A=A_{1}\oplus A_{2}$ and $B=B_{\mathrm{i}}\oplus B_{2}$ with $A_1,B_1$ unitary and $RA_{2}=0$ $=RB_{2}$ .Exercise 1.17 shows further that $f(P)\subset B_1$ and $g\mid A_1$ is an epimorphism $A_1\to B_1$ , so that we have a diagram of unitary modules:

$$A_1\overset{g}{\operatorname*{\to}}B_1\overset{g}{\operatorname*{\to}}0$$

Thus the existence of $h:P\to A$ with $gh=f$ is equivalent to the existence of $h:P\to A_1$ with $gh=f.$

Theorem 3.2. Every free module F over a ring R with identity is projective

REMARK. The Theorem is true if the words “with identity" are deleted and $F$ is a free module in the category of all left $R$ -modules (as defined in Exercise 2.2). The proof below carries over verbatim, provided Exercise 2.2 is used in place of Theorem 2.1 and the word "unitary" deleted.

PROOF OF 3.2. In view of the remarks preceding the theorem we may assume that we are given a diagram of homomorphisms of unitary $R$ -modules

$$\underset{A\overset{g}{\operatorname*{\to}}B\overset{g}{\operatorname*{\to}}B\overset{g}{\operatorname*{\to}}0}{\operatorname*{\operatorname*{\to}}}$$

------------------------------------------------------------------

with $g$ an epimorphism and $F$ a free $R$ -module on the set $X\left(\iota:X\to F\right)$ . For each xeX $x\varepsilon X$ $x\in X,f(\iota(x))\varepsilon B.$ Since $g$ is an epimorphism, there exists $a_x$ E $A$ with $g(a_x)=f(u(x))$ Since $F$ is free, the map $X\to A$ given by $x\vdash a_x$ induces an $R$ -module homomorphism $h:F\to A$ such that $h(u(x))=a_x$ for all $x\varepsilon X$ . Consequently, $ghu(x)=g(a_x)$ $=fu(x)$ for all $x\epsilon X$ so that $gh\iota=f\iota:X\rightarrow B.$ By the uniquenesspart of Theorem 2.1 (iv) we have $gh=f.$ Therefore $F$ is projective.

Corollary 3.3. Every module A ouer a ring R is the homomorphic image ofa projec tive R-module.

PROOF. Immediate from Theorem 3.2 and Corollary 2.2.

Theorem 3.4.LerR be a ring.Thefollowing conditions on an R-module $P$ are equivalent.

(i) Pis projective; (i) every short exact sequence $0\to\mathbf{A}\overset{\mathbf{f}}{\operatorname*{\rightarrow}}\mathbf{B}\overset{\mathbf{g}}{\operatorname*{\rightarrow}}\mathbf{P}\to0$ is split exact (hence $\mathbf{B}\cong\mathbf{A}\oplus\mathbf{P})$ (i) there is a free module $F$ and an R-module K such that $\mathbf{F}\cong\mathbf{K}\oplus\mathbf{P}$

REMARK. The words “free module' in condition (ii) may be interpreted in the sense of Theorem 2.1 if $R$ has an identity and $P$ is unitary, and in the sense of Exercise 2.2 otherwise. The proof is the same in either case.

PROOF OF 3.4. (i$) \Rightarrow$ = $\Longrightarrow$ (ii) Consider the diagram

$$B\overset{g}{\operatorname*{\to}}P_{P\to0}$$

with bottom row exact by hypothesis. Since $P$ is projective there is an $R$ -module homomorphism $h:P\dashrightarrow B$ such that $gh=1_{F}$ . Therefore, the short exact sequence $0\to A\overset{f}{\operatorname*{\rightarrow}}B\overset{g}{\operatorname*{\overset{h}{\operatorname*{\leftarrow}}}}P\to0$ is split exact by Theorem 1.18 and $B\cong A\oplus P$

(i) $\Rightarrow$ (ii)By Corollary 2.2 there is a free $R$ -module $F$ and an epimorphism $g:F\to P$ If $K=$Ker $g_{i}$ , then $0\to K\xrightarrow{\mathrm{c}}F\xrightarrow{\mathrm{g}}P\to0$ is exact. By hypothesis the se quence splits so that $F\cong K\oplus P$ by Theorem 1.18. (ii $\Rightarrow$ = i$) \Rightarrow ($i) Let $\pi$ be the composition $F\cong K\oplus P\dashrightarrow P$ where the second map is the

canonical projection. Similarly let. $\iota$ be the composition $P\dashrightarrow K\oplus P\cong F$ with the first map the canonical injection. Given a diagram of $R$ -module homomorphisms

$$\int_{A\overset{g}{\operatorname*{\to}}B\to0}^{P}$$

------------------------------------------------------------------

with exact bottom row,consider the diagram

$$\underset{A\overset{g}{\operatorname*{\to}}}{\operatorname*{\overset{g}{\operatorname*{\to}}}}\underset{B\overset{g}{\operatorname*{\to}}}{\operatorname*{\overset{g}{\operatorname*{\to}}}}$$

Since $F$ is projective by Theorem 3.2, there is an $R$ -module homomorphism $h_1:F\to A$ such that $gh_{1}=f\pi$ .Let $h=h_1\iota:P\to A$ . Then $gh=gh_{1}\iota=(f\pi)\iota$ $=f(\pi\iota)=f1_{P}=f.$ Therefore, $P$ is projective.

EXAMPLE. If $R=Z_{6}$ then $Z_3$ and $Z_2$ are $Z_6$ -modules (see Exercise 1.1) and there is a $Z_{6}$ module isomorphism $Z_6\cong Z_2\oplus Z_3$ .Hence both $Z_2$ and $Z_3$ are projective $Z_6$ -modules that are not free $Z_6$ -modules

Proposition 3.5. Ler R be a ring. A direct sum of R-modules $\sum_{i\in I}\mathbf{P_i}$ is projecie i and only if each $P_{\mathrm{i}}$ is projective

SKETCH OF PROOF. Suppose $\sum P_i$ is projective. Since the proof of (i) $\Rightarrow(\mathrm{i})$ in Theorem 3.4 uses only the fact that $F$ is projecive, itremains vlid with $\sum_{iel}P_i$ $\sum_{i\neq j}P_i$ and $P_{i}$ in place of $F,K$ and $P$ respectively. The convers is proved by similar techniques using the diagram

![](https://storage.simpletex.cn/view/fo4Tl5hCMzUDUbPCwBP5F4d9XTmukRsAD)

If each $P_j$ is projective, then for each $j$ there exists $h_1:P,\to A$ such that $gh_{j}=f\iota_{j}$ By Theorem 1.13 there is a unique homomorphism / $:\sum P_{i}\to A$ with $h_{l_j}=h_j$ for every $j$ . Verify that $gh=f$

Recall that the dual of a concept defined in a category (that is, a concept defined in terms of objects and morphisms), is obtained by *reversing all the arrows." Pushing this idea a bit further one might say that a monomorphism is the dual of an epimorphism, since $A\to B$ is a monomorphism if and only if $0\to A\to B$ is exact and $B\to A$ is an epimorphism if and only if $B\to A\to0$ (arrows reversed!) is exact. This leads us to define the dual notion of projectivity as follows.

Definition 3.6. A module J over a ring $R$ is said to be injective if given any diagram of R-module homomorphisms

------------------------------------------------------------------

0→A&B 小

with top row exact (that is, g a monomorphism), there exists an R-module homomor phism $\mathbf{h}:\mathbf{B}\to\mathbf{J}$ such that the diagran

$$\overset{0\to A\overset{g}{\operatorname*{\to}}B}{\operatorname*{f}}\overset{g}{\operatorname*{f}}\overset{g}{\operatorname*{h}}$$

is commutative(that is, $hg=f.$

Remarks analogous to those in theparagraph following Definition3.1 apply here to unitary injective modules over a ring with identity. It is not surprising that the duals of many (but not all) of the preceding propositions may be readily proved. For. example since in a category products are the dual concept of coproducts (direct sums), the dua! of Proposition 3.5 is

Proposition 3.7. dret produt oS R-mocudes $\prod_{i\in I}\mathbf{J}_{\mathrm{i}}$ is njecrive fand nl ifis injective for every i eI.

PROOF. Exercise; see Proposition 3.5.

Since the concept of a free module cannot be dualized (Exercise 13), there are no analogues of Theorems 3.2 or 3.4 (i) for injective modules. However, Corollary 3.3 can be dualized.It states,in effect, that for every module $A$ thereis a projective module $P$ and an exact sequence $P\to A\to0$ . The dual of this statement is that for every module $A$ there is an injective module $J$ and an exact sequence $0\to A\to J$ ; in other words, every module may be embedded in an injective module. The remainder of this section, which is not needed in the sequel, is devoted to proving this fact for unitary modules over a ring with identity. Once this has been done the dual of Theorem 3.4 (i), (ii), is easily proved (Proposition 3.13). We begin by characterizing injective $R$ -modules in terms of left ideals (submodules) of the ring. $R$

Lemma 3.8. Let R be u ring with identity. A unitary R-module J is injective if and only if for every left ideal L ofR,any R-module homomorphism $\mathbf{L}\to\mathbf{J}$ may be extended to an R-module homomorphism $\mathbb{R}\to\mathbf{J}$

SKETCH OF PROOF. To say that $f:L\to J$ may be extended to $R$ means that there is a homomorphisr1 $h:R\to J$ such that the diagram

------------------------------------------------------------------

O+LEr 小

is commutative. Clearly, such an $h$ always exists if $J$ is injective. Conversely, suppost $J$ has the stated extension property and suppose we are given a diagram of module homomorphisms

$$\overset{0\to A}{\operatorname*{\to}}\overset{g}{\operatorname*{\to}}\overset{g}{\operatorname*{\to}}B\\\overset{f}{\operatorname*{\to}}$$

with top row exact. To show that $J$ is injective we must find a homomorphism $h:B\to J$ with $hg=f.$ Let S be the set of all $R$ -module homomorphisms $h:C\to J$ where $\operatorname{Im}g\subset C\subset B.$ S is nonempty since $fg^{-1}:\operatorname{Im}g\to J$ is an element of $S(g$ is a monomorphism). Partially order S by extension: $h_1\leq h_2$ if and only if Dom $h_1\subset$ Dom $h_2$ and $h_2$ $\mid$Dom$h_1=h_1$ .Verify that the hypotheses of Zorn's Lemma are satisfied and conclude that S contains a maximal element $h:H\to J$ with $hg=f.$ We shall complete the proof by showing $H=B.$

If $H\neq B$ and $b\in B-H$ ,then $L=\{r\in R\mid rb\varepsilon H\}$ is a left ideal of $R$ . The map $L\to J$ givenby $r\vdash h(rb)$ is a well-defined $R$ -module homomorphism. By hypothesis there is an $R$ -module homomorphism $k:R\to J$ such that $k(r)=h(rb)$ forall $r\varepsilon L$ L $L$ Let $c=k(1_R)$ and define a map $\bar{h}:H+Rb\to J$ by $a+rb\vdash h(a)+rc$ Weclaim that $\bar{h}$ is well defined. For if $a_{1}+r_{1}b=a_{2}+r_{2}b\varepsilon H+Rb$ $H+Rb$ H+Rb ,then $a_{1}-a_{2}=(r_{2}-r_{1})b$ $\varepsilon H\cap Rb$ .Hence $r_2-r_1\varepsilon L$ and $h(a_{1})-h(a_{2})=h(a_{1}-a_{2})=h((r_{2}-r_{1})b)=$ $k\left(r_{2}-r_{1}\right)=(r_{2}-r_{1})k(1_{R})=(r_{2}-r_{1})c$ . Therefore, $\bar{h}(a_{1}+r_{1}b)=h(a_{1})+r_{1}c=h(a_{2})$ $+r_{2}c=\bar{h}(a_{2}+r_{2}b)$ and $\bar{h}$ is well defined. Verify that $\bar{h}:H+Rb\to J$ is an $R$ -module homomorphism that is an element of the set S. This contradicts the maximality of $h$ since $b\notin H$ and hence $H\subseteq H+Rb$ . Therefore, $H=B$ and $J$ is injective.

An abelian group $D$ is said to be divisible if given any $y\in D$ $D$ D and $0\neq n\in\mathbf{Z}$, there exists $x\varepsilon D$ such that $nx=y$ .For example, the additive group Q is divisible,but $\mathbf{Z}$ is not (Exercise 4). It is easy to prove that a direct sum of abelian groups is divisible if and only if each summand is divisible and that the homomorphic image of a divisible group is divisible (Exercise 7).

Lemma 3.9. An abelian group D is divisible if and only if D is an injective (unitary) Z-module.

PROOF. If $D$ is injective, $y\in D$ and $0\neq n\in\mathbf{Z}$ ,let $f{:}\langle n\rangle\to D$ be the unique homomorphism determined by $n\vdash y;(\langle n\rangle$ is a free $\mathbf{Z}$ -module by Theorems I.3.2 and I1.1.1). Since $D$ is injective, there is a homomorphism $h:\mathbf{Z}\to D$ such that the diagram

------------------------------------------------------------------

$$\overset{0\rightarrow\langle n\rangle\subsetneqq\mathbf{z}}{\operatorname*{f}}$$

is commutative. If $x=h(1)$ , then $nx=nh(1)=h(n)=f(n)=y$ .Therefore, $D$ is divisible. To prove the converse note that the only left ideals of $\mathbf{Z}$ are the cyclic groups $\langle n\rangle$ (n) $\langle n\rangle,n\in\mathbf{Z}$ If $D$ is divisible and $f:\langle n\rangle\to D$ is a homomorphism, then there exists $x\varepsilon D$ with $nx=f(n)$ . Define $h:\mathbf{Z}\to D$ by $1\vdash x$ and verify that $h$ is a homomorphism that extends $f.$ Therefore, $D$ is injective by Lemma 3.8.

REMARK. A complete characterization of divisible abelian groups (injective unitary $\mathbf{Z}$ -modules) is given in Exercise 11.

Lemma 3.10.Euery abelian group A may be embedded in a divisible abelian group.

PROOF. By Theorem II.1.4 there is a free $\mathbf{Z}$ -module $F$ and an epimorphism $F\to A$ with kernel $K$ so that $F/K\cong A$ .Since $F$ is a direct sum of copies of $\mathbf{Z}$ (Theorem I1.1.1) and $\mathbf{Z}\subset\mathbf{Q}$, $F$ may be embedded in a direct sum $D$ of copies of the rationals $\mathbf{Q}$ (Theorem 1.8.10). But $D$ is a divisible group by Proposition 3.7, Lemma 3.9, and the remarks preceding it. If $f:F\to D$ is the embedding monomorphism, then finduces an isomorphism $F/K\cong f(F)/f(K)$ by Corollary I.5.8. Thus the composition $A\cong F/K\cong f(F)/f(K)\subset D/f(K)$ is a monomorphism. But $D/f(K)$ is divisible since it is the homomorphic image of a divisible group.

If $R$ is a ring with identity and $J$ is an abelian group, then $\mathrm{Hom}_{\mathbf{Z}}(R,J)$ ,the set of all $\mathbf{Z}$ -module homomorphisms $R\to J$ ,is an abelian group(Exercise 1.7).Verify that Homz$( R, J)$ is a unitary left $R$ -module with the action of $R$ defined by $(rf)(x)=f(xr)$ (r,x ε R $(r,x\in R$ $(r,x\in R;f\varepsilon\operatorname{Hom}_{\mathbf{Z}}(R,J))$

Lemma 3.11. If J is a divisible abelian group and R is a ring with identity, then $Hom_{\mathbf{Z}}(\mathbf{R},\mathbf{J})$ is an injective left R-module.

SKETCH OF PROOF. By Lemma 3.8 it suffices to show that for each left ideal $L$ of $R$ ,every $R$ -module homomorphism $f:L\to\operatorname{Hom}_{\mathbf{Z}}(R,J)$ may be extended to an $R$ -module homomorphism $h:R\to\mathrm{Hom}_{\mathbf{Z}}(R,J)$ . The map $g:L\to J$ given by $g(a)=[f(a)](1_R)$ is a group homomorphism. Since $J$ is an injective $\mathbf{Z}$ -module by Lemma $^{\prime}3.9$ and we have the diagram

$$\overset{0\to L\subseteq R}{\operatorname*{g}}$$

there is a group homomorphism $\bar{g}:R\to J$ such that $\bar{g}\mid L=g$ . Define $h:R\to$ $\mathrm{Hom}_{\mathbf{Z}}(R,J)$ by $r\mapsto h(r)$ ,where $h(r):R\to J$ is the map given by $[h(r)](x)=\bar{g}(xr)$

------------------------------------------------------------------

$(x_{\varepsilon}R)$ .Verify that $h$ is a well-defined function (that is,each $h(r)$ is a group homo morphism $R\to J$, and that $h$ is a group homomorphism $R\to\operatorname{Hom}_{\mathbf{Z}}(R,J)$ .If $s,r,x\in R$ ,then

$$h(sr)(x)=\bar{g}(x(sr))=\bar{g}((xs)r)=h(r)(xs).$$

By the definition of the $R$ -module structure of $\mathrm{Hom}_{\mathbf{Z} }( R, J)$, $h( r) ( xs) = [ sh( r) ] ( x)$, whence $h(sr)=sh(r)$ and $h$ is an $R$ -module homomorphism. Finally suppose r e $L$ and $x\varepsilon R$ . Then $xr\varepsilon L$ L $L$ and

$$h(r)(x)=\bar{g}(xr)=g(xr)=[f(xr)](1_{R}).$$

Since $f$ is an $R$ -module homomorphism and $\mathrm{Hom}_{\mathbf{Z}}(R,J)$ an $R$ -module

$$[f(xr)](1_R)=[xf(r)](1_R)=f(r)(1_Rx)=f(r)(x).$$

Therefore, $h(r)=f(r)$ for $r\varepsilon L$ $L$ L and $h$ is an extension of $f.$ ■

We arenow able toprove the duals of Corollary3.3 and Theorem 3.4.

Proposition 3.12. Every unitary module A over a ring R with identity may be em bedded in an injective R-module.

SKETCH OF PROOF. Since $A$ is an abeliangroup, there is a divisiblegroupJ and a group monomorphism $f:A\to J$ by Lemma 3.10. The map $\bar{f}:\operatorname{Hom}_{\mathbf{Z}}(R,A)$ $\to\mathrm{Hom}_{\mathbf{Z}}(R,J)$ given on g e ${:}\mathrm{Hom}_{\mathbf{Z}}(R,A)$ by $\bar{f}(g)=fg\varepsilon Hom_{\mathbf{Z}}(R,J)$ is easily seen to be an $R$ -module monomorphism. Since every $R$ -module homomorphism is a $\mathbf{Z}$ -module homomorphism, we have $\mathrm{Hom}_R(R,A)\subset\mathrm{Hom}_{\mathbf{Z}}(R,A)$ .In fact, it is easy to see that $\mathrm{Hom}_{R}(R,A)$ is an $R$ -submodule of $\mathrm{Hom}_{\mathbf{Z}}(R,A)$ . Finally, verify that the map $A\to\operatorname{Hom}_R(R,A)$ given by $a\vdash f_a$, where $f_{a}(r)=ra$ , is an $R$ -module monomorphism (in fact it is an isomorphism). Composing these maps yields an $R$ -module monomorphisr

$$A\to\mathrm{Hom}_R(R,A)\overset{\subset}{\operatorname*{\to}}\mathrm{Hom}_{\mathbf{Z}}(R,A)\overset{\bar{f}}{\operatorname*{\to}}\mathrm{Hom}_{\mathbf{Z}}(R,J).$$

Since $\mathrm{Hom}_{\mathbf{Z}}(R,J)$ is an injective $R$ -module by Lemma 3.11, we have embedded $A$ in an injective.

Proposition 3.13.Let R be a ring with identity.The following conditions on a unitary R-module J are equivalent

(i) J is injective; (i) every short exact sequence $0\to\mathbf{J}\overset{\mathbf{f}}{\operatorname*{\operatorname*{\rightarrow}}}\mathbf{B}\overset{\mathbf{g}}{\operatorname*{\rightarrow}}\mathbf{C}\to0$ is split exact (hence

$\mathbf{B}\cong\mathbf{J}\oplus\mathbf{C})$ (ii) Jis a direct summand of any module B of which it is a submodule.

SKETCH OF PROOF. (i$) \Rightarrow ($ii) Dualize the proof of (i$) \Rightarrow$ (ii) of Theorem 3.4 (ii$) \Rightarrow$ $\Longrightarrow$ = (ii) since the sequence $0\to\boldsymbol{J}\overset{\in}{\operatorname*{\rightarrow}}B\overset{\pi}{\operatorname*{\rightarrow}}B/\boldsymbol{J}\to0$ is split exact, there is a homomorphism $g{:}B/J\longrightarrow B$ such that $\pi g=1_{B/J}$ . By Theorem 1.18 ((i$) \Rightarrow ($iii)) there is an isomorphism $J\oplus B/J\cong B$ given by $(x,y)\vdash x+g(y)$ . It follows easily that $B$ is the

------------------------------------------------------------------

internal direct sum of $J$ and $g(B/J)$ g(B/J) $g(B/J).(\mathrm{iii})\Rightarrow(\mathrm{i})$ → $\Rightarrow$ It follows from Proposition 3.12 that J is a submodule of an injective module $Q$ . Proposition 3.7 and (iii) imply that $J$ is injective.

### EXERCISES

Note: $R$ is a ring. If $R$ has an identity, all $R$ -modules are assumed to be unitary.

1. The following conditions on a ring $R$ [with identity] are equivalent:

(a) Every [unitary] $R$ -module is projective. (b) Every short exact sequence of [unitary] $R$ -modules is split exact. (c) Every [unitary] $R$ -module is injective.

2. Let $R$ be a ring with identity. An $R$ -module $A$ is injective if and only if for every left ideal $L$ of $R$ and $R$ -module homomorphism $g:L\to A$ ,there exists a e A such that $g(r)=ra$ for every $r\varepsilon L$

 3. Every vector space over a division ring $D$ is both a projective and an injective $D$ -module. [See Exercise 1.]

4. (a) For each prime $p,Z(p^{\infty})$ (see Exercise I.1.10) is a divisible group. (b) No nonzero finite abelian group is divisible.

(c)No nonzero free abelian group is divisible. (d) Q is a divisible abelian group.

5. Q is not a projective $\mathbf{Z}$ -module

6. If $G$ is an abelian group, then $G=D\oplus N$ ,with $D$ divisible and $N$ reduced (meaning that $N$ has no nontrivial divisible subgroups). [Hint: Let $D$ be the subgroup generated by the set theoretic union of all divisible subgroups of G.]

7. Without using Lemma 3.9 prove that:

(a) Every homomorphic image of a divisible abelian group is divisible. (b) Every direct summand (Exercise I.8.12) of a divisible abelian group is divisible. (c)A direct sum of divisible abelian groups is divisible

8. Every torsion-free divisible abelian group $D$ is a direct sum of copies of the rationals Q. [Hinr: if $0\neq n$ ε Z and ae $D$ , then there exists a unique $b\in D$ such that $nb=a$ .Denote $b$ by $(1/n)a$ .For ml, $n\in\mathbf{Z}(n\neq0)$ , define $(m/n)a=m(1/n)u$ Then $D$ is a vector space over Q. Use Theorem 2.4.]

9. (a) If $D$ is an abelian group with torsion subgroup $D_{l}$ then $D/D_i$ is torsion free (b) If $D$ is divisible, then so is $D_{t}.$ whence $D=D_{\iota}\oplus E$ with $E$ torsion free.

10. Let $p$ be a prime and $D$ a divisible abelian $P$ -group. Then $D$ is a direct sum of copies of $Z(p^{\infty})$ . [Hinr: let $X$ be a basis of the vector space $D[p]$ over $Z_p$ (see Exercise 2.4). If $x\varepsilon X$ , then there exists $x_{1},x_{2},x_{3},\ldots\varepsilon D$ D $D$ such that $x_{1}=.r$ $|x_{1}|=p$ ， $px_{2}=x_{1}$ ， $px_{3}=x_{2},\ldots,px_{n+1}=x_{n},\ldots.$ If $H_{x}$ is the subgroup generated bythe $x_{i}$, then $H_x\cong Z(p^\infty)$ by ExerciseI.3.7 Show that $\dot{D}\cong\sum_{xeX}H_{x.}\dot{]}$

11.Every divisible abelian group is a direct sum of copies of the rationals $\mathbf{Q}$ and copies of $Z(p\infty)$ for various primes $p$ . [Hinr: apply Exercise 9 t0 $D$ and Exercises

------------------------------------------------------------------

7 and 8 to the torsion-free summand so obtained. The other summand $D_t$ is a direct sum of copies of various $Z(p^{\infty})$ by Exercises 7, 10 and I1.2.7.]

12. Let $G,H,K$ be divisible abelian groups.

(a) If $G\oplus G\cong H\oplus H$, then $G\cong H$ [see Exercise 11]. (b) If $G\oplus H\cong G\oplus\boldsymbol{K}$ , then $H\cong K$ [see Exercises 11 and I1.2.11.].

13. If one attempted to dualize the notion of free module over a ring $R$ (and called the object so defined “co-free') the definition would read: An $R$ -module $F$ is cofree on a set $X$ if there exists a function $\iota:F\to X$ such that for any $R$ -module $A$ and function $f:A\to X$ , there exists a unique module homomorphism $\bar{f}:A\to F$ such that f = f(see $\iota\bar{f}=f($see $\iota\bar{f}=f($see Theorem 2.1(iv)) . Show that for any set $X$ with $|X|\geq2$ no such $R$ -module $F$ exists. If $|X|=1$ , then O is the only co-free module. [Hint: If $F$ exists and $|X|\geq2$ , arrive at a contradiction by considering possible images of 0 and constructing $f:R\to X$ such that $\iota\bar{f}\neq f$ for every homomorphism $\bar{f}:R\to F.$

14. If $D$ is a ring with identity such that every unitary $D$ -module is free, then $D$ is a division ring. [Hinr: it suffices by Exercise II1.2.7 and Theorem II1.2.18 to show that $D$ has no nonzero maximal left ideals.Note that every left ideal of $D$ is a free $D$ -module and hence a (module) direct summand of $D$ by Theorem 3.2, Exercise 1, and Proposition 3.13.]

## 4. HOM AND DUALITY

We first discuss the behavior of $\mathrm{Hom}_R(A,B)$ with respect to induced maps, exact sequences, direct sums, and direct products. The last part of the section, which is essentially independent of the first part, deals with duality. Recall that if $A$ and $B$ are modules over a ring $R$ , then $\mathrm{Hom}_R(A,B)$ is the set of all

$R$ -module homomorphisms $f:A\to B$ .If $R=\mathbf{Z}$ we shall usually write $\operatorname{Hom}(A,B)$ in place of Homz$( A, B)$ $\mathrm{Hom}_R(A,B)$ is an abelian group under addition and this addition is distributive with respect to composition of functions (see p. 174).

Theorem 4.1.Let A,B,C,D be modules over a ring R and $\varphi:\mathbf{C}\to\mathbf{A}$ and $\Psi:\mathbf{B}\to\mathbf{D}$ R-module homomorphisms. Then the map $\theta:Hom_{\mathbb{R}}(\mathcal{A},\mathcal{B})\to Hom_{\mathbb{R}}(\mathcal{C},\mathcal{D})$ given by $\mathbf{f}\vdash\psi\mathbf{f}\varphi$ is a homomorphism of abelian groups..

SKETCH OF PROOF. $\theta$ is well defined since composition of $R$ -module homomorphisms is an $R$ -module homomorphism. $\theta$ is a homomorphism since such composition of homomorphisms is distributive with respect to addition.

The map $\theta$ of Theorem 4.1 is usually denoted $\operatorname{Hom}(\varphi,\psi)$ and called the homomor phism induced by $\varphi$ and $\psi.$ Observe that for homomorphisms $\varphi_1:E\to C,\varphi_2:C\to A$ $\psi_1:B\to D$ V:B→D $\psi_1:B\to D,\psi_2:D\to F$, $\psi_2:D\to F$, $\psi_2:D\to F$,

$$\mathrm{Hom}(\varphi_1,\psi_2)\mathrm{~Hom}(\varphi_2,\psi_1)=\mathrm{Hom}(\varphi_2\varphi_1,\psi_2\psi_1):\mathrm{Hom}_R(A,B)\to\mathrm{Hom}_R(E,F).$$

There are two important special cases of the induced homomorphism. If $B=D$ and $\psi=1_B$ , then the induced map Hom$( \varphi , \mathbf{1} _B) : \mathrm{Hom}_R( A, B) \to \mathrm{Hom}_R( C, B)$ is given

------------------------------------------------------------------

by $f\vdash f\varphi$ and is denoted $\bar{\varphi}$ . Similarly if $A=C$ and $\varphi=1_{A}$ the induced-map $\mathrm{Hom}(1_A,\psi):\mathrm{Hom}_R(A,B)\to\mathrm{Hom}_R(A,D)$ is given by $f\vdash\psi f$ and is denoted $\bar{\psi}$ We now examine the behavior of $Hom_R$ with respect to exact sequences

Theorem 4.2. Let R be a ring. $0\to\mathcal{A}\overset{\varphi}{\operatorname*{\rightarrow}}\mathcal{B}\overset{\downarrow}{\operatorname*{\rightarrow}}\mathcal{C}$ is an exact sequence of R-modules if and only if for every R-module D.

$$0\to Hom_{\mathbb{R}}(\mathbb{D},\mathbb{A})\overset{\bar{\varphi}}{\operatorname*{\to}}Hom_{\mathbb{R}}(\mathbb{D},\mathbb{B})\overset{\bar{\psi}}{\operatorname*{\to}}Hom_{\mathbb{R}}(\mathbb{D},\mathbb{C})$$

is an exact sequenceof abelian groups.

PROOF. If $0\to A\overset{\varphi}{\operatorname*{\rightarrow}}B\overset{\downarrow}{\operatorname*{\rightarrow}}C$ is exact we must prove:(i) Ker $\bar{\varphi}=0$ (that is, $\bar{\varphi}$ is a monomorphism); (ii) Im $\bar{\varphi}\subset$Ker $\bar{\psi};$ $\bar{\psi};$ and (ii) Ker $\bar{\psi}\subset\operatorname{Im}\bar{\varphi}$ (i) $f\varepsilon$ Ker $\bar{\varphi}\Rightarrow\varphi f$ $=0\Rightarrow\varphi f(x)=0$ for all $x\in D$ . Since $0\to A\xrightarrow{\varphi}B$ is exact, $\varphi$ is a monomorphism, whence $f(x)\:=\:0$ for all $x\in D$ and $f=0$ . Therefore, Ker $\underline{\bar{\varphi}}=0$ . (i) Since I ${\mathbf{m}}\varphi={\mathbf{Ker}}\psi$ 4 $\psi$ by exactness, we have $\psi_{\varphi}=0$ and hence $\bar{\psi}\overline{\varphi}=\overline{\psi_{\varphi}}=0$ . Therefore, Im $\bar{\varphi}\subset$Ker $\bar{\psi}$ V $\bar{\psi}$ (ii) $g$ εKer $\bar{\boldsymbol{\psi}}\Rightarrow\boldsymbol{\psi}g=0\Rightarrow\mathbf{I}\mathfrak{m}$ $g\subset\mathsf{Ker}\not=\mathbf Im\varphi.$ =Im p $\psi=$Im$\varphi$ Since 4 is a monomorphism, $\varphi:A\to\operatorname{Im}\varphi$ is an isomorphism. If $h$ is the composite $D\overset{O}{\operatorname*{\to}}\operatorname{Img}\subset$ Ir $\mathbf{n}\varphi\overset{\varphi-1}{\operatorname*{\rightarrow}}A$ , then $h\varepsilon Hom_R(D,A)$ and $g=\varphi h\:=\:\bar{\varphi}(h)$ . Therefore, Ker $\bar{\psi}\subset\operatorname{Im}\bar{\varphi}$

Conversely, assume that the Hom sequence of induced maps is exact for every $D$ First let $D=$Ker $\varphi$ \$ $\varphi$ and let $i:D\to A$ be the inclusion map. Since Ker $\bar{\varphi}=0$ (exactness) and $\bar{\varphi}(i)=\varphi i=0$ , we must have $i=0$ , which implies that $0=D=$Ker$\varphi$ Therefore, $0\to A\stackrel{\varphi}{\operatorname*{\rightarrow}}B$ is exact. Next let $D=A$ . Since Ker $\bar{\psi}=$Im$\bar{\varphi}$ wehave $0=\bar{\psi}\bar{\varphi}(1_{A})=\psi\varphi\mathbf{l}_{A}=\psi\varphi$ , whence Im $\varphi\subset\ker\psi$ . Finally let $D=$Ker $\psi$ and let $j:D\to B$ be the inclusion map. Since $0=\psi j=\bar{\psi}(j)$ and Ker $\bar{\psi}=$Im$\bar{\varphi}$ ,we have $j=\bar{\varphi}(f)=\varphi f$ for some $f:D\to A$ . Therefore, for every $x\varepsilon D=$Ker$\psi$ 4 $\psi$ $x=j(x)$ $=\varphi f(x)\varepsilon$Im$\varphi$ \$ $\varphi$ and Ker $\psi\subset\operatorname{Im}\varphi$ . Thus Ker $\psi=$Im$\varphi$ and $0\to A\overset{\varphi}{\operatorname*{\rightarrow}}B\overset{\downarrow}{\operatorname*{\rightarrow}}C$ is exact.

Proposition 4.3. Let R be a ring. A $A\overset{\theta}{\operatorname*{\rightarrow}}B\overset{5}{\operatorname*{\rightarrow}}C\to0$ is an exact sequence of R-mod ules if and only if for every R-module D

$$0\to Hom_{\mathbb{R}}(\mathbb{C},\mathbb{D})\overset{\bar{\zeta}}{\operatorname*{\to}}Hom_{\mathbb{R}}(B,D)\overset{\bar{\theta}}{\operatorname*{\to}}Hom_{\mathbb{R}}(\mathbb{A},\mathbb{D})$$

is an exact sequence of abelian groups

SKETCH OF PROOF. If $A\overset{\theta}{\operatorname*{\to}}B\overset{5}{\operatorname*{\to}}C\rightarrow0$ is exact, we shall show that Ker $\bar{\theta}\subset\operatorname{Im}\bar{\zeta}$ .If feKer $\overline{\theta}$ , then $\mathbf{0}=\bar{\theta}(f)=\boldsymbol{f}\theta$ , whence $0=f($Im $\theta)=f($Ker $\zeta)$ .By Theorem 1.7 finduces a homomorphism $\bar{f}:B/$Ker $\zeta\to D$ such that $\bar{f}(b+$Ker $\zeta)$ $=f(b)$ . By Theorem 1.7 again there is an isomorphism $\varphi:B/$Ker $\zeta\cong C$ ≤C $\zeta\cong C$ such that $\varphi(b+$Ker $\zeta)=\zeta(b)$ . Then the map $\bar{f}\varphi^{-1}:C\rightarrow D$ is an $R$ -module homomorphism such that $\bar{\zeta}(\bar{f}\varphi^{-1})=f.$ Hence Ker $\bar{\theta}\subset\operatorname{Im}\bar{\tau}$ .The remainder of this half of the proof is analogous to that of Theorem 4.2. Conversely if the Hom sequence is exact for every $D$ ,let $D=C/\mathbf{Im}\:\zeta$ and let

$\pi:C\to D$ be the canonical projection. Then $\bar{\zeta}(\pi)=\pi\zeta=0$ and Ker $\bar{\zeta}=0$ imply $\pi=0$ whence $C=\operatorname{Im}\zeta$ and $B\overset{5}{\operatorname*{\to}}C\rightarrow0$ is exact. Similarly, show that Ker $\zeta\subset\operatorname{Im}\theta$

------------------------------------------------------------------

by considering $D=B/\operatorname{Im}\theta$ and the canonical epimorphism $B\to D$ . Finally, if $D=C$ , then $0=\bar{\theta}\bar{\zeta}(1_{c})=\zeta\theta$ ,whence Im $\theta\subset Ker\zeta$ 55 . Therefore, $A\overset{\theta}{\operatorname*{\to}}B\overset{\xi}{\operatorname*{\to}}C\dashrightarrow0$ is exact.

One sometimes summarizes the two preceding results by saying that $\mathrm{Hom}_R(A,B)$ is left exact. It is not true in general that a short exact sequence $0\to A\to B\to C\to0$ induces a short exact sequence $0\to\mathrm{Hom}_R(D,A)\to\mathrm{Hom}_R(D,B)\to\mathrm{Hom}_R(D,C)\to0$ (and similarly in the first variable; see Exercise 3). However, the next three theorems show that this result does hold in several cases.

Proposition 4.4.Thefollowing conditions on modules over a ring R areequivalent

(i $0\to\mathbf{A}\overset{\varphi}{\operatorname*{\rightarrow}}\mathbf{B}\overset{\psi}{\operatorname*{\rightarrow}}\mathbf{C}\to0$ is a split exact sequence of R-modules, (i) $0\dashrightarrow Hom_{\mathbb{R}}(\mathbb{D},\mathbb{A})\overset{\bar{\varphi}}{\operatorname*{\to}}Hom_{\mathbb{R}}(\mathbb{D},\mathbb{B})\overset{\overline{\psi}}{\operatorname*{\to}}Hom_{\mathbb{R}}(\mathbb{D},\mathbb{C})\rightarrow0$ is α splin exact se-

quence of abelian groups for every R-module D; (i) $0\dashrightarrow Hom_{\mathbf{R}}(\mathbf{C},\mathbf{D})\overset{\bar{\nu}}{\operatorname*{\operatorname*{\to}}}Hom_{\mathbf{R}}(\mathbf{B},\mathbf{D})\overset{\bar{\varphi}}{\operatorname*{\operatorname*{\to}}}Hom_{\mathbf{R}}(\mathbf{A},\mathbf{D})\rightarrow0$ is a spli exact se-

quence of abelian groups for every R-module D.

SKETCH OF PROOF. ( i) $\Rightarrow$( iii) By Theorem 1.18 there is a homomorphism $\alpha:B\to A$ such that $\alpha\varphi=\mathbf{1}_{A}$ . Verify that the induced-homomorphism

$$\bar{\alpha}:\mathrm{Hom}_R(A,D)\to\mathrm{Hom}_R(B,D)$$

is such that $\bar{\varphi}\overline{\alpha}=1_{\mathrm{Hom}R^{(A,D)}}$ . Consequently, $\bar{\varphi}$ is an epimorphism (Introduction,. Theorem 3.1) and the $Hom_R$ sequence is split exact by Proposition 4.3 and Theorem 1.18. (ii) $\Rightarrow ($i) If $D=A$ and $f:B\to A$ is such that $\mathbf{1}_{A}=\boldsymbol{\overline{\varphi}}(f)=f\varphi$ ,then $\varphi$ is a monomorphism (Introduction, Theorem 3.1) and $0\to A\overset{\varphi}{\operatorname*{\rightarrow}}B\overset{\psi}{\operatorname*{\rightarrow}}C\to0$ is split exact by Proposition 4.3 and Theorem 1.18. The other implications are proved similarly.

Theorem 4.5. The following conditions on a module $P$ over a ring R are equivalent

(i) P is projective; (i) $if\psi:\mathbf{B}\to\mathbf{C}$ is any R-module epimorphism then $\bar{\psi}:Hom_{\mathbb{R}}(\mathbb{P},\mathbb{B})\to Hom_{\mathbb{R}}(\mathbb{P},\mathbb{C})$

is an epimorphism of abelian groups;. (ii) if $0\dashrightarrow\mathbf{A}\overset{\varphi}{\operatorname*{\rightarrow}}\mathbf{B}\overset{\downarrow}{\operatorname*{\rightarrow}}\mathbf{C}\to0$ is any short exact sequence of R-modules, then

$0\to Hom_{\mathbf{R}}(\mathbf{P},\mathbf{A})\overset{\bar{\varphi}}{\operatorname*{\rightarrow}}Hom_{\mathbf{R}}(\mathbf{P},\mathbf{B})\overset{\bar{\psi}}{\operatorname*{\rightarrow}}Hom_{\mathbf{R}}(\mathbf{P},\mathbf{C})\dashrightarrow0$ is an exact sequence of abelian groups.

SKETCH OF PROOF. (i$) \Leftrightarrow$ (i)The map $\bar{\psi}:\operatorname{Hom}_R(P,B)\dashrightarrow\operatorname{Hom}_R(P,C)$ (given by $g\mapsto\psi g$ is an epimorphism if and only if for every $R$ -module homomorphism $f:P\to C$ ,there is an $R$ -module homomorphism $g:P\to B$ such that the diagram

$$\sum_{B\overset{\psi}{\operatorname*{\to}}C\overset{\psi}{\operatorname*{\to}}0}^p$$

------------------------------------------------------------------

is commutative (that is, $f=\psi g=\bar{\psi}(g)$ 0. (i) $\Rightarrow$ (ii) Theorem 4.2. (ii) $\Longrightarrow$ (ii) Giver an epimorphism $\psi:B\to C$ let $A=$Ker$\psi$ 4 $\psi$ and apply (ii) to the short exact sequenct $0\to A\overset{\mathcal{F}}{\operatorname*{\rightarrow}}B\overset{\mathcal{V}}{\operatorname*{\rightarrow}}C\to0$ .

Proposition 4.6. The following conditions on a module J over a ring R are equivalent

(i)J is injective; (iif $\theta{:}\mathbf{A}\to\mathbf{B}$ is any R-module monomorphism, then $\bar{\theta}$ 0 $\bar{\theta}{:}Hom_{\mathbb{R}}(\mathbf{B},\mathbf{J})\to Hom_{\mathbb{R}}(\mathbf{A},\mathbf{J})$

is an epimorphism of abelian groups, (ii) if $0\to\mathbf{A}\overset{\prime\prime}{\operatorname*{\rightarrow}}\mathbf{B}\overset{5}{\operatorname*{\rightarrow}}\mathbf{C}\to0$ is any short exact sequence of R-modules, then $0\to Hom_{\mathbb{R}}(\mathbb{C},\mathbb{J})\overset{\overline{5}}{\operatorname*{\operatorname*{\rightarrow}}}Hom_{\mathbb{R}}(\mathbb{B},\mathbb{J})\overset{\overline{\theta}}{\operatorname*{\rightarrow}}Hom_{\mathbb{R}}(\mathbb{A},\mathbb{J})\to0$ is an exaci sequence of abeliar groups.

PROOF.The proof is dual to that of Theorem 4.5and isleft as anexercise.

Theorem 4.7. Let A,B, $\{\mathbf{A}_{\mathrm{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\}$ and $\{\mathbf{B}_{\mathbf{j}}\mid\mathbf{j}\in\mathbf{J}\}$ be modules over aring R. Then there are isomorphisms of abelian groups?

(i)
$$Hom_{\mathrm{R}}(\sum_{ieI}\mathrm{A_{i},B})\cong\prod_{ieI}Hom_{\mathrm{R}}(\mathrm{A_{i},B});\\Hom_{\mathrm{R}}(\mathrm{A},\prod_{jeJ}\mathrm{B_{j}})\cong\prod_{jeJ}Hom_{\mathrm{R}}(\mathrm{A,B_{j}}).$$
(i)

REMARKS. If $I$ and $J$ are fnite, then $\sum_{ieI}A_{i}=\prod_{ieI}A_{i}$ and $\sum_{j\in J}B_i=\prod_{j\in J}B_i$ If I and $J$ are infinite, however, the theorem may be false if the direct product $\Pi$ is replaced by the direct sum $\sum$ (see Exercise 10).

SKETCH OF PROOF OF 4.7. (i) For each ie $I$ let $\iota_{i}:A_{i}\rightarrow\sum_{i\in I}A_{i}$ be the canonical injecion (Theorem 1.11). Given $\left\{g_{i}\right\}\in\prod_{i\in I}\operatorname{Hom}_{R}(A_{i},B)$ there is a unique $R$ mdue homomopi &HmB $g:\sum_{i\in I}A_i\to B$ $\psi:\prod_{\mathrm{Hom}_R(A_i,B)\to\mathrm{Hom}_R(\sum A_i,B)}$ 8- $g_{l_{i}}=g_{i}$ veyiaty $\{g_i\}\mapsto g$ is a homomorphism. Show that the map $\varphi:\mathrm{Hom}_R(\overline{\sum A}_i,B)\to\prod$ Hom$_R(A_i,B)$ given by $f\vdash\{f_i\}$ , is a homomorphism such that $\varphi\psi$ and $\psi_{\varphi}$ are the respective identity maps. Thus $\varphi$ is an isomorphism. (ii) is proved similarly with Theorem 1.12 in place of Theorem 1.13.

In order to deal with duality and other concepts we need to consider possible module structures on the abelian group $\mathrm{Hom}_{R}(A,B)$ . We begin with some remarks about bimodules. Let $R$ and $S$ be rings.An abelian group $A$ is an $R-S$ bimodule provided that $A$ is both a left $R$ -module and a right $S$ -module and

$$r(as)=(ra)s\quad\mathrm{for~all}\quad a\varepsilon A,r\varepsilon R,s\varepsilon S.$$

We sometimes write $_{R}A_{\mathbf{s}}$ to indicate the fact that $A$ is an $R-S$ bimodule. Similarly $_{R}B$ indicates a left $R$ -module B and $C_{\boldsymbol{s}}$ a right $S$ -module C.

------------------------------------------------------------------

EXAMPLES. Every ring $R$ has associative multiplication and hence is an $R-R$ bimodule. Every left module $A$ over a commutative ring $R$ is an $R-R$ bimodule with ra = ar $ra=ar$ $ra=ar\left(a\varepsilon A,r\varepsilon R\right)$

Theorem 4.8. Ler R and S be rings and let $RA$ $_{\mathrm{R}}\mathbf{B}_{\mathrm{S}}$ $_{\mathrm{R}}C_{\mathrm{S}}$ $_{\mathrm{R}}$D be $(bi)$ modules as indicated.

(i)Homn(A,B) is a righr S-module, with the action ofS gicen by (fs )(a)=(f(a))s (s e S;a ε A; f∈ Homr(A,B) (i) $If\varphi:\mathbf{A}\rightarrow\mathbf{A}^{\prime}$ is a homomorphism of left R-modules, then the induced may $\bar{\varphi}:\operatorname{Hom}_{\mathbb{R}}(\mathcal{A}^{\prime},\mathcal{B})\to\operatorname{Hom}_{\mathbb{R}}(\mathcal{A},\mathcal{B})$ is a homomorphism of right S-modules.. (i) $Hom_{\mathbb{R}}(\mathbb{C},\mathbb{D})$ is a lefr S-module,withthe actionofSgiven by (sg)(c)=g(cs) (s e S; c e C; g e Homr(C,D)). (iv) $If\boldsymbol{\psi}:\mathbf{D}\to\mathbf{D^{\prime}}$ is a homomorphism of leff R-modules,then $\bar{\boldsymbol{\psi}}:Hom_{\mathbb{R}}(\mathbb{C},\mathbb{D})\to$ $Hom_{\mathbb{R}}(\mathbf{C},\mathbf{D}^{\prime})$ is a homomorphism of left S-modules..

SKETCH OF PROOF. (i) The verification that $fs$ is a well-defined module homomorphism and that $\mathrm{Hom}_R(A,B)$ is actually a right $S$ -module is tedious but straight-forward; similarly for (iii). (ii). $\bar{\varphi}$ is an abelian group homomorphism by Theorem 4.1. If $f\varepsilon\operatorname{Hom}_R(A^{\prime},B)$ ,a∈ $A$ and $s\varepsilon S$ ,then

$$\overline{\varphi}(\:fs)(a)=((\:fs)\varphi)(a)\:=\:(\:fs)(\varphi(a))\:=\:(\:f(\varphi(a)))s\:=\:(\:f\varphi(a))s\:=\:((\overline{\varphi}f)(a))s.$$

Hence $\bar{\varphi}(fs)=(\bar{\varphi}f)s$ and $\bar{\varphi}$ is a right $S$ -module homomorphism. (iv) is proved an. alogously.

REMARK.An important special case of Theorem 4.8 occurs when $R$ is commutative and hence every $R$ -module $C$ is an $R-R$ bimodule with $rc=cr$ $(r\in R,c\in C)$ .In this case for everyr e $R$ ,ae $A$ , and $f\varepsilon\operatorname{Hom}_R(A,B)$ wehave

$$(rf)(a)=f(ar)=f(ra)=rf(a)=(f(a))r=(fr)(a).$$

It follows that $\mathrm{Hom}_R(A,B)$ is an $R-R$ bimodule with $rf=fr$ for all re $R$ $f\varepsilon\operatorname{Hom}_R(A,B)$

Theorem 4.9. If A is a unitary left module over a ring R with identity then there is an isomorphism of left R-modules. $\mathbf{A}\cong Hom_{\mathbb{R}}(\mathbf{R},\mathbf{A})$

SKETCH OF PROOF. Since $R$ is an $R-R$ bimodule, the left module structure of $\mathrm{Hom}_{R}(R,A)$ is given by Theorem 4.8(ii). Verify that the map $\varphi:\operatorname{Hom}_R(R,A)$ $\to A$ given by $f\vdash f(1_R)$ is an $R$ -module homomorphism. Define a map $\psi:A\to$ $\mathrm{Hom}_R(R,A)$ by $a\vdash f_u$, where $f_{u}(r)=ra$ Verify that $\psi$ is a well-defined $R$ -module homomorphism such that $\varphi\psi=1_A$ and $\psi\varphi=1_{\mathrm{Hom}_{R}(R,A)}$ .■

Let $A$ be a left module over a ring $R$ . Since $R$ is an $R-R$ bimodule, $\mathrm{Hom}_R(A,R)$ is a right $R$ -module by Theorem 4.8(i). $\mathrm{Hom}_{R}(A,R)$ is called the dual module of $A$ and is denoted $A^*$ . The elements of $A^*$ are sometimes called linear functionals. Similarly if $B$ is a right $R$ -module, then the dual $B^*$ of $B$ is the left $R$ -module $\mathrm{Hom}_R(B,R)$ (Exercise 4(a)).

------------------------------------------------------------------

Theorem 4.10. Let A,B and C be left modules over a ring R.

(i $\boldsymbol{If}\varphi:\mathbf{A}\rightarrow\mathbf{C}$ is a homomorphism of left R-modules, then the inducedmap $\bar{\varphi}:\mathbf{C}^*=Hom_{\mathbf{R}}(\mathbf{C},\mathbf{R})\to Hom_{\mathbf{R}}(\mathbf{A},\mathbf{R})=\mathbf{A}^*$ is a homomorphism of righ R-modules. (i) There is an R-module isomorphisn $(\mathbf{A}\oplus\mathbf{C})^{*}\cong\mathbf{A}^{*}\oplus\mathbf{C}^{*}$ (ii) IfR is $Q$ division ring and $0\to\mathbf{A}\overset{\theta}{\operatorname*{\rightarrow}}\mathbf{B}\overset{\xi}{\operatorname*{\rightarrow}}\mathbf{C}\to0$ is a short exact sequence of

lefi vector spaces, then $0\to\mathbf{C}^*\overset{\bar{f}}{\operatorname*{\operatorname*{\rightarrow}}}\mathbf{B}^*\overset{\bar{\theta}}{\operatorname*{\rightarrow}}\mathbf{A}^*\to0$ is a short exact sequence of righi vector spaces.

PROOF. Exercise; see Theorems 2.4, 3.2, 4.1, 4.5, and 4.7. The map $\bar{\varphi}$ of(i) is called the dual map of $\varphi$ .

If $A$ is a left module over a ring $R$ ,ae $A$ , and $f\varepsilon\:A^{*}=\mathrm{Hom}_{R}(A,R)$ , then one fre quently denotes $f(a)\varepsilon R$ by $\langle a,f\rangle$ . Since $f$ is a left $R$ -module homomorphism,

$$\langle r_1a_1+r_2a_2,f\rangle=r_1\langle a_1,f\rangle+r_2\langle a_2,f\rangle\quad(r_i\varepsilon R,f\varepsilon A^*,a_i\varepsilon A).$$

Similarly since $A^*$ is a right $R$ -module with $(fr)(a)=f(a)r$ ,wehave

$$\langle a,f_1r_1+f_2r_2\rangle=\langle a,f_1\rangle r_1+\langle a,f_2\rangle r_2\quad(r_i\varepsilon R,f_i\varepsilon A^*,a\varepsilon A).$$

In the proofs below we shall use the brackets notation for linear functionals as well as the Kronecker delta notation: for any index set $I$ and ring $R$ with identity the symbol $\delta_{ij}$ $_{i}\left(i,j\in I\right)$ denotes $0\varepsilon R$ if $i\neq j$ and $1_R\varepsilon R$ if $i=j$

Theorem 4.11. Ler F be a free left module orer a ring R with identity. Let $X$ beal basis of F and for eachi x E $X$ let $\mathbf{f}_{\mathbf{x}}:\mathbf{F}\to\mathbf{R}\:b\boldsymbol{e}$ given by $f_{x}(y)=\delta_{xy}\left(y\varepsilon X\right)$ .Then

(i) $\{f_x\mid x\in X\}$ is a linearly independent subset of $F^*$ of cardinality $|\mathbf{X}|$ (ii) ifX is finite, then $F^*$ is a free right R-module with basis $\{f_{x}\mid x\in X\}$

REMARKS. The homomorphisms $f_x$ are well defined since $F$ is free with basis $X$ (Theorem 2.1). In part (i), $\{f_x\mid x\in X\}$ is called the dual basis to $X$ . This theorem is clearly true for any vector space $V$ over a division ring by Theorem 2.4. In particular, if $V$ is finite dimensional, then Proposition 2.9 and Theorem 4.11 imply that dim $V$ = = $=\dim V^{*}$ V* $V^*$ and $V\cong V^*$ . However, if $V$ is infinite dimensional then dim $V^*>\dim V$ (Exercise 12). More generally, if $F$ is a free module over an arbitrary ring (for example, $\mathbf{Z}$ ， $F^*$ need not be free (see Exercise 10).

PROOF OF 4.11. (i) I $f_{x_{1}}r_{1}+f_{x_{2}}r_{2}+\cdots+f_{x_{n}}r_{n}=0\:(r_{i}\varepsilon R;\:x_{i}\varepsilon X)$ , then for each $j=0,1,2,\ldots,n$,

$$0=\langle x_{j},0\rangle=\left\langle x_{j},\sum_{i=1}^{n}f_{x_{i}}r_{i}\right\rangle=\sum_{i}\langle x_{j},f_{x_{i}}\rangle r_{i}=\sum_{i}\delta_{ij}r_{i}=r_{j}.$$

Since $r_{j}=0$ for all $j,\left\{f_{x}\mid x\in X\right\}$ is linearly independent. If $x\neq y\varepsilon X$ , then $f_x(x)$ $=1_{R}\neq0=f_{u}(x)$ ,whence $f_{x}\neq f_{y}$ . Therefore, $|X|=|\{f_x\mid x\in X\}|$

(i) If $X$ is finite, say $X=\{x_{1},\ldots,x_{n}\}$ ,and $f\varepsilon F^*$ ，let $s_{i}=f(x_{i})=\langle x_{i,}f\rangle\varepsilon R$ and denote $f_{x,j}$ by $f_i$ If $u\varepsilon F$ F $F$ , then $u=r_{1}x_{1}+r_{2}x_{2}+\cdots+r,x_{n}\in F$ for some $r_i\varepsilon R$ $R$ R and

|

1

1

------------------------------------------------------------------

$$\begin{aligned}
\left\langle u,\sum_{j=1}^{n}f_{j}s_{j}\right\rangle & =\left\langle\sum_{i=1}^{n}r_{i}x_{i},\sum_{j}f_{j}s_{j}\right\rangle \\
&=\sum_{i}\sum_{j}r_{i}\langle x_{i},f_{j}\rangle s_{j}=\sum_{i}\sum_{j}r_{i}\delta_{ij}s_{j}=\sum_{i}r_{i}s_{i} \\
&=\sum_{i}r_{i}\langle x_{i},f\rangle=\langle\sum_{i}r_{i}x_{i},f\rangle=\langle u,f\rangle.
\end{aligned}$$

Therefore, $f=f_{\mathrm{l}}s_{\mathrm{l}}+f_{2}s_{2}+\cdots+f_{n}s_{n}$ and $\{$ $f_{i}\}$ = $\{$ $f_{x}\mid x$ $\varepsilon$ $X\}$ generates $F^*$ .Hence $\{f_x\mid x\in X\}$ is a basis and $F^*$ is free.

The process of forming duals may be repeated. If $A$ is a left $R$ -module, then $A^*$ is a right $R$ -module and $A^{**}=(A^{*})^{*}=\mathrm{Hom}_{R}(\mathrm{Hom}_{R}(A,R),R)$ (where the left hand $Hom_R$ indicates all right $R$ -module homomorphisms) is a left $R$ -module (see Exercise 4(a)). $A^{**}$ is called the double dual of $A$

Theorem 4.12. Ler A be a lef1 module ocer a ring R.

(i) There is an R-module homomorphism $\theta:\mathbf{A}\to\mathbf{A}^{**}$ (ii) IfR has anidenrity and Aisfree,then $\theta$ is a monomorphism. (ii) IfR has an identity and A is free with a finite basis, then $\theta$ is an isomorphism

A module $A$ such that $\theta:A\to A^{**}$ is an isomorphism is said to be reflexive

PROOF OF 4.12.(i) For each ae $A$ let $\theta(a):A^*\to R$ be the map defined by $[\theta(a)](f)=\langle a,f\rangle\varepsilon R$ . Statement (2) after Theorem 4.10 shows that $\theta(a)$ is a homomorphism of right $R$ -modules (that is, $\theta(a)\varepsilon A^{**}$ .The map $\theta:A\to A^{**}$ given by $a\vdash\theta(a)$ is a left $R$ -module homomorphism by (1) after Theorem 4.10.

(i) Let $X$ be a basis of $A$ .Ifae $A$ , then $a=r_{1}x_{1}+r_{2}x_{2}+\cdots+r_{n}x_{n}(r_{i}\varepsilon R;x_{i}\varepsilon X)$ If $\theta(a)=0$ , then for all $f\varepsilon A^*$

$$0=\langle a,f\rangle=\left\langle\sum_{i=1}^nr_ix_i,f\right\rangle=\sum_ir_i\langle x_i,f\rangle.$$

 In particular, for $f=f_{x,j}\left(j=1,2,\ldots,n\right)$

$$0=\sum_{i}r_{i}\langle x_{i},f_{x_{j}}\rangle=\sum_{i}r_{i}\delta_{ij}=r_{j}.$$

Therefore, a = ∑ rx: = ∑ Ox; = 0 and $\theta$ is a monomorphism.

(ii) If $X$ is a finite basis of $A$ , then $A^*$ is free on the (finite) dual basis $\{f_x\mid x\in X\}$ by Theorem 4.11. Similarly $A^{**}$ isfree on the(finite)dual basis $\{g_x\mid x\in X\}$ , where for each $x\varepsilon X$ $g_x:A^*\to R$ is the homomorphism that is uniquely determined by the condition: $g_{x}(f_{y})=\delta_{xy}(y\varepsilon X)$ .But 0(x) $\theta(x)$ $\theta(x)\varepsilon A^{**}$ A** $A^{**}$ is a homomorphism $A^{*}\dashrightarrow R$ such that for every $y$ y $y\varepsilon X$

$$\theta(x)(f_{y})=\langle x,f_{y}\rangle=\delta_{xy}=g_{x}(f_{y}).$$

Hence $g_{x}=\theta(x)$ and $\{\theta(x)|x\in X\}$ is a basis of $A^{**}$ . This implies that $\mathbf{Im}\theta=A^{**}$ whence $\theta$ is an epimorphism.

------------------------------------------------------------------

### EXERCISES

Note: $R$ is a ring.

1. (a) For any abelian group $A$ and positive integer m, $\operatorname{Hom}(Z_m,A)\cong A[m]$ $=\{a\in A\mid ma=0\}$ (b) Hom$( Z_{m}, Z_{n}) \cong Z_{( m, n) }$ (c) The $\mathbf{Z}$ -module $Z_{m}$ has $Z_{m}^{*}=0$ (d) For each $k\geq1$ $Z_m$ is a $Z_{mk}$ -module (Exercise 1.1); as a $Z_{mk}$ -module, $Z_{m}^{*}\cong Z_{m}$

2.If $A,B$ are abelian groups and $m,n$ integers such that $mA=0=nB$ ,then every element of $\operatorname{Hom}(A,B)$ has order dividing $(m,n)$

3. Let $\pi:\mathbf{Z}\to\mathbf{Z}_2$ be the canonical epimorphism. The induced map $\overline{\pi}:$Hom$(Z_2,\mathbf{Z})$ $\to$Hom$(Z_2,Z_2)$ is the zero map.Since $\operatorname{Hom}(Z_2,Z_2)\neq0$ (Exercise 1(b)), $\bar{\pi}$ is not an epimorphism.

4. Let $R,S$ be rings and $A_{R}$, $sB_{R}$, $sC_{R}$, $L$ D $D_{R}$ (bi)modules as indicated. Let $Hom_R$ denote all righr $R$ -module homomorphisms (a) $\mathrm{Hom}_R(A,B)$ is a left $S$ -module, with the action of $S$ given by $(sf)(a)=$

$s(f(a))$ (b) If $\varphi:A\to A^{\prime}$ is an homomorphism of right $R$ -modules, then the induced map $\bar{\varphi}:\operatorname{Hom}_R(A^{\prime},B)\to\operatorname{Hom}_R(A,B)$ is an homomorphism at left $S$ -modules (c) $\mathrm{Hom}_{R}(C,D)$ is a right $S$ -module, with the action of $S$ given by $(gs)(c)=g(sc)$ (d) If $\psi:D\to D^{\prime}$ is an homomorphism of right $R$ -modules, then $\bar{\psi}:\operatorname{Hom}_R\left(C,D\right)\to\operatorname{Hom}_R(C,D^{\prime})$ is an homomorphism of right $S$ -modules.

5.Let $R$ be a ring with identity; then there is a ring isomorphism $\mathrm{Hom}_R(R,R)\cong R^{op}$ where $Hom_R$ denotes left $R$ -module homomorphisms (see Exercises III.1.17 and 1.7). In particular, if $R$ is commutative, then there is a ring isomorphism $\mathrm{Hom}_R(R,R)\cong R.$

6. Let $S$ be a nonempty subset of a vector space $V$ over a division ring. The annihila tor of $S$ is the subset $S^0$ of $V^*$ given by $S^{0}=\left\{\begin{array}{c}{f\varepsilon V^{*}\mid\langle s,f\rangle=0}\\\end{array}\right\}$ for all $s\in S\}$ (a) $0^0=V^*$ $V^0=0$ $S\neq\{0\}\Rightarrow S^{0}\neq V^{*}$ (b) If $W$ is a subspace of $V$ , then $W^0$ is a subspace of $V^*$

(c) If $W$ is a subspace of $V$ and dim $V$ is finite, then dim $W^{0}=\dim V-\dim W$ (d) Let $W,V$ be as in (c). There is an isomorphism $W^{*}\cong V^{*}/W^{0}$ (e) Let $W,V$ be as in (c) and identify $V$ with $V^{**}$ under the isomorphism $\theta$ of Theorem 4.12. Then $(W^{0})^{0}=W\subset V^{**}$

7. If $V$ is a vector space over a division ring and $f\varepsilon V^*$ , let $W=\left\{a\in V\mid\langle a,f\rangle=0\right\}$ then $W$ is a subspace of $V.$ If dim $V$ is fnite, what is dim W?

8. If $R$ has an identity and we denote the left $R$ -module $R$ by $RR$ and the right $R$ -module $R$ by $R_{R}$ ,then $(_RR)^*\cong R_R$ and $(R_{R})^{*}\cong_{R}R$

9. For any homomorphism $f:A\to B$ of left $R$ -modules the diagram

![](https://storage.simpletex.cn/view/fT8FYMwpPOULIr0vIQANcGDn6bomG2u0T)

------------------------------------------------------------------

is commutative, where $\theta_{i1},\theta_{is}$ are as in Theorem 4.12 and $f^{*}$ is the map induced on $A^{**}=\operatorname{Hom}_{n}(\operatorname{Hom}_{R}(A,R),R)$ by the map $\bar{f}:\operatorname{Hom}_K(B,R)\to\operatorname{Hom}_R(A,R)$

10. Let $F=\sum_{r\epsilon X^{\prime}}\mathbf{Z}x$ be a free $Z$ -module with an infinite basis $X$ . Then $|f_{x}\mid x\in X|$ (Theorem 4.11) does not form a basis of $F^*$ . [Hinr: by Theorems 4.7 and 4.9, $F^{*}\cong\prod_{x\in X}\mathbf{Z}x$ ; but under ths isomorphisnm $f_{\nu}\mapsto\left\{\delta_{x_{\nu}}x\right\}\in\prod_{x_{\varepsilon}X}\mathbf{Z}x.]$ Note: $F^{*}=\mathbf{IIZ}_{x}$ is not a free $\mathbf{Z}$ -module; see L. Fuchs [13; p. 168].

11.If $R$ has an identity and $P$ is a finitely generated projective unitary left $R$ -module, then (a) $P^*$ is a finitely generated projective right $R$ -module.

(b) $P$ is refexive. This proposition may be false if the words "fnitely generated’'are omitted; see Exercise 10.

12. Let $F$ be a field, $X$ an infnite set, and $V$ the free left $F.$ -module (vector space) on the set $X.$ Let $F.Y$ be the set of all functions. $f:X\to F$ (a) $F^{X}$ is a (right) vector space over $F$ (with $(f+g)(x)=f(x)+g(x)$ and

$(fr)(x)=rf(x))$ (b) There is a vector-space isomorphism $V^{*}\cong F^{X}$

(c) $\dim_FF^{X}=|F|^{|X|}$ (see Introduction, Exercise 8.10). (d) dim $V^*>\dim_FV$ [Hint: by Introduction, Exercise 8.10 and Introduction, Theorem $8.5\dim_{F}V^{*}=\dim_{F}F^{X}=|F|^{|X|}\geq2^{|X|}=|P(X)|>|X|=\dim_{F}V.]$

## 5. TENSOR PRODUCTS

The tensor product $A\otimes_RB$ of modules $A_R$ and $\iota_{l}B$ over a ring $R$ is a certain abelian group, which plays an important role in the study of multilinear algebra. It is frequently useful to view the tensor product $A\otimes_RB$ as a universal object in a certain category (Theorem 5.2). On the other hand, it is also convenient to think of $A\otimes_RB$ as a sort of dual notion to $\mathrm{Hom}_R(A,B)$ We shall do this and consider such topics as induced maps and module structures for $A\otimes_RB$ as well as the behavior of tensor products with respect to exact sequences and direct sums. If $A_R$ and $_{R}B$ are modules over a ring $R$ ,and $C$ is an (additive) abelian group, then

 a middle linear map from $A\times B$ to $C$ is a function $f:A\times B\to C$ such that for all $(u,(u_{i}\in A,b,b_{i}\in B$ , and $r\varepsilon R$ $R$ R

$$\begin{aligned}
f(a_{1}+a_{2},b)& =\:f(a_{1},b)+f(a_{2},b); \\
f(a,b_{1}+b_{2})& =f(a,b_{1})+f(a,b_{2}); \\
f(ar,b)& =f(a,rb). 
\end{aligned}$$

For fixed $A_R,_RB$ consider the category $\mathfrak{M}(A,B)$ whose objects are all middle linear maps on $A\times B$ . By definition a morphism in $\mathfrak{M}(A,B)$ from the middle linear map $f:A\times B\to C$ to the middle linear map $g:A\times B\to D$ is a grouphomomorphism $h:C\to D$ such that the diagram

![](https://storage.simpletex.cn/view/fz0IzuhNXtYhcH2v755FBsZPSRkFtGBVs)

------------------------------------------------------------------

is commutative. Verify that $\mathfrak{m}(A,B)$ is a category, that $1_C$ is the identity morphism from $f$ to $f$, and that $h$ is an equivalence in $\mathfrak{m}(A,B)$ ifand onlyif $h$ is an isomorphism of groups. In Theorem 5.2 we shall construct a universal object in the category $\mathfrak{m}(A,B)$ (see Definition I.7.9). First, however, we need

Definition 5.1. Let A be a right module and B a lefi module orer a ring R. Let F be thefree abeliangroup onthe set $A\times B.$ Let K be the subgroup of F generated by al elements of the following forms (for all a,a' e A; b,b' e B; r e R):

$$\mathrm{(a+a',b)-(a,b)-(a',b);}$$

$$\mathrm{(a,b+b')-(a,b)-(a,b');}$$
(iii) (ar,b) - (a,rb).

The quotient group $F/K$ is calledthe tensorproduct ofA andB;it isdenoted A $\textcircled{8}_{\mathrm{R}}B$ (or simply A $\textcircled{8}$ B $if\mathbf{R}=\mathbf{Z}$ ). The coset (a,b$)+\mathbf{K}$ ofthe element (a,b) in $F$ is denoted a $\textcircled{8}$ b; the coset of(O,0) is denoted 0.

Since $F$ is generated by the set $A\times B$ , the quotient group $F/K=A\otimes_RB$ is generated by all elements (cosets) of the form $a\otimes b\left(a\in A,b\in B\right)$ . But it is nor true that every element of $A\otimes_RB$ is of the form a $\textcircled{8}b$ (Exercise 4). For the typical element of $F$ is a uom $\sum_{i=1}^{r}n_{i}(a_{i},b_{i})\left(n_{i}\in\mathbf{Z},a_{i}\in A,b_{i}\in B\right)$ and hence is cose in $A\otimes_RB$ $=F/K$ is of the fom $\sum_{i=1}^rn_i(a_i\otimes b_i)$ Furthermore, sine i is posibleto choses different representatives for a coset, one may have $a\textcircled{X}b=a^{\prime}\textcircled{X}b^{\prime}$ in $A\otimes_RB$ ,bur $a\neq a^{\prime}$ and $b\neq b^{\prime}$ (Exercise 4). It is also possible to have $A\otimes_RB=0$ even thougl $A\neq0$ and $B\neq0$ (Exercise 3)

 Definition 5.1 implies that the generators $a\textcircled{8}b$ of $A\otimes_RB$ satisfy the following relations (for all $a,a_{i}\varepsilon A,b,b_{i}\varepsilon B$ , and $r\varepsilon R$ $R$ R

$$\begin{aligned}
(a_{1}+a_{2})\otimes b& =\:a_{1}\otimes b+a_{2}\otimes b; \\
a\otimes(b_1+b_2)& =a\otimes b_{1}+a\otimes b_{2}; \\
ar\otimes b& =\:a\:\otimes\:\boldsymbol{r}b. 
\end{aligned}$$

The proof of these facts is straightforward; for example, since $(a_{1}+a_{2},b)-(a_{1},b)-$ $(a_2,b)\in K$ , the "zero coset," we have

$$[(a_1+a_2,b)+K]-[(a_1,b)+K]-[(a_2,b)+K]=K;$$

 or in the notation $(a,b)+K=a\textcircled{8}b$,

$$(a_1+a_2)\otimes b-a_1\otimes b-a_2\otimes b=0.$$

Indeed an alternate definition of $A\otimes_RB$ is that it is the abelian group with genera tors all symbols $a\otimes b\left(a\in A,b\in B\right)$ , subject to the relations (6)-(8) above. Furthermore, since O is the only element of a group satisfying $x+x=x$ , it is easy to see that for all $a\in A,b\in B$ $b\varepsilon B$ $b\varepsilon B$

$$a\otimes0=0\otimes b=0\otimes0=0.$$

------------------------------------------------------------------

Given modules $A_{R}$ and $_{R}B$ over a ring $R$ , it is easy to verify that the map $i:A\times B\to A\otimes_RB$ given by $(a,b)\vdash a\otimes b$ is a middle linear map. The map $i$ is called the canonical middle linear map. Its importance is seen in

Theorem 5.2. Let $\mathbf{A}_{\mathbf{R}}$ and $RB$ be modules over a ring R,and let C be an abelian group. $If\mathbf{g}:\mathcal{A}\times\mathcal{B}\to\mathcal{C}$ is a middle linear map,then there exists a uniquegroup homomorphism $\overline{\mathbf{g}}:\mathbf{A}\otimes_{\mathbf{R}}\mathbf{B}\to\mathbf{C}$ such that $\bar{\mathbf{g}}\mathbf{i}=\mathbf{g}$ , where i $:\mathcal{A}\times\mathcal{B}\to\mathcal{A}\otimes_{\mathbf{R}}$ B is the canonical middle linear map. A $\textcircled{8}_{\mathbf{R}}$ Bis uniquely determined up to isomorphism by this property. In other words i $:\mathcal{A}\times\mathcal{B}\to A\otimes_{\mathbf{R}}$ Bis universal in the category Sm(A,B)ofall middle linear maps on $A\times B$

SKETCH OF PROOF. Let $F$ be the free abelian group on the set $A\times B$ ,and let $K$ be the subgroup described in Definition 5.1. Since $F$ is free, the assignment $(a,b)\mapsto g(a,b)\varepsilon C$ determines a unique homomorphism $g_{1}:F\to C$ by Theorem 2.1 (iv). Use the fact that $g$ is middle linear to show that $g_1$ maps every generator of $K$ to 0.Hence $K\subset$ KC $K\subset Kerg_1$ $g_{1}$ g1 .By Theorem $1.7g_1$ induces a homomorphism $\bar{g}:F/K\to C$ such that $\bar{g}[(a,b)+K]=g_{1}[(a,b)]=g(a,b)$ ．But $F/K=A\otimes_RB$ and $(a,b)+K$ $=a\otimes b$ . Therefore, $\bar{g}:A\otimes_RB\to C$ is a homomorphism such that $\bar{g}i(a,b)$ $=\bar{g}(a\otimes b)=g(a,b)$ for all (a,b) $(a,b)$ $(a,b)\in A\times B$ ; that is, $\bar{g}i=g$ if $h:A\otimes_RB\to C$ is any homomorphism with $hi=g$ , then for any generator $a\textcircled{8}b$ of $A\otimes_RB$

$$h(a\otimes b)=hi(a,b)=g(a,b)=\bar{g}i(a,b)=\bar{g}(a\otimes b).$$

Since $h$ and $\bar{g}$ are homomorphisms that agree on the generators of $A\otimes_RB$ , we must have $h=\bar{g}$ ,whence $\bar{g}$ is unique. This proves that $i:A\times B\to A\otimes_{R}\bar{B}$ is a universal object in the category of all middle linear maps on $A\times B$ ,whence $A\otimes_RB$ is uniquely determined up to isomorphism (equivalence) by Theorem I.7.10.

Corollary 5.3. If $\mathbf{A}_{\mathbf{R}}$ $\mathbf{A}_{\mathbf{R}}^{\prime}$ , $_{\mathbf{R}}\mathbf{B}$ and $_{\mathbf{R}}\mathbf{B^{\prime}}$ are modules over a ring R and $\mathbf{f}:\mathbf{A}\rightarrow\mathbf{A}^{\prime}$ $\mathbf{g}:\mathbf{B}\to\mathbf{B^{\prime}}$ are R-module homomorphisms, then there is a unique group homomorphism $A\otimes_{\mathbf{R}}B\to A^{\prime}\otimes_{\mathbf{R}}B^{\prime}$ such that a $\textcircled{8}$ $\textcircled{8}$ $\textcircled{\times}$b$\vdash$f(a)$\otimes$g(b) for all a e A, b ε B.

SKETCH OF PROOF. Verify that the assignment $(a,b)\vdash f(a)\otimes g(b)$ defines a middle linear map $h:A\times B\to C=A^{\prime}\otimes_RB^{\prime}$ .By Theorem 5.2 there is a unique homomorphism $\bar{h}:A\otimes_RB\to A^{\prime}\otimes_RB^{\prime}$ such that $\bar{h}(a\otimes b)=\bar{h}i(a,b)=h(a,b)$ $=f(a)\otimes g(b)$ for all $a\in A,b\in B$ .

The unique homomorphism of Corollary 5.3 is denoted $f\otimes g:A\otimes_RB\to$ $A^{\prime}\otimes_{R}B^{\prime}$ .If $f^{\prime}:A_{R}^{\prime}\to A_{R}^{\prime\prime}$ and $g^{\prime}:_{R}B^{\prime}\dashrightarrow{}_{R}B^{\prime\prime}$ are also $R$ -module homomorphisms, then it is easy to verify that

$$(f'\otimes g')(f\bigotimes g)=(f'f\bigotimes g'g):A\bigotimes_RB\to A''\bigotimes_RB''.$$

 It follows readily that if $f$ and $g$ are $R$ -module isomorphisms, then $f\textcircled{8}g$ is a group isomorphism with inverse $f^{-1}\otimes g^{-1}$

Proposition 5.4. $If\overset{\mathbf{f}}{\operatorname*{\operatorname*{\rightarrow}}}B\overset{\mathbf{g}}{\operatorname*{\rightarrow}}C\to0$ is an exact sequence ofleft modules over a ring Rand D is a right R-module, then

------------------------------------------------------------------

$$\mathrm{D}\otimes_{\mathbb{R}}\mathrm{A}\xrightarrow{\mathrm{ıD}\otimes\mathbf{f}}\mathrm{D}\otimes_{\mathbb{R}}\mathrm{B}\xrightarrow{\mathrm{ıD}\otimes\mathbf{g}}\mathrm{D}\otimes_{\mathbb{R}}\mathrm{C}\to0$$

is an exact sequence of abelian groups. An analogous statement holds for an exact se quence in the first variable.

PROOF. We must prove: (i) Im $(1_{D}\otimes g)=D\otimes_{R}C$ (i) Im $(1_{D}\otimes f)\subset$ Ker $(1_{D}\otimes g)$ ; and (ii) Ker $(1_{D}\otimes g)\subset\operatorname{Im}(1_{D}\otimes f)$

(i) Since $g$ is an epimorphism by hypothesis every generator $d\textcircled{8}c$ of $D\otimes_RC$ is of the forrn $d\otimes g(b)=(1_D\otimes g)(d\otimes b)$ for some $b\in B.$ Thus Im $(1_{D}\otimes g)$ contains all generators of $D\left(\mathbb{Z}\right)_{R}C$ ,whence Im $(1_{D}\otimes g)=D\otimes_{R}C$ . (ii) Since Ker $g=\operatorname{Im}f$ we have $gf=0$ and $(1_D\otimes g)(1_D\otimes f)=1_D\otimes gf=1_D\textcircled {又}0=0$ ，whence Im $(\mathbf{1}_{D}\otimes f)\subset$Ker $(1_{\bullet}\otimes g)$ .(i) Let $\pi:D\textcircled{\times}_RB\to(D\otimes_RB)/\operatorname{Im}(1_b\otimes f)$ (lf) $(1_{D}\otimes f)$ be the canonical epimorphism. By (i) and Theorem 1.7 there is a homomorphism $\alpha:(D\otimes_RB)/$Im α : (D βR B)/Im $\alpha:(D\otimes_RB)/$Im $(1_D\otimes f)\to D\otimes_RC$ such that $\alpha(\pi(d\otimes b))=(1_{D}\otimes g)(d\otimes b)$ $=d\otimes g(b)$ We shall show that $\alpha$ is an isomorphism. This fact and Theorem 1.7 will imply Ker $(1,\otimes g)=\operatorname{Im}\left(1,\otimes f\right)$ and thus complete the proof. We showfirst that themap $\beta:D\times C\to(D\otimes_RB)/\operatorname{Im}\left(1_D\otimes f\right)$ given by $(d,c)\vdash$

$\pi(d\otimes b)$ ,where $g(b)=c$ ,is independent of the choice of $b$ . Note that there is ai least one such $b$ since $g$ is an epimorphism. If $g(b^{\prime})=c$ , then $g(b-b^{\prime})=0$ and $b-b^{\prime}\varepsilon$ Ker $g=$Im$f$, whence $b-b^{\prime}=f(a)$ for some a e $A$ Since $d\otimes f(a)\varepsilon$ Im $(1_{D}\otimes f)$ and $\pi(d\otimes f(a))=0$ ,wehave

$$\begin{aligned}\pi(d\bigotimes b)&=\pi(d\bigotimes b^{\prime}+f(a))=\pi(d\bigotimes b^{\prime}+d\bigotimes f(a))\\&=\pi(d\bigotimes b^{\prime})+\pi(d\bigotimes f(a))=\pi(d\bigotimes b^{\prime}).\end{aligned}$$

Therefore $\beta$ is well defined. Verify that $\beta$ is middle linear. Then by Theorem 5.2 there is a unique_homomorphism $\bar{\beta}:D\otimes_RC\to(D\otimes_RB)/\operatorname{Im}(\mathbf{l}_D\otimes f)$ such that $\bar{\beta}(d\otimes c)=\bar{\beta}i(d,c)=\beta(d,c)=\pi(d\otimes b)$ ,where $g(b)=c$ Therefore, for any gener ator $d\textcircled{\times}c$ of $D\otimes_{R}C,\bar{\alpha\beta}(d\otimes\underline{c})=\:\alpha(\pi(d\otimes b))=\:d\otimes g(b)=\:d\otimes c$ ，whence $\alpha\overline{\beta}$ is the identity map. Similarly $\overline{\beta}_{\alpha}$ is the identity so that $\alpha$ is an isomorphism.

REMARKS. If $h:A_R\to A_R^{\prime}$ and $k:_{R}B\to_{R}B^{\prime}$ are module epimorphisms, then Proposition 5.4 implies that $1_A\otimes k$ and $h\otimes1_B$ are group epimorphisms. Hence $h\otimes k{:}A\otimes_RB\to A^{\prime}\otimes_RB^{\prime}$ is an epimorphism since $h\otimes k=(1_{A^{\prime}}\otimes k)(h\otimes1_{B})$ However, if $h$ and $k$ are monomorphisms, $h\otimes1_B$ and 1 $.1\textcircled{8}k$ need not be monomor. phisms (Exercise 7).

Theorem 5.5. Ler R and S be rings and $sA_R$ SAR $_{\mathbf{R}}\mathbf{B}$ RB $\mathbf{s}\mathbf{A}_{\mathrm{R}},\:\mathbf{R}\mathbf{B},\mathbf{C}_{\mathrm{R}},\:\mathbf{n}\mathbf{D}_{\mathrm{S}}(bi)$ modules as indicated

(i) A $1\otimes_{\mathrm{R}}B$ is a lefr S-module surh that $s(a\otimes b)=sa\textcircled{8}$ $\textcircled{8}$ b for all s e S, a e A. b e B.

(ii) $If$ f$:\mathbf{A}\to\mathbf{A^{\prime}}$ is a homomorphism of S-R binodules and $\mathbf{g}:\mathbf{B}\to\mathbf{B^{\prime}}$ isan R-module homomorphism, then the induced map $\mathbf{f}\otimes\mathbf{g}:\mathbf{A}\otimes_{\mathbf{R}}\mathbf{B}\to\mathbf{A^{\prime}}\otimes_{\mathbf{R}}\mathbf{B^{\prime}}$ is $a$ homomorphism of left S-modules

(ii) $C\otimes_R$ D is a right S-module such that (c$\otimes$d)s=c$\textcircled{\times}$ ds for all c e C, deD,s eS. (iv) $If\mathbf{h}:\mathbf{C}\to\mathbf{C^{\prime}}$ is an R-module homomorphism and $\mathbf{k}:\mathbf{D}\to\mathbf{D}^{\prime}$ a homomor

phism ofR-S bimodules,then the induced map $\mathbf{h}\otimes\mathbf{k}:\mathbf{C}\otimes_{\mathbf{R}}\mathbf{D}\to\mathbf{C}^{\prime}\otimes_{\mathbf{R}}\mathbf{D}^{\prime}$ is $a$ homomorphism ofright S-modules

------------------------------------------------------------------

SKETCH OF PROOF. (i) For each $s\varepsilon S$ the map $A\times B\to A\otimes_RB$ given by $(a,b)\vdash sa\textcircled {天}b$ is $R$ -middle linear, and therefore induces a unique group homomor. phism $\alpha_{s}:\bar{A}\otimes_{R}B\to A\otimes_{R}B$ such that $\alpha_{s}(a\otimes b)=sa\otimes\bar{b}$ . For.each element $u=\sum_{i=1}^{n}a_{i}\otimes b_{i}\in A\otimes_{R}B$ defne $su$ to be the eement $\alpha_{s}(u)=\sum_{i=1}^{n}\alpha_{s}(a_{i}\otimes b_{i})$ $=\sum_{i=1}^nsa_i\otimes b_i$ Since $\alpha_s$ is homomorphism, his ction of $S$ is wll define tha is independent of how $u$ is written as a sum of generators). It is now easy to verify that $A\otimes_RB$ is a left $S$ -module.

REMARK. An important special case of Theorem 5.5 occurs when $R$ is a com mutative ring and hence every $R$ -module $A$ is an $R-R$ bimodule with $ra=ar$ $(r\in R,a\in A)$ . In this case $A\otimes_RB$ is also an $R-R$ bimodule with

$$r(a\otimes b)=ra\otimes b=ar\otimes b=a\otimes rb=a\otimes br=(a\otimes b)r$$

for all $r\varepsilon R,a\varepsilon A,b\varepsilon B.$

If $R$ is a commutative ring, then the tensor product of $R$ -modulesmay be characterized by a useful variation of Theorem 5.2. Let $A,B,C$ be modules over a com mutative ring $R$ .A bilinear map from $A\times B$ to $C$ is a function $f:A\times B\to C$ such that for all $a,a_{i}\varepsilon A,b,b_{i}\varepsilon B$ , and r e $R$

$$\begin{aligned}
f(a_{1}+a_{2},b)& =f(a_{1},b)+f(a_{2},b); \\
f(a,b_1+b_2)& =f(a,b_{1})+f(a,b_{2}); \\
f(ra,b)& =rf(a,b)=f(a,rb). 
\end{aligned}$$

Conditions (9) and(10) are simply a restatement of (3) and (4) above. For modules over a commutative ring (11) clearly implies condition (5) above, whence every bilinear map is middle linear.

EXAMPLE. If $A^*$ is the dual ofa module $A$ over a commutative ring $R$ , then the map $A\times A^*\to R$ given by $(a,f)\mapsto f(a)=\langle a,f\rangle$ is bilinear (see p. 204)

EXAMPLE. If $A$ and $B$ are modules over a commutative ring $R$ ,then so is $A\otimes_RB$ and the canonical middle linear map $i:A\times B\to A\otimes_RB$ is easily seen to be bilinear. In this context $i$ is called the canonical bilinear map.

Theorem 5.6.If A,B,C are modules orer a commutatire ring R and $\mathbf{g}:\mathbf{A}\times\mathbf{B}\to\mathbf{C}$ is a bilinear map,then thereis a uniqueR-module homomorphism $\bar{\mathbf{g}}:\mathbf{A}\otimes_{\mathbf{R}}\mathbf{B}\to\mathbf{C}$ such that $\bar{\mathbf{g}}\mathbf{i}=\mathbf{g}$ ,where $\mathrm{i:A\times B\to A\otimes_RB}$ is the canonical bilinear map. The moduleA $\textcircled{8}_{\mathbf{R}}$ B is uniguely determined up to isomorphism by this properiy

SKETCH OF PROOF. Verify that the unique homomorphism of abelian groups $\bar{g}:A\otimes_{R}B\to C$ given by Theorem 5.2 is actually an $R$ -module homomorphism. To prove the last statement let $B(A,E)$ be the category of all bilinear maps on $A\times B$ (defined by replacing the groups $C,D$ and group homomorphism $h:C\to D$ by modules and module homomorphisms in the definition of $\mathfrak{m}(A,B)$ on p. 207)

------------------------------------------------------------------

Then first part of the Theorem shows that $i:A\times B\to A\otimes_RB$ is a universal object in $\textcircled{3}(A,B)$ ，whence $A\otimes_RB$ is uniquely determined up to isomorphism by Theorem 1.7.10.

Theorem 5.6 may also be used to provide an alternate definition of $A\otimes_RB$ when $R$ is a commutative ring with identity. Let $F_{1}$ be the free $R$ -module on the set $A\times B$ and $K_1$ the submodule generated by all elements of the forms:

$$\begin{aligned}
&(a+a,b)-(a,b)-(a^{\prime},b); \\
&(a,b+b^{\prime})-(a,b)-(a,b^{\prime}); \\
&(ra,b)-r(a,b); \\
&(a,rb)-r(a,b);
\end{aligned}$$

where $a,a^{\prime}\varepsilon A;b,b^{\prime}\varepsilon B$ ; and $r\varepsilon R$ R $R$ ; (compare Definition 5.1). We claim that there is an $R$ -module isomorphism $A\otimes_RB\cong F_\mathrm{l}/K_1$ .The obvious analogue of the proof of Theorem 5.2 shows that the map $A\times B\to F_1/K_1$ given by $(a,b)\vdash\mathbf{l}_R(a,b)+K_1$ is a universal object in the category $\textcircled{3}(A,B)$ of bilinear maps on $A\times B$ . Consequently $A\otimes_RB\cong F_1/K_1$ by Theorem 5.6. We return now to modules over arbitrary rings.

Theorem 5.7. If R is a ring with identity and $\mathbf{A}_{\mathbf{R}}$ AR $\mathbf{A}_{\mathbf{R}},\mathbf{R}\mathbf{B}$ RB $_{\mathbf{R}}\mathbf{B}$ are unitary R-modules, then there are R-module isomorphisms

$$A\otimes_{\mathbb{R}}\mathbb{R}\cong\mathbb{A}\quad and\quad\mathbb{R}\otimes_{\mathbb{R}}\mathbb{B}\cong\mathbb{B}.$$

SKETCH OF PROOF. Since $R$ is an $R-R$ bimodule $R\otimes_RB$ is a left $R$ module by Theorem 5.5. The assignment $(r,b)\vdash rb$ defines a middle linear map $R\times B\to B$ .By Theorem 5.2 there is a group homomorphism $\alpha:R\otimes_RB\to B$ such that $\alpha(r\otimes b)=rb.$ Verify that $\alpha$ is in fact a homomorphism of left $R$ -modules Then verify that the map $\beta:B\to R\otimes_RB$ given by $b\vdash\mathbf{1}_R\otimes b$ is an $R$ -module homomorphism such that $\alpha\beta=1_{B}$ and $\beta\alpha=1_{R\otimes_{R}R}$ .Hence $\bar{\alpha}:R\otimes_RB\cong B$ . The isomorphism $A\otimes_RR\cong A$ is constructed similarly.

If $R$ and $S^{\prime}$ are rings and AR $A_R$ $A_R, \:_RB_S$, $sC$ are (bi)modules, then $A\otimes_RB$ is a right $S$ -module and $B\otimes_{s}C$ is a left $R$ -module by Theorem 5.5. Consequently, both $(A\otimes_RB)\otimes_sC$ and $A\otimes_R(B\otimes_sC)$ are well-defined abelian groups.

Theorem 5.8. IfR and S are rings and $\mathbf{A}_{\mathbf{R}}$ R $_{\mathrm{R}}B_{\mathrm{S}}$ RBs $\mathbf{R}$, $\mathbf{R} \mathbf{B} _{\mathbf{S} }$, $\mathbf{s} \mathbf{C}$ sC $_{\mathrm{s} }\mathbf{C}$ are $(bi)$ modules, then there is an. isomorphism

$$(A\otimes_RB)\otimes_SC\cong A\otimes_R(B\otimes_SC).$$

PROOF. By definition every element $v$ of $(A\otimes_RB)\otimes_sC$ is a finite sum $(a_{ij}\in A,b_{ij}\in B)$ # $\sum_{i=1}^{n}u_{i}\otimes c_{i}(u_{i}\varepsilon A\otimes_{R}B,c_{i}\varepsilon C)$ Since $u_{\mathrm{i}}\varepsilon A\otimes_{R}B$ s es $\sum_{j=1}^{m_i}a_i,\otimes b_{i_j}$
$$v=\sum_{i}u_{i}\otimes c_{i}=\sum_{i}\left(\sum_{j}a_{ij}\otimes b_{ij}\right)\otimes c_{i}=\sum_{i}\sum_{j}\left[\left(a_{ij}\otimes b_{ij}\right)\otimes c_{i}\right].$$

1

------------------------------------------------------------------

Therefore, $(A\otimes_RB)\otimes_sC$ is generated by all elements of the form $(a\otimes b)\otimes c$ $(a\varepsilon A,b\varepsilon B,c\varepsilon C)$ . Similarly, $A\otimes_R(B\otimes_sC)$ is generated by all $a\otimes(b\otimes c)$ with $a\varepsilon A,b\varepsilon B,c\varepsilon C.$ Verily that te aesigemenn $\left(\sum_{i=1}^na_i\otimes b_{i,c}\right)\mapsto\sum_{i=1}^n\left[a_i\otimes(b_i\otimes c)\right]$ defines an $S$ -middle linear map $(A\otimes_RB)\times C\to A\otimes_R(B\otimes_sC)$ .Therefore, by Theorem 5.2 there is a homomorphism

$$\alpha:(A\otimes_RB)\otimes_SC\to A\otimes_R(B\otimes_SC)$$

with $\alpha[(a\otimes b)\otimes c]=a\otimes(b\otimes c)$ for all a e $A$ A $A,b\varepsilon B,c\varepsilon C.$ Similarly there is an $R$ -middle linear map $A\times(B\otimes_{S}C)\to(A\otimes_{R}B)\otimes_{S}C$ that induces a homomorphism

$$\beta:A\otimes_R(B\otimes_SC)\to(A\otimes_RB)\otimes_SC$$

such that $\beta[a\otimes(b\otimes c)]=(a\otimes b)\otimes c$ for all a ε $A$ $b$ b $,b\in B,c\in C$ C.For every generator $(a\otimes b)\otimes c$ of $(A\otimes_RB)\otimes_sC,\beta\alpha[(a\otimes b)\otimes c]=(a\otimes b)\otimes c$ ,whence $\beta\alpha$ is the identity map on $(A\otimes_RB)\otimes_{\mathbf{s}}C.$ A similar argument shows that $\beta\alpha$ is the identity on $A\otimes_R(B\otimes_sC)$ . Therefore, $\alpha$ and $\beta$ are isomorphisms.

In the future we shall identify $(A\otimes_RB)\otimes_sC$ and $A\otimes_R(B\otimes_sC)$ under the isomorphism of Theorem 5.8 and simply write $A\otimes_RB\otimes_sC$ . It is now possible to define recursively the $n$ -fold tensor product:

$$A^1\bigotimes_{R_1}A^2\bigotimes_{R_2}\cdots\bigotimes_{R_n}A^{n+1},$$

where $R_{1},\ldots,R_{n}$ Rn $R_n$ are rings and $A_{R_{1}}^{1},_{R_{1}}A_{R_{2}}^{2},\ldots,_{R_{n}}A^{n+1}$ are (bi)modules. Such iterated tensor products may also be characterized in terms of universal $n$ -linear maps (Exercise 10).

Theorem 5.9.Let R be a ring,A and IAi $\{A_i$ $\{\mathbf{A}_{\mathrm{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\}$ right R-modules,B and $\{\mathbf{B}_{\mathbf{j}}\mid\mathbf{j}\in\mathbf{J}\}$ left R-modules. Then there are group isomorphisms

$$(\sum_{ieI}A_{i})\otimes_{R}B\cong\sum_{ieI}(A_{i}\otimes_{R}B);\\\mathrm{A}\otimes_{\mathrm{R}}(\sum_{jeJ}\mathrm{B}_{i})\cong\sum_{jeJ}\mathrm{(A}\otimes_{\mathrm{R}}\mathrm{B}_{j}).$$

PROOF. Let $\iota_k,\pi_k$ be the canonia inetos andprjetions of $\sum_{i\epsilon I}A_i$ By Theorem IL.8.5 the family of homomorphisms $\iota_{k}\otimes\mathbf{1}_{B}:A_{k}\otimes_{R}\boldsymbol{B}\to(\sum_{i\in I}^{-\infty}A_{i})\otimes_{R}B$ induce a homomorphism $\alpha:\sum_{i\in I}\left(A_{i}\otimes_{R}B\right)\to\left(\sum_{i\in I}A_{i}\right)\otimes_{R}B$ such that $\alpha[\{a_i\otimes b\}]$ $=\sum_{i\in I_{0}}\left(\iota_{i}(a_{i})\otimes b\right)=\left(\sum_{i\in I_{0}}\iota_{i}(a_{i})\right)\otimes b$ where $I_{0}=\{i\varepsilon I\mid a_{i}\otimes b\neq0\}$ . The assignment $(u,b)\vdash\{\pi_i(u)\otimes b\}_{i\wr l}$ defnes a middle linear map $(\sum_{i\in I}A_i)\times B\to$ $\sum_{i\in I}\left(A_i\otimes_RB\right)$ and thus induces a homomorphism $\beta:(\sum A_i)\otimes_RB\to\sum^{i\in I}(A_i\otimes_RB)$ such that $\beta(u\otimes b)=\{\pi_i(u)\otimes b\}_{\mathrm{i}.I}$ . We shall show that $\alpha\beta$ and $\beta\alpha$ are the respec tive identity maps, whence $\alpha$ is an isomorphism

------------------------------------------------------------------

Recall that if $u\in\sum A_i$ and $I_{0}=\{i\varepsilon I\mid\pi_{i}(u)\neq0\}$ , then $u=\sum_{i\in I_{0}}\iota_{\mathrm{i}}\pi_{\mathrm{i}}(u)$ Thus for every generator $u\textcircled{8}b$ of $(\sum A_{i})\otimes_{R}B$ we have

$$\alpha\beta(u\otimes b)=\alpha[\{\pi_{i}(u)\otimes b\}]=(\sum_{i\in I_{0}}\iota_{i}\pi_{i}(u))\bigotimes b=u\bigotimes b.$$

Consequently $\alpha\beta$ is the identity map. For each $j\varepsilon I$ let $\iota_{i}^{*}:A_{i}\otimes_{R}B\to\sum_{i}\left(A_{i}\otimes_{R}B\right)$ be the canonical injection and

verify that $\sum_i\left(A_i\otimes_RB\right)$ is generated by all elements of the form $\iota_{i}^{*}(a\otimes b)=$ $\{\pi_i\iota_j(a)\otimes b\}_{i,l}(j\varepsilon I,a\varepsilon A_j,b\varepsilon B)$ . For each such generator we have $(\pi_{i}\iota_{j}(a))\otimes b$ =0 if $i\neq j$ and $(\pi_{il_{j}}(a))\otimes b=a\otimes b$ ,whence

$$\begin{aligned}
\beta\alpha[\iota_{j}{}^{*}(a\otimes b)]& =\beta\alpha[\{\pi_{i}\iota_{j}(a)\bigotimes b\}]=\beta[\iota_{j}\pi_{j}\iota_{j}(a)\bigotimes b] \\
&=\beta[\iota_{j}(a)\otimes b]=\{\pi_{i}\iota_{j}(a)\otimes b\}_{iel}=\iota_{j}*(a\otimes b).
\end{aligned}$$

Consequently the map $\beta\alpha$ must be the identity. The second isomorphism is proved similarly.

Theorem 5.10.(Adjoint Associativity)Let R and S be rings and $\mathbf{A}_{\mathbf{R}}$ AR $\mathbf{A} _{\mathrm{R} }, \:_{\mathrm{R} }\mathbf{B} _{\mathrm{S} }$, $\mathbf{C} _{\mathrm{S} }$ $( bi)$ modules. Then there is an isomorphism of abelian groups

$$\alpha:Hom_\mathbf{s}(\mathbf{A}\otimes_\mathbf{R}\mathbf{B},\mathbf{C})\cong Hom_\mathbf{R}(\mathbf{A},Hom_\mathbf{S}(\mathbf{B},\mathbf{C})),$$

defined for each $\mathbf{f}:\mathbf{A}\otimes_{\mathbf{R}}\mathbf{B}\to\mathbf{C}$ by

$$\mathrm{[(\alpha f)(a)](b)=f(a\otimes b).}$$

Note that $\mathrm{Hom}_R(\_,\_)$ and $\mathrm{Hom}_{s(—,—)}$ consist of homomorphisms of righi modules. Recall that the $R$ -module structure of Homs( B, C) is given by: $(gr)(b)=$ $g(rb)$ (for r ε R, b ε B, gε Homs(B,C); see Exercise 4.4(c))

SKETCH OF PROOF OF 5.10. The proof is a straightforward exercise in the use of the appropriate definitions. The following items must be checked (i) For each $a\varepsilon A$ , and $f_{\varepsilon}\operatorname{Hom}_{s}(A\otimes_RB,C),(\alpha f)(a):B\to C$ (αf)(a) : B → C $(\alpha f)(a):B\to C$ is an $S$ -module

homomorphism (ii) $(\alpha f):A\to\mathrm{Hom}_{s}(B,C)$ is an $R$ -module homomorphism. Thus. $\alpha$ is a well-

defined function.

(ii) $\alpha$ is a group homomorphism (that is, $\alpha(f_{1}+f_{2})=\alpha(f_{1})+\alpha(f_{2}))$ .To show that $\alpha$ is an isomorphism, construct an inverse map $\beta:\operatorname{Hom}_R(A,\operatorname{Hom}_S(B,C))\to$ $\mathrm{Hom}_{\mathrm{s}}(A\otimes_{R}B,C)$ by defining

$$(\beta g)(a\otimes b)=[g(a)](b),$$

where $a\in A,b\varepsilon B$ , and $g\varepsilon\operatorname{Hom}_R(A,\operatorname{Hom}_S(B,C))$ . Verify that

(iv) $\beta g$ as defined above on the generators determines a unique $S$ -module homo- morphism $A\otimes_RB\to C$ (v) $\beta$ is a homomorphism

(vi) $\beta\alpha$ and $\alpha\beta$ are the respective identities. Thus $\alpha$ is an isomorphism.

We close this section with an investigation of the tensor product of free modules. Except for an occasional exercise this material will be used only in Section IX.6

1

1

------------------------------------------------------------------

Theorem 5.11. Let R be a ring with identity. If A is a unitary right R-module and F is a free left R-module with basis Y, then every element u of A $\textcircled{8}_{\mathbf{R}}$ F may be written uniquelyin the form $\mathbf{u}=\sum_{i=1}^n\mathbf{a}_i\otimes\mathbf{y}_i$, where $a_{\mathrm{i}}\varepsilon$ A and the y are istinc elemenisof Y

REMARK. Given $u=\sum_{k=1}^{t}a_k\otimes y_k$ and $v= \sum _{j= 1}^{m}b_{i}\otimes z_{i}$ $( a_{k}, b_{i}\varepsilon$ $A, y_{k}, z_{i}$ $\varepsilon$ $Y)$, we may, if necessary, insert terms of the form $\dot{0}\otimes y(y\in Y)$ and assume that $u=\sum_{i=1}^na_i\otimes y_i$ and $v=\sum_{i=1}^nb_i\otimes y_i$ . Th word "uiquely"inThorem 5.1 man that if $\sum_{i=1}^{n}a_{i}\otimes y_{i}=\sum_{i=1}^{n}b_{i}\otimes y_{i}$ then $u_{i}=b_{i}$ for every In paticular,if $\sum_{i=1}^na_i\otimes y_i$ =0 = $\sum _{i= 1}^{n}0\otimes y_{i}$, then $a_i=0$ for every i

PROOF OF 5.11. For each $y\varepsilon Y$ , let $A_y$ be a copy of $A$ and consider the direct sum $\sum_{yeY}A_{u}$ We frst construct an isomorphism $\theta:A\otimes_RF\cong\sum_{y\in Y}A_v$ as follows Since $Y$ is a basis, $\{y\}$ is a linearly independent set for each $y\varepsilon Y$ . Consequently the $R$ -module epimorphism $\varphi:R\to Ry$ given by $r\vdash ry$ (Theorem 1.5) is actually an isomorphism.Therefore, by Theorem 5.7 there is for each y e $Y$ an isomorphism

$$A\otimes_RRy\xrightarrow{1_A\otimes\varphi^{-1}}A\bigotimes_RR\cong A=A_y.$$

Thus by Theorems 5.9 and I.8.10 there is an isomorphism $\theta$

$$A\bigotimes_RF=A\bigotimes_R(\sum_{y\in Y}Ry)\cong\sum_{y\in Y}A\bigotimes_RRy\cong\sum_{y\in Y}A_y.$$

Verify that for every A $A$ $\mid a\varepsilon A,z\varepsilon Y,\theta(a\otimes z)=\{u_{y}\}\varepsilon\sum A_{v}$, where $u_{z}=a$ and $u_{\nu}=0$ for $y\neq z$ ; in other words, $\theta(a\otimes z)=\iota_z(a)$ with $\iota_{z}:A_{z}\to\sum A_{y}$ the canonical in jection. Now every nonzero $v\in\sum A_{y}$ is a finite sum $v=$ $\iota _{y_{1}}( a_{1}) + \cdots +$ $\iota _{y_{n}}( a_{n})$ $=\theta(a_1\otimes y_1)+\cdots+\theta(a_n\otimes y_n)$ with $y_1,\ldots,y_n$ distinct elements of $Y^{\prime}$ and $a_i$ uniquely determined nonzero elements of $A$ . It follows that every element of $A\otimes_RF$ (which is neessarily $\theta^{-1}(v)$ for some $\upsilon$ ) may be writen uniquly as $\sum_{i=1}^na_i\otimes y_i$

Corollary 5.12. IfR is a ring with identity and $\mathbf{A}_{\mathbf{R}}$ and $_{\mathbf{R}}\mathbf{B}$ arefree R-modules with bases $X$ and $Y$ respectively, then A $\textcircled{8}_{\mathbf{R}}$ B is a free (right) R-module with basis. $\mathbf{W}=\{\mathbf{x}\otimes\mathbf{y}|\mathbf{x}\varepsilon\mathbf{X},\mathbf{y}\varepsilon\mathbf{Y}\}$ of cardinality $|\mathbf{X}||\mathbf{Y}|$

REMARKS. Since $R$ is an $R-R$ bimodule, so is every direct sum of copies of $R$ In particular, every free left $R$ -module is also a free right $R$ -module and vice versa. However, it is not true in general that a free (left) $R$ -module is a free object in the category of $R-R$ bimodules (Exercise 12).

SKETCH OF PROOFOF 5.12. By the proof of Theorem 5.11 and byTheo rem 2.1 (for right $R$ -modules) there is a group isomorphism

$$\theta:A\otimes_{R}B\cong\sum_{y\in Y}A_{y}=\sum_{y\in Y}A=\sum_{y\in Y}(\sum_{x\in X}xR).$$

------------------------------------------------------------------

Since $B$ is an $R-R$ bimodule by the remark preceding the proof, $A\otimes_RB$ is a right $R$ -module by Theorem 5.5. Verify that $\theta$ is an isomorphism of right $R$ -modules such that $\theta(W)$ is abasisof thefreright $R$ -module $\sum_Y(\sum_XxR)$ . Therefore, $A\otimes_RB$ isa free right $R$ -module with basis $W$ . Since the elements of $W$ are all distinct by Theorem 5.11, $|W|=|X||Y|$ .

Corollary 5.13. Let Sbe a ring with identity and R a subring ofS that contains 1s. If F is a free left R-module with basis $X$ ,then $S\otimes_{\mathbf{R}}F$ is a free left S-module with basis $\{\mathbf{1}_{\mathbf{s}}\otimes\mathbf{x}\mid\mathbf{x}\varepsilon\mathbf{X}\}$ of cardinality $|\mathbf{X}|$

SKETCH OF PROOF. Since $S$ is clearly an $S-R$ bimodule, $S\otimes_RF$ is a left $S$ -module byTheorem5.5.Theproof of Theorem5.11 shows that there is a group isomorphism $\theta:\mathcal{S}\otimes_RF\cong\sum_{xeX}\dot{S}_x$, with each $S_{x}=S$ . Furthermore, if for $z\varepsilon X$ $\iota_{z}:S=S_{z}\rightarrow\sum_{x\in X}S_{x}$ is the canonical injection, then $\theta(1_{s}\otimes z)=\iota_{z}(1_{S})$ for each $z\varepsilon X$ Verify that $\theta$ is in fact an isomorphism of left $S$ -modules. Clearly, $\{\iota_x(1_s)\mid x\in X\}$ is a basis of cardiality $|X|$ of the fre let $S$ module $\sum_{x\text{е}X}S_x$, whence $S\otimes_RF$ is a free $S$ -module with basis $\{1_s\otimes x\mid x\in X\}$ of cardinality $|X|$ .

### EXERCISES

Note: $R$ is a ring and β = βz

1.If $R=\mathbf{Z}$ ,then condition (ii) of Definition 5.1 is superfluous (that is, (i) and (ii) imply (ii)).

2. Let $A$ and $B$ be abelian groups (a) For each $m>0$ $A\otimes Z_m\cong A/mA$

(b) $Z_m\otimes Z_n\cong Z_c$ ,where $c=(m,n)$ (c) Describe $A\otimes B$ , when $A$ and $B$ are finitely generated

3. If $A$ is a torsion abelian group and $\mathbf{Q}$ the (additive) group of rationals, then (a) $A\otimes\mathbf{Q}=0$ (b) $\mathbf{Q}\otimes\mathbf{Q}\cong\mathbf{Q}.$

4. Give examples to show that each of the following may actually occur for suitable rings $R$ and modules $A_R,_RB$ (a) $A\otimes_RB\neq A\otimes_\mathbf{Z}B$

(b) $u\in A\otimes_RB$, but $u\neq a\otimes b$ for any $a\varepsilon A,b\varepsilon B$ (c) $a\otimes b=a_1\otimes b_1$ but $a\neq a_1$ and $b\neq b_1$

5.If $A^{\prime}$ is a submodule of the right $R$ -module $A$ and $B^{\prime}$ is a submodule of the left $R$ -module $B$ , then $A/A^{\prime}\otimes_RB/B^{\prime}\cong(A\otimes_RB)/C$ ,where $C$ is the subgroup of $A\otimes_RB$ generated by all elements $a^{\prime}\textcircled{8}b$ and $a\textcircled{\times}b^{\prime}$ with $a\in A,a^{\prime}\varepsilon A^{\prime},b\varepsilon B$, $b^{\prime}\varepsilon B^{\prime}$

6. Let $f:A_R\to A_R^{\prime}$ and $g:_R\boldsymbol{B}\to_R\boldsymbol{B}^{\prime}$ be $R$ -module homomorphisms. What is the difference between the homomorphism $f\textcircled{8}g$ (as given by Corollary 5.3) and the element $f\textcircled{\mathbb{X}}g$ of the tensor product of abelian groups

$$\mathrm{Hom}_R(A,A^{\prime})\otimes\mathrm{Hom}_R(B,B^{\prime})?$$

1

1

------------------------------------------------------------------

7. The usual injection $\alpha:\mathbb{Z}_2\to\mathbb{Z}_4$ is a monomorphism of abelian groups. Show that. $1\otimes\alpha:Z_2\otimes Z_2\to Z_2\otimes Z_4$ is the zero map $Z_2\otimes Z_2\neq0$ $Z_2\otimes Z_2\neq0$ (but$Z_2\otimes Z_2\neq0$ and$Z_2\otimes Z_4\neq0$ $Z_2\otimes Z_4\neq0$ $Z_2\otimes Z_4\neq0$ see Exercise 2).

8. Let $0\to A\overset{f}{\operatorname*{\rightarrow}}B\overset{g}{\operatorname*{\rightarrow}}C\to0$ be a short exact sequence of left $R$ -modules and $D$ a right $R$ -module. Then $0\to D\textcircled{\times}_RA\xrightarrow{\mathrm{l}_D\otimes f}D\textcircled{\times}_RB\xrightarrow{\mathrm{l}_D\otimes g}D\otimes_RC\to0$ is a short exact sequence of abelian groups under any one of the following hypotheses (a) $0\to A\overset{f}{\operatorname*{\rightarrow}}B\overset{g}{\operatorname*{\rightarrow}}C\to0$ is split exact. (b) $R$ has an identity and $D$ is a free right $R$ -module. (c) $R$ has an identity and $D$ is a projective unitary right $R$ -module

9. (a) If Iis a right ideal of a ring $R$ with identity and $B$ a left $R$ -module, then there is a group isomorphism $R/I\otimes_RB\cong B/IB$ ,where $IB$ is the subgroup of $B$ generated by all elements $rb$ with r ε I, $b\varepsilon B$ (b) If $R$ is commutative and $I,J$ are ideals of $R$ , then there is an $R$ -module isomorphism $R/I\otimes_RR/J\cong R/(I+J)$

10. If $R,S$ are rings, $A_R, \:_RB_S$, $sC$ sC $sC$ are (bi)modules and $D$ an abelian group, define a middle linear map to be a function. $f:A\times B\times C\to D$ such that

(i) $f(a+a^{\prime},b,c)=f(a,b,c)+f(a^{\prime},b,c)$ (i) $f(a,b+b^{\prime},c)=f(a,b,c)+f(a,b^{\prime},c);$ (ii) $f(a,b,c+c^{\prime})=f(a,b,c)+f(a,b,c^{\prime});$ (iv) $f(ar,b,c)=f(a,rb,c)$ forre $R$ (v) $f(a,bs,c)=f(a,b,sc)$ for $s\varepsilon S$

$$\circ i:A\times B\times C\rightarrow(A\bigotimes_{R}B)\bigotimes_{S}C\mathrm{~given~by~}(a,b,c)\vdash(a\bigotimes b)\bigotimes c$$
(a) is middle linear. (b) The middle linear map $i$ is universal; that is, given a middle linear map

$g:A\times B\times C\to D$ ,there exists a unique group homomorphism $\bar{g}:(A\otimes_RB)\otimes_SC\to D$ such that $\bar{g}i=g$ (c) Themap $j:A\times B\times C\to A\otimes_R(B\otimes_sC)$ given by

$(a,b,c)\vdash a\otimes(b\otimes c)$ is also a universal middle linear map. (d) $(A\otimes_RB)\otimes_sC\cong A\otimes_R(B\otimes_sC)$ by $( b)$, $( c)$ , and Theorem I.7.10. (e) Define a middle linear function on $n$ (bi)modules $(n\geq4)$ in the obvious way and sketch a proof of the extension of the above results to the case of $n$ (bi)- modules (over $n-1$ rings) (f) If $R=S$ $R$ is commutative and $A,B,C,D$ are $R$ -modules, define a trilinear map $A\times B\times C\to D$ and extend the results of $(a),(b),(c)$ to such maps.

11. Let $A,B,C$ be modules over a commutative ring $R$

(a)The set $\mathcal{L}(A,B;C)$ ofall $R$ -bilinear maps $A\times B\to C$ is an $R$ -module with $(f+g)(a,b)=f(a,b)+g(a,b)$ and $(rf)(a,b)=rf(a,b)$ (b) Each one of the following. $R$ -modules is isomorphic to $\mathcal{L}(A,B;C)$

(i) (i)
$$\begin{aligned}
&\mathrm{Hom}_{R}(A\otimes_{R}B,C); \\
&\mathrm{Hom}_{R}(A,\mathrm{Hom}_{R}(B,C)); \\
&\mathrm{Hom}_{R}(B,\mathrm{Hom}_{R}(A,C)).
\end{aligned}$$
(ii)

12. Assume $R$ has an identity. Let C be the category of all unitary $R-R$ bimodules and bimodule homomorphisms (that is, group homomorphisms $f:A\to B$ such that $f(ras)=rf(a)s$ for all $r,s\in R$ 0.Let $X=\{1_{R}\}$ and let $\iota:X\to R$ be the inclusion map.

------------------------------------------------------------------

(a) If $R$ is noncommutative, then $R$ (equipped with $\iota:X\to R$ is not a free object on the set $X$ in the category ୧ (b) $R\otimes_{\mathbf{z}}R$ is an $R-R$ bimodule (Theorem 5.5). If $\iota:X\to R\otimes_{\mathbf{Z}}R$ is

given by $\mathbf{1}_{R}\vdash\mathbf{1}_{R}\otimes\mathbf{1}_{R}$ , then $R\otimes_\mathbf{Z}R$ is a free object on the set $X$ in the category C.

## 6. MODULES OVER A PRINCIPAL IDEAL DOMAIN

The chief purpose of this section,which will be used again only in Sections VII.2 and VII.4, is to determine the structure of all finitely generated modules over a principal ideal domain.Virtually all of the structure theorems for finitely generated abelian groups (Sections I1.1,I1.2) carry over to such modules. In fact, most of the proofs in Sections II.1 and II.2 extend immediately to modules over Euclidean domains. However, several of them must be extensively modified in order to be valid for modules over an arbitrary principal ideal domain. Consequently, we shall use a different approach in proving the structure theorems here. We shall show that just as in the case of abelian groups every finitely generated module may be decomposed in two ways as a direct sum of cyclic submodules(Theorem 6.12).Each decomposition provides a set of invariants for the given module (that is, two modules have the same invariants if and only if they are isomorphic (Corollary 6.13)). Thus each method of decomposition leads to a complete classification (up to isomorphism) of all finitely generated modules over a principal ideal domain. Here and throughout this section "module" means "unitary module" We begin with free modules over a principal ideal domain $R$ . Since $R$ has the in-

variant dimension property by Corollary 2.12,the rank of a free $R$ -module (Definition 2.8) is well defined. In particular, two free $R$ -modules are isomorphic if and only if they have the same rank (Proposition 2.9). Furthermore we have the following generalization of Theorem II.1.6.

Theorem 6.1. Ler F be a free module over a principal ideal domain R and G a sub. module of F. Then G is a free R-module and rank. $G\leq$ rankF.

SKETCH OF PROOF. Let $\{x_{i}\mid i\in I\}$ be a basis of $F$ : Then $F=\sum_{i\in I}Rx_i$ with each $Rx_i$ isomorphic to $R$ (as a left $R$ -module). Choose a well ordering $\leq$ of the set $I$ (Introduction,Section 7). For each i e I denote the immediate successor of $i$ by $i+1$ (Introduction, Exercise 7.7). Let $J=I\cup\{\alpha\}$ ,where $\alpha\notin I$ and by definition $i<\alpha$ for all i ε I. Then $J$ iswell ordered andevery element ofI has animmediate successor in J.1 For eachj e J define $F_{i}$ to be the submodule of $F$ generated by the set $\{ x_{i}|$ $i< j\}$ Verify that the submodules $F_{j}$ have the following properties:

$$\begin{array}{l}{{\mathrm{i)~}j<k\Leftrightarrow F,\subset F_{k};}}\\{{\mathrm{i)~}\bigcup_{j\in J}F_{j}=F;}}\end{array}$$

1The set $J$ is a technical device needed to cope with the possibility that some (necessarily unique) element of $I$ has no immediate successor in I. This occurs, for example,when is finite.

------------------------------------------------------------------

(i) for each i e I, $F_{i+1}/F_{i}\cong Rx_{i}\cong R.$ [Apply Theorem 1.7 to the canonical projection $F_{i+1}=\sum_{k<i+1}Rx_{k}\to Rx_{i}.]$

For each $j\varepsilon J$ let $G_{i}=G\cap F_{i}$ and verify that:
$$\begin{aligned}&(\mathrm{iv})\:j<k\Rightarrow G_{j}\subset G_{k};\\&(\mathrm{v})\bigcup_{j\in J}G_{i}=G;\\&(\mathrm{vi})\:\mathrm{for}\:\mathrm{each}\:i\:\varepsilon\:I,\:G_{i}=\:G_{i+1}\cap\:F_{i}.\end{aligned}$$

Property (vi) and Theorem 1.9(i) imply that $G_{i+1}/G_{i}=G_{i+1}/(G_{i+1}\cap F_{i})$ $\cong(G_{i+1}+F_i)/F_i$ .But $(G_{i+1}+F_{i})/F_{i}$ is a submodule of $F_{i+1}/F_i$ .Therefore, $G_{i+1}/G_i$ is isomorphic to a submodule of $R$ by (ii). But every submodule of $R$ is necessarily an ideal of $R$ and hence of the form $(c)=Rc$ for some $c\in R.$If$c\neq0$ c≠0 $c\neq0$ then the $R$ -module epimorphism $R\to Rc$ of Theorem 1.5(i) is actually an isomorphism. Thus every submodule of $R$ (and hence each $G_{i+1}/G_i)$ is free of rank 0 or 1. By Theorems 3.2 and 3.4 the sequence $0\to G_{i}\overset{\mathrm{E}}{\operatorname*{\rightarrow}}G_{i+1}\to G_{i+1}/G_{i}\to0$ is split exact for every $i\varepsilon I.$ Theorem 1.18 and Exercise 1.15 imply that each $G_{i+1}$ is an internal direct sum $G_{i+1}=G_{i}\oplus Rb_{i}$ ,where $b_{i}\varepsilon G_{i+1}-G_{i}$ and $Rb_{i}\cong R$ if $G_{i+1}\neq G_{i}$, and $b_i=0$ if $G_{i+1}=G_{i}$ (that is, $G_{i+1}/G_{i}=0)$ .Thus $b_i\varepsilon G$ is defined for each ie l. Let $B=\{b_{i}\mid b_{i}\neq0\}$ . Then $|B|\leq|I|=$rank $F$ F $F.$ To complete the proof we need only show that $B$ is a basis of $G$ Suppose u = ≥ r;b; = 0 (ie I; r, ε R; finite sum). Let $k$ be the largest index (if

one exists) such that $r_k\neq0$ Then $u=\sum_{j<k}r_{i}b_{i}+r_{k}b_{k}\varepsilon G_{k}\oplus Rb_{k}=G_{k+1}$ But $u=0$ implies that $r_k=0$ , which is a contradiction. Hence $r_{j}=0$ for all j. Theref ore. $B$ is linearly independent. Finally we must prove that $B$ spans $G$ . It suffices by (v) to prove that for each

$k\varepsilon J$ the subset $B_{k}=\left\{b_{i}\varepsilon B\mid j<k\right\}$ of $B$ spans $G_{k}$ We shall use transfinite induction (Introduction, Theorem 7.1). Suppose, therefore, that $B_{i}$ spans $G_{i}$ for all $j<k$ and let $u\in G_k$ G& $G_{k}$ . If $k=j+1$ for some $j\varepsilon I$ ，then $G_{k}=G_{i+1}=G_{i}\oplus Rb_{i}$ and $u=v+rb_{i}$ with $\upsilon\varepsilon G_i$ G, $G_{i}$ By the induction hypothesis $\upsilon$ is a fnite sum $v=\sum r_{\mathrm{i}}b_{\mathrm{i}}$ with $r_i\varepsilon R$ and $b_{i}\varepsilon B_{i}\subset B_{k}$ . Therefore, $u=\ddot{\sum}r_{i}b_{i}+rb_{k}$, whence $B_k$ spans $G_k$ .Now suppose that $k\neq j+1$ for all $j\varepsilon I$ (and this may happen; see the examples preceding Theorem 7.1 of the Introduction). Since $u$ E $G_k=G\cap F_k$, $u$ is a finite sum $u=\tilde{\sum}r_{i}x_{i}$ with $j<k$ . If 1 is the largest index such that $r_1\neq0$ , then u e $F_{t+1}$ with $\iota+1<k$ by hypothesis. Therefore, $u\in G\cap F_{t+1}=G_{t+1}$ with $1+1<k$ . By the induction hypothesis $u$ is a linear combination of elements of $B_{t+1}$ , which is a subset of $B_k$ .Hence $B_k$ spans $G_k$ .

Corollary 6.2. Let R be aprincipal ideal domain. I fA is a finitely generated R-module generated by n elements, then every submodule of A may be generated by m elements with $m\leq n$

PROOF. Exercise; see Corollary I1.1.7 and Corollary 2.2.

Corollary 6.3.A unitary module A over a principal ideal domain is free ifand only if A is projective

------------------------------------------------------------------

PROOF. $(\Rightarrow)$ Theorem 3.2. $(\Leftarrow)$ There is a short exact sequence $0\to K\overset{\mathcal{S}}{\operatorname*{\rightarrow}}F\overset{\prime}{\operatorname*{\xrightarrow{\mathcal{S}}}}$ $A\to0$ with $F$ free, $f$ an epimorphism and $K=\ker f$ $f$ f by Corollary 2.2. If $A$ is projective, then $F\cong K\oplus$ A by Theorem 3.4. Therefore, $A$ is isomorphic to a submodule of $F$ ,whence $A$ is free by Theorem 6.1.

We now develop the analogues of the order of an element in a group and of the torsion subgroup of an abelian group.

Theorem 6.4. Let A be a left module over an integral domain R and for each a e A let $\mathcal{O} _{\mathrm{a} }= | \mathbf{r} \varepsilon \mathbf{R} |$ra=0|

(i) $\mathcal{O}_{\mathrm{a}}$ is an ideal ofRforeachaεA (ii) $\mathbf{A}_{\mathbf{t}}=\{\mathbf{a}\varepsilon\mathbf{A}\mid\mathbf{O}_{\mathbf{a}}\neq0\}$ is a submoduleof $A$ (ii) For each a e A there is an isomorphism of left modules

$$\mathbb{R}/\mathbb{C}_{\mathfrak{a}}\cong\mathbb{R}\mathfrak{a}=\left\{\mathrm{ra}\mid\mathrm{r}\in\mathbb{R}\right\}.$$

Let R be a principal ideal domain and p e R a prime.

(iv) $If\mathbf{p} ^{\mathrm{i} }\mathbf{a} = 0$ (equivalently $(\mathbf{p}^{\mathrm{i}})\subset\mathcal{O}_{\mathrm{a}}$ ),then $\mathcal{O}_{\mathrm{a}}=(\mathbf{p}^{\mathrm{j}})$ with $0\leq$j$\leq$i (v) If $\mathcal{O}_{\mathrm{a}}=(\mathbf{p}^{\mathrm{i}})$ ,then $p^\mathrm{ja\neq0}$ for all j such that $0\leq$j<i

REMARK. Prime and irreducible elements coincide in a principal ideal domain by Theorem IIl.3.4.

SKETCH OF PROOF OF 6.4. (ii) Use Theorems 1.5(i) and 1.7. (iv) By hypothesis $\mathcal{O}_a=(r)$ for some r E $R.$ Since $p^i$ E $\mathcal{O}_a$ $r$ divides $p^i$ . Unique factorization in $R$ (Theorem I1l.3.7) implies that $r=p^{i}u$ with $0\leq j\leq$ iand $u$ a unit. Hence $\mathcal{O}_a=(r)$ $=(p^{i}u)=(p^{j})$ by Theorem II1.3.2. (v) If $p^ia=0$ with $j<i$ ,then $p^{i}\in\mathcal{O}_{a}=(p^{i})$, whence $p^i\mid p^i$ . This contradicts unique factorization in $R$ .■

Let $A$ be a module over an integral domain. The ideal $\mathcal{O}_a$ in Theorem 6.4 is called the order ideal of $a\varepsilon A$ . The submodule $A_t$ in Theorem 6.4 is called the torsion submodule of $A.A$ is said to be a torsion module if $A_{.}=A_{\mathrm{t}}$ and to be torsionfree if $A_t=0$ .Every free module is torsion-free, but not vice versa (Exercise 2).

Let $A$ be a module over a principal ideal domain $R$ . The order ideal of a ε $A$ is a principal ideal of $R.$ ，say $\mathcal{O}_a=(r)$ , and $a$ is said to have order $r$ . The element $r$ is unique only up to multiplication by a unit (Theorem Ill.3.2). The cyclic submodule $Ra$ generated by $a$ (Theorem 1.5) is said tobe cyclic oforder r.Theorem 6.4(ii)shows that a e A has order O (that is, $Ra$ is a cyclic module of order O)if and only if $Ra\cong R$ (that is, $Ra$ is free of rank one). Also a e $A$ has order $r$ ,with $r$ a unit, if and only if $a=0$ ; (for $a=1_{R}a=r^{-1}(ra)=r^{-1}0=0$

EXAMPLE. If $R$ is a principal ideal domain and $r\varepsilon R$ , then the quotient ring $R/(r)$ is a cyclic $R$ -module with generator $a=1_{\kappa}+(r)$ . Clearly $\mathcal{O}_a=(r)$ ,whence $a$ has order $r$ and $R/(r)$ is cyclic of order $r$ . Theorem 6.4(ii) shows that every cyclic module $C$ over a principal ideal domain $R$ is isomorphic to $R/(r)$ ,where $(r)=\mathcal{O}_a$ and $a$ is a generator of $C$

1

[

------------------------------------------------------------------



------------------------------------------------------------------

Theorem 6.7. Let A be a torsion module over a principal ideal domain R and for each prime pe R let $\mathbf{A}(\mathbf{p})=\{\mathbf{a}\varepsilon\mathbf{A}|$ Ia has order a power of p}.

(i) $A(p)$ is a submodule of A for each prime pe R; (i) $\mathbf{A}=\sum\mathbf{A}(\mathbf{p})$ , where the sum is over all primes p e R. If A is finitely generated, only finitely many of the A(p) are nonzero.

PROOF. (i) Let $a,b\in A(p)$ . If $\mathcal{O}_a=(p^r)$ and $\mathcal{O}_b=(p^s)$ let $k=\max\left(r,s\right)$ . Then $p^k(a+b)=0$ ,whence $\mathcal{O}_{a+b}=(p^{i})$ with $0\leq i\leq k$ by Theorem 6.4(iv). Therefore, $a,b\in A(p)$ imply $a+b\in A(p)$ .A similar argument shows that a E $A(p)$ and $r\varepsilon R$ R $R$ imply ra e $A(p)$ . Therefore, $A(p)$ is a submodule.

(i) Let $0\neq a\varepsilon A$ with $\mathcal{O}_a=(r)$ . By Theorem $\cdot \mathbf{III}. 3. 7$ $r= p_{1}^{n_{1}}\cdots p_{k}^{n_{k}}$ with $p_i$ distinct primes in $R$ and each $n_i>0$ . For each $i$ ,let $r_{i}=p_{1}^{n_{1}}\cdots p_{i-1}^{n_{i-1}}p_{i+1}^{n_{i+1}}\cdots p_{k}^{n_{k}}$ .Then $r_1,\ldots,r_k$ are relatively prime and there exist $s_{1},\ldots,s_{k}\in R$ such that $s_1r_1+\cdots+$ $s_kr_k=1_R$ (Theorem III.3.11). Consequently, $a=1_{R}a=s_{1}r_{1}a+\cdots+s_{k}r_{k}a$ .But $\rho_{i}^{ni}s_{i}r_{i}a=s_{i}ra=0$ ,whence $s_ir_ia\in A(p_i)$ . We have proved that the submodules $A(p)$ $p$ prime) generate the module $A$ Let $p\varepsilon R$ R $R$ be prime and let $A_1$ be the submodule of $A$ generated by all $A(q)$ with

$q\neq p$ . Suppose a e A(p) $A(p)$ $A(p)\cap A_1$ A $A_1$ . Then $P^{m}a=0$ for some $m\geq0$ and $a=a_{1}+\cdots+a_{t}$ with $a_i$ E $A(q_i)$ for some primes $q_1,\ldots,q_t$ Yt $y_t$ all distinct from $P$ . Since ae $A(q_i)$ ,there are integers $m_i$ such that $q_{i}^{mi}a_{i}=0$ ，whence $(q_{1}^{m_{1}}\cdots q_{t}^{m_{t}})a=0$ .If $d=q_{1}^{m_{1}}\cdots q_{t}^{m_{t}}$ ,then $P^{m}$ and $d$ are relatively prime and $rp^{m}+sd=1_{R}$ for some $r,s\in R$ . Consequently $a=1_{R}a=rp^{m}a+sda=0$ . Therefore, $A(p)\cap A_1=0$ A= 0 $A_1=0$ and $A=\sum A(p)$ by Theo rem 1.15. The last statement of the Theorem is a consequence of the easily verified fact that a direct sum of modules with infinitely many nonzero summands cannot be finitely generated. For each generator has only finitely many nonzero coordinates.

 In order to determine the structure of finitely generated modules in which every element has order apower of aprime $P$ (such as $A(p)$ in Theorem6.7),weshall need a lemma. If $A$ is an $R$ -module and r e $R.$ , then $rA$ is the set $|ra|a\in A|$

1

1

Lemma 6.8. Let A be a module over a principal ideal domain R such that $\mathbf{p} ^{\mathrm{n} }\mathbf{A} = 0$ and $\mathbf{p} ^{\mathrm{n- 1}}\mathbf{A} \neq 0$ for some prime p e R and positice integer n. Let a be an element ofA of order $\mathbf{p}^n$

(i) $IfA\neq\mathbb{R}$ ,then there exists a nonzero b e A such that Ra $\cap$ Rb =0 (i)There is a submodule C of A such that $\mathbf{A}=\mathbf{R}\mathbf{a}\oplus\mathbf{C}$

REMARK. The following proof is quite elementary. A more elegant proof of (ii) which uses the concept of injectivity, is given in Exercise 7.

PROOF OF 6.8. (G. S. Monk) (i) If $A\neq Ra$ , then there exists $c\in A-Ra$ Since $p^nc\in p^nA=0$ ,there is a least positive integer $j$ such that $p^{i}c\in Ra$ whence $p^{i-1}c\notin Ra$ and $p^{i}c=r_{1}a\left(r_{1}\varepsilon R\right)$ . Since $R$ is a unique factorization domain $r_{1}=rp^{k}$ for some $k\geq0$ and re $R$ such that $p\not Xr$ . Consequently, 0 = $p^{n}c$ = $p^{n- i}( p^{i}c)$ $=p^{n-i}rp^ka$ .Since $p\not Xr$ and $p^{n-1}a\neq0$ (Theorem 6.4(v)), we must have $n-j+k\geq n$ whence $k\geq j\geq1$ . Therefore, $b=p^{j-1}c-rp^{k-1}a$ is a well-defined element of $A$

1

1

------------------------------------------------------------------

Furthermore, $b\neq0$ (since $p^{i-1}c\notin Ra)$ and $pb=p^{j}c-rp^{k}a=p^{i}c-r_{1}a=0$ .If Ra ∩ $Rb\neq0$ , then there exists $s\varepsilon R$ R $R$ such that $sb$ E $Ra$ and $sb\neq0$ . Since $sb\neq0$ and $pb=0$ ， $p$ does not divide $s$ .Therefore, $s$ and $p^n$ are relatively prime and $sx+p^{n}y=1_{R}$ for some $x,y\in R$ $R$ R (Theorem II.3.11). Thus since $P^nA=0$ ， $b=1_{R}b$ $=sxb+p^nyb=x(sb)$ Ra. Consequently, $p^{j-1}c=b+rp^{k-1}a\varepsilon Ra$ .If $j-1\neq0$ this contradicts the minimality of $j.$ , and if $j-1=0$ , this contradicts the fact that $c\notin Ra$ . Therefore, $Ra\cap Rb=0$

(i) If $A=Ru$ , let $C=0$ . If $A\neq Ra$ , then let S be the set of all submodules $B$ of $A$ such that Ra M $B=0.8$ is nonempty since by (i) there is a nonzero $b$ E $A$ such that $Ra\cap Rb=0.$ Partially order S by set-theoretic inclusion and verify that every chain in S has an upper bound in S. By Zorn's Lemma there exists a submodule $C$ of $A$ that is maximal in S. Consider the quotient module $A/C$ . Clearly $p^n(A/C)=0$ and $p^n(a+C)=0$ . Since $Ra\cap C=0$ and $p^{n-1}a\neq0$ ，we have $p^{n-1}(a+C)\neq C$, whence $a+C$ has order $p^n$ in $A/C$ and $P^{n-1}(A/C)\neq0$ Now if $A/C$ is nor the cyclic $R$ -module generated by $a+C$ (that is, $A/C\neq R(a+C))$ , then by (i) there exists $d+C\in A/C$ such that $d+C\neq C$ and R(a + C) $R(a+C)$ $R(a+C)\cap R(d+C)=C$ .Since Ra ∩ $C=0$ , it follows that Ra ∩ $(Rd+C)=0$ . Since $d\notin C,Rd+C$ is in S and properly contains $C$ , which contradicts the maximality of $C$ . Therefore, $A/C$ is the cyclic $R$ -module generated by $a+C$ (that is, $A/C=R(a+C))$ . Consequently, $A=Ra+C$ ,whence $A=Ra\oplus C$ by Theorem 1.15.

Theorem 6.9. Let A be a finitely generated module over a principal ideal domain R. such that every element of A has order a power of some prime p e R. Then A is a direci sum of cyclicR-modules of orders $p^{n1}$ pn1 $\mathbf{p}^{\mathrm{n1}},\ldots,\mathbf{p}^{\mathrm{nk}}$ respectively, where $\mathbf{n}_{1}\geq\mathbf{n}_{2}\geq\cdots\geq$ $n_k\geq1$

PROOF. The proof proceeds by induction on the number $r$ of generators of $A$ with the case $r=1$ being trivial. If $r>1$ , then $A$ is generated by elements $a_1,\ldots,a_r$ whose orders are respectively $p^{n_1},p^{m_2},p^{m_3},\ldots,p^{m_r}$ pm $p^{m_r}$ .We may assume that

$$n_1\:=\:\max\{n_1,m_2,\ldots,m_r\}\:.$$

Then $p^{n_1}A=0$ and $P^{n_1-1}A\neq0$ .By Lemma 6.8 there is a submodule $C$ of $A$ such that $A=Ra_{1}\oplus C$ Let $\pi$ be the canonical epimorphism $\pi:A\to C$ Since $A$ is generated by $a_1,a_2,\ldots,a_r$ ， $C$ must be generated by $\pi(a_1),\pi(a_2),\ldots,\pi(a_r)$ π(ar) $\pi(a_r)$ .But $\pi(a_1)=0$ whence $C$ may be generated by $r-1$ or fewer elements. Consequently, the induction hypothesis implies that $C$ is a direct sum of cyclic $R$ -modules of orders $P^{n_2},P^{n_5},\ldots,p^{n_k}$ respectively with $n_2\geq n_3\geq\cdots\geq n_k\geq1$ . Thus $C$ contains an element of order $n_2.$ Since $P^{n_1}A=0$ , we have $p^{n|C}=0$ ,whence $n_1\geq n_2$ . Since $Ra_1$ is a cyclic $R$ -module of order $p^{n_1}$ $A$ is a direct sum of cyclic $R$ -modules of orders $p^{n_1},p^{n_2},\ldots,p^{n_k}$ pruk $p^{nk}$ respectively with $n_{1}\geq n_{2}\geq\cdots\geq n_{k}\geq1$ .■

Theorems 6.6, 6.7, and 6.9 immediately yield a structure theorem for finitely generated modules over a principal ideal domain (see Theorem 6.12(i) below). Just as in the case of abelian groups (Section I1.2), there is a second way of decomposing a finitely generated module as a direct sum of cyclic submodules.In order to obtain this second decomposition and to prove a uniqueness theorem about each of the decompositions, we need two lemmas.

------------------------------------------------------------------

Lemma 6.10. Let A,B, and $\mathbf{A}_{\mathrm{i}}$ (i e I) be modules ocer a principal ideal domain R Let r e R and let p e R be prime.

(i) $\mathbf{r}\mathbf{A}=\{$ra|a$\varepsilon\mathbf{A}\}$ and $\mathbf{A}[\mathbf{r}]=\{\mathbf{a}\varepsilon\mathbf{A}|\mathbf{r}\mathbf{a}=0\}$ are submodules of A (i) $\mathbb{R}/(\mathfrak{p})$ is a field and $A[p]$ is a vector space ocer $\mathbf{R}/(\mathbf{p})$ (iii) For each positive integer n there are R-module isomorphisms

$$\mathrm{(R/(p^n))[p]\cong R/(p)~and~p^m(R/(p^n))\cong R/(p^{n-m})~(0\leq m<n).}$$

$$IfA\cong\sum_{ieI}A_i,thenrA\cong\sum_{ieI}rA_i\:and\:A[r]\cong\sum_{ieI}A_i[r].$$

(v) $If\mathbf{f}:\mathbf{A}\to\mathbf{B}$ is an R-moduleisomorphism,then f : At=B $\mathbf{A}_{\mathrm{t}}\cong\mathbf{B}_{\mathrm{t}}$ $\mathrm{A_{t}\cong B_{t}~andf:A(p)\cong B(p)}$

SKETCH OF PROOF. (ii) Exercise 2.4. (v) See Lemma II.2.5 (vii). (ii) The first example preceding Theorem 6.5 may be helpful. Verify that $(R/(p^n))[p]$ is generated as an $R$ -module (and hence as a vector space over $R/(p)$ by the single nonzero element $P^{n-1}+(p^n)$ . Therefore, $(R/(p^n))[p]\cong R/(p)$ by Theorems 2.5 and 2.1. The submodule of $R/(p^n)$ generated by $P^{m}+(p^{n})$ is precisely $P^m(R/(p^n))$ .Since $P^{m}+(p^{n})$ has order $P^{n-m}$ ,we have $p^m(R/(p^n))\cong R/(p^{n-m})$ by Theorem 6.4(iii).

[

Lemma 6.11.Ler R be a principal ideal domain.Ifr e R factors as $\mathbf{r}=\mathbf{p}_{\mathrm{l}}^{\mathrm{n}_{\mathrm{l}}}\cdots\mathbf{p}_{\mathrm{k}}^{\mathrm{n}_{\mathrm{k}}}$ with $p_{1},\ldots,p_{k}\varepsilon R$ $p_{k}$ Pk distinct primes and each $n_i>0$ , then there is an R-module iso morphism

$$\mathrm{R/(r)\cong R/(p_1^{n_1})\oplus\cdots\oplus R/(p_k^{n_k}).}$$

Consequently every cyclic R-module of order r is a direct sum of'k cyclic R-modules of orders $p_1^{n_1}$ $p_1^{n_1}$ $p_{1}^{n_{1}},\ldots,p_{k}^{n_{k}}$ Pknk $p_k^{\mathrm{nk}}$ respectively

SKETCH OF PROOF. We shall prove that if $s,t\in R$ R $R$ are relatively prime, then $R/(st)\cong R/(s)\oplus R/(t)$ . The first part of the lemma then follows by induction on the number of distinct primes in the prime decomposition of $r$ .Thelast statement of the lemma is an immediate consequence of the fact that $R/(c)$ is a cyclic $R$ -module of order $c$ for each $c\varepsilon R$ $R$ R by Theorem 6.4. The map $\theta:R\to R$ given by $x\vdash tx$ is an $R$ -module monomorphism that takes the ideal (s) onto the ideal $(st)$ . By Corollary 1.8 $\theta$ induces an $R$ -module homomorphism $R/(s)\to R/(st)$ given by $x+(s)\vdash Ix+(st)$ Similarly there is a homomorphism $R/(t)\to R/(st)$ given by $x+(t)|\mapsto sx+(st)$ By the proof of Theorem 1.13 the map $\alpha:R/(s)\oplus R/(t)\to R/(st)$ given by $(x+(s),y+(t))\mapsto[tx+sy]+(st)$ is a well-defined $R$ -module homomorphism Since $(s,t)=1_{R}$, there exist $u,v\in R$ such that $su+tv=1_{R}$ (Theorem II1.3.11). If $c\varepsilon R$, $R.$ R then $c=suc+tvc$ , whence $\alpha(\iota c+(s),uc+(t))=c+(st)$ . Therefore, $\alpha$ is an epimorphism. In order to show that $\alpha$ is a monomorphism we must show that

$$\alpha(x+(s),y+(t))=0\quad\Rightarrow\quad x\varepsilon(s)\quad\mathrm{and}\quad y\varepsilon(t).$$

If $\alpha(x+(s),y+(t))=0$ , then $1x+sy=stb\varepsilon(st)$ for some b $b$ $b\varepsilon R$ .Hence $utx+usy$ $=ustb$ .But $y=1_{R}y=(su+tv)y$ ,whence $utx+(y-tvy)=ustb$ and $y=ustb-$ $utx+tvy\varepsilon(t)$ .A similar argument shows that $x\in(s)$ .■

1

1

1

------------------------------------------------------------------

Theorem 6.12. Let A be a finitely generated module over a principal ideal domain R

(i) A is the direct sum of a free submodule F of finite rank and a finite number of. cyclic torsion modules. The cyclic torsion summands (if any) are of orders $r_{\mathrm{l}},\ldots,r_{\mathrm{t}}$ where $r_{\mathrm{l}},\ldots,r_{\mathrm{t}}$ are (not necessarily distinct) nonzero nonunit elements of R such that $r_{1}\mid r_{2}\mid\cdots\mid r_{t}$ . The rank of F and the list of ideals $(\mathbf{r}_1),\ldots,(\mathbf{r}_t)$ are uniquely determinea by A. (i)Ais the direct sum ofa free submoduleEof finite rank and a finite number of

cyclic torsion modules. Th cyclic torsion summands (ifany) are oforders. $p_{1}^{\theta_{1}},\ldots,p_{k}^{\theta_{k}}$ where $\mathbf{p}_{\mathrm{l}},\ldots,\mathbf{p}_{\mathrm{k}}$ are (not necessarily distinct) primes in R and $s_{\mathrm{l}}$ S1 $s_{\mathrm{l}},\ldots,s_{\mathrm{k}}$ $Sk$ Sk are(not necessarily distinct) positive integers. Therank of E and the list of ideals. $(\mathbf{p}_{1}^{81}),\ldots,(\mathbf{p}_{k}^{8k})$ are uniquely determined $by$ A (except for the order of the pi)

The notation $r_1|r_2|\cdots|r_t$ means $r_1$ divides $r_2$, $r_2$ r2 $r_2$ divides $r_3$, etc. The elements $r_1,\ldots,r_l$ in Theorem 6.12 are called the invariant factors of the module $A$ just as in the special case of abelian groups. Similarly $p_{1}^{s1},\ldots,p_{k}^{sk}$ are called the elementary divisors of $A$

SKETCH OF PROOF OF 6.12. The existence of a direct sum decomposition of the type described in (i) is an immediate consequence of Theorems 6.6, 6.7, and 6.9. Thus $A$ is the direct sum of a free module and a finite family of cyclic $R$ -modules, each of which has order a power of a prime. In the case of abelian groups these prime powers areprecisely the elementary divisors ofA.The method of calculating the invariant factors of an abelian group from its elementary divisors (see pp. 80-81) may be used here, mutatis mutandis, to prove the existence of a direct sum decomposition of $A$ of the type described in (i). One need only make the following modifications. The role on ${\mathrm{f}}Z_{p^n}\cong{\mathbf{Z}}/(p^n)(p\varepsilon{\mathbf{Z}}$ prime) is played by a cyclic torsion submodule of $A$ of order $P^n$ $p$ E $R$ prime). Such a cyclic torsion module is isomorphic to $R/(p^n)$ by Theorem 6.4(ii). Lemma I1.2.3 is replaced by Lemma 6.11.

The proof of the uniqueness of the direct sum decompositions in (i) and (ii) is essentially the same as the proof of the corresponding facts for abelian groups (Theorem I1.2.6). The following modifications of the argument are necessary. First of all prime factorization in $R$ is unique only up to multiplication by a unit (Definition III.3.5 and Theorem IIl.3.7). This causes no difficulty in $\mathbf{Z}$ since the only units are $\pm1$ and primes are defined to be positive. In an arbitrary principal ideal domain $R$ , however, an element a e $R$ may have order $P$ and order $q$ with $p,q$ distinct primes. However, since $( p) =$ ${\mathcal{C} }_{a}= ( q)$ ， $p$ and $q$ are associates by Theorem II1.3.2; that is, $q=pu$ with $u\varepsilon R$ a unit. Hence the uniqueness statements in (i) and (i) deal with ideals rather than elements. Note that $a\neq0$ implies that $\mathcal{O}_a\neq R$ and that a cyclic module $Ra$ is free if and only if $\mathcal{O}_{a}=(0)$ . Thus the elements $r_i$ in (i) are nonzero nonunits.Other modifications: as above replace each finite cyclic summand $Z_n\cong\mathbf{Z}/(n)$ with $n>1$ by a cyclic torsion module $R/(r)$ $(r\varepsilon R$ a nonzero nonunit) Replace the subgroup generated by the infinite cyclic summands $\mathbf{Z}$ by a free $R$ -module of finite rank. Use Lemmas 6.10 and 6.11 in place of Lemmas I1.2.3 and I1.2.5. Instead of the counting argument on p. 79 (showing that $r=d$ ) use the fact that $A[p]$ is a vector space over $R/(p)$ . Hence the number of summands $R/(p)$ is precisely $\dim_{R/(p)}A[p]$ , which is invariant by Theorem 2.7.

------------------------------------------------------------------

Corollary 6.13. Two finitely generated modules over a principal ideal domain, A and B, are isomorphic ifand only i f A/ $^{\prime}\mathbf{A}_{t}$ andB/B, have the same rank and A and B have the same invariant factors [resp. elementary divisors].

PROOF. Exercise.

### EXERCISES

Note: Unless stated otherwise, $R$ is a principal ideal domain and all modules are unitary.

1. If $R$ is a nonzero commutative ringwith identity and every submoduleof everyfree $R$ -module is free, then $R$ is a principal ideal domain. [Hint: Every ideal $I$ of $R$ is a free $R$ -module. If u,vε I $(u\neq0,v\neq0)$ ,then $uv+(-v)u=0$ ,which implies that I has a basis of one element; that is, $I$ is principal.]

2. Every free module over an arbitrary integral domain with identity is torsion-free. The converse is false (Exercise I1.1.10).

3. Let $A$ be a cyclic $R$ -module of order r e $R$

(a) If $s\varepsilon R$ is relatively prime to $r$ , then $sA=A$ and $A[s]=0$ (b) If $s$ divides $r$ , say $sk=r$ , then $sA\cong R/(k)$ and $A[s]\cong R/(s)$

4.If $A$ is a cyclic $R$ -module of order $r$ ,then (i)every submodule of $A$ is cyclic,with order dividing $r$ ;(i) for every ideal $(s)$ containing $(r)$ $A$ has exactly one submodule. which is cyclic of order $s$

5.If $A$ is a finitely generated torsion module, then $\{r\varepsilon R\mid rA=0\}$ is a nonzero ideal in $R$ ,say $(r_1)$ . $r_1$ is called the minimal annihilator of $A$ . Let $A$ be a finite abelian group with minimal annihilator $m\in\mathbf{Z}.$ Show that a cyclic subgroup of $A$ of order properly dividing $m$ need not be a direct summand of $A$

6. If $A$ and $B$ are cyclic modules over $R$ of nonzero orders $r$ and $s$ respectively, and r. is not relatively prime to $s$ ,then the invariant factors of $A\oplus B$ are the greatest common divisor of $r,s$ and the least common multiple of $r,s$

7. Let $A$ and ae $A$ satisfy the hypotheses of Lemma 6.8.

(a) Every $R$ -submodule of $A$ is an $R/(p^n)$ -module with $(r+(p^n))a=ra$ Conversely, every $R/(p^n)$ -submodule of $A$ is an $R$ -submodule by pullback along $R\to R/(p^n)$ (b) The submodule $Ra$ is isomorphic to $R/(p^n)$

(c) The only proper ideals of the ring $R/(p^n)$ are the ideals generated by

$p^i+(p^n)$ $p^i+(p^n)$ $p^{i}+\left(p^{n}\right)\left(i=1,2,\ldots,n-1\right)$ (d) $R/(p^n)$ (and hence $Ra$ ) is an injective $R/(p^n)$ -module. [Hint: use (c) and

Lemma 3.8.] (e) There exists an $R$ -submodule $C$ of $A$ such that $A=Ra\oplus G$ C.[Hinr: Propo

sition 3.13.]

1

1

1

## 7. ALGEBRAS

Algebras are introduced and their basic properties developed. Tensor products are used extensively in this discussion. Algebras will be studied further in Chapter IX.

------------------------------------------------------------------

Definition 7.1. Let K be a commutative ring with identity. A K-algebra (or algebra over K)A is a ringA such that:

(i) $(A,+)$ is a unitary (left)K-module; (i) $\mathrm{k(ab)=(ka)b=a(kb)}$ for all k e K and a,b e A.

AK-algebra A which,as a ring,is a division ring,is called a division algebra.

The classical theory of algebras deals with algebras over a field $K$ .Such an algebra is a vector space over $K$ and hence various results of linear algebra are applicable. An algebra over a field $K$ that is finite dimensional as a vector space over $K$ is called a finite dimensional algebra over $K$

EXAMPLE. Every ring $R$ is an additive abelian group and hence a $\mathbf{Z}$ -module. It is easy to see that $R$ is actually a $\mathbf{Z}$ -algebra

EXAMPLES. If $K$ is a commutative ring with identity, then the polynomial ring $K[x_1,\ldots,x_n]$ and the power series ring $K[[x]]$ are $K.$ algebras, with the respective $K.$ -module structures given in the usual way.

EXAMPLE. If $V$ is a vector space over a feld $F$ , then the endomorphism ring $\operatorname{Hom}_{\mu}(V,V)$ (Exercise 1.7) is an $F$ -algebra. The $F$ -module structure of $\operatorname{Hom}_F(V,V)$ is discussed in the Remark after Theorem 4.8.

EXAMPLES. Let $A$ be a ring with identity and $K$ a subring of the center of $A$ such that $1_A\varepsilon K$ . Then $A$ is a $K$ algebra, with the $K$ -module structure being given by multiplication in $A$ .In particular, every commutative ring $K$ with identity is a $K.$ -algebra.

EXAMPLE.Both the field of complex numbers $\mathbf{C}$ and the division ring of real quaternions (p. 117) are division algebras over the field R of real numbers

EXAMPLE. Let $G$ be a multiplicative group and $K$ a commutative ring with identity. Then the group ring $K(G)$ (p. 117) is actually a $K$ -algebra with $K.$ -module structure given by

$$k(\sum r_{i}g_{i})=\sum(kr_{i})g_{i}\quad(k,r_{i}\varepsilon K;g_{i}\varepsilon G).$$

$K(G)$ is called the group algebra of $G$ over $K.$

EXAMPLE. If $K$ is a commutative ring with identity, then the ring $Mat_nK$ of all $n\times n$ matrices over $K$ isa $K$ -algebra with the $K.$ -module action of $K$ given in the usual way. More generally, if $A$ is a $K$ -algebra, then so is $Mat_nA$

REMARK. Since $K$ is commutative, every left $K$ -module (and hence every $K.$ algebra) $A$ is also a right $K$ module with $ka=ak$ for all a ε $A$ ,k e K. This fact is implicitly assumed in Theorems 7.2 and 7.4 below, where tensor products are used.

The motivation for the next theorem, which provides another means of defining $K$ algebras, is the fact that for any ring $R$ the unique map $R\otimes_\mathbf{Z}R\to R$ , defined on a generator $r\textcircled{8}s$ by $r\textcircled{\times}s\mapsto rs.$ ,is a homomorphism of additive abelian groups Since rings are simply $\mathbf{Z}$ -algebras, this fact is a special case of

------------------------------------------------------------------

Theorem 7.2.Let K be a commutative ring with identity and Aa unitary lefi K-module.Then A is a K-algebraifand only ifthere exists a K-module homomorphism $\pi:\mathbf{A}\otimes_{\mathbf{K}}\mathbf{A}\to\mathbf{A}$ such that the diagran.

$$\begin{array}{c}A\otimes_KA\otimes_KA\xrightarrow{\pi\otimes1_A}A\otimes_KA\\\downarrow1_A\otimes\pi\\\uparrow\\A\otimes_KA\xrightarrow{\pi}A\end{array}$$

is commutative. In this case the K-algebra A has an identity if and only if there is a K-module homomorphism $\mathbf{I}:\mathbf{K}\to\mathbf{A}$ such that the diagran.

$$\begin{array}{c}K\otimes_KA\overset{\zeta}{\rightarrow}A\overset{\theta}{\rightarrow}A\overset{\otimes_KK}{\rightarrow}\\\downarrow I\otimes1_A\\\downarrow\\A\otimes_KA\overset{\pi}{\rightarrow}A\overset{\pi}{\rightarrow}A\overset{\pi}{\rightarrow}A\overset{\otimes_KA}{\rightarrow}\end{array}$$

is commutative, where $\zeta,\theta$ are the isomorphisms of Theorem 5.7.

SKETCH OF PROOF. If $A$ is a $K$ -algebra, then the map $A\times A\to A$ given by $(a,b)\mapsto ab$ is $K.$ bilinear, whence there is a $K.$ -module homomorphis

$$\pi:A\otimes_KA\to A$$

by Theorem 5.6. Verify that $\pi$ has the required properties. If $A$ has an identity $1_{A}$ then the map $I:K\to A$ given by $k\vdash k1_A$ is easily seen to be a $K$ -module homoInorphism with the required properties. Conversely, given $A$ and the map $\pi:A\otimes_{K}A\to A$ , define $ab=\pi(a\otimes b)$ and verif y that $A$ is a $K$ -algebra. If $I:K\to A$ is also given, then $I(1_K)$ is an identity for $A$

The homomorphism $\pi$ of Theorem 7.2 is called the product map of the $K$ -algebra A. The homomorphism $I$ is called the unit map.

Definition 7.3. Let K be a commutarive ring with identity and A, B K-algebras!

(i) A subalgebra of A is a subring of A that is also a K-submodule of A. (ii) A (left, right, two-sided) algebra ideal of A is a (lefi, right, rwo-sided) ideal of

the ring A that is also a K-submodule of A (i) $A$ homomorphism [resp. isomorphism] of K-algebras $\mathbf{f}:\mathbf{A}\to\mathbf{B}$ is a ring ho-

momorphism [isomorphism] that is also a K-module homomorphism [isomorphism]

REMARKS. If $A$ is a $K$ -algebra,an ideal of the ring $A$ need not be an algebra ideal of $A$ (Exercise 4). If, however, $A$ has an identity, then for all $k\varepsilon K$ and a e $A$

$$ka=k(1_Aa)=(k1_A)a\quad\mathrm{and}\quad ka=(ka)1_A=a(k1_A),$$

with $k1_A\in A$ . Consequently, for a left [resp. right] ideal $J$ in the ring $A$

$$kJ=(k1_A)J\subset J\quad[\text{resp.}kJ=J(k1_A)\subset J].$$

1

------------------------------------------------------------------

Therefore, if A has an identity, every (left, right, two-sided) ideal is also a (left, right two-sided) algebra ideal. The quotient algebra of a $K.$ -algebra $A$ by an algebra ideal Iis now defined in the

 obvious way, as are the direct product and direct sum of a family of $K$ -algebras. Tensor products furnish another way to manufacture new algebras. We first

observe that if $A$ and $B$ are $K.$ -modules, then there is a $K$ -module isomorphism $\alpha:A\otimes_KB\to B\otimes_KA$ such that $\alpha(a\otimes b)=b\otimes a\left(a\in A,b\in B\right)$ ; see Exercise 2.

Theorem 7.4.Let A and B be algebras [with idenriry] over a commutative ring K with identit y. Let $\pi$ be the composition

$$\mathrm{(A\otimes_KB)\otimes_K(A\otimes_KB)\xrightarrow{1A\otimes a\otimes1B}(A\otimes_KA)\otimes_K(B\otimes_KB)\xrightarrow{\pi_A\otimes\pi_B}A\otimes_KB,}$$

where TA $\pi_{\mathbf{A}}$ $\pi_{\mathbf{A}},\:\pi_{\mathbf{B}}$ TB $\pi_{\mathrm{B}}$ are the product maps of A and B respectively. Then A $\textcircled{8}_{\mathrm{K}}B$ isaK algebra [with identity] with product map $\pi$

PROOF. Exercise; note that for generators $a\otimes b$ and $a_1\otimes b_1$ of $A\otimes_{K}B$ the product is defined to be

$$(a\otimes b)(a_1\otimes b_1)=\pi(a\otimes b\otimes a_1\otimes b_1)=aa_1\otimes bb_1.$$

Thus if $A$ and $B$ have identities 1A $1_{A}$ $1_A,1_B$ 1B $1_{B}$ respectively, then $1_A\otimes1_B$ is the identity in $A\otimes_KB$ .■

The $K$ -algebra $A\otimes_KB$ of Theorem 7.4 is called the tensor product of the Kalgebras $A$ and $B$ . Tensor products of algebras are useful in studying the structure of division algebras over a feld $K$ (Section IX.6).

### EXERCISES

Nore: $K$ is always a commutative ring with identity.

1.Let Cbe the categorywhose objectsare all commutative $K$ -algebras with identity and whose morphisms are all $K$ -algebra homomorphisms $f\colon A\to B$ such that $f(1_{A})=1_{B}$ . Then any two $K$ algebras $A,B$ of ୧ have a coproduct. [Hinr: consider $A\to A\otimes_KB\leftarrow B$ where $a\vdash a\otimes\mathbf{l}_B$ and $b\mapsto1_A\otimes b.]$

2. If $A$ and $B$ are unitary $K.$ modules [resp. $K$ -algebras], then there is an isomorphism of $K.$ -modules [resp. $K$ algebras] $\alpha:A\otimes_KB\to B\otimes_KA$ such that $\alpha(a\otimes b)$ $=b\otimes a$ for all a e $A,b\in B$

3. Let $A$ be a ring with identity. Then $A$ isa $K$ -algebra with identityif and only if there is a ring homomorphism of $K$ into the center of $A$ such that $1_K\mapsto1_A$

4. Let $A$ be a one-dimensional vector space over the rational field Q. If we define $ab=0$ for all $a,b\in A$ , then $A$ is a $\mathbf{Q}$ -algebra. Every proper additive subgroup of $A$ is an ideal of the ring $A$ , but not an algebra ideal.

5. Let ୧ be the category of Exercise 1. If $X$ is the set $\{x_1,\ldots,x_n\}$ , then the polynomial algebra $K[x_1,\ldots,x_n]$ is a free object on the set $X$ in the category ୧ [Hinr: Given an algebra $A$ in ୧ and a map $g:\{x_1,\ldots,x_n\}\to A$ , apply Theorem II1.5.5 to the unit map $I:K\to A$ and the elements $g(x_1),\ldots,g(x_n)\varepsilon A.]$

------------------------------------------------------------------

CHAPTER V

# FIELDS AND GALOIS THEORY

The first principal theme of this chapter is the structure theory of fields.We shall study a field $F$ in terms of a specified subfield $K$ $F$ is said to be an extension field of $K$ ). The basic facts about field extensions are developed in Section 1, in particular, the distinction between algebraic and transcendental extensions. For the most part we deal only with algebraic extensions in this chapter.Arbitraryfield extensions are considered in Chapter VI. The structure of certain fields and feld extensions is thoroughly analyzed: simple extensions (Section 1); splitting fields (normal exten-. sions) and algebraic closures (Section 3); finite felds (Section 5); and separable algebraic extensions (Sections 3 and 6). The Galois theory of field extensions (the other main theme of this chapter) had

its historical origin in a classical problem in the theory of equations, which is discussed in detail in Sections 4 and 9. Various results of Galois theory have important applications, especially in the study of algebraic numbers (see E. Artin [48]) and algebraic geometry (see S. Lang [54]). The key idea of Galois theory is torelatea field extension $K\subset F$ to the group of

all automorphisms of $F$ that fixK elementwise (the Galois group of the extension).A Galois field extension may be defined in terms of its Galois group (Section 2) or in terms of the internal structure of the extension (Section 3). The Fundamental Theorem of Galois theory (Section 2) states that there is a one-to-one correspondence between the intermediate fields of a (finite dimensional) Galois field extension and the subgroups of the Galois group of the extension. This theorem allows us to translate properties and problems involving fields, polynomials, and field extensions into. group theoretic terms. Frequently, the corresponding problem in groups has a solution, whence the original problem in field theory can be solved. This is the case, for instance, with the classical problem in the theory of equations mentioned in the previous paragraph. We shall characterize those Galois field extensions whose Galois. groups are finite cyclic (Section 7) or solvable (Section 9). The approximate interdependence of the sections of this chapter is as follows:

1

------------------------------------------------------------------

![](https://storage.simpletex.cn/view/fdGwvGUpdRLDB9br87QZB7a9mKxnvuPUU)

A broken arrow $A-\rightarrow B$ indicates that an occasional result from section $A$ is used in section $B.$ , but that section $B$ is essentially independent of section $A$ .See page xvii for a description of a short basic course in fields and Galois theory

## 1. FIELD EXTENSIONS

The basic facts needed for the study of field extensions are presented frst, followed by a discussion of simple extensions.Finally a number of essential proper. ties of algebraic extensions are proved. In the appendix, which is not used in the sequel, several famous geometric problems of antiquity are settled, such as the trisection of an angle by ruler and compass constructions

Definition 1.1.Afield F is said tobe an extensionfield ofK(orsimply an extension ofK) provided that K is a subfield ofF

If $F$ is an extension field of $K$ , then it is easy to see that $\mathbf{1}_{K}=\mathbf{1}_{F}$ . Furthermore, $F$ is a vector space over $K$ (Definition IV.1.1). Throughout this chapter the dimension. of the $K$ -vector space $F$ will be denoted by $[F:K]$ rather than $\dim_KF$ as previously. $F$ is said to be a finite dimensional extension or infinite dimensional extension of $K$ according as $[F:K]$ is fnite or infinite.

Theorem 1.2. Let F be an extension field of E and E an extension field of K. Then $[F:K]=[F:E][E:K]$ . Furthermore $[F:K]$ is finite i fand only if[F : E] and $[\mathbb{E}:\mathbb{K}]$ are finite.

PROOF. This is a restatement of Theorem IV.2.16.

In the situation $K\subset E\subset F$ of Theorem 1.2, $E$ is said to be an intermediate field of $K$ and $F$ If $F$ is a field and $X\subset F$ , then the subfield [resp. subring] generated by $X$ is the

intersection of all subfields [resp. subrings] of $F$ that contain $X$ . If $F$ is an extension

------------------------------------------------------------------

feld of $K$ and $X\subset F$ , then the subfield [resp. subring] generated by $K$ K $K\cup X$ $X$ X is called the subfield [resp. subring] generated by $X$ over $K$ and is denoted $K(X)$ [resp. $K[X]]$ Note that $K[X]$ is necessarily an integral domain. If $X=\{u_{1},\ldots,u_{n}\}$ , then the subfield $K(X)$ [resp. subring $K[X]]$ of $F$ is denoted

$K(u_{1},\ldots,u_{n})$ [resp. $K[u_1,\ldots,u_n]]$ . The field $K(u_1,\ldots,u_n)$ is said to be a finitely generated extension of $K$ (but it need not be finite dimensional over $K$ ;see Exercise 2). If $X=\{u\}$ , then $K(u)$ is said to be a simple extension of $K.$ . A routine verification shows that neither $K(u_{1},\ldots,u_{n})$ nor $K[u_{1},\ldots,u_{n}]$ depends on the order of the $u_{i}$ and that $K(u_1,\ldots,u_{n-1})(u_n)=K(u_1,\ldots,u_n)$ and $K[u_1,\ldots,u_{n-1}][u_n]=K[u_1,\ldots,u_n]$ (Exercise 4). These facts will be used frequently in the sequel without explicit mention.

NOTATION. If $F$ is a field $u,v\in F$ , and $v\neq0$ , then $uv^{-1}\varepsilon F$ will sometimes be denoted by $u/v$

Theorem 1.3. If F is an extension field of a field K, u, $u_i\varepsilon F$ ,and $X\subset F$ ，then

(i) the subring K[u] consists of all elements of the form $f(u)$ ,where f isa polynomial with coefficients in K (that is, f e K[x)); (ii) the subring $\mathbf{K}[\mathrm{u_1,\ldots,u_m}]$ um] $u_{\mathrm{m}}]$ consists of all elements of the form $\mathbf{g}(\mathbf{u}_{1},\mathbf{u}_{2},\ldots,\mathbf{u}_{\mathrm{n}})$

where g is a polynomial in m indeterminates with coefficients in $K$ (that is, $g\varepsilon K[x_{1},\ldots,x_{m}])$ (ii) the subring $K[X]$ consists of all elements of the form $\mathbf{h}(\mathbf{u}_{1},\ldots,\mathbf{u}_{\mathrm{n}})$ , where each

$u_i\varepsilon X$ , n is a positive integer, and h is a polynomial in n indeterminates with coefficients in K (that is, n ∈ $N^{*}$ ,he $\mathbf{K}[\mathbf{x}_{1},\ldots,\mathbf{x}_{n}])$ (iv)the subfieldK(u) consists ofall elements of theform $f(u)/g(u)=f(u)g(u)^{-1}$

where f,g E $K[x]$ and $\mathbf{g}($u$)\neq0$ (v)the subfield $\mathbf{K}(\mathbf{u}_{\mathrm{l}},\ldots,\mathbf{u}_{\mathrm{m}})$ consists of all elements of the form

$$\mathrm{h(u_{1},\ldots,u_{m})/k(u_{1},\ldots,u_{m})=h(u_{1},\ldots,u_{m})k(u_{1},\ldots,u_{m})^{-1},}$$

where $\mathbf{h,k}\varepsilon\mathbf{K}[\mathbf{x}_{1},\ldots,\mathbf{x}_{\mathrm{m}}]$ and $\mathbf{k}(\mathbf{u}_{1},\ldots,\mathbf{u}_{\mathrm{m}})\neq0$ (vi) the subfield $K(X)$ consists of all element.s of the form

$$\mathrm{f(u_1,\ldots,u_n)/g(u_1,\ldots,u_n)=f(u_1,\ldots,u_n)g(u_1,\ldots,u_n)^{-1}}$$

where nE $N^{*}$ ,f,g ∈ $\mathbf{K}[\mathbf{x}_1,\ldots,\mathbf{x}_n]$ $\mathbf{K}[\mathbf{x}_1,\ldots,\mathbf{x}_n]$ $\mathbf{K}[\mathbf{x}_1,\ldots,\mathbf{x}_n],\mathbf{u}_1,\ldots,\mathbf{u}_n\in\mathbf{X}$ X $X$ and $\mathbf{g}(\mathbf{u}_1,\ldots,\mathbf{u}_n)\neq0$ (vii) For each v e $K(X)$ (resp. K[X]) there is a finite subset $\mathbf{X}^{\prime}$ of $X$ such tha

VE $K(\mathbf{X}^{\prime})$ (resp. $K[X^{\prime}]$ ）.

SKETCH OF PROOF. (vi) Every feld that contains $K$ and $X$ must contain the set $E=\{f(u_1,\ldots,u_n)/g(u_1,\ldots,u_n)|\: n\in\mathbb{N}^*$ ； $f,g\in K[x_1,\ldots,x_n]$ ； $u_i\in X$ $g(u_1,\ldots,u_n)\neq0\}$ ，whence $K(X)\supset E$ .Conversely, if $f,g\in K[x_1,\ldots,x_m]$ and $f_{1},g_{1}\in K[x_{1},\ldots,x_{n}]$, then define $h,k\in K[x_1,\ldots,x_{m+n}]$ $x_{m+n}]$ Xm+n] by

$$\begin{aligned}
&h(x_{1},\ldots,x_{m+n}) =f(x_{1},\ldots,x_{m})g_{1}(x_{m+1},\ldots,x_{m+n})  \\
&-g(x_1,\ldots,x_m)f_1(x_{m+1},\ldots,x_{m+n}); \\
&k(x_{1},\ldots,x_{m+n}) =g(x_{1},\ldots,x_{m})g_{1}(x_{m+1},\ldots,x_{m+n}). 
\end{aligned}$$

Then for any $u_{1},\ldots,u_{m},v_{1},\ldots,v_{n}\in X$ such that $g(u_{1},\ldots,u_{m})\neq0,g_{1}(v_{1},\ldots,v_{n})\neq0$

$$\frac{f(u_1,\ldots,u_m)}{g(u_1,\ldots,u_m)}-\frac{f_1(v_1,\ldots,v_n)}{g_1(v_1,\ldots,v_n)}=\frac{h(u_1,\ldots,u_m,v_1,\ldots,v_n)}{k(u_1,\ldots,u_m,v_1,\ldots,v_n)}\varepsilon E.$$

------------------------------------------------------------------

Therefore.. $E$ is a group under addition (Theorem I.2.5). Similarly the nonzero elements of $E$ form a group under nultiplication, whence $E$ is a field. Since $X\subset E$ and $K\subset E.$ we have $K(X)\subset E$ . Therefore, $K(X)=E$ . (vi) If $u\in K(X)$ . then by (vi) $u=f(u_1,\ldots,u_n)/g(u_1,\ldots,u_n)\varepsilon K(X^{\prime})$ ,where $X^{\prime}=\left\{u_{1},\ldots,u_{n}\right\}\subset X$ .

If $L$ and $M$ are subfields of a field $F$ , the composite of $L$ and $M$ in $F$ , denoted $LM$ is the subfeld generated by the set $LUM$ . An inmediate consequence of this definition is that $LM=L(M)=M(L)$ . It is easy to show that if $K$ is a subfeld of L $\cap M$ such that $M\:=\:K(S)$ where $S\subset M$ , then $LM=L(S)$ (Exercise 5). The relationships of the dimensions $[L:K],[M:K],[LM:K]$ [LM : K] $|LM:K]$ ,etc. are considered in Exercises 20-21. The composite of any finite number of subfelds $E_1,E_2,\ldots,E_n$ is defined to be the subfield generated by the set E $E_{1}$ $E_1\cup E_2\cup\ldots\cup E_n$ $E_{n}$ En and is denoted $E_{1}E_{2}\cdots E_{n}$ (see Exercise 5). The next step in the study of field extensions is to distinguish two fundamentally

different situations that occur.

Definition 1.4. Ler F be an extension field of K.An element u of F is said to be algebraic orer K prorided that u is a root of some nonzero polynomial f e K[]. If u is. not a root of any nonzero f ε K[x]. u is said to be transcendental over K. F is called an algebraic extension of K if ecery elenent ofF is algebraic orer K. F is called a transcendental extensionif at least one element ofF is transcendental over $K$

REMARKS. If $u\varepsilon K$ , then $u$ is a root of $x-u\varepsilon K[x]$ and therefore algebraic over $K$ .If ue $F$ is algebraic over some subfield $K^{\prime}$ of $K$ , then $u$ is algebraic over $K$ since $K^{\prime}[x]\subset K[x]$ . If $u\varepsilon F$ is a root of $f\varepsilon K[x]$ with leading coefficient $c\neq0$ , then $u$ is also a root of $c^{-1}f$, which is a monic polynomial in $K[x]$ . A transcendental extension may contain elements that are algebraic over $K$ (in addition to the elements of $K$ itself).

EXAMPLES. Let Q,R and C be the fields of rational, real, and complex numbers respectively. Then $i\varepsilon C$ is algebraic over 0 and hence over $R$ ; in fact, $\mathbf{C}=\mathbf{R}(i)$ . It is a nontrivial fact that $\pi$ ， $e\in\mathbf{R}$ are transcendental over $\mathbf{Q}$ ; see, for instance, I. Herstein [4].

EXAMPLE. If $K$ is a feld, then the polynomial ring $K[x_{1},\ldots,x_{n}]$ is an integral domain (Theorem Ill.5.3). The quotient field of $K[x_1,\ldots,x_n]$ is denoted $K(x_1,\ldots,x_n)$ It consists of all fractions $f/g$ ,with $f,g\varepsilon K[x_{1},\ldots,x_{n}]$ and $g\neq0$ ,and the usual addition and multiplication (see Theorem Ill.4.3). $K(x_1,\ldots,x_n)$ is called the field of rational functions in $x_1,\ldots,x_n$ over $K$ . In the field extension

$$K\subset K(x_1,\ldots,x_n)$$

each $x_i$ is easily seen to be transcendental over $K$ .In fact, every element of $K(x_1,\ldots,x_n)$ not in $K$ itself is transcendental over $K$ (Exercise 6). In the next two theorems we shall characterize all simple field extensions up to

isomorphism.e

Theorem 1.5. If F is an extension field of K and u e F is transcendental over K, then. there is an isomorphism offields $\mathbf{K}(\mathbf{u})\cong\mathbf{K}(\mathbf{x})$ which is the identity on K

------------------------------------------------------------------

SKETCH OF PROOF. Since $u$ is transcendental $f(u)\neq0$ ， $g(u)\neq0$ for all nonzero $f,g\in K[x]$ . Consequently, the map $\varphi:K(x)\to F$ given by $f/g\vdash f(u)/g(u)$ $=f(u)g(u)^{-1}$ is a well-defined monomorphism of fields which is the identity on $K$ But Im $\varphi=K(u)$ by Theorem 1.3, whence $K(x)\cong K(u)$ .■

Theorem 1.6. If F is an extension field ofK and u e F is algebraic over K, then

(i $\mathbf{K}($u$)=\mathbf{K}[$u]

(i) $K(u)\cong K[x]/(f)$ , where f e $K[x]$ is an irreducible monic polynomial of degree. $n\geq1$ uniquely determined by the conditions that $\mathbf{f}($u)=0 and g(u) = 0 $\mathbf{g}($u)=0 $\mathbf{g}($u$)=0\left(\mathbf{g}\varepsilon\mathbf{K}[\mathbf{x}]\right)if$ and onlyiff dividesg; (ii) $[\mathbf{K}(\mathbf{u}):\mathbf{K}]=\mathbf{n}$

(iv) $\left\{1_{\mathrm{K}},\mathrm{u,u^{2},\ldots,u^{\mathrm{n-1}}}\right\}$ is a basis of the vector space K(u) over K;

(v) every element of K(u) can be written uniquely in the form $\mathbf{a}_{\mathrm{c}}+\mathbf{a}_{\mathrm{l}}\mathbf{u}+\cdots+$ $\mathrm{a}_{n-1}\mathrm{u}^{n-1}\left(\mathrm{a}_{\mathrm{i}}\in\mathbf{K}\right)$

PROOF. (i) and(i) The map $\varphi:K[x]\to K[u]$ given by $g\vdash g(u)$ is a nonzerc ring epimorphism by Theorems I1.5.5. and 1.3. Since $K[x]$ is a principal ideal domain (Corollary II1.6.4), Ker $\varphi=(f)$ for some $f\varepsilon K[x]$ with $f(u)=0$ . Since $u$ is algebraic, Ker $\varphi\neq0$ and since $\varphi\neq0$ , Ker $\varphi\neq K[x]$ . Hence $f\neq0$ and deg $f\geq1$ Furthermore, if $c$ is the leading coefficient of $f$, then $c$ is a unit in $K[x]$ (Corollary 111.6.4), $c^{-1}f$ is monic, and $(f)=(c^{-1}f)$ (Theorem II1.3.2). Consequently we may assume that $f$ is monic. By the First Isomorphism Theorem (Corollary Ill.2.10)

$$K[x]/(f)=K[x]/\mathrm{Ker~}\varphi\cong\mathrm{Im~}\varphi=K[u].$$

Since $K[u]$ is an integral domain, the ideal $(f)$ is prime in $K[x]$ by Theorem II1.2.16 Theorem III.3.4 implies that $f$ is irreducible and hence that the ideal $(f)$ is maximal Consequently, $K[x]/(f)$ is a field (Theorem III.2.20). Since $K(u)$ is the smallest subfield of $F$ containing $K$ and $u$ and since $K(u)\supset K[u]\cong K[x]/(f)$ we must have $K(u)=K[u]$ . The uniqueness of $f$ follows from the facts that $f$ is monic and

$$g(u)=0\quad\Leftrightarrow\quad g\:\varepsilon\:\mathrm{Ker}\:\varphi=(f)\:\Leftrightarrow\:f\:\mathrm{divides}\:g.$$

(iv)Every element of $K(u)=K[u]$ is of the form $g(u)$ for some $g\in K[x]$ by Theorem 1.3. The division algorithm shows that $g=qf+h$ with $q,h\in K[x]$ and deg $h<$ deg f. Therefore, $g(u)=q(u)f(u)+h(u)=0+h(u)=h(u)=b_0+b_1u+\cdots+b_mu^m$ with $m<n=\deg f$ Thus $\{1_{K,}u,\ldots,u^{n-1}\}$ spans the $K$ vector space $K(u)$ . To see that $\left\{1_{K},u,\ldots,u^{n-1}\right\}$ is linearly independent over $K$ and hence a basis, suppose

$$a_0+a_1u+\cdots+a_{n-1}u^{n-1}=0\quad(a_i\varepsilon K).$$

Then $g=a_{0}+a_{1}x+\cdots+a_{n-1}x^{n-1}\varepsilon K[x]$ has $u$ as a root and has degree $\leq n-1$ Since $f\mid g$ by (i) and deg $f=n$ , we must have $g=0$ ; that is, $a_i=0$ for all $i$ ,whence $\{1_{K,U},\ldots,u^{n-1}\}$ is linearly independent. Therefore, $\{1_{K,U,\ldots,U^{n-1}}\}$ is a basis of $K(u)$ (i) is an immediate consequence of (iv). The equivalence of (iv) and $(\mathbf{v})$ is a

routine exercise.

Definition 1.7. Let F be an extension field of K and ue F algebraic over K. The monic irreducible polynomial f of Theorem 1.6 is called the irreducible (or minimal or minimum) polynomial of u. The degree of u over K is deg $\mathbf{f}=[\mathbf{K}(\mathbf{u}):\mathbf{K}]$

------------------------------------------------------------------

The following exarnple illustrates how Theorem 1.6 and the techniques of its proof may be used for specific computations.

EXAMPLE. The polynomial $x^{3}-3x-1$ is irreducible over $\mathbf{Q}$ (Theorem I11.6.6 and Proposition I11.6.8) and has real root $u$ (Exercise III.6.16(d)). By Theorem $1.6u$ has degree 3 over $\mathbf{Q}$ and $\{1,u,u^2\}$ is a basis of $\mathbf{Q}(u)$ over $\mathbf{Q}$ . The element $u^4+2u^3+3\varepsilon\mathbf{Q}(u)=\mathbf{Q}[u]$ may be expressed as a linear combination (over Q) of the basis elements as follows. The division algorithm (that is, ordinary long division) in the ring $\mathbf{Q}[x]$ shows that

$$x^4+2x^3+3=(x+2)(x^3-3x-1)+(3x^2+7x+5),$$

whence

$$\begin{aligned}
u^{4}+2u^{3}+3& =(u+2)(u^3-3u-1)+(3u^2+7u+5) \\
&=(u+2)0+(3u^2+7u+5) \\
&=3u^{2}+7u+5.
\end{aligned}$$

The multiplicative inverse of $3u^2+7u+5$ in $\mathbf{Q}(u)$ may be calculated as follows. Since $x^{3}-3x-1$ is irreducible in $\mathbf{Q}[x]$ , the polynomials $x^{3}-3x-1$ and $3x^2+7x+5$ are relatively prime in $\mathbf{Q}[x]$ . Consequently, by Theorem II1.3.11 there exist $g(x),h(x)\varepsilon\mathbf{Q}[x]$ such that

$$(x^3-3x-1)g(x)+(3x^2+7x+5)h(x)=1.$$

Therefore, since $u^{3}-3u-1=0$ wehave

$$(3u^2+7u+5)h(u)=1$$

so that $h(u)\in\mathbf{Q}[u]$ is the inverse of $3u^{2}+7u+5.$ The polynomials $g$ and $h$ maybe explicitly computed via the Euclidean algorithm (Exercise III.3.13): $g(x)=-7/37x$ +29/111 ,and h(x)= 7/111 $h(x)=7/111$ $h(x)=7/111$ $x^2-26/111$ $x+28/111$ $x+28/11$ $x+28/11$ .Hence $h(u)=7/111\:u^{2}-$ $26/111u+28/111$

Suppose $E$ is anextensionfield of $K,F$ is anextension fieldof $L$ ,and $\sigma:K\to L$ is an isomorphism offields.A recurrent question in the studyoffield extensions is: under what conditions can $\sigma$ be extended to an isomorphism of $E$ onto $F$ . In other words, is there an isomorphism $\tau:E\to F$ such that $\tau\mid K=\sigma?$ We shall answer this question now for simple extension fields and in so doing obtain criteria for two simple extensions $K(u)$ and $K(v)$ to be isomorphic (also see Exercise 16). Recall that if $\sigma:R\to S$ is an isomorphism of rings, then the map $R[x]\to S[x]$

given by $\sum_{i}r_{i}x^{i}|\mapsto\sum_{i}\sigma(r_{i})x^{i}$ is also a ring isomorphism (Exercis I1.5.1). Clearly this map extends $\sigma$ .We shall denote the extended map $R[x]\to S[x]$ by $\sigma$ also and the image of $f\varepsilon R[x]$ by $\sigma f$

Theorem 1.8. Let $\sigma:\mathbf{K}\to\mathbf{L}$ be an isomorphism of fields, u an element of some ex-. tension field of K and v an element of some extension field of L. Assume either

(i)u is iranscendental over K and v is iranscendental orer L; or (i) u is a root of an irreducible polynomial f ε K[x] and v is a roor of of e L[x)

Then o extends to an isomorphism of fields. $\mathbf{K}($u$)\cong\mathbf{L}(\mathbf{v})$ which maps u onto v

------------------------------------------------------------------

SKETCH OF PROOF. (i) By the remarks preceding the theorem $\sigma$ extends to an isomorphism $K[x]\cong L[x]$ .Verify that thismap inturn extends to an isomorphism $K(x)\to L(x)$ given by $h/g\mapsto\sigma h/\sigma g$ . Therefore, by Theorem 1.5 we have $K(u)\cong$ $K(x)\equiv L(x)\equiv L(v)$ The composite map extends $\mathbf{\sigma}$ and maps $u$ onto $\upsilon$

(ii) It suffices to assume that $f$ is monic. Since $\sigma:K[x]\cong L[x]$ this implies that ofe $L[x]$ is monic irreducible. By the proof of Theorem 1.6 the maps

$$\varphi:K[x]/(f)\to K[u]=K(u)\operatorname{and}\psi:L[x]/(\sigma f)\to L[v]=L(v),$$

given respectively by $\varphi[g+(f)]=g(u)$ and $\psi[h+(\sigma f)]=h(v)$ , are isomorphisms The map $\theta:K[x]/(f)\to L[x]/(\sigma f)$ given by $\theta[g+(f)]=\sigma g+(\sigma f)$ is an isomorphism by Corollary II1.2.11. Therefore the composite.

$$K(u)\overset{\varphi^{-1}}{\operatorname*{\to}}K[x]/(f)\overset{\theta}{\operatorname*{\to}}L[x]/(\sigma f)\overset{\psi}{\operatorname*{\to}}L(v)$$

is an isomorphism of fields such that $g(u)\vdash(\sigma g)(v)$ . In particular, $\psi\theta\varphi^{-1}$ agrees with $\sigma$ on $K$ and maps $u$ onto $v$ (since $\sigma(\mathcal{l}_{K})=\mathcal{l}_{L}$ by Exercise II1. 1.15).

Corollary 1.9.Ler E and F each be extension fields ofK and ler u eE andve F be algebraic over K. Then u and v are roots of the same irreducible polynomial f s $K[x]if$ and only if there is an isomorphism of fields. $\mathbf{K}($u$)\cong\mathbf{K}($v) which sends u onto v and is the identity on K.

PROOF. $(\Longrightarrow)$ Apply Theorem 1.8 with $\sigma=1_{\kappa}$ (so that $\sigma f=f$ for all $f\varepsilon K[x])$ $(\Leftarrow)$ Suppose $\sigma:K(u)\cong K(v)$ with $\sigma(u)=v$ and $\sigma(k)=k$ for all $k\varepsilon K$ . Let $f\varepsilon K[x]$ be the irreducibe polynomial of the algebrac element $u$ If $f=\sum_{i=0}^nk_ix^i$
$$\begin{aligned}&\text{then }0=f(u)=\sum_{i=0}^nk_iu^i.\text{Therefore},0=\sigma\biggl(\sum_{i=0}^nk_iu^i\biggr)=\sum_i\sigma(k_iu^i)=\sum_i\sigma(k_i)\sigma(u^i)\\&=\sum_ik_i\sigma(u)^i=\sum_{i=0}^nk_iv^i=f(v).\quad\blacksquare\end{aligned}$$

Up to this point we have always dealt with a root of a polynomial $f\varepsilon K[x]$ in some given extension field $F$ of $K$ . The next theorem shows that it really is not necessary to have $F$ given in advance.

Theorem 1.10. If K is a field and f e $K[x]$ polynomial of degree n, then there exists a simple extension field $\mathbf{F}=\mathbf{K}($u) ofK such that

(i) ue F is a root off; (i) $[K(u):K]\leq n$, with eyuality holding if and only if f is irreducible in $K[x]$

(ii) if f is irreducible in $K[x]$ ,then $K(u)$ is unique up to an isomorphism which is the

identity on K.

REMARK. In view of (i) it is customary to speak of the field $F$ obtained byad joining a root of the irreducible polynomial $f\varepsilon K[x]$ to the field $K$

SKETCH OF PROOF OF 1.10. We may assume that $f$ is irreducible (if not. replace $f$ by one of its irreducible factors). Then the ideal $(f)$ is maximal in $K[x]$ (Theorem II1.3.4 and Corollary IIl.6.4) and the quotient ring $F=K[x]/(f)$ is a

------------------------------------------------------------------

field (Theorem I11.2.20). Furthermore, the canonical projection $\pi:K[x]\to K[x]/(f)$ $=F$ , when restricted to $K$ , is a monomorphism (since O is the only constant in a maximal ideal of $K[x])$ .Thus $F$ contains $\pi(K)\cong K$ , and therefore may be considered as an extension field of $K$ (providing that $K$ is identifed with $\pi(K)$ under the isomorphism). For $x\in K[x]$, let $u=\pi(x)\varepsilon F$ .Verify that $F=K(u)$ and that $f(u)=0$ in $F$ . Theorem 1.6 implies statement (ii) and Corollary 1.9 gives (ii).

In the remainder of this section we shall develop the essential basic facts about algebraic field extensions.

Theorem 1.11.IfF is a finite dimensional extension field of K,then F is finitely generated and algebraic orer K.

PROOF. If $[F:K]=n$ and $u\varepsilon F$ ,then theset of $n+1$ elements $\{1_K,u,u^2,\ldots,u^n\}$ must be linearly dependent.Hence there are $a_i$ ai $a_i\varepsilon K$ K $K$ , not all zero, such that $a_0+a_1u+$ $a_{2}u^{2}+\cdots+a_{n}u^{n}=0$ , which implies that $u$ is algebraic over $K$ . Since $u$ was arbitrary, $F$ is algebraic over $K$ .If $\{v_1,\ldots,v_n\}$ is a basis of $F$ over $K$ ,then it is easytosee that $F=K(v_{1},\ldots,v_{n})$

Theorem 1.12.If F is an extension field of $K$ and $X$ is a subset of $F$ such that $\mathbf{F}=\mathbf{K}(\mathbf{X})$ and every element of $X$ is algebraic over K,then $F$ is an algebraic extension of K. If X is a finite set, then $F$ is finite dimensional over K.

PROOF. If $v\varepsilon F$ F $F$ , then $v$ E $K(u_{1},\ldots,u_{n})$ forsome $u_i$ ui $u_i\varepsilon X$ $X$ X (Theorem 1.3) and there is a tower of subfields:

$$K\subset K(u_1)\subset K(u_1,u_2)\subset\cdots\subset K(u_1,\ldots,u_{n-1})\subset K(u_1,\ldots,u_n).$$

Since $u_1$ is algebraic over $K$ ,it is necessarily algebraic over $K(u_1,\ldots,u_{i-1})$ for each $i\geq2$ ， say of degree $r_i$ . Since $K(u_1,\ldots,u_{i-1})(u_i)=K(u_1,\ldots,u_i)$ wehave $[K(u_1,\ldots,u_i):K(u_1,\ldots,u_{i-1})]=r_i$ by Theorem 1.6. Let $r_1$ be the degree of $u_1$ over $K$ ; then repeated application of Theorem 1.2 shows that $[K(u_1,\ldots,u_n):K]$ $=r_{1}r_{2}\cdots r_{n}$ . By Theorem 1.11 $K(u_1,\ldots,u_n)$ (and hence $v_{i}$ )is algebraic over $K$ Since UE $F$ was arbitrary, $F$ is algebraic over $K$ . If $X=\{u_{1},\ldots,u_{n}\}$ is fnite, the same proof (with $F=K(u_{1},\ldots,u_{n}))$ shows that $[F:K]=r_1r_2\cdots r_n$ is fnite.

Theorem 1.13. If $F$ is an algebraic extension field of E and E is an algebraic exten sion field of K, then F is an algebraic extension of $K$

PROOF. Let $u\varepsilon F$ ;since $u$ is algebraic over $E,\:b_nu^n+\cdots+b_1u+b_0=0$ for some $b_i$ bi $b_{i}\varepsilon E\left(b_{n}\neq0\right)$ . Therefore, $u$ is algebraic over the subfield $K(b_0,\ldots,b_n)$ .Consequently, there is a tower of fields

$$K\subset K(b_0,\ldots,b_n)\subset K(b_0,\ldots,b_n)(u),$$

with $[K(b_0,\ldots,b_n)(u){:}K(b_0,\ldots,b_n)]$ finite by Theorem 1.6 (since $u$ is algebraic over $K(b_0,\ldots,b_n))$ and $[K(b_0,\ldots,b_n):K]$ finite by Theorem 1.12 (since each $b_i\varepsilon E$ is algebraic over $K$ ). Therefore, $[K(b_0,\ldots,b_n)(u):K]$ is finite (Theorem 1.2). Hence

------------------------------------------------------------------

ue $K(b_0,\ldots,b_n)(u)$ is algebraic over $K$ (Theorem 1.11). Since $u$ was arbitrary, $F$ is algebraic over $K$ .

Theorem 1.14. Let $F$ be an extension field of K and E the set of all elements of F which are algebraic over K. Then E is a subfield ofF (which is,of course,algebraic over K).

Clearly the subfield $E$ is the unique maximal algebraic extension of $K$ contained in $F$

PROOF OF 1.14. If $u,v\varepsilon E$ , then $K(u,v)$ is an algebraic extensionfield of $K$ by Theorem 1.12. Therefore, since $u-v$ and $uv^{-1}$ $(v\neq0)$ are in $K(u,v)$ $K(u,v)$ $K(u,v),u-v$ u-v $u-v$ and $uv^{-1}\varepsilon E$ . This implies that $E$ is a field (see Theorem I.2.5).

## APPENDIX: RULER AND COMPASS CONSTRUCTIONS

The word “ruler" is to be considered as a synonym for straightedge (as is customary in geometric discussions).We shall use field extensions to settle twofamous problems of antiquity:

(A) Is it possible to trisect an arbitrary angle by ruler and compass constructions? (B) Is it possible via ruler and compass constructions to duplicate an arbitrary

cube (that is, to construct the side of a cube having twice the volume of the given cube)? We shall assume as known all the standard ruler and compass constructions as

 presented in almost any plane geometry text. Example: given a straight line $L$ and a point $P$ not on $L$ , the unique straight line through $P$ and parallel $L$ [resp. perpendicular to $L]$ is constructible. Here and below "constructible"' means "constructible by ruler and compass constructions." Furthermore we shall adopt the viewpoint of analytic geometry as follows.

Clearly we may construct withruler and compass two perpendicular straight lines (axes). Choose a unit length. Then we can construct all points of the plane with integer coordinates (that is, locate them precisely as the intersoction of suitable constructible straight lines parallel to the axes). As will be seen presently, the solution to the stated problems will result from a knowledge of what other points in the plane can be constructed via ruler and compass constructions. If $F$ is a subfield of the field R of real numbers,the plane of F is the subset of the

plane consisting of all points $(c,d)$ with CEF $c\varepsilon F$ $c\in F,d\varepsilon F$ deF $d\varepsilon F$ .If $P,Q$ are distinct points in the plane of $F$ the unique line through $P$ and $Q$ is called a line in $F$ and the circle with center $P$ and radius the line segment $PQ$ is called a circle in F. It is readily verified that every straight line in $F$ has an equation of the form $ax+by+c=0(a,b,c\in F)$ and every circle in $F$ an equation of theform $x^2+y^2+ax+by+c=0$ (a,b,c ε F) (Exercise 24).

------------------------------------------------------------------

(i) $\mathbf{L}_1\cap\mathbf{L}_2$ is a point in the plane ofF; (i) $\mathbf{L}_{1}\cap\mathbf{C}_{1}=\varnothing$ or consists of one or two points in the plane of $^{r}$F$(\sqrt{\mathrm{u}})$ for some

uεF (u$\geq0)$ ； (ii) $\mathbf{C}_1\cap\mathbf{C}_2=\varnothing$ or consists ofone or two points in the plane of $F(\sqrt{u})$ for some ueF (u$\geq0$;

SKETCH OF PROOF. (i) Exercise. (i) If the circles are $C_1:x^2+y^2+a_1x+$ $b_{1}y+c_{1}=0$ and $C_{2}:x^{2}+y^{2}+a_{2}x+b_{2}y+c_{2}=0\left(a_{i},b_{i},c_{i}\right.\varepsilon F$ by the remarks pre ceding the lemma), show that $C_{\mathrm{l}}$ C $C_{\mathrm{i}}\cap C_{2}$ C2 $C_2$ is the same as the intersection of $C_1$ or $C_2$ with the straight line $L:(a_1-a_2)x+(b_1-b_2)y+(c_1-c_2)=0$ .Verify that $L$ is a line in $F$ ; then case (ii) reduces to case (ii).

(ii) Suppose $L_{\mathrm{l}}$ has the equation $dx+ey+f=0$ (d,e,fεF) .The case $d=0$ is left as an exercise; if $d\neq0$ , we can assume $d=1$ (why?), so that $x=(-ey-f)$ . If $(x,y)\varepsilon L_1\cap C_1$, then substitution gives the equation of $C_{\mathbf{l}}$ as $0=(-ey-f)^{2}+$ $y^2+a_1(-ey-f)+b_1y+c_1=Ay^2+By+C=0$ ，with $A,B,C\in F$ . If $A=0$ then $y\varepsilon F$ ;hence $x\varepsilon F$ and $x,y\in F(\sqrt{1})=F$ If $A\neq0$ , we may assume $A=1$ . Then $y^{2}+By+C=0$ and completing the square yields $(y+B/2)^{2}+(C-B^{2}/4)=0$ This implies that either $L_{1}$ n $C_{\mathbf{i}}=\varnothing$ or $x,y\in F(\sqrt{u})$ with $u=-C+B^{2}/4\geq0$ .

A real number $c$ will be said to be constructible if the point $(c,0)$ can be constructed (precisely located) by a finite sequence of ruler and compass constructions that begin with points with integer coordinates. The constructibility of $c$ (or $(c,0))$ is clearly equivalent to the constructibility (via ruler and compass) of a line segment of length $|c|$ . Furthermore the point $(c,d)$ in the plane may be constructed via ruler and compass if and only if both $c$ and $d$ are constructible real numbers. The integers are obviously constructible, and it is not difficult to prove the following facts (see Exercise 25):

(i) every rational number is constructible; (i) if $c\geq0$ is constructible, so is $V\overline{c}$

(ii) if $c,d$ are constructible, then $c\pm d$ , cd, and $c/d\left(d\neq0\right)$ are constructible, so that the constructible numbers form a subfield of the real numbers that contains the rationals.

Proposition 1.16. If a real number c is constructible, then c is algebraic of degree c power of 2 over the field Q of rationals

PROOF. The preceding remarks show that we may as well take the plane of Q as given. To say that $c$ is constructible then means that $(c,0)$ may be located (constructed) by a finite sequence of allowable ruler and compass constructions beginning with the plane of Q. In the course of these constructions various points of the plane will be determined as the intersections of lines and/or circles used in the construction process. For this is the only way to arrive at new points using only a ruler and compass. The first step in the process is the construction of a line or circle either of which is completely determined by two points (center $P$ and radius $PT$ for the circle). Either these points are given as being in the plane of Q or else they may be chosen arbitrarily, in which case they may be taken to be in the plane of $Q$ also. Similarly at each stage of the construction the two points that determine the line or circleused maybe taken to be either points in theplaneof $Q$ or points constructed

------------------------------------------------------------------

in previous steps. In view of Lemma 1.15 the first new point so constructed lies in the plane of an extension field $\mathbf{Q}(\sqrt{u})$ of $\mathbf{Q}$ ,with $u\varepsilon Q$ ,or equivalentlyin theplane of an extension $\mathbf{Q}(v)$ with $v^2\varepsilon Q$ .Such an extension has degree $1=2^0$ or 2 over $\mathbf{Q}$ (de- pending on whether or not $\upsilon\varepsilon Q$ .Similarly the next new point constructed lies in the plane of $\mathbf{Q}(v,w)=\mathbf{Q}(v)(w)$ with $w^{2}\varepsilon\mathbf{Q}(v)$ . It follows that a finite sequence of ruler and compass constructions givesrise to a finite tower offields:

$$\mathbb{Q}\subset\mathbb{Q}(v_1)\subset\mathbb{Q}(v_1,v_2)\subset\cdots\subset\mathbb{Q}(v_1,\ldots,v_n)$$

with $v_{i}^{2}\varepsilon\mathbf{Q}(v_{1},\ldots,v_{i-1})$ and $[\mathbf{Q}(v_{1},\ldots,v_{i}):\mathbf{Q}(v_{1},\ldots,v_{i-1})]=1$ or $2\left(2\leq i\leq n\right)$ The point $(c,0)$ constructed by this process then lies in the plane of $F=\mathbf{Q}(v_{1},\ldots,v_{n})$ By Theorem 1.2, $[F:\mathbf{Q}]$ is a power of two. Therefore, $c$ is algebraic over $\mathbf{Q}$ (Theorem 1.11). Now $\mathbf{Q}\subset\mathbf{Q}(c)\subset\mathbf{F}$ implies that $[\mathbf{Q}(c):\mathbf{Q}]$ divides $[F:\mathbf{Q}]$ (Theorem 1.2) whence the degree $[\mathbf{Q}(c):\mathbf{Q}]$ of $c$ over $\mathbf{Q}$ is a power of 2.

Corollary 1.17. An angle of $60^{\circ}$ cannot be trisected by ruler and compass constructions

PROOF. If it were possible to trisect a $60^{\circ}$ angle, we would then be able to construct a right triangle with one acute angle of $20^\circ$ . It would then be possible to construct the real number (ratio) cos $20^\circ$ (Exercise 25). However for any angle $\alpha$ elementary trigonometry shows that

$$\cos3\alpha=4\cos^3\alpha-3\cos\alpha.$$

Thus if $\alpha=20^{\circ}$ , then cos $3\alpha=\cos60^{\circ}=\frac{1}{2}$ and cos $20^{\circ}$ is a root of the equation $\frac{1}{2}=4x^{3}-3x$ and hence of the polynomial $8x^{8}-6x-1$ .But this polynomial is irreducible in $\mathbf{Q}[x]$ (see Theorem I11. 6.6 and Proposition II1.6.8). Therefore cos $20^{\circ}$ has degree 3 over $\mathbf{Q}$ and cannot be constructible byProposition 1.16.

Corollary 1.18. It is impossible by ruler and compass constructions to duplicate acube of side length 1 (that is, to construct the side of a cube of colume 2)..

PROOF. If $s$ is the side length of a cube of volume 2, then $s$ is a root of $x^3-2$ which is irreducible in $\mathbf{Q}[x]$ by Eisenstein's Criterion (Theorem III.6.15). Therefore. $s$ is not constructible by Proposition 1.16.

## EXERCISES

Note: Unless specified otherwise $F$ is always an extension field of the field $K$ and Q,R,C denote the fields of rational, real, and complex numbers respectively

1. (a) $[F:K]=1$ if and only if $F=K$ (b) If $[F:K]$ is prime, then there are no intermediate fields between $F$ and $K$ (c) If ue $F$ has degree $n$ over $K$ , then $n$ divides $[F:K]$

2. Give an example of a finitely generated field extension, which is not finite dimensional. [Hint: think transcendental.].

------------------------------------------------------------------

3. If $u_1$ u1 $u_{1},\ldots,u_{n}\in F$ $u_n$ un F $F$ then the field $K(u_1,\ldots,u_n)$ is (isomorphic to) the quotient field of the ring $K[u_{1},\ldots,u_{n}]$

4. (a) For any u, ... , $u_{n}$ E $F$ and any permutation $\sigma\varepsilon S_n$ ， $K(u_{1},\ldots,u_{n})$ $=K(u_{\sigma_{(1)}},\ldots,u_{\sigma_{(n)}})$ (b) $K(u_1,\ldots,u_{n-1})(u_n)=K(u_1,\ldots,u_n)$

(c) State and prove the analogues of (a) and (b) for $K[u_1,\ldots,u_n]$ (d) If each $u_{i}$ is algebraic over $K$ , then $K(u_1,\ldots,u_n)=K[u_1,\ldots,u_n]$

5. Let $L$ and $M$ be subfields of $F$ and $LM$ their composite. (a) If $K\subset L\cap M$ and $M=K(S)$ for some $S\subset M$ , then $LM=L(S)$ (b) When is it true that $LM$ is the set theoretic union $L$ U m? (c) If $E_{\mathrm{l}},\ldots,E_{n}$ are subfields of $F.$ ,show that

$$E_1E_2\cdots E_n=E_1(E_2(E_3(\cdots(E_{n-1}(E_n)))\cdots).$$

6.Every element of $K(x_1,\ldots,x_n)$ which is not in $K$ is transcendental over $K$

7. If $\upsilon$ is algebraic over $K(u)$ for some u e $F$ and $\upsilon$ is transcendental over $K$ , then $u$ is algebraic over $K(v)$

8. If $u\varepsilon F$ is algebraic of odd degree over $K$ , then so is $u^2$ and $K(u)=K(u^2)$

9.If $x^{n}-a\varepsilon K[x]$ is irreducible and u e $F$ is arootof xn $x^n$ $x^{n}-a$ and $m$ divides $n$ ,then prove that the degree of $u^{m}$ over $K$ is $n/m$ What is the irreducible polynomial for $u^m$ over $K?$

10. If $F$ is algebraic over $K$ and $D$ is an integral domain such that $K\subset D\subset F$ ,then $D$ is a feld.

11. (a) Give an example of a field extension $K\subset F$ such that $u,v\in F$ are transcendental over $K.$ ，but $K(u,v)\ncong K(x_1,x_2)$ . [Hint: consider $\upsilon$ over the field $K(u).]$ (b) State and prove a generalization of Theorem 1.5 to the case of $n$ transcendental elements $u_1,\ldots,u_n$

12. If $d\geq0$ is an integer that is not a square describe the feld $\mathbf{Q}(\sqrt{d})$ and find a set of elements that generate the whole field.

13. (a) Consider the extension $\mathbf{Q}(u)$ of $\mathbf{Q}$ generated by a real root $u$ of $x^{3}-6x^{2}+$ $9x+3$ .(Why is this irreducible?) Express each of the following elements in terms of the basis $\{1,u,u^2\}:u^4;u^5;3u^5-u^4+2$ ； $(u+1)^{-1}$ ; $(u^2-6u+8)^{-1}$ (b) Do the same with respect to the basis $\{1,u,u^2,u^3,u^4\}$ of $\mathbf{Q}(u)$ where $u$ is a real root of $x^5+2x+2$ and the elements in question are: $(u^{2}+2)(u^{3}+3u);u^{-1}$ $u^4(u^4+3u^2+7u+5);(u+2)(u^2+3)^{-1}$

14. (a) If $F=\mathbf{Q}(\sqrt{2},\sqrt{3})$ , find $[F:\mathbf{Q}]$ and a basis of $F$ over $\mathbf{Q}$ (b)Do the same for $F=\mathbf{Q}(i,\sqrt{3},\omega)$ ,where i e C, $i^{2}=-1$ ,and $\omega$ is a complex (nonreal) cube root of 1.

15. In the field $K(x)$ ,let $u=x^{3}/(x+1)$ .Show that $K(x)$ is a simpleextensionof the field $K(u)$ . What is $[K(x):K(u)]$

16. In the field C, $\mathbf{Q}(i)$ and $\mathbf{Q}(\sqrt{2})$ are isomorphic as vector spaces, but not as fields.

17. Find an irreducible polynomial $f$ of degree 2 over the field $Z_2$ . Adjoin a root $u$ of $f$to$Z_2$ to obtain a field $Z_2(u)$ of order 4. Use the samemethod to construct a field of order 8.

------------------------------------------------------------------

18.A complex number is said to be an algebraic number if it is algebraic over $\mathbf{Q}$ and an algebraic integer if it is the root of a monic polynomial in $\mathbf{Z}[x]$ (a) If $u$ is an algebraic number, there exists an integer $n$ such that $nu$ is an

algebraic integer (b) If $r\varepsilon Q$ is an algebraic integer, then r e Z. (c)If $u$ is an algebraic integer and $n\varepsilon\mathbf{Z}$, $\mathbf{Z}$, Z, then $u+n$ and nu are algebraic integers. (d) The sum and product of two algebraic integers are algebraic integers

19. If $u,v\in F$ F $F$ are algebraic over $K$ of degrees $m$ and $n$ respectively, then $[K(u,v):K]\leq mn$ If $(m,n)=1$ , then $[K(u,v):K]=mm$

20.Let $L$ and $M$ be intermediate fields in the extension $K\subset F$ (a) $[LM:K]$ is finite if and only if $[L:K]$ and $[M:K]$ are finite.

(b) If $[LM:K]$ is finite, then $[L:K]$ and $[M:K]$ divide $[LM:K]$ and

$$[LM:K]\leq[L:K][M:K].$$

(c) If $[L:K]$ and $[M:K]$ are finite and relatively prime, then

$$[LM:K]=[L:K][M:K].$$

(d) If $L$ and $M$ are algebraic over $K$ , then so is $LM$

21. (a) Let $L$ and $M$ be intermediate fields of the extension $K\subset F$ , of finite dimension over $K$ . Assume that $[LM:K]=[L:K][M:K]$ and prove that L M $M=K$ (b) The converse of (a) holds if $[L:K]$ or $[M:K]$ is 2. (c) Using a real and a nonreal cube root of 2 give an example where L I $\uparrow M=K$ $[L:K]=[M:K]=3$ , but $[LM:K]<9$

22. $F$ is an algebraic extension of $K$ if and only if for every intermediate field $E$ every monomorphism $\sigma:E\to E$ which is the identity on $K$ is in fact an automorphism of $E$

23.If $u\varepsilon F$ is algebraic over $K(X)$ for some $X\subset F$ then there exists a finite subset $X^{\prime}\subset X$ such that $u$ is algebraic over $K(X^{\prime})$

24. Let $F$ be a subfield of R and $P,Q$ points in theEuclidean plane whose coordinates lie in $F$ (a) The straight line through $P$ and $Q$ has an equation of the form

$ax+by+c=0$ with $a,b,c\in F$ (b) The circle with center $P$ and radius the line segment $PQ$ has an equation of the form $x^{2}+y^{2}+ax+by+c=0$ with $a,b,c\in F$

25. Let $c,d$ be constructible real numbers. (a) $c+d$ and $c-d$ are constructible

(b) If $d\neq0$ , then $c/d$ is constructible. [Hinr: If $(x,0)$ is the intersection of the $x$ axis and the straight line through (O,1) that is parallel the line through $(0,d)$ and $(c,0)$ , then $x=c/d$ ] (c)cd is constructible [Hinr: use (b)].

(d) The constructible real numbers form a subfield containing Q. (e) If $c\geq0$ then $\sqrt{c}$ is constructible. [Hinr: If $y$ is the length of the straight

line segment perpendicular to the $x$ axis that joins (1,0) with the (upper half of the) circle with center $((c+1)/2,0)$ and radius $(c+1)/2$ then $y=\sqrt{c}.]$

------------------------------------------------------------------



------------------------------------------------------------------



------------------------------------------------------------------



------------------------------------------------------------------



------------------------------------------------------------------

REMARKS. It is quite possible for $L^{\prime\prime}$ to contain $L$ properly (similarly for $H^{\prime\prime}$ and $H$ ). $F$ is Galois over $K$ (by definition) if $G^{\prime}=K$ . Thus since $K^{\prime}=G$ in any case, $F$ is Galois over $K$ if and only if $K=K^{\prime\prime}$ . Similarly $F$ is Galois over an intermediate field $E$ if and only if $E=E^{\prime\prime}$

Let $X$ be an intermediate field or subgroup of the Galois group. $X$ will becalled closed provided $X=X^{\prime\prime}$ . Note that $F$ is Galois over $K$ if and only if $K$ is closed.

Theorem 2.7. If F is an extension field of K, then there is aone-to-one correspondence. between the closed intermediate fields of the extension and the closed subgroups of the Galois group,given by $\mathsf{E}\vdash\mathsf{E}^{\prime}=Aut_\mathsf{E}\mathsf{F}$

PROOF. Exercise; the inverse of the correspondence is given by assigning to each closed subgroup $H$ its fixed field $H^{\prime}$ .Note that by Lemma 2.6(iv) all primed objects are closed.

This theorem is not very helpful until we have some more specific information as to which intermediate fields and which subgroups are closed. Eventually we shall. show that in an algebraic Galois extension all intermediate fields are closed and that in thefinite dimensional case all subgroups of the Galois group are closed as well. Webegin with some technicallemmas that give us estimates ofvariousrelative dimensions.

Lemma 2.8. Let $F$ be an extension field of K and L,M intermediate fields with. $\mathbf{L}\subset M$ If $[M:L]$ is finite, then $[\mathbf{L}^{\prime}:\mathbf{M}^{\prime}]\leq[\mathbf{M}:\mathbf{L}]$ . In particular, if. $[F:K]$ is finite, then $|Aut_{\mathrm{K}}$F$|\leq[\mathbf{F}:\mathbf{K}]$

PROOF. We proceed by induction on $n=[M:L]$, with the case $n=1$ being trivial. If $n>1$ and the theorem is true for all $i<n$ ,choose u E $M$ with $u\notin L$ .Since $[M:L]$ is finite, $u$ is algebraic over $L$ (Theorem 1.11) with irreducible polynomia $f\varepsilon L[x]$ of degree $k>1.$ By Theorems 1.6 and 1.1, $[L(u):L]=k$ and $[M:L(u)]=n/k$ Schematically we have:

![](https://storage.simpletex.cn/view/f1PG4OWXvr844mRwcfgeZvl7FegfgcrFe)

There are now two cases. If $k<n$ ,then $1<n/k<n$ and by induction $[L^{\prime}:L(u)^{\prime}]\leq k$ and $[L(u)^{\prime}:M^{\prime}]\leq n/k$ .Hence $[L^{\prime}:M^{\prime}]=[L^{\prime}:L(u)^{\prime}][L(u)^{\prime}:M^{\prime}]\leq k(n/k)=n$ $=[M:L]$ and the theorem is proved. On the other hand if $k=n$ ,then $[M:L(u)]=1$ and $M$ = $L( u)$ .In order to complete theproof in this case,we shall construct an injective map from the set of $S$ of all left cosets of $M^{\prime}$ in $L^{\prime}$ to the set $T$ of all distinct

------------------------------------------------------------------

roots (in $F$ ) of the polynomial $f_{\varepsilon}L[x].$ whence $|S|\leq|T|$ . Since $|T|\leq n$ by Theorem 111.6.7 and $|S|=[L^{\prime}:M^{\prime}]$ by definition, this will show that $[L^{\prime}:M^{\prime}]\leq|T|\leq n$ $=[M:L]$ . The final statement of the theorem then follows immediately since $|\mathrm{Aut}_KF|=[\mathrm{Aut}_KF:1]=[K^{\prime}:F^{\prime}]\leq[F:K]$ Let $\tau M^{\prime}$ be a left coset of $M^{\prime}$ in $L^{\prime}$ .If $\sigma\varepsilon M^{\prime}=\mathrm{Aut}_MF$ , then since u E $M$

$\tau\sigma(u)=\tau(u)$ .Thus every element of the coset $\tau M^{\prime}$ has the same effect on $u$ and maps $u\mapsto\tau(u)$ . Since $\tau\varepsilon L^{\prime}=\operatorname{Aut}_{L}F$ ,and $u$ is a root of $f\varepsilon L[x]$ $\tau(u)$ is also a root of fby Theorem 2.2. This implies that the map $S\to T$ given by $\tau M^{\prime}\vdash\tau(u)$ is well defined. If $\tau(u)\:=\:\tau_{0}(u)\:(\tau,\tau_{0}\varepsilon\:L_{-}^{\prime})$ , then $\tau_{0}^{-1}\tau(u)=u$ and hence $\tau_0^{-1}\tau$ fixes $u.$ .Therefore, $\tau_{0}^{-1}\tau$ fixes $L(u)=M$ elementwise (see Theorem 1.6(iv)) and $\tau_{0}^{-1}\tau\varepsilon M^{\prime}$ M' $M^{\prime}$ . Consequently by Corollary $\mathbf{I}.4.3\:\tau_{0}M^{\prime}=\tau M^{\prime}$ and the map $S\to T$ is injective.

Several important applications of Lemma 2.8 are treated in tne appendix. We now prove an analogue of Lemma 2.8 for subgroups of the Galois group.

Lemma 2.9.Let F be an extensionfield ofK and let H,J be subgroups ofthe Galois group $Aut_\mathrm{K}F$ with $H<J$ H<J $\mathbf{H}<\mathbf{J}.If[\mathbf{J}:\mathbf{H}]$ [J : H] $[\mathbf{J}:\mathbf{H}]$ is finite,then $[\mathbf{H}^{\prime}:\mathbf{J}^{\prime}]\leq[\mathbf{J}:\mathbf{H}]$

PROOF. Let $[J:H]=n$ and suppose that $[H^{\prime}:J^{\prime}]>n$ . Then there exist $u_{1},u_{2},\ldots,u_{n+1}\varepsilon H^{\prime}$ un+1 $u_{n+1}$ H' $H^{\prime}$ that are linearly independent over $J^{\prime}$ . Let $\{\tau_{1},\tau_{2},\ldots,\tau_{n}\}$ be a complete set of representatives of the left cosets of $H$ in $J$ (that is, $J=\tau_1H\cup\tau_2H$ $\bigcup\cdots\cup\tau_nH$ and $\tau_{i}^{-1}\tau_{j}\varepsilon H$ if and only if $i=j)$ and consider the system of $n$ homogeneous linear equations in $n+1$ unknowns with coefficients $\tau_1(u_1)$ in the field $F$

$$\begin{aligned}
&\tau_{1}(u_{1})x_{1}\:+\:\tau_{1}(u_{2})x_{2}\:+\:\tau_{1}(u_{3})x_{3}\:+\:\cdots\:+\:\tau_{1}(u_{n+1})x_{n+1}& \text{=0} \\
&\tau_{2}(u_{1})x_{1}\:+\:\tau_{2}(u_{2})x_{2}\:+\:\tau_{2}(u_{3})x_{3}\:+\:\cdots\:+\:\tau_{2}(u_{n+1})x_{n+1}& =0 \\
&\tau_{n}(u_{1})x_{1}+\tau_{n}(u_{2})x_{2}+\tau_{n}(u_{3})x_{3}+\cdots+\tau_{n}(u_{n+1})x_{n+1}=& \text{0} 
\end{aligned}$$

Such a system always has a nontrivial solution (that is, one.different from the zero solution $x_{1}=x_{2}=\cdots=x_{n+1}=0;$ see Exercise VIl.2.4(d)).Among all such nontrivial solutions choose one, say $x_{1}=a_{1},\ldots,x_{n+1}=a_{n+1}$ with a minimal number of nonzero $a_i$ .By reindexing if necessary we may assume that $x_{1}=a_{1},\ldots,x_{r}=a_{r}$ $x_{r+1}=\cdots=x_{n+1}=0\left(a_{\mathrm{i}}\neq0\right)$ $(a_i\neq0)$ (ai≠0） . Since every multiple of a solution is also a solution we may also assume $a_{\mathrm{l}}=1_{F}$ (if not multiply through by $a_{1}^{-1}$ ). Weshall showbelow that the hypothesis that $u_{1},\ldots,u_{n+1}\varepsilon H^{\prime}$ un+1 $u_{n+1}$ H' $H^{\prime}$ are linearly inde-

pendent over $J^{\prime}$ (that is, that $[H^{\prime}:J^{\prime}]>n)$ implies that there exists $\sigma\varepsilon J$ such that $x_{1}=\sigma a_{1}$ aa X2=αa2 $X_{2}=\sigma a_{2}$ $=\sigma a_{1},\:x_{2}=\:\sigma a_{2},\ldots,\:x_{r}=\:\sigma a_{r}$ $X_{r}=\sigma a_{r}$ X=oa $x_{r+1}=\cdots=x_{n+1}=0$ is a solution of the system (1) and $\sigma a_2\neq a_2$ .Since the difference of two solutions is also a solution, $x_{1}=a_{1}-\sigma a_{1}$ $x_{2}=a_{2}-\sigma a_{2},\ldots,x_{r}=a_{r}-\sigma a_{r}$, $x_{r+1}=\cdots=x_{n+1}=0$ , is also a solution of (1). But since $a_{1}-\sigma a_{1}=1_{F}-1_{F}=0$ and $a_2\neq\sigma a_2$, it follows that $x_{1}=0$ $x_{2}=a_{2}-$ Oa?,..., $x_{r}=a_{r}-\sigma a$, $x_{r+1}=\cdots=x_{n+1}=0$ is a nontrivial solution of (1) $(x_{2}\neq0)$ with at most $r-1$ nonzero entries. This contradicts the minimality of the solution $x_{1}=a_{1},\ldots,x_{r}=a_{r}$ Xr=ar $x_{r}=a_{r}$ ， $x_{r+1}=\cdots=x_{n+1}=0$ . Therefore $[H^{\prime}:J^{\prime}]\leq n$ as desired.

------------------------------------------------------------------

To complete theproof wemustfind $\sigma$ E J with the desired properties.Now exactly one of the $\tau_{i}$, say $\tau_\mathrm{l}$ , is in $H$ by definition; therefore $\tau_{1}(u_{i})=u_{i}\varepsilon H^{\prime}$ H' $H^{\prime}$ for all i. Since the $a_i$ form a solution of (1), the first equation of the system yields:

$$u_1a_1+u_2a_2+\cdots+u_ra_r=0.$$

The linear independence of the $u_i$ over $J^{\prime}$ and the fact that the $a_i$ are nonzero imply that some $a_i$ ,say $a_2$, is not in $J^{\prime}$ .Therefore there exists $\sigma\varepsilon J$ such that $\sigma a_2\neq a_2$ Next consider the system of equations

$$\begin{aligned}
&\sigma\tau_{1}(u_{1})x_{1}\:+\:\sigma\tau_{1}(u_{2})x_{2}\:+\:\cdots+\:\sigma\tau_{1}(u_{n+1})x_{n+1}&& =0 \\
&\sigma\tau_{2}(u_{1})x_{1}+\:\sigma\tau_{2}(u_{2})x_{2}+\cdots+\:\sigma\tau_{2}(u_{n+1})x_{n+1}&& =0 \\
&\sigma\tau_{n}(u_{1})x_{1}+\sigma\tau_{n}(u_{2})x_{2}+\cdots+\sigma\tau_{n}(u_{n+1})x_{n+1}&& =0 
\end{aligned}$$

(2)

It is obvious, since $\sigma$ is an automorphism and $x_{1}=a_{1},\ldots,x_{r}=a_{r}$ $x_{r+1}=\cdots=$ $x_{n+1}=0$ is a solution of (1), that $x_{1}=\sigma a_{1}$ ga $\sigma a_1,\ldots,x_r=\sigma a_r,x_{r+1}=\cdots=x_{n+1}=0$ is a solution of (2). We claim that system (2), except for the order of the equations, is identical with system (1)(so that x1 = oa1, ... ,x, = oa,,X+1 = ... = xn+1 = 0 is a solution of (1)). To see this the reader should first verify the following two facts. (i) For any $\sigma\varepsilon J$ J $J,\left\{\sigma\tau_{1},\sigma\tau_{2},\ldots,\sigma\tau_{n}\right\}\subset J$ is a complete set of coset representa-

tives of $H$ in $J$ (ii) if 5 and $\theta$ are both elements in the same coset of $H$ in $J$ , then (since $u_i\varepsilon H^{\prime}$

$\zeta(u_i)=\theta(u_i)$ for $i=1,2,\ldots,n+1$ It follows from (i) that there is somereordering $i_1,\ldots,i_{n+1}$ of $1,2,\ldots,n+1$ ，SO

that for each $k=1,2,\ldots,n+1\:\sigma\tau_{k}$ and $\tau_{ik}$ arein the same coset of $H$ in $J$ .By (ii) the kth equation of (2) is identical with the. $i_k$ th equation of (1).

Lemma 2.10.Let F be anextensionfield ofK,L and M intermediatefields with $L\subset M$ ,and H,J subgroups of theGaloisgroup $Aut_KF$ with $H<J$

(i) IfL is closed and $[M:L]$ finite, then M is closed and $[\mathbf{L}^{\prime}:\mathbf{M}^{\prime}]=[\mathbf{M}:\mathbf{L}]$ (i) ifH is closed and $[\mathbf{J}:\mathbf{H}]$ finite, thenJ is closed and $[\mathbf{H}^{\prime}:\mathbf{J}^{\prime}]=[\mathbf{J}:\mathbf{H}]$ (ii) if F is a finite dimensional Galois extension of K, then all intermediate fields. and all subgroups of the Galois group are closed and. $Aut_KF$ has order $[F:K]$

Note that (i) (with $H=1$ ) implies that every finite subgroup of $Aut_KF$ is closed

SKETCH OF PROOF OF 2.10.(i) Applying successively the facts that $J\subset J^{\prime\prime}$ and $H=H^{\prime\prime}$ and Lemmas 2.8 and 2.9yields

$$[J:H]\leq[J'':H]=[J'':H'']\leq[H':J']\leq[J:H];$$

this implies that $J=J^{\prime\prime}$ and $[H^{\prime}:J^{\prime}]=[J:H]$ (i) is proved similarly (i) If $E$ is an intermediate field then $[E:K]$ is finite (since $[F:K]$ is). Since $F$ is

Galois over $K$ K $K,K$ K $K$ is closed and (i) implies that $E$ is closed and $[K^{\prime}:E^{\prime}]=[E:K]$ In particular, if $E=F$ ,，then $\left|\mathrm{Aut}_{K}F\right|=\left[\mathrm{Aut}_{K}F:1\right]=\left[K^{\prime}:F^{\prime}\right]=\left[F:K\right]$ is finite.

------------------------------------------------------------------

Therefore, every subgroup $J$ of $Aut_KF$ KF $:KF$ is finite. Since 1 is closed (ii) implies that $J$ is closed.

Thefirst part of the Fundamental Theorem 2.5 can easily be derived from Theorem 2.7 and Lemma 2.10. In order to prove part (ii) of Theorem 2.5 we must determine which intermediatefelds correspond to normal subgroups of the Galoisgroup under the Galois correspondence. This will be done in the next lemma.

If $E$ is anintermediate field of the extension $K\subset F,E$ is said to be stable (relative to $K$ and $F$ ) if every $K$ automorphism e AutF maps. $E$ into itself. If $E$ is stable and $\sigma^{-1}\varepsilon$ α-l e $\sigma^{-1}\varepsilon Aut_KF$ is the inverse automorphism, then $\sigma^{-1}$ also maps $E$ into itself. This implies that $\sigma\mid E$ is in fact a $K$ -automorphism of $E$ (that is, $\sigma\mid E_{\varepsilon}$ Aut$_KE)$ with inverse $\sigma^{-1}\mid E$ . It will turn out that in the finite dimensional case $E$ is stable if and only if $E$ is Galois over $K$

Lemma 2.11.Let F be an extension field ofK.

(i IfE is a stable intermediate field of the extension, then. $\mathbf{E}^{\prime}=Aut_{\mathbf{E}}\mathbf{F}$ is a normal subgroup of the Galois group. $Aut_\mathrm{K}F$ (i) if H is a normal subgroup of $Aut_\mathrm{K}F$ ,，then the fixed field $H^{\prime}$ of $H$ is a stable

intermediate field of the extension.

PROOF. (i) If $u\varepsilon E$ and $\sigma\varepsilon Aut_KF$ ，then $\sigma(u)\in E$ by stability and hence $\tau\sigma(u)=\sigma(u)$ for any $\tau\varepsilon E^{\prime}=\mathrm{Aut}_{E}F$ .Therefore, for any $\sigma\varepsilon Aut_KF$ $_{.K}F$ KF $\tau\varepsilon E^{\prime}$ and u e $E.$ $\sigma^{-1}\tau\sigma(u)=\sigma^{-1}\sigma(u)=u$ Consequently, $\sigma^{-1}\tau\sigma\in E^{\prime}$ $E^{\prime}$ E and hence $E^{\prime}$ is normal in $Aut_KF$

(i) If $\sigma\varepsilon Aut_KF$ and $\tau\varepsilon H$ ，then $\sigma^{-1}\tau\sigma\varepsilon H$ by normality. Therefore, for any ue $H^{\prime}$ ， $\sigma^{-1}\tau\sigma(u)=u$ ,which implies that $\tau\sigma(u)=\sigma(u)$ for all $\tau\varepsilon H$ .Thus $\sigma(u)\in H^{\prime}$ for any $u\varepsilon H^{\prime}$ H' $H^{\prime}$ ,which means that $H^{\prime}$ is stable.

In the next three lemmas we explore in some detail the relationships between stable intermediate fields and Galois extensions and the relationship of both to the Galois group.

Lemma 2.12.IfF is a Galois extension field ofK and E is a stable intermediate fiela of the extension,then E is Galois over K.

PROOF. Ifu ∈ $E-K$ ,then there exists $\sigma$ EAut $_{.K}F$ such that $\sigma(u)\neq u$ since $F$ is Galois over $K$ .But $\sigma\mid E_{\varepsilon}\operatorname{Aut}_{\kappa}E$ by stability. Therefore,. $E$ is Galois over $K$ by the Remarks after Definition 2.4.

Lemma 2.13. If'F is an extension field of K and E is an intermediate field of the extension such that E is algebraic and Galoisover K,then E is stable(relative toF and K)

REMARK. The hypothesis that $E$ is algebraic is essential; see Exercise 13.

PROOF OF 2.13. If u E $E.$ , let $f\varepsilon K[x]$ be the irreducible polynomial of $u$ and let $u=u_{1},u_{2},\ldots,u_{r}$ ur $u_r$ be the distinct roots of $f$ that lie in $E$ . Then $r\leq n=\deg f$ by Theo-

------------------------------------------------------------------

rem II1.6.7. If $\tau\varepsilon Aut_KE$ ,then it follows fromTheorem 2.2 that $\tau$ simply permutes the $u_i$ . This implies that the coefficients of the monic polynomial $g(x)=(x-u_1)$ $(x-u_{2})\cdots(x-u_{r})\varepsilon E[x]$ are fixed by every $\tau\varepsilon Aut_{\kappa}E$ .Since $E$ is Galois over $K$ ,we must have $g\in K[x]$ . Now $u=u_1$ is a root of $g$ and hence $f\mid g$ (Theorem 1.6(ii). Since $g$ is monic and deg $g\leq\deg f$ we must have $f=g$ . Consequently, all the roots of $f$ are distinct and lie in $E$ .Now if $\sigma\varepsilon Aut_{K}F$ ,then $\sigma(u)$ is a root of $f$ by Theorem 2.2, whence $\sigma(u)\in E$ . Therefore, $E$ is stablerelative to $F$ and $K$ .

Let $E$ be an intermediate field of the extension $K\subset F$ .A $K$ -a utomorphism $\tau\varepsilon Aut_{\kappa}E$ is said to be extendible to $F$ if there exists $\sigma\varepsilon Aut_{\kappa}F$ such that $\sigma\mid E=\tau$ It is easy to see that the extendible $K$ -automorphisms form a subgroup of $Aut_KE$ KE $_{K}E$ Recall that if $E$ is stable, $E^{\prime}=\operatorname{Aut}_EF$ is a normal subgroup of $G=\mathrm{Aut}_KF$ (Lemma 2.11). Consequently, the quotient group $G/E^{\prime}$ is defined.

Lemma 2.14. Let F be an extension field of K and E a stable intermediate field of the. extension. Then the quotient group $Aut_\mathrm{K}\mathbf{F}/Aut_\mathrm{E}\mathbf{F}$ is isomorphic to the group of all K-automorphisms of E that are extendible to F.

SKETCH OF PROOF. Since $E$ is stable, the assignment $\sigma\models\sigma\mid E$ defines a group homomorphism $\mathrm{Aut}_KF\to\mathrm{Aut}_KE$ whose image is clearly the subgroup of all $K.$ -automorphisms of. $E$ that are extendible to $F.$ Observe that the kernel is $Aut_EF$ EF $EF$ and apply the First Isomorphism Theorem I.5.7.

PROOF OF THEOREM 2.5.(Fundamental Theorem of Galois Theory) Theorem 2.7 shows that there is a one-to-one correspondence between closed intermediate felds of the extension and closed subgroups of the Galois group.But in this case all intermediate fields and all subgroups are closed by Lemma 2.10(i). Statement (i) of the theorem follows immediately from Lemma 2.10(i).

(i) $F$ is Galois over $E$ since $E$ is closed (that is, $E=E^{\prime\prime}$ ）. $E$ is finite dimensional over $K$ (since $F$ is) and hence algebraic over $K$ by Theorem 1.11. Consequently, if $E$ is Galois over $K$ , then $E$ is stable by Lemma 2.13.By Lemma 2.11(i) $E^{\prime}=\mathrm{Aut}_EF$ is normal in $Aut_KF$ .Conversely if $E^{\prime}$ is normal in $Aut_kF$ then $E^{\prime\prime}$ is a stable intermediate feld (Lemma 2.11(i)). But $E=E^{\prime\prime}$ since all intermediate fields are closed and hence $E$ is Galois over $K$ by Lemma 2.12

Suppose $E$ is an intermediate field that is Galois over $K$ (so that $E^{\prime}$ is normal in $\mathrm{Aut}_{K}F)$ . Since $E$ and $E^{\prime}$ are closed and $G^{\prime}=K$ $F$ is Galois over $K$ ), Lemma 2.10 implies that $|G/E^{\prime}|=[G:E^{\prime}]=[E^{\prime\prime}:G^{\prime}]=[E:K]$ .By Lemma $2.14G/E^{\prime}=$ $\mathrm{Aut}_KF/\mathrm{Aut}_EF$ is isomorphic to a subgroup (of order $[E:K])$ of $Aut_{K}E$ . But part (i) of the theorem shows that $|\mathsf{Aut}_KE|=[E:K]$ (since $E$ is Galois over $K$ ). This implies that $G/E^{\prime}\cong\operatorname{Aut}_KE$ .

The modern development of Galois Theory owes a great deal to Emil Artin. Although our treatment is ultimately due to Artin (via I. Kaplansky) his approach differs from the one given here in terms of emphasis.Artin's viewpoint is that the basic object is a given field $F$ together with a (finite) group $G$ of automorphisms of $F$ One then constructs the subfield $K$ of $F$ as the fixed field of $G$ (the proof that the subset of $F$ fixed elementwise by $G$ is a field is a minor variation of the proof of Theorem 2.3).

------------------------------------------------------------------

Theorem 2.15.(Artin) Let F bea field,G a group ofautomorphisms of F and K the fixed field ofG in F. Then F is Galois over K. If G is finite,then $F$ is a finite dimen sional Galois extension of K with Galois group G.

PROOF. In any case $G$ is a subgroup of $Aut_KF$ .If u e $F-K$ , then there must be aae $G$ such that $\sigma(u)\neq u$ .Therefore, the fixed field of $Aut_KF$ KF $:KF$ is $K$ ，whence $F$ is Galois over $K$ . If $G$ is finite, then Lemma 2.9 (with $H=1$ ， $J=G$ ）shows that $[F:K]=[1^{\prime}:G^{\prime}]\leq[G:1]=|G|$ . Consequently, $F$ is finite dimensional over $K$ whence $G=G^{\prime\prime}$ by Lemma 2.10(ii). Since $G^{\prime}=K$ (and hence $G^{\prime\prime}=K^{\prime}$ byhypothesis, we have $\mathrm{Aut}_KF=K^{\prime}=G^{\prime\prime}=G$ .

### APPENDIX: SYMMETRIC RATIONAL FUNCTIONS

Let $K$ be a field, $K[x_1,\ldots,x_n]$ the polynomial domain and. $K(x_1,\ldots,x_n)$ the field of rational functions (see the example preceding Theorem 1.5). Since $K(x_1,\ldots,x_n)$ is by definition the quotient field of $K[x_1,\ldots,x_n]$ ，we have $K[x_1,\ldots,x_n]\subset K(x_1,\ldots,x_n)$ (under the usual identificationof fwith $f/1_{K})$ .Let $S_n$ be the symmetric group on $n$ letters. $\dot{A}$ rational function $\varphi$ E $K(x_1,\ldots,x_n)$ is said to be symmetric in $x_1,\ldots,x_n$ over $K$ if for every $\sigma\varepsilon S_n$

$$\varphi(x_{1},x_{2},\ldots,x_{n})=\varphi(x_{\sigma(1)},x_{\sigma(2)},\ldots,x_{\sigma(n)}).$$

Trivially every constant polynomial is a symmetric function. If $n=4$ , then the polynomials $f_{1}=x_{1}+x_{2}+x_{3}+x_{4}$, $f_{2}=\:x_{1}x_{2}+x_{1}x_{3}+x_{1}x_{4}+x_{2}x_{3}+\:x_{2}x_{4}+\:x_{3}x_{4}$, $f_{3}=x_{1}x_{2}x_{3}+x_{1}x_{2}x_{4}+x_{1}x_{3}x_{4}+x_{2}x_{3}x_{4}$ and $f_{4}=x_{1}x_{2}x_{3}x_{4}$ are all symmetric functions. More generally the elementary symmetric functions in $x_1,\ldots,x_n$ over $K$ are defined to be the polynomials

$$\begin{aligned}
&\text{VITIINIUI} \\
& f_{1}=\:x_{1}+\:x_{2}+\cdots+\:x_{n}\:=\:\sum_{i=1}^{n}x_{i}; \\
&f_{2}=\sum_{1\leq i<j\leq n}x_{i}x_{j}; \\
&f_{3}=\sum_{1\leq i<j<k\leq n}x_{i}x_{j}x_{k}; \\
&f_{k}=\sum_{1\leq i_{1}<\ldots<i_{k}\leq n}x_{i_{1}}x_{i_{2}}\cdots x_{i_{k}}; \\
&f_{n}=x_{1}x_{2}\cdots x_{n}. \\
\end{aligned}$$

The verification that the $f_{2}$ are indeed symmetric follows from the fact that they are simply the coefficients of $y$ in the polynomial $g(y)$ E $K[x_1,\ldots,x_n][y]$ ,where

$$\begin{aligned}g(y)&=(y-x_{1})(y-x_{2})(y-x_{3})\cdots(y-x_{n})\\&=y^{n}-f_{1}y^{n-1}+f_{2}y^{n-2}-\cdots+(-1)^{n-1}f_{n-1}y+(-1)^{n}f_{n}.\end{aligned}$$

If $\sigma\varepsilon S_n$ , then the assignments $x_{i}|\mapsto x_{\sigma(i)}(i=1,2,\ldots,n)$ and

$$f(x_1,\ldots,x_n)/g(x_1,\ldots,x_n)|-f(x_{\sigma(1)},\ldots,x_{\sigma(n)})/g(x_{\sigma(1)},\ldots,x_{\sigma(n)})$$

1

------------------------------------------------------------------

define a $K$ -automorphism of the field $K(x_1,\ldots,x_n)$ which will also be denoted $\sigma$ (Exercise 16). The map $S_n\to\operatorname{Aut}_KK(x_1,\ldots,x_n)$ given by $\sigma\vdash\sigma$ is clearly a mono morphism of groups, whence $S_n$ may be considered to be a subgroup of theGalois group $\mathrm{Aut}_KK(x_1,\ldots,x_n)$ . Clearly, the fixed feld $E$ of $S_n$ in $K(x_1,\ldots,x_n)$ consists precisely of the symmetric functions; that is, the set of all symmetric functions is a subfield of $K(x_1,\ldots,x_n)$ containing $K$ .Therefore, by Artin's Theorem 2.15 $K(x_1,\ldots,x_n)$ is a Galois extension of $E$ with Galois group $S_n$ and dimension $|S_n|$ $=n!$

Proposition 2.16. If G is a finite group, then there exists a Galois field extension with Galois group isomorphic to G

PROOF. Cayley's Theorem 11.4.6 states that for $n=|G|$ ， $G$ is isomorphic to a subgroup of $S_n$ (also denoted $G$ ).Let $K$ be any field and $E$ the subfield of symmetric rational functions in $K(x_1,\ldots,x_n)$ The discussion preceding the theorem shows that $K(x_1,\ldots,x_n)$ is a Galois extension of $E$ with Galois group $S_n$ . The proof of the Fundamental Theorem 2.5 shows that $K(x_1,\ldots,x_n)$ is a Galois extension of the fixed field $E_{\mathrm{l}}$ of $G$ such that $\mathrm{Aut}_{E_1}K(x_1,\ldots,x_n)=G$ .■

Theremainder of this appendix(which will beused onlyin the appendix to Section 9) is devoted to proving two classical theorems about symmetric functions Throughout this discussion $n$ is a positive integer, $K$ an arbitrary feld, $E$ the subfield of symmetric rational functions in $K(x_1,\ldots,x_n)$ and $f_{1},\ldots,f_{n}\in E$ the elementary symmetric functions in $x_1,\ldots,x_n$ over $K$ . We have a tower of fields:

$$K\subset K(f_1,\ldots,f_n)\subset E\subset K(x_1,\ldots,x_n).$$

 In Theorem 2.18 we shall show that $E=K(f_{1},\ldots,f_{n})$

If $u_1,\ldots,u_r\in K(x_1,\ldots,x_n)$ , then every element of $K(u_{1},\ldots,u_{r})$ is of the form $g(u_{1},\ldots,u_{r})/h(u_{1},\ldots,u_{r})$ with $g.$ he $K[x_1,\ldots,x_r]$ by Theorem 1.3. Consequently an element of $K(u_{1},\ldots,u_{r})$ [resp. $K[u_{1},\ldots,u_{r}]]$ is usually called a rational function [resp. polynomial] in $u_1,\ldots,u_r$ over $K$ . Thus the statement $E=K(f_{1},\ldots,f_{n})$ may berephrased as:everyrational symmetric function is infact a rational function of the elementary symmetric functions $f_1,\ldots,f_n$ over $K$ .In order to prove that $E=K(f_{1},\ldots,f_{n})$ weneed

Lemma 2.17. Let K be a field, $\mathbf{f}_1,\ldots,\mathbf{f}_n$ the elementary symmetric functions in $\mathbf{x}_1,\ldots,\mathbf{x}_n$ Xn $x_n$ over K and k an integer with $1\leq k\leq n-1.Ifh_{1},\ldots,h_{k}\varepsilon K[x_{1},\ldots,x_{n}]$ hk e K[x1, ... , Xn] $\mathbf{h} _{\mathrm{k} }\varepsilon \mathbf{K} [ \mathbf{x} _{\mathrm{l} }, \ldots , \mathbf{x} _{\mathrm{n} }]$ are the elementary symmetric functions in $\mathbf{x}_{\mathrm{I}},\ldots,\mathbf{x}_{\mathrm{k}}$ Xk $x_k$ , then each. $h_{j}$ can be written as a polynomial over K in fi,f2 $f_{1},f_{2}$, $\mathbf{f}_{1},\mathbf{f}_{2},\ldots,\mathbf{f}_{n}$ and $\mathbf{x}_{k+1},\mathbf{x}_{k+2},\ldots,\mathbf{x}_{\mathrm{n}}$

SKETCH OF PROOF.The theorem is true when $k=n-1$ since in that case $h_{1}=f_{1}-x_{n}$ and $h_{j}=f_{i}-h_{j-1}x_{n}$ $(2\leq j\leq n)$ . Complete the proof by induction on $k$ in reverse order: assume that the theorem is true when. $k$ = $r+ 1$ and $r+1\leq n-1$ .Let $g_{1}.$ ..·， $g_{r+1}$ be the elementary symmetric functionsin X1,..., $x_{1},\ldots,x_{r+1}$ $x_{r+1}$ $x_{1},\ldots,x_{r+1}$and$h_1,\ldots,h_r$ $h_{1}.$ $h_1,\ldots,h_r$ ....,h, the elementary symmetric functions in $x_1,\ldots,x_r$ .Since $h_{1}=g_{1}-x_{r+1}$ and $h_{j}=g_{j}-h_{j-1}x_{r+1}\left(2\leq j\leq r\right)$ $(2\leq j\leq r)$ $(2\leq j\leq r)$ it follows that the theorem is alsc true for $k=r$

------------------------------------------------------------------

Theorem 2.18.If K is a field, E the subfield of all symmetric rational functions in $\mathbf{K}(\mathbf{x}_1,\ldots,\mathbf{x}_n)$ and $f_{1}$ ..... $f_n$ the elementary symmetric functions, then. $\mathbf{E}=\mathbf{K}(\mathbf{f}_{1},\ldots,\mathbf{f}_{\mathrm{n}})$

SKETCH OF PROOF. Since $[K(x_{1},\ldots,x_{n}):E]=n!$ and $K(f_1,\ldots,f_n)\subset E\subset$ $K(x_1,\ldots,x_n)$ , it suffices by Theorem 1.2 to show that $[K(x_1,\ldots,x_n):K(f_1,\ldots,f_n)]$ $\leq n!$ . Let $F=K(f_1,\ldots,f_n)$ and consider the tower of fields:

$$F\subset F(x_n)\subset F(x_{n-1},x_n)\subset\cdots\subset F(x_2,\ldots,x_n)\subset F(x_1,\ldots,x_n)=K(x_1,\ldots,x_n).$$

Since $F(x_{k},x_{k+1},\ldots,x_{n})=F(x_{k+1},\ldots,x_{n})(x_{k})$ , it suffices by Theorems 1.2 and 1.6 to show that $x_n$ is algebraic over $F$ of degree $\leq n$ and for each $k<n,x_k$ is algebraic of degree $\leq k$ over $F(x_{k+1},\ldots,x_n)$ .To do this, let $g_n(y)\in F[y]$ be the polynomia

$$g_{n}(y)=(y-x_{1})(y-x_{2})\cdots(y-x_{n})=y^{n}-f_{1}y^{n-1}+\cdots+(-1)^{n}f_{n}.$$

Since $g_{n}\in F[y]$ has degree $n$ and $x_n$ is a root of gn $g_n$ $g_n,x_n$ Xn $X_n$ is algebraic of degree at most $n$ over $F=K(f_{1},\ldots,f_{n})$ by Theorem 1.6. Now for each $k$ $(1\leq k<n)$ define amonic polynomial:

$$g_{k}(y)=g_{n}(y)/(y-x_{k+1})\cdots(y-x_{n})=(y-x_{1})(y-x_{2})\cdots(y-x_{k}).$$

Clearly each $g_k(y)$ has degree $k$ $x_k$ is a root of $g_k(y)$ and the coeffcients of $g_k(y)$ are precisely the elementary symmetric functions in $x_{1},\ldots,x_{k}$ .By Lemma 2.17 each $g_k(y)$ lies in $F(x_{k+1},\ldots,x_n)[y]$, whence $x_k$ is algebraic of degree at most $k$ over $F(x_{k+1},\ldots,x_{n})$

We shall nowprove an analogue of Theorem 2.18forsymmetric polynomial functions, namely: every symmetric polynomial in $x_1,\ldots,x_n$ Xn $x_n$ over $K$ is in fact a polynomial in the elementary symmetric functions $f_{1},\ldots,f_{n}$ over $K$ .In other words, every symmetric polynomial in $K[x_1,\ldots,x_n]$ lies in $K[f_1,\ldots,f_n]$ . First we need

Lemma 2.19.Let K be afield and E the subfieldofall symmetric rational functions in $\mathbf{K}(\mathbf{x}_1,\ldots,\mathbf{x}_n)$ . Then the set. $\mathbf{X}=\left\{\mathbf{x}_{1}^{\mathrm{i}_{1}}\mathbf{x}_{2}^{\mathrm{i}_{2}}\cdots\mathbf{x}_{\mathrm{n}}^{\mathrm{i}_{\mathrm{n}}}\mid0\leq\mathbf{i}_{\mathrm{k}}<\mathbf{k}\right.$ for each k } is a basis of. $\mathbf{K}(\mathbf{x}_{\mathrm{l}},\ldots,\mathbf{x}_{\mathrm{n}})$ overE

SKETCH OF PROOF. Since $[K(x_1,\ldots,x_n):E]=n!$ and $|X|=n!$ , it suffices to show that $X$ spans $K(x_1,\ldots,x_n)$ (see Theorem IV.2.5). Consider the tower of fields $E\subset E(x_n)\subset E(x_{n-1},x_n)\subset\cdots\subset E(x_1,\ldots,x_n)=K(x_1,\ldots,x_n)$ .Since $x_n$ is algebraic of degree $\leq n$ over $E$ (by the proof of Theorem 2.18), the set $\{x_n^j\mid0\leq j<n\}$ spans $E(x_n)$ over $E$ (Theorem 1.6). Since $E(x_{n-1},x_{n})=E(x_{n})(x_{n-1})$ and $x_{n-1}$ is algebraic of degree $\leq n-1$ over $E(x_n)$ , the set $\left\{x_{n-1}^{i}\mid0\leq i<n-1\right\}$ spans $E(x_{n-1},x_n)$ over $E(x_n)$ .The argument in the second paragraph of the proof of Theorem IV.2.16 shows that the set $\left\{x_{n-1}^{i}x_{n}^{j}\mid0\leq i<n-1;0\leq j<n\right\}$ spans $E(x_{n-1},x_{n})$ over $E$ . This is the frst step in an inductive proof, which is completed by similar arguments. 

Proposition 2.20.Ler K be a field and let $\mathbf{f}_{1},\ldots,\mathbf{f}_{n}$ be the elementary symmetric. functions in. $\mathbf{K}(\mathbf{x}_{1},\ldots,\mathbf{x}_{n})$

------------------------------------------------------------------

(i)Ecery polynomial in $\mathbf{K}[\mathbf{x}_{1},\ldots,\mathbf{x}_{n}]$ can be written uniquely as a linear combination of the n!elements $x_{1}^{\mathrm{i}_{1}}\mathbf{x}_{2}^{\mathrm{i}_{2}}\cdots\mathbf{x}_{\mathrm{n}}^{\mathrm{i}_{\mathrm{n}}}$ $( 0\leq i_k<$k for each $k$ ) with coefficients in $\mathbf{K}[\mathbf{f}_{1},\ldots,\mathbf{f}_{n}]$ (i) every symmetric polynomial in $\mathbf{K}[\mathbf{x}_{1},\ldots,\mathbf{x}_{n}]$ lies in $\mathbf{K}[\mathbf{f}_1,\ldots,\mathbf{f}_n].$

PROOF. Let gk $g_k$ $g_k(y)$ $( k$ = 1, $\ldots , n)$ be as in the proof of Theorem 2.18. As noted there the coefficients of $g_k(y)$ are polynomials (over $K$ )in $f_{\mathrm{l}},\ldots,f_{n}$ and $x_{k+1},\ldots,x_n$ Since $g_k$ is monic of degree $k$ and $g_{k}(x_{k})=0$ $x_k^k$ can be expressed as a polynomial over $K$ in $f_{1},\ldots,f_{n}$ f,...,f $f_1, \ldots , f_n$, $x_{k+ 1}, \ldots , x_n$ and $x_k^i(i\leq k-1)$ . If we proceed step by step beginning with $k=1$ and substitute this expression for $x_k^k$ in a polynomial $h\in K[x_1,\ldots,x_n]$ , the result is a polynomial in $f_1, \ldots , f_n$, $x_1, \ldots$, $x_n$ in which the highest exponent of any $x_k$ is $k-1$ . In other words $h$ is a linear combination of the $n!$ elements $x_{1}^{i_{1}}x^{i_{2}}\ldots x_{n}^{i_{n}}$ $(i_k<k$ for each $k$ ）with coefficients in $K[f_{1},\ldots,f_{n}]$ . Furthermore these coefficient polynomials are uniquely determined since

$$\{{x_1}^{i_1}\cdots{x_n}^{i_n}\mid0\leq i_k<k\quad\text{for each }k\}$$

is linearly independent over $E=K(f_1,\ldots,f_n)$ by Lemma 2.19. This proves (i) and also implies that if a polynomial $h\in K[x_1,\ldots,x_n]$ is a linear combination of the $x_{1}^{i_{1}}\cdots x_{n}^{i_{n}}\left(i_{k}<k\right)$ (ik<k) $(i_{k}<k)$ with coefficients in $K(f_1,\ldots,f_n)$ , then the coeffcients are in fact polynomials in $K[f_1,\ldots,f_n]$ . In particular, if $h$ is a symmetric polynomial (that is, $h_{\varepsilon}E=K(f_{1},\ldots,f_{n}))$ , then $h=hx_{1}^{0}x_{2}^{0}\cdots x_{n}^{0}$ necessarily lies in $K[f_1,\ldots,f_n]$ . This proves (ii).

## EXERCISES

Note: Unless stated otherwise $F$ is always an extension field of the field $K$ and $E$ is an intermediate field of the extension

1. (a) If $F$ is a feld and $\sigma:F\to F$ a (ring) homomorphism, then $\sigma=0$ or $\sigma$ is a monomorphism. If $\sigma\neq0$ ,then $\sigma(1_F)=1_F$ (b) The set Aut $F$ of all feld automorphisms $F\to F$ forms a group under the operation of composition of functions. (c) $Aut_KF$ , the set of all $K$ -automorphisms of $F$ is a subgroup of Aut $F$

2. AutgR is the identity group. [Hint: Since every positive element of R is a square. it follows that an automorphism of R sends positives to positives and hence that it preserves the order in R. Trap a given real number between suitable rational numbers.]

3. If $0\leq d\varepsilon\mathbf{Q}$ , then $\mathrm{Aut}_{0}$Q($\sqrt d)$ is the identity or is isomorphic to $Z_2$

4. What is the Galois group of $\mathbf{Q}(\sqrt{2},\sqrt{3},\sqrt{5})$ over Q?

5. (a) If $0\leq d\varepsilon\mathbf{Q}$ then $Q(\bar{\surd d})$ is Galois over $\mathbf{Q}$ (b) $C$ is Galois over $R$

6. Let $f/g\in K(x)$ with $f/g\notin K$ and $f,g$ relatively prime in $K[x]$ and consider the ex tension of $K$ by $K(x)$ (a) $x$ is algebraic over $K(f/g)$ and $[K(x):K(f/g)]=\max$ (deg f,deg g)

[Hint: $x$ is aroot of the nonzeropolynomial $\varphi(y)=(f/g)g(y)-f(y)\varepsilon K(f/g)[y];$ show that 4 has degree max (deg $f$,deg $g$ 0.Show that $\varphi$ is irreducible as follows

------------------------------------------------------------------

Since $f/g$ is transcendental over $K$ (why?) we may for convenience replace $K(f/g)$ by $K(z)$ $z$ an indeterminate) and consider $\varphi=zg(y)-f(y)$ E $K(z)[y]$ .By Lemma $\textbf{III. 6. 13 }\varphi$ \$ $\varphi$ is irreducible in $K(z)[y]$ provided it is irreducible in $K[z][y]$ The truth of this latter condition follows from the fact that $\varphi$ is linear in $z$ and $f,g$ are relatively prime.] (b) If $E\neq K$ is an intermediate feld, then $[K(x):E]$ is finite.

(c) The assignment $x|\mapsto f/g$ induces a homomorphism $\sigma:K(x)\to K(x)$ such

that $\varphi(x)/\psi(x)\vdash\varphi(f/g)/\psi(f/g)$ $\sigma$ isa $K$ automorphism of. $K(x)$ ifandonly if max(deg $f$,deg $g)=1$ (d) $\mathrm{Aut}_{K}K(x)$ consists of all those automorphisms induced (as in (c) by the

assignment

$$x\mapsto(ax+b)/(cx+d),$$

where $a,b,c,d\varepsilon K$ K $K$ and a $d-bc\neq0$

7. Let $G$ be the subset of $\mathrm{Aut}_{K}K(x)$ consisting of the three automorphisms induced (as in 6 (c)) by $x\models x,x\mapsto1_{K}/(1_{K}-x),x\mapsto(x-1_{K})/x$ . Then $G$ is a subgroup of $\mathbf{Aut}_{K}K(x)$ . Determine the fixed field of $G$

8. Assume char $K=0$ and let $G$ be the subgroup of $\mathbf{Aut}_{K}K(x)$ that is generatedby the automorphism induced by $x|\mapsto x+1_{K}$ . Then $G$ is an infinite cyclic group Determine the fixed field $E$ of $G$ .What is $[K(x):E]?$

9.(a) If $K$ is aninfinite field, then $K(x)$ is Galois over $K$ . [Hint: If $K(x)$ is not Galois over $K$ , then $K(x)$ is finite dimensional over the fixed field $E$ of $\mathrm{Aut}_{K}K(x)$ by Exercise 6(b). But $\mathrm{Aut}_EK(x)=\mathrm{Aut}_KK(x)$ is infinite by Exercise 6(d),which contradicts Lemma 2.8.] (b) If $K$ is finite, then $K(x)$ is nor Galois over $K$ . [Hinr: If $K(x)$ were Galois over

$K$ , then $\mathrm{Aut}_{\kappa}K(x)$ would be infnite by Lemma 2.9. But $\mathrm{Aut}_{\kappa}K(x)$ is finite by Exercise 6(d).]

10.If $K$ is an infinite field, then the only closed subgroups of $\mathrm{Aut}_{K}K(x)$ are itself and its finite subgroups. [Hinr: see Exercises 6(b) and 9.]

11. In the extension of $\mathbf{Q}$ by $\mathbf{Q}(x).$ the intermediate field $\mathbf{Q}(x^2)$ is closed, but $\mathbf{Q}(x^3)$ is not.

12.If $E$ is an intermediate field of the extension such that $E$ is Galois over $K$ $F$ is Galois over $E$ , and every $\sigma\varepsilon Aut_{K}E$ is extendible to $F$ , then $F$ is Galois over $K$

13. In the extension of an infinite field $K$ by $K(x,y)$ , the intermediate field $K(x)$ is Galois over $K$ , but not stable (relative to $K(x,y)$ and $K$ ). [See Exercise 9; compare this result with Lemma 2.13.]

14. Let $F$ be a finite dimensional Galois extension of $K$ and let $L$ and $M$ be two inter mediate fields. (a) $\mathrm{Aut}_{LM}F=\mathrm{Aut}_LF\cap\mathrm{Aut}_MF;$

(b) $\mathrm{Aut}_{L\cap M}F=\mathrm{~Aut}_LF\vee\mathrm{~Aut}_MF;$ (c)What conclusion can be drawn if $\mathrm{Aut}_LF\cap\mathrm{Aut}_MF=1?$

15.If $F$ is a finite dimensional Galois extension of $K$ and $E$ is an intermediate field, then there is a unique smallest field $L$ such that $E\subset L\subset F$ and $L$ is Galois over $K$ ; furthermore

------------------------------------------------------------------

$$\mathrm{Aut}_{L}F=\bigcap_{\sigma}\sigma(\mathrm{Aut}_{E}F)\sigma^{-1},$$

where $\sigma$ runs over $Aut_KF$

16. If $\sigma\varepsilon S_n$ , then the map $K(x_1,\ldots,x_n)\to K(x_1,\ldots,x_n)$ givenby

$$\frac{f(x_1,\ldots,x_n)}{g(x_1,\ldots,x_n)}\mapsto\frac{f(x_{\sigma(1)},\ldots,x_{\sigma(n)})}{g(x_{\sigma(1)},\ldots,x_{\sigma(n)})}$$

is a $K$ -automorphism of $K(x_1,\ldots,x_n)$

## 3. SPLITTING FIELDS, ALGEBRAIC CLOSURE AND NORMALITY

We turn now to the problem of identifying and/or constructing Galois exten sions. Splitting fields, which constitute the principal theme of this section, will enable us to do this. We first develop the basic properties of splitting fields and algebraic closures (a special case of splitting fields). Then algebraic Galois extensions are characterized in terms that do not explicitly mention the Galois group (Theorem 3.11), and the Fundamental Theorem is extended to the infinite dimensional algebraic case (Theorem 3.12). Finally normality and other characterizations of splitting felds are discussed. The so-called fundamental theorem of algebra (every polynomial equation over the complex numbers has a solution) is proved in the appendix Let $F$ be a field and $f\varepsilon F[x]$ a polynomial of positive degree. $f$ is said to split over $F$

(or to split in $F[x])$ if $f$ can be written as a product of linear factors in $F[x]$ ; that is, $f=u_{0}(x-u_{1})(x-u_{2})\cdots(x-u_{n})$ with $u_i\in F$

Definition 3.1. Ler K be a field and f e $K[x]$ a polynomial of positive degree. An extension field F of K is said to be a splitting field over K of the polynomial f iff splits in $F[x]$ and $\mathbf{F}=\mathbf{K}(\mathbf{u}_{1},\ldots,\mathbf{u}_{n})$ where $\mathbf{u}_1,\ldots,\mathbf{u}_n$ Un $u_{\mathrm{n}}$ are the roors off in F. LetSbeaset ofpolynomials of positive degree in $K[x]$ . An extension field F ofK is

said to be a splitting field over K of the set $S$ of polynomials if erery polynomial in S splits in $F[x]$ and F is generated over K by the roors of all the polynomials in S.

EXAMPLES. The only roots of $x^2-2$ over $\mathbf{Q}$ are $v^{/\overline{2}}$ and $-\sqrt{2}$ and $x^2-2$ $=(x-\sqrt{2})(x+\sqrt{2})$ . Therefore $\mathbf{Q}(\sqrt{2})=\mathbf{Q}(\sqrt{2},-\sqrt{2})$ is a splitting feld of $x^2-2$ over Q. Similarly $\mathbf{C}$ is a splitting field of $x^2+1$ over R. However, if $u$ is a root of an irreducible $f_{\varepsilon}K[x],K(u)$ need not be a splitting field of $f.$ For instance if $u$ is the real cube root of 2 (the others being complex), then $\mathbf{Q}(u)\subset\mathbf{R}$ ，whence $\mathbf{Q}(u)$ is not a splitting field of $x^3-2$ over $Q$

REMARKS. If $F$ is a splitting field of $S$ over $K.$ then $F=K(X)$ , where $X$ is the set of all roots of polynomials in the subset $S$ of $K[x]$ . Theorem 1.12 immediately implies that $F$ is algebraic over $K$ (and finite dimensional if $S$ , and hence $X$ , is a finite set). Note that if $S$ is finite, say $S= \{$ $f_{1}, f_{2}, \ldots , f_{n}\}$ , then a splitting field of $S$ coincides with a splitting field of the single polynomial $f=f_{1}f_{2}\cdots f_{n}$ (Exercise 1). This fact will be used frequently in the sequel without explicit mention. Thus the splitting feld of a set $S$ of polynomials will bechiefy of interest when $S$ either consists of a single polynomial or is infnite. It will turn out that every [finite dimensional

------------------------------------------------------------------

algebraic Galois extension is in fact a particular kind of splitting field of a [finite] se of polynomials.

The obvious question to be answered next is whether every set of polynomials has a splitting field. In the case of a single polynomial (or equivalently a finite set of polynomials), the answer is relatively easy.

Theorem 3.2. If K is a fieldandf e $K[x]$ has degree $n\geq1$ ,then there existsa splitting feldF off with $[\mathbf{F}:\mathbf{K}]\leq\mathbf{n}$

SKETCH OF PROOF. Use induction on $n=\deg f$ If $n=1$ or if $f$ splits over $K.$ then $F=K$ is a splitting feld. If $n>1$ and fdoes not split over $K$ ,let $g\varepsilon K[x]$ be an irreducible factor of fof degree greater than one. By Theorem 1.10 there is a simple extension field $K(u)$ of $K$ such that $u$ is a root of $g$ and $[K(u):K]=\deg g>1$ Then by Theorem II1. 6.6, $f=(x-u)h$ with $h\in K(u)[x]$ of degree $n-1$ . By induction there exists a splitting field $F$ of $h$ over $K(u)$ of dimension at most $(n-1)$ !Show that $F$ is a splitting field of fover $K$ (Exercise 3) of dimension $[F:K]=[F:K(u)][K(u):K]$ ≤(n - 1)! $\leq(n-1)!$ $\leq(n-1)!\left(\deg g\right)\leq n!$

Proving the existence of a splitting field of an infinite set of polynomials is considerably more difficult.We approach the proof obliquely by introducing a special case of such a splitting field (Theorem 3.4) which is of great importance in its own right.

Note:Thereader who is interested only in splitting fields of a single polynomial (i.e.finite dimensional splitting fields) should skip to Theorem 3.8. Theorem 3.12 should be omitted and Theorems 3.8-3.16 read in the finite dimensional case. The proof of each of these results is either divided in two cases (finite and infinite dimensional) or is directly applicable to both cases. The only exception is the proof of $(\mathrm{ii})\Rightarrow(\mathrm{i})$ in Theorem 3.14; an alternate proof is suggested in Exercise 25.

Theorem 3.3. The following conditions on a field F are eyuivalent.

(i) Every nonconstant polynomial f e F[x] has a root in F;. (ii) every nonconstant polynomial f e F[x] splits over F; (iii) every irreducible polynomial in F[x] has degree one;. (iv) there is no algebraic extension field of F (except F itself);. (v) there exists a subfield K ofF such that F is algebraic over K and every polynomial in K[x] splits in F[x].

PROOF. Exercise; see Section I1. 6 and Theorems 1.6, 1.10, 1.12 and 1.13. 

A field that satisfies the equivalent conditions of Theorem 3.3 is said to be algebraically closed. For example, we shall show that the field C of complex numbers is algebraically closed (Theorem 3.19).

Theorem 3.4. If F is an extension field of K, then the following conditions are eyuivalent

------------------------------------------------------------------

(i) F is algebraic over K and F is algebraically closed; (ii) F is a splitting field over K of the set of all [irreducible] polynomials in $K[x]$

PROOF. Exercise; also see Exercises 9, 10.

An extension field $F$ of a field $K$ that satisfies the equivalent conditions of Theorem 3.4 is called an algebraic closure of $K$ . For example, $\mathbf{C}=\mathbf{R}(i)$ is an algebraic closure of R. Clearly, if $F$ is an algebraic closure of $K$ and $S$ is any set of polynomials in $K[x]$, then the subfield $E$ of $F$ generated by $K$ and all roots of polynomials in $S$ is a splitting field of $S$ over $K$ by Theorems 3.3 and 3.4. Thus the existence of arbitrary splitting felds over a field $K$ is equivalent to the existence of an algebraic closure of $K$ The chief difficulty in proving that every field $K$ has an algebraic closure is set-

theoretic rather than algebraic. The basic idea is to apply Zorn's Lemma to a suitably chosen set of algebraic extension fields of $K$ 2To do this we need

Lemma 3.5. IfF is an algebraic extension field of K, then $|F|\leq\mathbf{x}_{\mathrm{olK}|}$

SKETCH OF PROOF. Let $T$ be the set of monic polynomials of positive degree in $K[x].$ We first show that $|T|=\aleph_{0|K|}.$ For each n E $N^{*}$ let $T_n$ be the set of all polynomials in $T$ of degree $n$ . Then $|T_{n}|=|K^{n}|$ ，where $K^{n}=K\times K\times\cdots K$ (n factors), since every polynomial $f=x^{n}+a_{n-1}x^{n-1}+\cdots+a_{0}\varepsilon T_{n}$ is completely determined by its $n$ coefficients $a_{0},a_{1},\ldots,a_{n-1}\in K.$ an-1 E K $a_{n-1}\in K$ .For each $n\in\mathbb{N}^*$ let $f_n:T_n\to K^n$ be a bijection. Since the sets $T_{n}$ [resp. $K^n]$ are mutually disjoint, the map f :T = U Tn -→ U K, given by $f(u)=f_{n}(u)$ for $u\in T_n$ Tn $T_n$ , is a well-defined bijection. $f:T=\bigcup_{n\in\mathbb{N}^{*}}T_{n}\rightarrow\bigcup_{n\not\in\mathbb{N}^{*}}K^{n}$ neN* neN* Therefore $|T|=|\cup\:K^{n}|=\aleph_{0}|K|$ by Introduction, Theorem 8.12(ii) neN*

Next we show that $|F|\leq|T|$ , which will complete the proof. For each irreducible $f\varepsilon T_{:}$ choose an ordering of the distinct roots of fin $F$ .Define a map $F\to T\times\mathbb{N}^*$ as follows. If a e $F$ then $a$ is algebraic over $K$ by hypothesis, and there exists a unique irreducible monic polynomial fe Twith $f(a)=0$ (Theorem 1.6). Assign to a e $F$ the pair $(f,i)\varepsilon T\times\mathbb{N}^{*}$ where $a$ is the ith root of fin the previously chosen ordering of the roots of $f$ in $F$ Verify that this map $F\to T\times\mathbb{N}^*$ is well defined and injective Since $T$ is infinite, $|F|\leq|T\times\mathbf{N}^{*}|=|T||\mathbf{N}^{*}|=|T|\mathbf{X}_{0}=|T|$ byTheorem8.11 of the Introduction.

Theorem 3.6. Every field K has an algebraic closure. Any two algebraic closures of K are K-isomorphic.

SKETCH OF PROOF. Choose a set $S$ such that $\aleph_0|K|<|S|$ (this can always be done by Theorem 8.5 of the Introduction). Since $|K|\leq\aleph_0|K|$ (Introduction, Theorem 8.11) there is by Definition 8.4 of the Introduction an injective map $\theta:K_{-\rightarrow S}$ . Consequently we may assume $K\subset S$ (if not, replace $S$ by the union of $S-\operatorname{Im}\theta$ and $K$ )

------------------------------------------------------------------

T

Let S be the class of all fields $E$ such that $E$ is a subset of $S$ and $E$ is an algebraic extension field of $K$ .Such afield $E$ is completely determined by the subset $E$ of $S$ and the binary operations of addition and multiplication in $E$ . Now addition [resp. multiplication] is a function $\varphi:E\times E\to E$ [resp. $\psi:E\times E\to E$ . Hence $\varphi$ [resp. $\psi]$ may beidentified with itsgraph,a certain subset of $E\times E\times E\subset S\times S\times S$ (see Introduction, Section 4). Consequently, there is an injective map $\tau$ from S into the set $P$ of all subsets of the set $S\times(S\times S\times S)\times(S\times S\times S)$ given by $E\vdash(E,\varphi,\psi)$ Now Im $\tau$ is actually a set since Im $\tau$ is a subclass of the set $P$ .Since S is the image of $Im\tau$ 7 $\tau$ under the function $\tau^{-1}$ 7-1 $\tau^{-1}:\operatorname{Im}\tau\to\operatorname{S}$ , the axioms of set theory guarantee that S is in fact a set. Note that $S\neq\emptyset$ since $K\varepsilon S$ . Partially order the set S by defining $E_{1}\leq E_{2}$ if and

only if $E_2$ is an extension field of $E_{\mathrm{i}}$ .Verify that every chain inS has anupperbound (the union of the fields in the chain will do). Therefore by Zorn's Lemma there exists a maximal element $F$ of s. We claim that $F$ is algebraically closed. If not, then some $f\varepsilon F[x]$ does not split

over $F$ .Thus there is a proper algebraic extension $F_{0}=F(u)$ of $F$ ,where $u$ is aroot of $f$ which does not lie in $F$ (Theorem 1.10). Furthermore $F_0$ is an algebraic extension of $K$ by Theorem 1.13. Therefore, $|F_0-F|\leq|F_0|\leq\mathbf{x}_0|K|<|S|$ by Lemma 3.5. Since $|F|\leq|F_0|<|S|$ and $|S|=|(S-F)\cup F|=|S-F|+|F|$ , we must have $|S|=|S-F|$ by Theorem 8.10 of the Introduction. Thus $|F_{0}-F|<|S-F|$ and the identity map on $F$ may be extended to an injective map of sets $\zeta:F_0\to S$ Then $F_{\mathrm{i}}=$Im$\zeta$ maybe made into a field by defining $\zeta(a)+\zeta(b)=\zeta(a+b)$ and $\zeta(a)\zeta(b)=\zeta(ab)$ Clearly $F_{1}$ is an extension field of $F$ F $F,F_{1}\subset S$ and $\zeta:F_0\to F_1$ is an $F$ -isomorphism of fields. Consequently, since $F_0$ is a proper algebraic extension of $F$ (and hence of $K$ ), so is $F_{1}$ This means that $F_{1}$ F $F_1\varepsilon S$ and $F<F_1$ ,which contradicts the maximality of $F$ . Therefore. $F$ is algebraically closed and algebraic over $K$ and hence an algebraic closure of $K$ The uniqueness statement of the theorem is proved in Corollary 3.9 below.

Corollary 3.7. IfK is a feld and S a set of polynomials (of positice degree) in $K[x]$, then there exists a splitting field ofS over K.

### PROOF. Exercise.

We turn now to the question of the uniqueness of splitting fields and algebraic closures. The answer will be an immediate consequence of the following result on the extendibility of isomorphisms (see Theorem 1.8 and the remarks preceding it).

Theorem 3.8. Let $\sigma:\mathbf{K}\to\mathbf{L}$ be an isomorphism of fields, $\mathbf{S}=\left\{\mathbf{f_{i}}\right\}$ a set of polynomials (of positive degree) in $K[x]$ ,and $\mathbf{S}^{\prime}=\{\sigma\mathbf{f}_{\mathrm{i}}\}$ the corresponding set of polynomials in L[x]. IfF is a splitting fieldof'S over K and M is a splitting field ofS' over L then $\sigma$ is extendible to an isomorphism $F\cong M$

SKETCH OF PROOF. Suppose first that $S$ consists of a single polynomial fe $K[x]$ and proceed by induction on $n=[F:K]$ If $n=1$ , then $F=K$ and $f$ splits over $K$ . This implies that $\sigma f$ splits over $L$ and hence that $L=M$ . Thus $\sigma$ itself is the desired isomorphism $F=K\overset{\sigma}{\operatorname*{\rightarrow}}L=M$ .If $n>1$ , then $f$ must have an irreducible factor $g$ of degree greater than 1. Let $u$ be a root of $g$ in $F$ . Then verify that $\sigma g$ is ir-

1

------------------------------------------------------------------

reducible in $L[x]$ . If $\upsilon$ is a root of $\sigma g$ in $M$ , then by Theorem $1.8\sigma$ extends to an iscmorphism $\tau:K(u)\cong L(v)$ with $\tau(u)=v$ . Since $[K(u):K]=\deg g>1$ (Theorem 1.6), we must have $[F:K(u)]<n$ (Theorem 1.2). Since $F$ is a splitting field of $f$ over $K(u)$ and $M$ is a splitting field of of over $L(v)$ (Exercise 2), the induction hypothesis implies that $\tau$ extends to an isomorphism $F\cong M$ If $S$ is arbitrary, let S consist of all triples $(E,N,\tau)$ ,where $E$ is anintermediate field

of $F$ and $K$ $N$ is anintermediate field of $M$ and $L$ ,and $\tau:E\to N$ is an isomorphism that extends $\sigma$ .Define $(E_1,N_1,\tau_1)\leq(E_2,N_2,\tau_2)$ if $E_{1}\subset E_{2}$ $N_1\subset N_2$ and $\tau_{2}\mid E_{1}=\tau_{1}$ Verify that S is a nonemptypartially ordered set in which every chainhas an upper bound in S. By Zorn's Lemma there is a maximal element $(F_0,M_0,\tau_0)$ of S. We claim that $F_0=F$ and $M_{0}=M$ ,so that $\tau_{\bullet}:F\cong M$ is the desired extension of $\sigma$ . If $F_0\neq F$ then some $f\varepsilon S$ does not split over $F_{0}$ . Since all the roots of $f$ lie in F $F$ $F,F$ F $F$ contains a splitting field $F_{1}$ of $f$ over $F_{\bullet}$ . Similarly, $M$ contains a splitting field $M_1$ of $\tau_{0}f=\sigma f$ over $M_0$ .The first part of the proof shows that $\tau_0$ can be extended to an isomorphism $\tau_{1}:F_{1}\cong M_{1}$ . But this means that $(F_1,M_1,\tau_1)\in S$ and $(F_0,M_0,\tau_0)<(F_1,M_1,\tau_1)$ which contradicts the maximality of $(F_0,M_0,\tau_0)$ .A similar argument using $\tau_{0}^{-1}$ worksif $M_0\neq M$ .■

Corollary 3.9. Let K be a field and S a set of polynomials (of positive degree) in $K[x]$ Then any two splitting fields of S over K are K-isomorphic.In particular,any two algehraic closures of K are K-isomorphic.

SKETCH OF PROOF. Apply Theorem 3.8 with $\sigma=1_{\kappa}$ . The last statement is then an immediate consequence of Theorem 3.4(i).

In order to characterize Galois extensions in terms of splitting fields, we must first consider a phenomenon that occurs only in the case of fields of nonzero characteristic. Recall that if $K$ is any field, $f$ is a nonzero polynomial in $K[x]$, and $c$ is a root of $f$, then $f=(x-c)^mg(x)$ where $g(c)\neq0$ and $m$ is a uniquely determined. positive integer. The element $c$ is a simple or multiple root of faccording as. $m=1$ or $m>1$ (see p. 161).

Definition 3.10. Ler K be a field and f e $K[x]$ an irreducible polynomial. The polynomial f is said to be separable if in some splitting fieldof f over K every root of f is a simple root. IfF is an extension feld ofK and u e F is algebraic over K,then u is said to be

separable orer K prorided its irreducible polynomial is separable.Ifevery element ofF is separable ocer K, then F is said to be a separable extension of K.

REMARKS.(i) In view of Corollary 3.9 it is clear that a separable polynomial $f\varepsilon K[x]$ has no multiple roots in any splitting field of fover K. (i) Theorem Ill.6.10 shows that an irreducible polynomial in $K[x]$ is separable if andonly if its derivative is nonzero, whence every irreducible polynomial is separable if char $K=0$ (Exercise I11.6.3). Hence every algebraic extension field ofa field ofcharacteristic O is separable. (ii) Separability is defined here only for irreducible polynomials. (iv) According to Definition 3.10 a separable extension field of. $K$ is necessarily algebraic over $K$ There

------------------------------------------------------------------

T

is a definition of separability for possibly nonalgebraic extension fields that agrees with this one in the algebraic case (Section VI.2). Throughout this chapter, however, we shall use only Definition 3.10.

EXAMPLES. $x^{2}+1\varepsilon\mathbf{Q}[x]$ is separable since $x^{2}+1=(x+i)(x-i)$ in $\mathbf{C}[x]$ On the other hand, the polynomial $x^2+1$ over $Z_2$ has no simple roots; in fact it is not even irreducible since $x^{2}+1=(x+1)^{2}$ in $Z_2[x]$

Theorem 3.11.If F is an extension field ofK,then the following statements are equivalent.

(i) F is algebraic and Galois over K;

(i)F is separable overK andF isa splirringfield overK ofasetSof polynomials in $K[x]$ (ii)F is a splittingfield overK of a ser T of separable polynomials in $K[x]$

REMARKS. If $F$ is finite dimensional over $K$ , then statements (ii) and (ii) can be slightly sharpened. In particular (ii) may be replaced by: $F$ is a splitting field over $K$ of a polynomial $f\varepsilon K[x]$ whose irreducible factors are separable (Exercise 13).

PROOF OF 3.11. $\mathrm{(i)\Rightarrow(ii)}$ and (ii). If $u\varepsilon F$ has irreducible polynomial $f$, then the first part of the proof of Lemma 2.13(with $E=F$ ) carries over verbatim and shows that $f$ splits in $F[x]$ into a product of distinct linear factors. Hence $u$ is separable over $K$ .Let $\{v_{i}\mid i\in I\}$ be a basis of $F$ over $K$ and for each i e I let $f_{i}\in K[x]$ be the irreducible polynomial of $\upsilon_{i}.$ The preceding remarks show that each $f_i$ is separable and splits in $F[x]$ . Therefore $F$ is a splitting field over $K$ of $S=\{\:f_{i}\mid i\in I\}$ $\Rightarrow$ = $(\mathrm{ii})\Rightarrow(\mathrm{iii})$ Let $f\varepsilon S$ and let $g\in K[x]$ be a monic irreducible factor of $f.$ Since $f$

splits in $F[x]$ $g$ must be the irreducible polynomial of some $u\varepsilon F$ .Since $F$ is separable over $K$ $g$ is necessarily separable. It follows that $F$ is a splitting field over $K$ of the set $T$ of separable polynomials consisting of all monic irreducible factors (in $K[x])$ of polynomials in $S$ (see Exercise 4).

$(\mathrm{iii})\Rightarrow(\mathrm{i})\:F$ $F$ F is algebraic over $K$ since any splitting field over $K$ is an algebraic extension. If $\iota\in F-K$ , then $u\in K(v_1,\ldots,v_n)$ with each $v_i$ a root of some $f_i$ f $f_i\varepsilon T$ by the definition of a splitting field and Theorem 1.3(vi). Thus $u\in E=K(u_1,\ldots,u_r)$ where the $u_i$ are all the roots of $f_{1},\ldots,f_{n}$ in $F$ Hence $[E:K]$ is finite by Theorem 1.12. Since each $f_{i}$ splits in $F,E$ E $E$ is a splitting field over $K$ of the finite set $\{f_1,\ldots,f_n\}$ or equivalently, of $f=f_{1}f_{2}\cdots f_{n}$ .Assume for now that the theorem is true in the finite dimensional case. Then $E$ is Galois over $K$ and hence there exists $\tau\in\mathrm{Aut}_{\kappa}E$ such that $\tau(u)\neq u$ Since $F$ is a splitting field of $T$ over $E$ (Exercise 2), $\tau$ extends to an automorphism $\sigma\varepsilon Aut_KF$ KF $\kappa F$ such that $\sigma(u)=\tau(u)\neq u$ by Theorem 3.8. Therefore, $u$ (which was an arbitrary element of $F-K)$ is not in the fixed field of $Aut_kF$ ; that is. $F$ is Galois over $K$ The argument in the preceding paragraph shows that we need only prove the

theorem when $[F:K]$ is finite.In this case there exist a finite number of polynomials $g_{1},\ldots,g_{t}\in T$ gteT $g_l\varepsilon T$ such that $F$ is a splitting feld of $\{g_1,\ldots,g_t\}$ over $K$ (otherwisea $F$ would be infinite dimensional over $K$ ). Furthermore $\mathrm{Aut}_{Ii}F$ is a finite group by Lemma 2.8. If $K_0$ is the fixed field of $Aut_KF$ KF $\kappa F$ , then $F$ is a Galois extension of $K_0$ with

1

------------------------------------------------------------------

$[F:K_0]=|\mathrm{Aut}_KF|$ by Artin's Theorem 2.15 and the Fundamental Theorem. Thus in order to show that $F$ is Galois over $K$ (that is, $K=K_{0}$ it suffices to show that $[F:K]=|\mathrm{Aut}_KF|$ We proceed by induction on $n=[F:K]$, with the case $n=1$ being trivial. If

$n>1$ , then one of the $g_i$ , say $g_1$ , has degree $s>1$ (otherwise all the roots of the $g_i$ lie in $K$ and $F=K$, 0.Letue $F$ be a root of $g_1$ ; then $[K(u):K]=\deg g_{1}=s$ by Theorem 1.6 and the number of distinct roots of $g_1$ is $s$ since $g_1$ is separable. The second paragraph of the proof of Lemma 2.8 (with $L=K$ $M=K(u)$ and $f=g_{1.}$ shows that there is an injective map from the set of all left cosets of $H=\mathrm{Aut}_{K(u)}F$ in $Aut_KF$ to the set of all roots of $g_1$ in $F.$ ，given by $\sigma H\vdash\sigma(u)$ . Therefore, $[\mathrm{Aut}_KF:H]\leq s.$ .Now if $\upsilon\varepsilon F$ is any other root of $g_1$ , there is an isomorphism $\tau:K(u)\cong K(v)$ with $\tau(u)=v$ and r $\mid K=1_{K}$ by Corollary 1.9. Since $F$ is a splitting field of $\{g_{1},\ldots,g_{t}\}$ over $K(u)$ and over $K(v)$ (Exercise 2), $\tau$ extends to an automorphism $\sigma\varepsilon Aut\kappa F$ with $\sigma(u)=v$ (Theorem 3.8). Therefore, every root of $g_1$ is the image of some coset of $H$ and $[\mathrm{Aut}_KF:H]=s.$ Furthermore, $F$ is a splitting field over $K(u)$ of the set of all irreducible factors $h_{i}$ (in $K(u)[x])$ of the polynomials $g_i$ (Exercise 4). Each $h_{j}$ is clearly separable since it divides some $g_i$ .Since $[F:K(u)]=n/s<n$ the induction hypothesis implies that $[F:K(u)]=|\mathrm{Aut}_{K(u)}F|=|H|$ . Therefore

$$[F:K]=[F:K(u)][K(u):K]=|H|s=|H|[\mathrm{Aut}_KF:H]=|\mathrm{Aut}_KF|$$

and the proof is complete. 

Theorem 3.12. (Generalized Fundamental Theorem) If F is an algebraic Galois extension field of K, then there is a one-to-one correspondence berween the set of all intermediate fields of the extension and the set of all closed subgroups of the Galois group $Aut_\mathrm{K}F$ (given by $\mathsf{E}\vdash\mathsf{E}^{\prime}=Aut_\mathsf{E}\mathsf{F})$ such that : (i)F is Galois over every intermediatefieldE,but E is Galois over K if and only if

the corresponding subgroup $E^{\prime}$ is normal in $\mathcal{G}=Aut_{\mathrm{K}}\mathcal{F}$ ;in this case $\mathbf{G}/\mathbf{E^{\prime}}$ is (isomorphic to) the Galois group $Aut_\mathrm{K}E$ ofE over K.

REMARKS. Compare this Theorem, which is proved below, with Theorem 2.5. The analogue of (i) in the Fundamental Theorenn is false in the infinite dimensional case (Exercise 16). If $[F:K]$ is infinite there are always subgroups of $Aut_KF$ that are not closed. The proof of this fact depends on an observation of Krull64]: when $F$ is algebraic over $K$ , it is possible to make $Aut_KF$ into a compact topological group in such a way that a subgroup is topologically closed if and only if it is closed in the sense of Section 2 (that is, $H=H^{\prime\prime}$ ). It is not difficult to show that some infinite compact topological groups contain subgroups that are not topologically closed. A fuller discussion, with examples, is given in P. J. McCarthy [40; pp. 60-63]. Also see Exercise 5.11 below.

PROOF OF 3.12.In view of Theorem 2.7 we need only show that every intermediate field $E$ is closed in order to establish the one-to-one correspondence.By Theorem $3.11F$ F $F$ is the splitting field over $K$ of a set $T$ of separable polynomials Therefore, $F$ is also a splitting field of $T$ over $E$ (Exercise 2). Hence by Theorem 3.11 again, $F$ is Galois over $E$ ; that is, $E$ is closed.

------------------------------------------------------------------



------------------------------------------------------------------

Corollary 3.15. Let F be an algebraic extension field of K. Then F is Galois over K if and only if F is normal and separable over K. If char $K=0.$ , then F is Galois over K if. and only if F is normal over K.

PROOF. Exercise; use Theorems 3.11 and 3.14.

Theorem 3.16. If E isan algebraic extension field of K, then there exists an extension field F of E such that.

(i) F is normal over K; (ii) no proper subfield of F containing E is normal over K; (ii) ifE is separable oterK,then F is Galois overK; (iv) $[F:K]$ is finite if and only $if[E:K]$ is finite The field F is uniquely determined uy to an E-isomorphism.

The field $F$ in Theorem 3.16 is sometimes called the normal closure of $E$ over $K$

PROOF OF 3.16. (i) Let $X=\left\{u_{i}\mid i\varepsilon I\right\}$ be a basis of $E$ over $K$ and let $f_i\varepsilon K[x]$ be the irreducible polynonial of $u_i$ .If $F$ is a splitting feld of $S=\{f_{i}\mid i\varepsilon I\}$ over $E$ ,then $F$ is also a splitting field of $S$ over $K$ (Exercise 3), whence $F$ is normal over $K$ by Theorem 3.14. (i) If $E$ is separable over $K$ , then each $f_{i}$ is separable. Therefore $F$ is Galois over $K$ by Theorem 3.11. (iv) If $[E:K]$ is finite, then so is $X$ and hence $S$ . This implies that $[F:K]$ is finite (by the Remarks after Definition 3.1). (i) A subfeld $F_0$ of $F$ that contains $E$ necessarily contains the root $u_{i}$ of $f_i\varepsilon S$ for every $i.$ If $F_0$ is normal over $K$ (so that each $f_{\mathrm{i}}$ splits in $F_0$ by definition), then $F\subset F_0$ and hence $F=F_0$ Finally let $F_1$ be another extension field of $E$ with properties (i) and (ii). Since $F_{1}$

is normal over $K$ and contains each $u_i,F_1$ F $F_{1}$ must contain a splitting field $F_2$ of $S$ over $K$ with $E\subset F_{2}.F_{2}$ $F_2$ F2 is normal over $K$ (Theorem 3.14), whence $F_{2}=F_{1}$ by (ii). Therefore both $F$ and $F_{1}$ are splitting fields of $S$ over $K$ and hence of $S$ over $E$ (Exercise 2).By Theorem 3.8 the identity map on $E$ extends to an $E$ -isomorphism $F\cong F_1$ .

## APPENDIX: THE FUNDAMENTAL THEOREM OF ALGEBRA

The theoremreferred toin thetitle states that thefield C ofcomplexnumbers is algebraically closed (that is, every polynomial equation over C can be completely solved.) Every known proof of this fact depends at some point on results from analysis. We shall assume:

------------------------------------------------------------------

[

Lemma 3.17.If F is afinite dimensional separable exiension of an infinite feld K then $\mathbf{F}=\mathbf{K}(\mathbf{u})$ for some u E F

SKETCHOF PROOF.By Theorem3.16 there is a fnite dimensional Galois extension feld $F_{\mathrm{l}}$ of $K$ that contains $F$ . The Fundamental Theorem 2.5 implies that $Aut_{N}F_{1}$ is fnite and that the extension of $K$ by $F_1$ has only fnitely many intermediate felds. Therefore, there can be only a fnite number of intermediate fields in the extension of $K$ by $F$ Since $[F:K]$ is finite.we can choose $u\varepsilon F$ F $F$ such that $[K(u):K]$ is maximal. If

$K(u)\neq F$ ,there exists $c\in F-K(u)$ .Consider all intermediatefields of the form $K(u+av)$ withae $K$ .Since $K$ is infnite and there are only finitely many intermediate felds, there exist $a,b\in K$ such that $a\neq b$ and $K(u+av)=K(u+bv)$ . Therefort $(a-b)v=(u+av)-(u+bv)$ (u+br) $(u+bv)$ E $K(u+uv)$ . Since $u\neq b$ ，we have $t=$ $(u-b)^{-1}(a-b)v$ E $K(u+av)$ 、whence $u=(u+av)-av\varepsilon K(u+ai)$ $K(u+ai)$ $K(u+ai)$ ：Consequently $K\subset K(u)\subseteq K(u+ui)$ , whence $|K(u+ai):K]>|K(u):K]$ This contra-

dicis the choice of $u$ .Hence $K( u)$ $= F$

Lemma 3.18.There are no exiensionfields ofdiniension 2 orer the held of conplex numbers.

SKETCH OF PROOF. It is easy to see that any extension feld $F$ of dimension 2 over C would necessarily be of the form $F=\mathbf{C}(u)$ for any u $\iota\in F-\mathbb{C}$ By Theorem $1.6u$ would be the root of an irreducible monic polynomial $f\varepsilon C[\lambda]$ of degree 2. To complete the proof we need only show that no such $f$ can exist. For each a + bi e $\mathbf{C}=\mathbf{R}(i)$ the positive real numbers $|(a+\sqrt{u^{2}+b^{2})^{\prime}}2|$ and

$|(-a+\sqrt{a^2+b^2}),2|$ have real positive square roots $c$ and $d$ respectively by assumption (A). Verify that with a proper choice of signs $(\pm c\pm di)^{2}=a+bi$ .Hence every element of $C$ has a square root in $C$ . Consequently, if. $f=.x^{2}+sx+1\varepsilon C[x]$ then $f$ has roots $(-s\pm\sqrt{s^{2}-41}),2$ in C, whence $f$ splits over C. Thus there are no irreducible monicpolynomials of degree 2 in $C[x]$ .■

Theorem 3.19. (The Fundumental Theorem of A/gebra) The peld of complex numbers is algebraically closed..

PROOF. In order to show that every nonconstant $f\varepsilon$ C$[x]$ splits over C, it sufces by Theorem 1.10 to prove that C has no finite dimensional extensions except itself. Since $[\mathbf{C}:\mathbf{R}]=2$ and char $\mathbf{R}=0$ every finite dimensional extension field $E$, of C is a fnite dimensional separable extension of $R$ (Theorem 1.2). Consequently, $E_{1}$ is contained in a finite dimensional Galois extension field $F$ of $R$ by Theorem 3.16. We need only show that. $F=C$ in order to conclude $E_{1}=\mathbf{C}$ The Fundamental Theorem 2.5 shows that $Aut_RF$ is a finite group. By Theorems

I1.5.7 and $2.5Aut_RF$ has a Sylow 2-subgroup $H$ of order $2^n\left(n\geq0\right)$ and odd index, whose fixed field $E$ has odd dimension, $|E:\mathbf{R}|=[Aut_{\mathbf{R}}F:H]$ $E$ is separable over $R$ (since char $\mathbf{R}=0$ ), whence $E=\mathbf{R}(u)$ by Lemma 3.17. Thus the irreducible polynomial of $u$ has odd degree $[E:\mathbb{R}]=[\mathbb{R}(u):\mathbb{R}]$ (Theorem 1.6). This degree must be 1

------------------------------------------------------------------

by assumption (B). Therefore, $u\varepsilon R$ and $[\mathrm{Aut}_{\mathbf{R}}F:H]=[E:\mathbf{R}]=1$ ，whence $\mathrm{Aut}_{\mathbf{R}}F=H$ and $\left|\mathrm{Aut}_{\mathrm{R}}F\right|=2^n$ . Consequently, the subgroup AutcF of. $Aut_RF$ has order $2^m$ for some $mn$ $(0\leq m\leq n)$

Suppose $m>0$ . Then by the First Sylow Theorem Il.5.7 AutcF has a subgroup $J$ of index 2; let $E_{\parallel}$ be the fxed field of $J$ .By the Fundamental Theorem $E_0$ is an extension of $\mathbf{C}$ with dimension $[\mathrm{Aut}_{\mathbf{C}}F:J]=2$ ，which contradicts Lemma 3.18. Therefore, $m=0$ and $\operatorname{Aut}_{\mathrm{C}}F=1$ . The Fundamental Theorem 2.5 implies that $[F:\mathbb{C}]=[\mathrm{Aut}_{\mathbb{C}}F:1]=|\mathrm{Aut}_{\mathbb{C}}F|=1$ ,whence $F=\mathbb{C}$ .

Corollary 3.20. Ecery proper ulgebraic extension field of the field of real numbers is isomorphic to the field of complex numbers..

PROOF. 1f $F$ is an algebraic extension of $R$ and $u\in F-\mathbf{R}$ has irreducible poly. nomial $f\varepsilon\:R[x]$ of degree greater than one, then $f$ splits over $\mathbf{C}$ by Theorem 3.19. If $\upsilon\varepsilon C$ isa root of $f.$ then by Corollary 1.9 the identity map on $R$ extendsto an isomor phism $\mathbf{R}(u)\cong\mathbf{R}(v)\subset\mathbf{C}$ .Since $[\mathbf{R}(v):\mathbf{R}]=[\mathbf{R}(u):\mathbf{R}]>1$ and $[\mathbf{C}:\mathbf{R}]=2$ ，we must have $[\mathbf{R}(v):\mathbf{R}]=2$ and $\mathbf{R}(v)=\mathbf{C}$ .Therefore, $F$ is an algebraic extension of the. algebraically closed field $\mathbf{R}(u)\cong\mathbf{C}$ But an algebraically closed field hasno algebraic extensions except itself (Theorem 3.3). Thus $F=\mathbf{R}(u)\cong\mathbf{C}$ .■

## EXERCISES

Note: Unless stated otherwise $F$ is always an extension field of the field $K$ and $S$ is a set of polynomials (of positive degree) in $K[x]$

1. $F$ is a splitting field over $K$ of a finite set $\{f_1,\ldots,f_n\}$ of polynomials in $K[x]$ if and only if $F$ is a splitting field over $K$ of the single polynomial $f=f_{1}f_{2}\cdots f_{n}$ 2. 1f $F$ is a splitting field of $S$ over $K$ and $E$ is an intermediate feld, then $F$ is a splitting field of $S$ over $E$ 3. (a) Let $E$ be an intermediate field of the extension $K\subset F$ and assume that $E=K(u_1,\ldots,u_r)$ where the $u_{i}$ are (some of the) roots of $f\varepsilon K[x]$ . Then $F$ is a splitting field of $f$ over $K$ if and only if $F$ is a splitting field of $f$ over $E$ (b) Extend part (a) to splitting fields of arbitrary sets of polynomials. 4. If $F$ is a splitting field over $K$ of $S$ , then $F$ is also a splitting field over $K$ of the set $T$ of all irreducible factors of polynomials in. $S$ 5.If $f\varepsilon K[x]$ has degree $n$ and $F$ is a splitting field of fover $K$ ,then $[F:K]$ divides n! 6. Let $K$ be a field such thatfor every extensionfield $F$ the maximal algebraic ex tension of $K$ contained in $F$ (see Theorem 1.14) is $K$ itself. Then $K$ is algebraically closed. 7.If $F$ is algebraically closed and $E$ consists of all elements in $F$ that are algebraic over $K$ ,then $E$ is an algebraic closure of $K$ [see Theorem 1.14] 8. No finite field $K$ is algebraically closed. [Hint: If $K=\{a_{0},\ldots,a_{n}\}$ consider $a_{1}+(x-a_{0})(x-a_{1})\cdots(x-a_{n})\varepsilon K[x]$, where $a_1\neq0$ J

------------------------------------------------------------------

1

1

1

1

9. $F$ is an algebraic closure of $K$ if and only if $F$ is algebraic over $K$ and for every algebraic extension $E$ of $K$ there exists a $K$ -monomorphism $E\to F$

10. $F$ is an algebraic closure of $K$ if and only if $F$ is algebraic over $K$ and for every algebraic field extension $E$ of another field $K_{1}$ and isomorphism of fields $\sigma:K_1\to K$, $\sigma$ extends to a monomorphism $E\to F$

11.(a) If $u_{1},\ldots,u_{n}\in F$ $u_n$ Un are separable over. $K$ , then $K(u_{1},\ldots,u_{n})$ is a separable extension of $K$ (b) If $F$ is generated by a (possibly infinite) set of separable elements over $K$

then $F$ is a separable extension of $K$

12. Let $E$ be an intermediate feld.

(a) If $u\varepsilon F$ is separable over $K$ ,then $u$ is separable over $E$ (b) If $F$ is separable over $K$ ，then $F$ is separable over $E$ and $E$ is separable over $K$

13. Suppose $[F:K]$ is finite. Then the following conditions are equivalent:

( $F$ is Galois over $K$ (i) $F$ is separable over $K$ and a splitting field of a polynomial $f\varepsilon K[x]$ (ii) $F$ is a splitting field over $K$ of a polynomial $f\varepsilon K[x]$ whose irreducible factors are separable.

14. (Lagrange's Theorem on Natural Irrationalities). If $L$ and $M$ are intermediate fields such that $L$ is a finite dimensional Galois extension of $K$ , then $LM$ is finite dimensional and Galois over $M$ and $\mathrm{Aut}_MLM\cong\mathrm{Aut}_{L\cap M}L$

15.Let $E$ be an intermediate feld.

(a) If $F$ is algebraic Galois over $K$ , then $F$ is algebraic Galois over $E$ . [Exercises 2.9 and 2.11 show that the "algebraic" hypothesis is necessary. (b) If $F$ is Galois over $E$ E $E,E$ $E$ E is Galois over $K$ and $F$ is a splitting feld over $E$ ofa family of polynomials in $K[x]$ , then $F$ is Galois over $K$ [see Exercise 2.12].

16. Let $F$ be an algebraic closure of the field Q of rational numbers and let $E\subset F$ be a splitting field over $\mathbf{Q}$ of the set $S=\{x^{2}+a|a\varepsilon\mathbf{Q}\}$ so that $E$ is algebraic and Galois over $\mathbf{Q}$ (Theorem 3.11). (a) $E=\mathbf{Q}(X)$ where $X=\{\sqrt{p}\mid p=-1$ or $p$ is a prime integer I.

(b) If $\sigma\in\operatorname{Aut}_{\mathbf{Q}}E$ ，then $\sigma^{2}=1_{E}$ . Therefore, the group $Aut_{\bullet}E$ is actually a vector space over $Z_2$ [see Exercises I.1.13 and IV.1.1] (c) AutQE QE $0E$ is infinite and not denumerable. [Hinr: for each subset $Y$ of $X$ there

exists o e AutoE such that $\sigma(\sqrt{p})=-\sqrt{p}$ for $\sqrt{p}\in Y$ and $\sigma(\sqrt{p})=\sqrt{p}$ for $\sqrt{p}\in X-Y$ .Therefore, |Aut$_\mathbf{O}E|=|P(X)|>|X|$ by Introduction, Theorem 8.5. But $|X|=\aleph_{0}$ ]

(d) If $B$ is a basis of $Aut_{\bullet}E$ over $Z_2$, then $B$ is infnite and not denumerable. (e) AutoE has an infinite nondenumerable number of subgroups of index 2. [Hinr: If $b\in B$ , then $B-\{b\}$ generates a subgroup of index 2.] (f)The set of extension fields of $\mathbf{Q}$ contained in $E$ of dimension 2 over $\mathbf{Q}$ is denumerable. (g)The set of closed subgroups of index 2 in Aut $\mathbf{Q}E$ is denumerable (h) $[ E: \mathbf{Q} ] \leq \aleph _{\mathrm{o} }$ ,whence $[E:\mathbf{Q}]<|$Aut$_\mathbf{O}E|$

1

1

1

------------------------------------------------------------------

17. If an intermediate feld $E$ is normal over $K$ , then $E$ is stable (relative to $F$ and $K$ ).

18. Let $F$ be normal over $K$ and $E$ an intermediate feld. Then $E$ is normal over $K$ if and only if $E$ is stable [see Exercise 17]. Furthermore $\operatorname{Aut}_{\text{К}}F/E^{\prime}\cong\operatorname{Aut}_{K}E$

19. Part (i) or (i)' of the Fundamental Theorem (2.5 or 3.12) is equivalent to: an intermediate field $E$ is normal over $K$ if and only if the corresponding subgroup $F^{\prime}$ is normal in $G=\operatorname{Aut}_{h}F$ in which case $G_{i}^{\prime}E^{\prime}\cong\operatorname{Aut}_{i}E$ . [See Exercise 18.]

20.If $F$ is nornal over an intermediate field $E$ and $E$ is normal over $K$ , then $F$ need not be normal over $K$ .[Hinr: Let $\sqrt[4/\overline{2}$ be a real fourth root of 2 and consider $\mathbf{Q}(\sqrt[4]{2})\supset\mathbf{Q}(\sqrt{2})\supset\mathbf{Q}$ ; use Exercise 23.] Compare Exercise 2.

21. Let $F$ be algebraic over $K$ $F$ is normal over $K$ if and only if for every $K$ -monomor phism of felds $\sigma:F\to N$ ,where $N$ is any normal extension of $K$ containing $F$ $\sigma(F)=F$ so that $\sigma$ is a $K$ a utonorphism of $F$ .[Hinr: Adapt the proof of Theoren 3.14, using Theorem 3.16.]

22.If $F$ is algebraic over $K$ and every element of $F$ belongs to an intermediate field that is normal over $K$ ,then $F$ is normal over $K$ 23.If $[F:K]=2$ ,then $F$ is normal over $K$ 24. An algebraic extension $F$ of $K$ is normal over $K$ if and only if for every irreducible $f\varepsilon K[x]$ $f$ factors in $F[x]$ as a product of irreducible factors all of which have the same degree. 25. Let $F$ be a splitting field of $f\varepsilon K[x]$ . Without using Theorem 3.14 show that $F$ is normal over $K$ [Hints: if an irreducible $\kappa\in K[x]$ has a root $u\varepsilon F$ ,but does not split in $F$ , then show that there is a $K$ -isomorphism $\varphi:K(u)\cong K(v)$ ，where $\because\notin F$ and $l$ is a root of $\xi$ . Show that $\varphi$ extends to an isoniorphism $F\cong F(v)$ This contradicts the fact that $[F:K]<|F(t):K].$

## 4. THE GALOIS GROUP OF A POLYNOMIAL

The primary purpose of this section is to provide some applications and example. of the concepts introduced in the preceding sections. With two exceptions this material is not needed in the sequel. Definition 4.1 and Theorem 4.12, which depends only on Theorem 4.2, are used in Section 9, where we shall consider the solvability by radicals of a polynomial equation

Definition 4.1. Ler K be a field. The Galois group of a polynomial f e K[x] is the group $Aut_kF$ ,where F is a splitting field of f orer K

By virtue of Corollary 3.9, the Galois group of $f$ is independent of the choice of $F$ Before giving any examples we first develop some usef ul facts. Recall that a subgroup $G$ of the symmetric group $S_n$ is said to be transitive if given any $i\neq j\left(1\leq i,j\leq n\right)$ there exists a $\sigma$ $\sigma\varepsilon G$ G $G$ such that $\sigma(i)=j$

------------------------------------------------------------------

「

1

1

Theorem 4.2. Ler K be a field andf e $K[x]$ a polynomial with Galois group $G$

(i) G is isomorphic to a subgroup of some symmetric group $S_{n}$ (i) 1ff is (irreducible) separable of degree n, then n dirides $|\mathbf{G}|$ and G is isomor

phic to a transitive subgroup of $S_{n}$

SKETCH OF PROOF. (i) If $u_1,\ldots,u_n$ are the distinct roots of $f$ in some splitting field $F(1\leq n\leq\deg f)$ , then Theorem 2.2 implies that every o e Aut $_{K}F$ induces a unique permutation of $\{u_1,\ldots,u_n\}$ (but not necessarily vice versa!) Consider $S_n$ as the group of all permutations of $\{u_1,\ldots,u_n\}$ and verify that the assignment of $\sigma\varepsilon Aut_{K}F$ to the permutation it induces defnes a monomorphism $\mathrm{Aut}_KF\to\mathcal{S}_n$ . (Note that $F=K(u_{1},\ldots,u_{n}).$ (i) $F$ is Galois over $K$ (Theorem 3.11) and $[K(u_{1}):K]=n=\deg f$ (Theorem 1.6).

Therefore,. $G$ has a subgroup of index $n$ by the Fundamental Theorem 2.5, whence $n\mid|G|$ . For any $i\neq j$ there is a $K$ -isomorphism $\sigma:K(u_{i})\cong K(u_{i})$ such that $\sigma(u_{i})=u_{j}$ (Corollary 1.9). $\sigma$ extends to a $K$ -automorphism of $F$ by*Theorem 3.8, whence $G$ is isomorphic to a transitive subgroup of $S_n$ .■

Hereafter the Galois group of polynomial fwill frequently be identified with the isomorphic subgroup of $S_n$ and considered as a group of permutations of the roots of f. Furthermore we shall deal primarily with polynomials $f\varepsilon K[x]$ all of whose roots are distinct in some splitting field. This implies that the irreducible factors of $f$ are separable. Consequently by Theorem 3.11 (and Exercise 3.13) the splitting feld $F$ of $f$ is Galois over $K$ . If she Galois groups of such polynomials can always be calculated then it ispossible(in principle at least) tocalculate the Galoisgroup of an arbitrary polynomial (Exercise 1).

1

1

Corollary 4.3. Let K be a field and f e K[] an irreducible polynomial of degree 2 with Galois group G. If f is separable (as is always the case when char $\mathbf{K}\neq2.$ ,then G$\cong Z_2$ otherwise $G=1$

SKETCH OF PROOF. Note that $S_{2}=Z_{2}$ .Use Remark (i) after Definition 3.10 and Theorem 4.2.

Theorem 4.2(ii) immediately yields thefact that theGalois groupof a separable polynomial of degree3is either $S_3$ or $A_3$ (the only transitive subgroups of $S_3$ ). In order to get a somewhat sharper result, we introduce a more general consideration

Definition 4.4. Let K be a feld withi char $\mathcal{K}\neq2$ and f ε K[x] a polynomial of degree n with n distinct roots $u_1,\ldots,u_n$ in some splitting field F off ocer K.Let $\Delta = \prod _{i< j}( u_{i}- u_{j}) = ( u_{1}- u_{2}) ( u_{1}- u_{3}) \cdots ( u_{n- 1}- u_{n}) \varepsilon$ $F$ ; the disriminant off is the element $\mathbf{D}=\Delta^{2}$

Note that $\Delta$ is an element of a specific splitting feld $F$ and therefore,a priori, $D=\Delta^{2}$ is also in $F$ . However, we have

1

------------------------------------------------------------------

Proposition 4.5. Let K, f, F and $\Delta$ be as in Definition 4.4.

(i) The discriminant $\Delta^2$ off actually lies in K (ii) For each o∈ $Aut_{\mathrm{K}}$F$<S_n$, $\sigma$ is an even[resp.odd]permutation if and only if $\sigma(\Delta)=\Delta$ [resp. $\sigma(\Delta)=-\Delta]$

SKETCH OF PROOF. For (ii) see the proof of Theorem I.6.7. Assuming (ii) note that for every $\sigma$ EAut $\therefore\kappa F$ $\sigma(\Delta^{2})=\:\sigma(\Delta)^{2}=(\pm\Delta)^{2}=\:\Delta^{2}.$ Therefore, $\Delta^2\varepsilon K$ since $F$ is Galois over $K$ (Theorem 3.11; Exercise 3.13).

Corollary 4.6. Ler K, f, F, $\Delta$ be as in Definition 4.4 (sothatF is Galois over K) and consider $\mathbf{G}=Aut_{\mathrm{K}}\mathbf{F}$ asa subgroup of $S_{n}$ . In the Galois correspondence (Theorem 2.5). the subfield $K(\Delta)$ corresponds to the subgroup G $\mathbf{A}_{11}$ .In particular, G consists of eren permutations if and only if△e K.

PROOF. Exercise.

Corollary 4.7. Let K be a field and f e K[x] an (irreducible) separable polynomial of. degree 3. The Galois group of f is either. $S_{3}$ or $\mathbf{A}_{3}$ .Ifchar $\mathbb{K}\neq2$ ,it is $\mathbf{A}_{3}$ ifand only if the discriminant of f is the square of an element of K..

PROOF. Exercise; use Theorem 4.2 and Corollary 4.6.

If the base field $K$ is a subfield of the field of real numbers, then the discriminan of a cubic polynomial $f\varepsilon K[x]$ can be used to find out how many real roots $f$ has (Exercise 2). Let $f$ be as in Corollary 4.7. If the Galois group of $f$ is $A_3\cong Z_3$ there are, of

course, no intermediate felds. If it is $S_{3.}$ ，then there are four proper intermediate fields, $K(\Delta)$ K(△) $K(u_1)$ K(u) $K(\Delta),K(u_{1}),K(u_{2})$, K(ue) $K(u_2)$ and $K(u_3)$ where $u_1,u_2,u_3$ are the roots of $f.K(\Delta)$ corresponds to $A_3$ and $K(u_i)$ corresponds to the subgroup $|(1),(jk)|(i\neq j,k)$ of $S_{:t}$, whichhas order 2 and index 3 (Exercise 3).

Except in the case of characteristic 2, then, computing the Galois group of a separable cubic reduces to computing the discriminant and determining whether or not it is a square in $K$ . The following result is sometimes helpful..

Proposition 4.8. Let K be a field with char $\mathbf{K}\neq2,3$ .If $f(x)=x^{3}+bx^{2}+cx+$ $\mathbf{d}\in\mathbf{K}[\mathbf{x}]$ has three distinct roots in some splinting field, then the polynomial $\mathbf{g(x)=f(x-b/3)\varepsilon K[x]}$ has the form. $x^3+px+q$ and the discriminant off is $-4\mathrm{p}^{3}-27\mathrm{q}^{2}$

SKETCH OF PROOF.Let $F$ be a splitting field of $f$ over $K$ and verify that $u\equiv F$ is a root of $f$ if and only if $u+b/3$ is a root of $g\:=\:f(x\:-\:b_{i}^{\prime}3)$ . This implies that $g$ has thesame discriminant as $f$ Verify that $g$ has the form $\lambda^{3}+p.x+q(p,q\in K)$ Let $r_1,c_2,c_3$ be the roots of $k$ in $F$ .Then $(x-r_{1})(x-t_{2})(x-r_{3})=g(x)=\lambda^{3}+px+q$ which implies

------------------------------------------------------------------

1

$$\begin{aligned}
&v_{1}+v_{2}+v_{3}=0; \\
&v_{1}v_{2}+v_{1}v_{3}+v_{2}v_{3}=p; \\
&-v_{1}v_{2}v_{3}=q.
\end{aligned}$$

Since each $v_i$ is a root of $g$

$$v_{i}^{3}=-pv_{i}-q\quad(i=1,2,3).$$

The fact that the discriminant $\Delta^2$ of $g$ is $-4p^{3}-27q^{2}$ now follows from a gruesome computation involving the definition $\Delta^{2}=(v_{1}-v_{i})^{2}(v_{1}-v_{3})^{2}(v_{2}-v_{3})^{2}$ ，the equa tions above and the fact that $(v_{i}-v_{i})^{2}=(v_{i}+v_{j})^{2}-4v_{i}v_{j}$ .

EXAMPLE. The polynomial $x^{3}-3x+1\varepsilon\mathbf{Q}[x]$ is irreducible by Theorem 1II.6.6 and Proposition IIl.6.8 and separable since char $\mathbf{Q}=0$ The discriminant is $-4(-3)^3-27(1)^2=108-27=81$ which is a square in Q. Hence the Galois group is $A_3$ by Corollary 4.7.

EXAMPLE. If $f(x)=x^3+3x^2-x-1\varepsilon\mathbf{Q}[x]$, then

$$g(x)=f(x-3/3)=f(x-1)=x^3-4x+2,$$

which is irreducible by Eisenstein's Criterion (Theorem IIl.6.15). By Proposition 4.8 the discriminant of $f$ is $-4(-4)^3-27(2)^2=256-108=148$ ，which is not a square in Q. Therefore the Galois group is $S_3$

We turn now to polynomials of degree four (quartics) over a field $K$ .As above, we shall deal only with those $f\varepsilon K[x]$ that have distinct roots $u_1,u_2,u_3,u_4$ in some splitting field $F$ . Consequently, $F$ is Galois over $K$ and the Galois group of $f$ maybe considered as a group of permutations of $\{u_1,u_2,u_3,u_4\}$ and a subgroup of $S_4$ . The subset $V=\{(1),(12)(34),(13)(24),(14)(23)\}$ is a normal subgroup of $S_4$ (Exercise 1.6.7), whichwill play an importantrole in the discussion.Note that $V$ is isomorphic to the four group $Z_2\oplus Z_2$ and $V\cap G$ $G$ G is a normal subgroup of $G=\operatorname{Aut}_{K}F<S_4$

1

1

1

Lemma 4.9. Let $\mathbf{K},\mathbf{f},\mathbf{F},\mathbf{u}_{\mathbf{i}},\mathbf{V}$ ,and $\mathbf{G} = Aut_{\mathrm{K} }\mathbf{F} < \mathbf{S} _{4}$ be as in the preceding puragraph. If $\alpha=u_{1}u_{2}+u_{3}u_{4}$ ， $\beta$ = $u_{1}u_{3}+ u_{2}u_{4}$ ， $\boldsymbol{\gamma}=\boldsymbol{u}_1\boldsymbol{u}_4+\mathbf{u}_2\boldsymbol{u}_3\varepsilon\boldsymbol{F}$ , then under the Gulois correspondence (Theorem 2.5) the subfield $\mathbf{K}(\alpha,\beta,\gamma)$ corresponds to the normal subgroup V ∩ G.Hence ${\mathcal{K}}(\alpha,\beta,\gamma)$ is Galois ocer K and $Aut_{\text{К }}\mathbf{K} ( \alpha , \beta , \gamma ) \cong$G/(G$\cap\mathbf{v})$

SKETCH OF PROOF. Clearly every element in $G\cap V$ fixes $\alpha,\beta,\gamma$ and hence $K(\alpha,\beta,\gamma)$ . In order to complete the proof it suffices, in view of the Fundamental Theoreni, to show that every element of $G$ not in $V$ moves at least one of $\alpha,\beta,\gamma$ .For instance if $\sigma=(12)\varepsilon G$ and $\sigma(\beta)=\beta$ ,then $u_2u_3+u_1u_4=u_1u_3+u_2u_4$ and hence $u_{2}(u_{3}-u_{4})=u_{1}(u_{3}-u_{4})$ . Consequently, $u_1=u_2$ or $u_3=u_4$ , either of which is a contradiction. Therefore $\sigma(\beta)\neq\beta$ .The other possibilities are handled similarly [Hinr:Rather than check all 20 possibilities show that it suffices toconsider only one representative from each coset of $V$ in $S_4]$ .

Let $K,f,F,u_{i}$ ui $u_i$ and $\alpha,\beta,\gamma$ be as in Lemma 4.9.The elements $\alpha,\beta,\gamma$ play a crucial role in determining the Galois groups of arbitrary quartics. The polynomial $(x-\alpha)(x-\beta)(x-\gamma)\varepsilon K(\alpha,\beta,\gamma)[x]$ is called the resolvant cubic of $f.$ The resolvant cubic is actually a polynomial over $K$

1

1

------------------------------------------------------------------

Lemma 4.10. If K is afeld and $\mathrm{f=x^{4}+bx^{3}+cx^{2}+dx+e\varepsilon K[x]}$ , then the resolvant cubic of f is the polynomial $\mathbf{x}^{3}-\mathbf{c}\mathbf{x}^{2}+(\mathbf{b}\mathbf{d}-4\mathbf{e})\mathbf{x}-\mathbf{b}^{2}\mathbf{e}+4\mathbf{c}\mathbf{e}-\mathbf{d}^{2}\mathbf{\epsilon}\mathbf{K}[\mathbf{x}]$

SKETCH OF PROOF. Let $f$ have roots $u_1,\ldots,u_4$ in some splitting field $F$ Then use the fact that $f=(x-u_{1})(x-u_{2})(x-u_{3})(x-u_{4})$ to express $b,c,d,e$ in terms of the. $u_i$ . Expand the resolvant cubic $(x-\alpha)(x-\beta)(x-\gamma)$ and make appro-. priate substitutions, using the definition of $\alpha,\beta,\gamma$ (Lemma 4.9) and the expressions for $b,c,d,e$ obtained above.

We are now in a position to compute the Galois group of any (irreducible) separable quartic $f\varepsilon K[x]$ . Since its Galois group $G$ is a transitive subgroup of $S_4$ whose order is divisible by 4 (Theorem 4.2), $G$ must have order 24, 12, 8 or 4. Verify that the only transitive subgroups of orders 24, 12, and 4 are $S_4,A_4$ $V(\cong Z_2\oplus Z_2)$ and the various cyclic subgroups of order 4 generated by 4-cycles; see Exercise I.4.5 and Theorem I.6.8. One transitive subgroup of $S_4$ of order 8 is the dihedral group $D_4$ generated by(1234) and (24) (page 50).Since $D_4$ is not normal in $S_4$, and since every subgroup of order 8 is a Sylow 2-subgroup, it follows from the second and third Sylow Theorems that $S_4$ has precisely three subgroups of order 8, each isomorphic to $D_4$

Proposition 4.11.Let K be a field and f e K[x] an (irreducible) separable yuartic with Galois group G (considered as a subgroup of $S_{4}$ ).Ler $\alpha,\beta,\gamma$ be the roots of the resolvant cubic of f and let $\mathbf{m}=[\mathbf{K}(\alpha,\beta,\gamma):\mathbf{K}]$ .Then

(i) $\mathbf{m}=6\Leftrightarrow\mathbf{G}=\mathbf{S}_{4}$, (i) $\mathbf{m}=3\Leftrightarrow\mathbf{G}=\mathbf{A}_{4}$ (ii) $\mathbf{m}=1\Leftrightarrow\mathbf{G}=\mathbf{V}$ (iv) $\mathbf{m}=2\Leftrightarrow\mathbf{G}\cong\mathbf{D}_{4}$ or $\mathbf{G}\cong\mathbf{Z}_{4}$ ; in this case $\mathbf{G}\cong\mathbf{D}_{4}$ iff is irreducible over $\mathbf{K}(\alpha,\beta,\gamma)$ and $\mathbf{G}\cong\mathbf{Z}_{4}$ Otherwise

SKETCH OF PROOF.Since $K(\alpha,\beta,\gamma)$ is a splitting field over $K$ of a cubic, the only possibilities for m are 1,2,3, and 6. In view of this and the discussion preceding the theorem, it suffices to prove only the implications $\Leftarrow$in each case.We use the fact that $m=[K(\alpha,\beta,\gamma):K]=|G/G\cap V|$ by Lemma 4.9 If $G=A_{4}$ ，then $G\cap V=V$ and $m=|G/V|=|G|/|V|=3$ . Similarly, if

$G=S_{4}$ then $m=6$ . If $G=V$ ,then $G\cap V=G$ and $m\:=\:|G/G|\:=\:1$ . If $G\cong D_{4}$ then $G\cap V=V$ since $V$ is contained in everySylow 2-subgroup of $S_{4}$ and $m=|G/V|$ $=|G|/|V|=2$ . If $G$ is cyclic of order 4, then $G$ is generated by a 4-cycle whose square must be in $V$ so that $|G\cap V|=2$ and $m=|G/G\cap V|=|G|/|G\cap V|=2$ Since $f$ is either irreducible or reducible and $D_4\not\cong\mathbb{Z}_4$, it suffices toprove the con-

verse of the last statement. Let $u_1,u_2,u_3,u_4$ be the roots of $f$ in some splitting field $F$ and suppose $G\cong D_{4}$ ,so that $G\cap V=V$ . Since $V$ is a transitive subgroup and $G\cap V=\mathrm{Aut}_{K(\alpha.\beta,\gamma)}F$ (Lemma 4.9), there exists for each pair $i\neq j\left(1\leq i,j\leq4\right)$ a $\sigma\varepsilon G\cap V$ which induces an isomorphism $K(\alpha,\beta,\gamma)(u_{i})\cong K(\alpha,\beta,\gamma)(u_{j})$ such that $\sigma(u_i)=u_j$ and $\sigma\mid K(\alpha,\beta,\gamma)$ is the identity. Consequently for each $i\neq j$ $u_{i}$ and $u_{i}$ are roots of the same irreducible polynomial over $K(\alpha,\beta,\gamma)$ by Corollary 1.9. It follows that $f$ is irreducible over $K(\alpha,\beta,\gamma)$ . On the other hand if $G\cong Z_4$ ，then $G\cap V=$

------------------------------------------------------------------

1

1

$\mathrm{Aut}_{K(\alpha,\beta.\gamma)}F$ has order 2 and is not transitive. Hence for some $i\neq j$ there is no $\sigma\varepsilon G\cap V$ such that $\sigma(u_{i})=u_{j}$ . But since $F$ is a splitting field over $K(\alpha,\beta,\gamma)(u_i)$ and $K(\alpha,\beta,\gamma)(u_{j})$ , if there were an isomorphism $K(\alpha,\beta,\gamma)(u_i)\cong K(\alpha,\beta,\gamma)(\iota_j)$ , which was the identity on $K(\alpha,\beta,\gamma)$ and sent $u_{i}$ to $u_{l}$, it would be the restriction of some $\sigma\varepsilon\mathrm{Aut}_{\dot{K}(\alpha,\beta.\dot{\gamma})}F=G\cap V$ by Theorem 3.8. Therefore, no such isomorphism exists, whence $u_{i}$ and $u_1$ cannot be roots of the same irreducible polynomial over $K(\alpha,\beta,\gamma)$ by Corollary 1.9. Consequently, $f$ must be reducible over $K(\alpha,\beta,\gamma)$ .

EXAMPLE. The polynomial $f=x^{4}+4x^{2}+2\varepsilon\mathbf{Q}[x]$ is irreducible by Eisenstein's Criterion (Theorem III.6.15); $f$ is separable since char $\mathbf{Q}=0$ .Using Lemma 4.10 the resolvant cubic is found to be $x^{3}-4x^{2}-8x+32=(x-4)(x^{2}-8)$ SC that α = 4 $\alpha=4$ $\beta=\sqrt{8}$ $\beta=\sqrt{8}$ $\alpha=4,\beta=\sqrt{8},\gamma=-\sqrt{8}$ = -v8 $\gamma=-\mathbf{\sqrt{8}}$ and $\mathbf{Q}(\alpha,\beta,\gamma)=\mathbf{Q}(\sqrt{8})=\mathbf{Q}(2\sqrt{2})=\mathbf{Q}(\sqrt{2})$ is of dimension 2 over Q. Hence the Galois group is (isomorphic to) $D_4$ or $Z_{4}$ . A substitution $z=x^2$ reduces $f$ to $z^{2}+4z+2$ whose roots are easily seen to be $z=-2\pm\sqrt{2}$ thus the roots of $f$ are $x=\pm\sqrt{z}=\pm\sqrt{-2\pm\sqrt{2}}$ .Hence

$$f=(x-\sqrt{-2+\sqrt{2}})(x+\sqrt{-2+\sqrt{2}})(x-\sqrt{-2-\sqrt{2}})(x+\sqrt{-2-\sqrt{2}})\\=(x^{2}-(-2+\sqrt{2})\left(x^{2}-(-2-\sqrt{2})\right)\varepsilon\mathbf{Q}(\sqrt{2})[x].$$

Therefore, $f$ is reducible over $\mathbf{Q}(\sqrt{2})$ and hence the Galois group is cyclic of order 4 by Proposition 4.11 (iv).

EXAMPLE. To find the Galois group of $f=x^4-10x^2+4\varepsilon\mathbf{Q}[x]$ we first verify that $f$ is irreducible (and hence separable as well). Now $f$ has no roots in $Q$ ,and thus no linear or cubic factors, by Theorem I1.6.6 and Proposition I11.6.8. To check for quadratic factors it suffices by Lemma II1.6.13 to show that $f$ has no quadratic factors in $\mathbf{Z}[x]$ .It is easy to verify that there are no integers $a,b,c,d$ such that $f=(x^{2}+ax+b)(x^{2}+cx+d)$ . Thus $f$ is irreducible in $\mathbf{Q}[x]$ . The resolvant cubic of $f$ is $x^{3}+10x^{2}-16x-160=(x+10)(x+4)(x-4)$ all of whoseroots are in Q. Therefore, $m=[\mathbf{Q}(\alpha,\beta,\gamma):\mathbf{Q}]=1$ and the Galois group of $f$ is $V(\cong Z_2\oplus Z_2)$ by Proposition 4.11.

EXAMPLE. The polynomial $x^{4}-2\varepsilon\mathbf{Q}[x]$ is irreducible (and separable) by Eisenstein's Criterion. The resolvant cubic is $x^{3}+8x=x(x+2\sqrt{2}i)(x-2\sqrt{2}i)$ and $\mathbf{Q} ( \alpha , \beta , \gamma )$ = $\mathbf{Q} ( \sqrt {2}i)$ has dimension 2 over Q. Verify that $x^{4}-2$ is irreducible over $Q(\sqrt{2}i)$ (since $\sqrt{2},\sqrt[4]{2}\notin\mathbf{Q}(\sqrt{2}i))$ . Therefore the Galois group is isomorphic to the dihedral group. $D_4$ by Proposition 4.11.

EXAMPLE. Consider $f=x^{4}-5x^{2}+6\varepsilon\mathbf{Q}_{\mathrm{i}}^{[x]}$ . Observe that $f$ is reducible over Q. namely $f=(x^2-2)(x^2-3)$ .Thus Proposition 4.11 is not applicable here. Clearly $F=\mathbf{Q}(\sqrt{2,\sqrt{3}})$ is a splitting field of $f$ over $Q$ and since $x^2-3$ is irreducible over $\mathbf{Q}(\sqrt{2})$ ， $|F:\mathbb{Q}]=|F:\mathbb{Q}(\sqrt{2})|\left[\mathbb{Q}(\sqrt{2}):\mathbb{Q}\right]=2\cdot2=4$ .Therefore $Aut_0F$ ，the Galois group of $f$, has order 4 by the Fundamental Theorem. It follows from the proof of Theorem 4.2 and Corollary 4.3 that AutoQ( $\bar{2}$) consists of two elements: the identity map 1 and a map $\sigma$ with $\sigma(\sqrt{2})=-\sqrt{2}$ . By Corollary 1.9, 1 and $\sigma$ each extend to a $Q$ -automorphism of $F$ in two different ways (depending on whether $\sqrt{3}\mapsto\sqrt{3}$ or $\sqrt{3}\vdash-\sqrt{3})$ This gives four distinct elements of $Aut_0F$ (determined by the four possible combinations: $\sqrt{2}\vdash\pm\sqrt{2}$ and $\sqrt{3}\vdash\pm\sqrt{3})$ .Since $|\mathbf{Aut}_0F|=4$ and each of these automorphisms hasorder 2 theGaloisgroupof $f$ must be isomor phic to the four group $Z_2\oplus Z_2$ by Exercise I.4.5.

1

1

1

1

1

------------------------------------------------------------------

Determining the intermediate fields and corresponding subgroups of the Galois group of a separable quartic is more complicated than doing the same for a separable cubic. Among other things one may have $K(u_{i})=K(u_{i})$ even though $u_i\neq u_i$ (see the last example above). There is no easily stated proposition to cover the quartic case and each situation must be attacked on an ad hoc basis.

EXAMPLE. Let $F\subset\mathbb{C}$ be a splitting field over $Q$ of $f=x^{4}-2\varepsilon\mathbf{Q}[x]$ . If $u$ is the positive real fourth root of 2, then the roots of fare $u$ ， $-u,ui$ $-ui$ In order to consider the Galois group $G=\mathbf{Aut}_{\mathbf{Q}}F$ of fas a subgroup of $S_4$ ,we must choose an ordering of the roots, say $u_{1}=u$ ， $u_{2}=-u$ $u_{3}=ui$ $u_{4}=-ui$ .Weknowfrom the third example after Proposition 4.11 that $G$ is one of the three subgroups of order 8 in $S_{4.}$ , each of which is isomorphic to the dihedral group $D_{4}$ . Observe that complex conjugation is an $R$ -automorphism of $\mathbf{C}$ which clearly sends u→u $u\vdash u$ $u\vdash u$, $- u\models - u$, $ui\vdash-ui$ and $-ui\vdash ui$ . Thus it induces a $\mathbf{Q}$ -automorphism $\tau$ of $F=\mathbf{Q}(u,ui)$ .As an element of $S_4$ $\tau=(34)$ . Now every subgroup of order 8 in $S_{4}$ is conjugate to $D_4$ (Second Sylow Theorem) and an easy calculation shows that the only one containing (34) is the subgroup $D$ generated by $\sigma=(1324)$ and $\tau=(34)$ . It is easy to see that $F=\mathbf{Q}(u,ui)=\mathbf{Q}(u,i)$ ,so that every $\mathbf{Q}$ -automorphism of $F$ is completely determinec by its action on $u$ and i.Thus the elements of $D$ maybe described eitherin terms of $\sigma$ and $\tau$ or by their action on $u$ and $i$ .This information is summarized in the table:

It is left to the reader to verify that the subgroup lattice of $D$ and the lattice of intermediate fields are asgiven below,withfields and subgroups in the same relative position corresponding to one another in the Galois correspondence. Subgroup lattice ( $H\to K$ means $H<K$ )：

![](https://storage.simpletex.cn/view/fm1tx1CyG3pb4Ir1zO3u03EG7ikqW8CU1)

Intermediate field lattice ( $M\to N$ means $M\subset N$ ：

------------------------------------------------------------------

![](https://storage.simpletex.cn/view/fdt0iNSMow0N74uAAwFRUe3yGL8LI21FI)

Specific techniques for computing Galois groups of polynomials of degree greater than 4 over arbitrary fields are rather scarce. We shall be content with a very special case.

1

1

Theorem 4.12.If p is prime andf is an irreducible polynomial of degree p ocer the field of rational numbers which has precisely two nonreal roots in the field of complex numbers, then the Galois group off is (isomorphic 1o) $S_{\mathrm{p}}$

SKETCH OF PROOF. Let $G$ be the Galois group of $f$ considered as a subgroup of $S_{p}$ . Since $p\mid|G|$ (Theorem 4.2), $G$ contains an element $\sigma$ of order $P$ by Cauchy's Theorem II.5.2.. $\sigma$ is a $p$ -cycle by Corollary I.6.4. Now complex conjugation $(a+bi|\mapsto a-bi)$ is an $R$ -automorphism of. $\mathbf{C}$ that moves every nonreal element. Therefore, by Theorem 2.2 it interchanges the two nonreal roots of $f$ and fixes all the others. This implies that $G$ contains a transposition $\tau=(ab)$ .Since $\sigma$ can be written $\sigma\:=\:(aj_{2}\cdots j_{p})$ , some power of $\sigma$ is of the form $\dot{\sigma}^{k}=(abi_{3}\cdots i_{p})\varepsilon\:G$ By changing notation, if necessary, we may assume $\tau=(12)$ and $\sigma^{k}=(123\cdots p)$ .But these two elements generate $S_n$ by Exercise I.6.4. Therefore $G=S_{p}$ .

EXAMPLE. An inspection of the graph of $f=\:x^{5}-4x+2\:\varepsilon\:\mathbf{Q}[x]$ shows that it has only three real roots. The polynomial $f$ is irreducible by Eisenstein's Criterior (Theorem II1.6.15) and its Galois group is $S_5$ by Theorem 4.12.

 It is still an open question as to whether or not there exists for every finite group $G$ a Galois extension field of Q with Galois group $G$ . If $G=S_{n}$ , however, the answer is affirmative (Exercise 14).

### EXERCISES

Note: Unless stated otherwise $K$ is a feld, $f\varepsilon K[x]$ and $F$ is a splitting field of $f$ over $K$

1. Suppose $f\varepsilon\:K[x]$ splits in $F$ as $f=(x-u_{1})^{n_{1}}\cdots(x-u_{k})^{n_{k}}$ ( $u_i$ distinct; $n_i\geq1)$ Let $v_0$, Do, $v_0,\ldots,v_k$ V $\upsilon_{k}$ be the coefficients of the polynomial $g=(x-u_{1})(x-u_{2})\ldots(x-u_{k})$ and let $E\:=\:K(v_{0},\:\ldots\:v_{k})$ . Then

1

1

------------------------------------------------------------------

(a) $F$ is a splitting field of $g$ over $E$ (b) $F$ is Galois over $E$ (c) $\mathrm{Aut}_EF=\mathrm{Aut}_KF$

2. Suppose $K$ is a subfield of R (so that $F$ may be taken to be a subfield of $\mathbf{C}$ )and that $f$ is irreducible of degree 3. Let $D$ be the discriminant of $f.$ Then (a) $D>0$ if and only if $f$ has three real roots. (b) $D<0$ if and only if $f$ has precisely one real root.

3. Let $f$ be a separable cubic with Galois group $S_3$ and roots $u_1,u_2,u_3\in F$ . Then the distinct intermediate fields of the extension of $K$ by $F$ are $F,K(\Delta),\:K(u_{1})$ K(u) $K(u_1)$ ， $K(u_2)$ $K(u_3)$ $K$ . The corresponding subgroups of the Galois group are $1,A_3,T_1,T_2,T_3$ and $S_3$ where $T_i=\{(1),(jk)\mid j\neq i\neq k\}$

4. If char $K\neq2,3$ then the discriminant of $x^{3}+bx^{2}+cx+d$ is $-4c^{3}-27d^{2}+$ $b^2(c^2-4bd)+18bcd$

5. If char $K\neq2$ and $f\varepsilon\:K[x]$ is a cubic whose discriminant is a square in $K$ , then $f$ is either irreducible or factors completely in $K$

6. Over any base field $K,\:x^{3}-3x+1$ is either irreducible or splits over $K$

7. $S_4$ has no transitive subgroup of order 6.

8. Let $f$ be an (irreducible) separable quartic over $K$ and $u$ a root of $f.$ There is no tield properly between. $K$ and $K(u)$ if and only if the Galois group of $f$ is either $A_4$ or $S_4$

9. Let $x^{4}+ax^{2}+b\varepsilon K[x]$ (with char $K\neq2.$ ) be irreducible with Galois group $G$ (a) If $b$ is a square in $K$ , then $G=V$ (b) If $b$ is not a square in $K$ and $b(u^2-4b)$ is a square in $K$ ，then $G\cong Z_4$ (c) If neither $b$ nor $b(a^2-4b)$ is a square in $K$ , then $G\cong D_{4}$

10. Determine the Galois groups of the following polynomials over the felds indicated: (a) $x^4-5$ over $Q$ ; over $Q(\sqrt{5})$ ; over $Q(\sqrt{5}i)$

(b) $(x^3-2)(x^2-3)(x^2-5)(x^2-7)$ over $Q$ (c) $x^{3}-x-1$ over $Q$ ; over $\mathbf{Q}(\sqrt{23}i)$ (d) $x^{3}-10$ over $\mathbf{Q}$ ; over $\mathbf{Q}(\sqrt{2})$ (e) $x^{4}+3x^{3}+3x-2$ over $Q$ (f) $x^{5}-6x+3$ over $Q$ (g) $x^3-2$ over Q. (h) $(x^{3}-2)(x^{2}-5)$ over $\mathbf{Q}$ (i) $x^{4}-4x^{2}+5$ over Q (i) $x^{4}+2x^{2}+x+3$ over $\mathbf{Q}$

11. Determine all the subgroups of the Galois group and all of the intermediate fields of the splitting field (over Q) of the polynomial $(x^{3}-2)(x^{2}-3)\varepsilon\mathbf{Q}[x]$

12. Let $K$ be a subfield of the real numbers and $f\varepsilon K[x]$ an irreducible quartic. If $f$ has exactly two real roots, the Galois group of $f$ is $S_4$ or $D_{4}$

13. Assume that $f(x)\varepsilon K[x]$ has distinct roots $u_1,u_2,\ldots,u_n$ in the splitting field $F$ and let $G=\operatorname{Aut}_{\kappa}F<S_{n}$ be the Galois group of $f.$ Let $y_{1},\ldots,y_{n}$ be indeterminates and define:

------------------------------------------------------------------

「

$$g(x)=\prod_{\sigma\epsilon S_m}(x-(u_{\sigma(1)}y_1+u_{\sigma(2)}y_2+\cdots+u_{\sigma(n)}y_n))$$

(a)Show that

$$g(x)=\prod_{\sigma\in S_{n}}(x-(u_{1}y_{\sigma(1)}+u_{2}y_{\sigma(2)}+\cdots+u_{n}y_{\sigma(n)})).$$

(b) Show that $g(x)\varepsilon K[y_{1},\ldots,y_{n},x]$ (c) Suppose $g(x)$ factors as $g_{1}(x)g_{2}(x)\cdots g_{r}(x)$ with $g_i(x)\varepsilon K(y_1,\ldots,y_n)[x]$

monic irreducible. If $x-\sum_iu_{\sigma(i)})_i$ is a factor of $g_1(x)$ , then show that

$$g_{1}(x)=\prod_{\tau\epsilon G}(x-\sum_{i}u_{\tau\sigma(i)}y_{i}).$$

Show that this implies that deg $g_i(x)=|G|$ (d) If $K=\mathbf{Q}$ ， $f\varepsilon\mathbf{Z}[x]$ is monic, and $p$ is a prime, let $\bar{f}\varepsilon Z_{p}[x]$ be the poly

nomial obtained from $f$ by reducing the coefficients of $f({\mathrm{mod~}}p)$ .Assume $\bar{f}$ has distinct roots $\bar{u}_1,\ldots,\bar{u}_n$ un $\bar{u}_n$ in some splitting feld $\bar{F}$ over $Z_n$ .Show that

$$\bar{g}(x)=\prod_{\tau\in S_{n}}(x-\sum_{i}\bar{u}_{i}y_{\tau(i)})\:\varepsilon\:\bar{F}[x.y_{1},\ldots,y_{n}].$$

If the $\bar{u}_1$ are suitably ordered, then prove that the Galois group $\bar{G}$ of $\bar{f}$ is a sub group of the Galois group $G$ of $f.$ that has (e) Show
$$x^6+22x^5-9x^4+12x^3-37x^2-29x-15\varepsilon\mathbf{Q}[x]$$

Galois group $S_6$ . [Hint: apply (d) with $p=2$ , 3, 5.] (f)The Galois group of $x^{5}-x-1\varepsilon\mathbf{Q}[x]$ is $S_{5}$

14. Here is a method for constructing a polynomial $f\varepsilon\mathbf{Q}[x]$ with Galois group $S_n$ for a given $n>3$ .It depends on thefact that there exist irreducible polynomials of every degree in $Z_n[x]$ ( $p$ prime; Corollary 5.9 below). First choose $f_{1},f_{2},f_{3}\varepsilon\mathbf{Z}[x]$ such that:

(i) deg $f_{\mathrm{i}}=n$ and $\bar{f}_{1}\in Z_{2}[x]$ is irreducible (notation as in 13(d)) (i) deg $f_2=n$ and $\bar{f}_{2}\in Z_{3}[x]$ factors in $Z_3[x]$ as $gh$ with 8 an irreducible of

degree $n-1$ and $h$ linear; (i) deg $f_3=n$ and $\bar{f}_{3}\varepsilon Z_{5}[x]$ factors as gh or $gh_1h_2$ with $g$ an irreducible

quadratic in $Z_5[x]$ and $h,h_1,h_2$ irreducible polynomials of odd degree in $Z_5[x]$

(a) Let $f=-15f_1+10f_2+6f_3$ . Then $f\equiv f_{\mathrm{l}}$ (mod 2), $f\equiv f_2$ (mod 3), and $f\equiv f_3$ $f\equiv f_3$ $f\equiv f_3\left({\mathrm{mod~}}5\right)$ (b) The Galois group $G$ of $f$ is transitive (since $\bar{f}$ is irreducible in $Z_2[x]$

(c) $G$ contains a cycle of the type $\zeta=(i_{1}i_{2}\cdots i_{n-1})$ and element $\sigma\lambda$ where $\sigma$ isa

transposition and $\lambda$ a product of cycles of odd order.Therefore $\sigma\varepsilon G$ ,whence $(i_ki_n)\in G$ for some $k(1\leq k\leq n-1)$ by Exercise I.6.3 and transitivity (d) $G=S_n$ (see part (c) and Exercise I.6.4(b))

1

## 5. FINITE FIELDS

In this section finite felds (sometimes called Galois fields) are characterized in terms of splitting fields and their structure completely determined. The Galois group of an extension of a finite feld by a finite field is shown to be cyclic and its generator is given explicitly

------------------------------------------------------------------

Webegin with two theorems and a lemma that applytofields which need norbe fnite. In each case, of course, we are interested primarily in the implications for finite fields.

Theorem 5.1. Let F be a fieldand let P be the intersection of all subfields of F. Then P is a field with no proper subfields. If char $F=p$ (prime), then $\mathbf{P}\cong\mathbf{Z}_{\mathfrak{p}}$ .Ifchar $F=0$ then $\mathbb{P}\cong\mathbf{Q}$ , the field of rational numbers.

The field $P$ is called the prime subfeld of $F$

SKETCH OFPROOFOF 5.1.Note that every subfield of $F$ must contain 0 and $1_F$ .It followsreadily that $P$ is a field that has noproper subfields.Clearly $P$ contains all elements of the form $m1_F$ $(m\in\mathbf{Z})$ . To complete the proof one may either show directly that $P=\{m\mathbf{l}_F\mid m\in\mathbf{Z}\}$ if char $F=p$ and $P=\left\{(m1_{F})(n1_{F})^{-1}\mid m,n\in\mathbf{Z},\right.$ $n\neq0$ if char $F=0$ or one may argue as follows. By Theorem Il1.1.9 the map $\varphi:\mathbf{Z}\to P$ given by $m\mapsto m1_F$ is a ring homomorphism with kernel $(n)$ ，where $n=$ char $F$ and $n=0$ or $n$ is prime. If $n=p$ (prime), then $Z_p\cong\mathbf{Z}/(p)=\mathbf{Z}/$Ker $\varphi$ $\cong\operatorname{Im}\varphi\subset P$ Since $Z_p$ is a field and $P$ has no proper subfields, we must have $Z_{p}\cong\mathbf{Im}\:\varphi=P$ .If $n=0$ ，then $\varphi:\mathbf{Z}\to P$ is a monomorphism and by Corollary II1.4.6 there is a monomorphism of fields $\overline{\varphi}:\mathbf{Q}\to P$ .As before, we must have $\mathbf{Q}\cong\mathbf{Im}\:\overline{\varphi}=P$

Corollary 5.2. 1f F is a finite field, then char $\mathbf{F}=\mathbf{p}\neq0$ for some prime $p$ and $|\mathbf{F}|=\mathbf{p}^{\mathrm{n}}$ for some integer $n\geq1$

PROOF. Theorem I11.1.9 and Theorem 5.1 imply that $F$ has prime characteristic $p\neq0$ . Since $F$ is a finite dimensional vector space over its prime subfield $Z_{\prime\prime},F\cong Z_{p}\oplus\cdots\oplus Z_{p}$ (n summands) by Theorem IV.2.4 and hence $|F|=p^n$ .

In the sequel the prime subfield of a field $F$ of characteristic $p$ will always be identified with $Z_{p}$ under the isomorphism of Theorem 5.1. For example, we shall write $Z_{_{n}}\subset F$ ; in particular, $1_{k}$ coincides with $1\varepsilon Z_{\mu}$

Theorem 5.3. 1fF is afield and G is a finite subgroup of the multiplicatice group of nonzero elements of F, then G is u cyclic group. In particular, the multiplicatire group of all nonzero elements of a finite field is cyclic.

PROOF. 1f $G\left(\neq1\right)$ is a finite abelian group, $G\cong Z_{m_1}\oplus Z_{m_2}\oplus\cdots\oplus Z_{m_k}$ where $m_1>1$ and $m_{1}\mid m_{2}\mid\cdots\mid m_{k}$ by Theorem I1.2.1. Since $m_{k}(\sum Z_{m_{i}})=0$ , it follows that every ue $G$ is a root of the polynomial $\chi^{mk}-1_{F}\varepsilon F[x]$ $G$ is a multiplicative group) Since this polynomial has at most $m_k$ distinct roots in $F$ (Theorem I11.6.7), we must have $k=1$ and $G\cong Z_{mk}$ .

Corollary 5.4. 1f F is afinite field, then $F$ is a simple extension of its prime subfield $Z_{\mathrm{p}}$ ; that is, $\mathbf{F}=\mathbf{Z}_{\mathrm{p}}($u) for some u e F

------------------------------------------------------------------

SKETCH OF PROOF. Let $u$ be a generator of the multiplicative group of nonzero elements of $F$

Lemma 5.5.ifF is a fieldofcharacteristicp and $r\geq1$ is an integer,then the map

$\varphi:\mathcal{F}\to\mathcal{F}$ given by $u\vdash\mathbf{u}^{\mathrm{p}^{\mathrm{r}}}$ isa $\mathbf{Z}_{\mathrm{p}}$ -monomor phism of fields. 1f $F$ is finite, then $\varphi$ isa $Z_{\mathrm{D}}$ -automorphism of F

SKETCH OF PROOF. The key fact is that for characteristic $p$ ， $(u\pm v)^{n^r}$ $=u^{p^r}\pm c^{p^r}$ for all $u,v\in F$ F $F$ (Exercise III.1.11). Since $1_F\mapsto1_F$ $\varphi$ fixes each element in the prime subfeld $Z_p$ of $F$ .

We can now give a useful characterization of finite fields.

Proposition 5.6. Let p be a prime and $n\geq1$ an integer. Then F is a finite field with $p^n$ elements if and only if F is a splitting field of $x^{p^{n}}-x$ over $Z_{\mathrm{p}}$

PROOF. If $|F|=p^{n}$ , then the multiplicative group of nonzero elements of $F$ has order $p^n-1$ and hence every nonzero $u\equiv F$ satisfies $u^{p^{n-1}}=1_{F}$ . Thus every nonzero $u\varepsilon F$ is a root of $x^{p^{n-1}}-1_{F}$ and therefore a root of $x(x^{p^{n-1}}-1_{F})=x^{\eta^{n}}-x\in Z_{p}[x]$ as well. Since $0\varepsilon F$ is also a root of $x^{\eta^{n}}-x,x^{p^{n}}-x$ has $p^n$ distinct roots in $F$ (that is, it splits over $F$ by Theorem Ill.6.7) and these roots are precisely the elements of $F$ Therefore, $F$ is a splitting field of $x^{n^n}-x$ over $Z_n$ If $F$ is a splitting field of $f=x^{\imath,n}-x$ over $Z_n$, then since char $F=$ char $Z_n=p$

$f^{\prime}=-1$ and $f$ is relatively primeto $f^{\prime}$ . Therefore $f$ has $p^{n}$ distinct roots in $F$ by Theorem I1I1.6.10(ii). If $\varphi$ is the monomorphism of Lemma 5.5 (with $r=n$ O, it is easy to see that $u\varepsilon F$ F $F$ is a root of fif and only if $\varphi(u)=u$ .Use this fact to verify that the set $E$ of all roots of $f$in $F$ $F$ F is a subfield of $F$ of order $p^n$ , which necessarily contains the prime subfield $Z_{p}$ of $F.$ Since $F$ is a splitting field, it is generated over $Z_{\nu}$ by the roots of $f$ (that is, the elements of $E$ ). Therefore, $F=Z_{n}(E)=E$ .

Corollary 5.7. If p is a prime and $n\geq1$ an integer, then there exists a field with $p^n$ elements. Any two finite fields with the same number of elements are isomorphic

PROOF. Given $p$ and $n$ , a splitting feld $F$ of $x^{n}-x$ over $Z_{\nu}$ exists by Theorem 3.2 and has order $p^n$ by Proposition 5.6. Since every finite feld of order $P^{n}$ is a splitting feld of $x^{\nu^{n}}-x$ over $Z_p$ by Proposition 5.6, any two such are isomorphic by Corollary 3.9.

Corollary 5.8. If K is a finite field and $n\geq1$ is an integer, then there exists a simple extension field $\mathbf{F}=\mathbf{K}($u) $of$ $\mathbf{K}$ such thar F is finite and $[F:K]=n$ . Any two n-dimen sional extension fields of K are K-isomorphic.

------------------------------------------------------------------

SKETCH OF PROOF. Given $K$ of order $p^r$ let $F$ be a splitting field of $f=x^{prn}-x$ over $K$ .By Proposition 5.6 every $u$ E $K$ satisfies $u^{p^{\prime}}=u$ and it follows inductively that $u^{p^{rn}}=u$ for all $u\varepsilon K$ K $K$ . Therefore, $F$ is actually a splittingfield of fover $Z_p$ (Exercise 3.3). The proof of Proposition 5.6 shows that $F$ consists of precisely the $p^{nr}$ distinct roots of $f.$ Thus $p^{nr}=|F|=|K|^{[F:K]}=(p^{r})^{[F:K]}$ ,whence $[F:K]=n$ Corollary 5.4 implies that $F$ is a simple extension of $K$ .If $F_{\mathrm{l}}$ is another extension field of $K$ with $[F_1:K]=n$ ，then $[F_1:Z_p]=n[K:Z_p]=nr$ ，whence $|F_{1}|=p^{nr}$ .By Proposition $5.6F_{1}$ is a splittingfield of $\chi^{p^{nr}}-x$ over $Z_p$ and hence over $K$ .Consequently, $F$ and $F_{1}$ are $K.$ -isomorphic by Corollary 3.9.

Corollary 5.9. IfK is a finite field and $n\geq1$ an integer,then there exists an irreducible polynomial of degree n in K[x].

PROOF. Exercise; use Corollary 5.8 and Theorem 1.6.

Proposition 5.10. If F is a finite dimensional extension field ofa finite field K, then F is finite and is Galois over K. The Galois group $Aut_KF$ is cyclic.

SKETCH OF PROOF. Let $Z_p$ be the prime subfield of $K$ . Then $F$ is finite dimensional over $Z_i$ (Theorem 1.2),say of dimension $n$ ,which implies that $|F|=p^{n}$ By the proof of Proposition 5.6 and Exercise $3.2F$ is a splitting feld over $Z_p$ and hence over $K$ ,of $\chi^{p^n}-x$ , all of whose roots are distinct. Theorem 3.11 implies that $F$ is Galois over $K$ . The map $\varphi:F\to F$ given by $u\vdash u^p$ is a $Z_{p}$ -automorphism by Lemma 5.5. Clearly $\varphi^n$ is the identity and no lower power $k$ of $\varphi$ can be the identity (for this would imply that $\chi^{p^k}-x$ had $p^{n}$ distinct roots in $F$ with $k<n$ , contradict ing Theorem I11.6.7). Since $\left|\mathrm{Aut}_{Z_p}F\right|=n$ by the Fundamental Theorem, $Aut_{Z_\mu}F$ must be the cyclic group generated by $\varphi$ . Since $Aut_KF$ is a subgroup of $Autz_pF$ $Aut_KF$ is cyclic by Theorem I.3.5.

## EXERCISES

Note: $F$ always denotes an extension field of a feld $K$

1. If $K$ is a fnite field of characteristic $p$ ,describe the structure of the additive group of $K$ 2. (Fermat) If $p\in\mathbf{Z}$ is prime, then $a^p=a$ for all $a\varepsilon Z_{\rho}$ or equivalently, $C^{p}\equiv c$ (mod $p$ ）for all $c\varepsilon Z$ 3.If $|K|=p^{n}$ ,then every element of $K$ has a unique pth root in $K$ 4. If the roots of a monic polynomial $f\varepsilon K[x]$ (in some splitting field of $f$ over $K$ are distinct and form a feld, then char $K=p$ and $f=x^{\nu^{n}}-x$ for some $n\geq1$ 5. (a) Construct a field with 9 elements and give its'addition and multiplication tables. (b) Do the same for a field of 25 elements. 6.If $|K|=q$ and $(n,q)=1$ and $F$ is a splitting field of $x^{n}-1_{K}$ over $K$ , then $[F:K]$ is the least positive integer $k$ such that $n\mid(q^k-1)$

------------------------------------------------------------------

7. If $|K|=u$ and $f\varepsilon K[x]$ is irreducible, then $f$ divides $x^{q^n}-x$ if and only if deg $f$ divides $n$

8. If $|K|=p^{r}$ and $|F|=p^{n}$ , then $r\mid n$ and $Aut_KF$ is cyclic with generator $\varphi$ given by $u\vdash u^{p^{r}}$

9. If $n\geq3.$ , then $x^{2^n}+x+1$ is reducible over $\mathbb{Z}_2$

10. Every element in a finite field may be written as the sum of two squares

11. Let $F$ be an algebraic closure of $Z_p$ $ip$ prime). (a) $F$ is algebraic Galois over $Z_p$

(b) The map $\varphi:F\to F$ given by $u\vdash u^p$ is a nonidentity $Z_n$ -automorphism of $F$ (c)The subgroup $H=\langle\varphi\rangle$ is a proper subgroup of $Aut_{Z_p}F$ whose fixed field is $Z_{p}$, which is also the fixed field of $Autz_pF$ by (a).

12.If $K$ is finite and $F$ is an algebraic closure of $K$ , then $Aut_KF$ is abelian. Every element of $Aut_kF$ $\kappa F$ KF (except $1_{h}$ )has infinite order.

## 6. SEPARABILITY

Our study of separability will be greatly facilitated by the simultaneous consideration of a concept that is, in a sense, the complete opposite of separability. Consequently the section begins with purely inseparable extensions, which are characterized in several different ways in Theorem 6.4. These ideas are then used to prove all the important facts about separability of algebraic extensions (principally Theorem 6.7). The degree of (in)separability of an algebraic extension is discussed in detail (most of this material, however, is not needed in the sequel). Finally the Primitive Elenient Theorem is proved (Proposition 6.15). This result is independent of the rest of the section and may be read at any time.

Definition 6.1. Let F be an extension fieldof K. An algebraic element u e F is purely inseparable over K ifits irreducible polynomial f in $K[x]$ factors in F[x] as $\mathbf{f}=(\mathbf{x}-\mathbf{u})^{\mathrm{m}}$ $F$ is $a$ purely inseparable extension of K if erery element of F is purely inseparable over K.

Thus $u$ is separable over Kif its irreducible polynomial fof degree n has $n$ distinct roots (in some splitting field) andpurely inseparable over $K$ if $f$ has precisely one root. It is possible to have an element that is neither separable nor purely inseparable over $K$

1

Theorem 6.2.Let F be an extension field ofK.Then ue F is both separable and purely inseparable over K if and only if u e K

PROOF. The element $u\varepsilon F$ is separable and purely inseparable over $K$ if and only if its irreducible polynomial is of the form $(x-u)^m$ and has $m$ distinct roots in some splitting field. Clearly this occurs only when $m=1$ so that $x-u\in K[x]$ and $u\in K$

1

------------------------------------------------------------------

If char $K=0$ , then every algebraic element over $K$ is separable over $K$ .Therefore, Theorem 6.2 implies that the only elements that are purely inseparable over $K$ are the elements of $K$ itself. Thus purely inseparable extensions of $K$ are trivial if char $K=0$ .Consequently, we usually restrict our attention to the case of nonzero (prime) characteristic. We shall frequently use the following fact about characteristic $P$ without explicit mention: if char $K=p\neq0$ and $u,v\in K$ K $K$ , then $(u\pm v)^{p^n}=u^{p^n}\pm v^{p^n}$ for all $n\geq0$ (Exercise III.1.11). In order to characterize purely inseparable extensions we need:

Lemma 6.3. Let F be an extension field of K with char $\mathbf{K}=\mathbf{p}\neq0$ .IfueF is algebraic orer K, then $u^\mathrm{pn}$ is separable ocerKfor sone $n\geq0$

SKETCH OF PROOF.Use induction on the degree of $u$ over $K$ :If deg $u=1$ or $u$ is separable, the lemma is true. If $f$ is the irreducible polynomial of a nonseparable $u$ of degree greater than one, then $f^{\prime}=0$ (Theorem III.6.10), whence $f$ is a polynomial in $x^p$ (Exercise II1.6.3). Therefore, $u^p$ is algebraic of degree less than deg $u$ over $K$ ,whence by induction $(u^p)^{p^m}$ is separable over $K$ for some $m\geq0$ .

Theorem 6.4.IfF is un algebraic extension field ofu field K ofcharucteristic $p\neq0$ then the following statements are eyuicalent.

(i) F is purely inseparable ocer K; (i) the irreducible polynomial of any u eF is of the form $x^{p^n}-$ ae $K[x]$ (ii) ifue F, then $u^\mathrm{pn}\varepsilon K$ for some $n\geq0$ (iv)the only elements ofF which are separable over K are the elements ofK itself (v)F is generated orer K by a set of purely inseparable elements.

SKETCH OF PROOF OF 6.4.( = $\Longrightarrow$ (i$) \Rightarrow ($ii) Let $(x-u)^{m}$ be the irreducible poly nomial of $u\varepsilon F$ and let $m=np^r$ with $(n,p)=1$ . Then $(x-u)^{m}=(x-u)^{p^{r}n}$ $=(x^{p^r}-u^{p^r})^n$ by Exercise III.1.11. Since $(x-u)^{m}\in K|x|$ , the coefficient of $\chi^{p^r(n-1)}$ namely $\pm nu^{p^r}$ (Theorem III.1.6), must lie in $K$ .Now $(p,n)=1$ implies that $u^{p^r}\varepsilon K$ (Exercise 1). Since $(x-u)^{m}=(x^{n^{r}}-u^{p^{r}})^{n}$ is irreducible in $K[x]$, we must have $n=1$ and $( x- u) ^{\eta _{\iota }}=$ $\chi ^{p^{\tau }}- a$ ,where $a=u^{p^{r}}\varepsilon K$ The implications (ii$) \Rightarrow ($iii) and (i$) \Rightarrow ($v) are trivial. (iii$) \Rightarrow ($i) by Exercise

111.1.11; (i$) \Longrightarrow ($iv) by Theorem 6.2; and (iv$)\Longrightarrow($iii) by Lemma6 $5.3.(\mathbf{v})\Rightarrow$ (i) If $u$ is purely inseparable over $K$ , then the proof of (i$) \Longrightarrow ($ii) shows that $u^{p^n}\in K$ for some $n\geq0$ If $u\varepsilon F$ is arbitrary use Theorem 1.3 and Exercise Ill.1.11.

Corollary 6.5. If F is a finite dimensionul purely inseparable extension field of K and char $\mathbf{K}=\mathbf{p}\neq0$ then $[\mathcal{F}:\mathbf{K}]=\mathbf{p}^{n}$ for some $n\geq0$

PROOF. By Theorem 1.11 $F=K(u_1,\ldots,u_m)$ . By hypothesis each $u_{i}$ is purely inseparable over $K$ and hence over $K(u_{1},\ldots,u_{i-1})$ as well (Exercise 2). Theorems 1.6 and 6.4(i)imply that every step in thetower $K\subset K(u_1)\subset K(u_1,u_2)\subset\cdots\subset$ $K(u_1,\ldots,u_m)=F$ has dimension a power of $P$ . Therefore $[F:K]=p^{n}$ by Theo rem 1.2.

------------------------------------------------------------------

One more preliminary is needed for the principal theorem on separability.

Lemma 6.6 If F is an extension field of K. $X$ is a subset ofFsuchthat $\mathbf{F}=\mathbf{K}(\mathbf{X})$ and every element of $X$ is separable over $K$ ,then $F$ is a separable extension of K.

PROOF. If $\upsilon\varepsilon F$ then there exist $u_1,\ldots,u_n\in X$ such that $c\in K(u_{1},\ldots,u_{n})$ by Theorem 1.3. Let $f_{i}\in K[x]$ be the irreducible separable polynomial of $u_{i}$ and $E$ a splitting feld of $\{f_{1},\ldots,f_{n}\}$ over $K(u_{1},\ldots,u_{n})$ . Then $E$ is also a splitting feld of $\{f_1,\ldots,f_n\}$ over $K$ (Exercise 3.3). By Theorem 3.11 $E$ is separable (in fact Galois) over $K$ , which implies that $v\in K(u_1,\ldots,u_n)\subset E$ is separable over $K$ .

Theorem 6.7.Ler F be an algebraic exiension fieldofK,S the set ofall elements of F which are separable over K, and. $P$ the set of all elements.of F which are purely in separable over K.

(i) S is a separable extension field ofK. (ii)F is purely inseparable over S. (ii) $P$ is a purely inseparable extension field of K. (iv) P ∩ $S=K$ (v) F is separable orer P if and only if $\mathbf{F}=\mathbf{SP}$ (vi) If F is normal over K, then S is Galois ocer K,F is Galois over P and $Aut_\mathrm{K}$S$\cong$ $Aut_{\mathrm{P}}$F$=Aut_\mathrm{K}$F

REMARKS. It is clear that $S$ is the unique largest subfield of $F$ separable over $K$ and that $S$ contains every intermediate field that is separable over $K$ ; similarly for $P$ and purely inseparable intermediate fields. If char $K=0$ ,then $S=F$ and $P=K$ (Theorem 6.2).

SKETCH OF PROOF OF 6.7. (i) If $lu$ $\upsilon\varepsilon S$ and $v\neq0$ , then $K(u,v)$ is separable over $K$ by Lemma 6.6, which implies that $u-v,uc^{-1}\varepsilon S$ . Therefore, $S$ is a subfeld Lemma 6.3 and Theorem 6.4 imply (i). (ii) is a routine exercise using Exercise I1I.1.11 if char $K=p$ and the fact that $P=K$ ifchar $K=0$ . Theorem 6.2 implies (iv) (v) If $F$ is separable over $P$ , then $F$ is separable over the composite fielde $SP$ (Exer-

cise 3.12) andpurely inseparable over $SP$ ((i) and Exercise 2). Therefore, $F=SP$ by Theorem 6.2. Conversely, if. $F=SP=P(S)$ ,then $F$ is separable over $P$ by Exercise 3.12 and Lemma 6.6. (vi) We show first that the fixed feld $K_0$ of $Aut_kF$ is in fact $P$ , which immediately

implies that $F$ is Galois over $P$ and Aut ${}_{P}F={}{}_{\mathrm{Aut}_{h}}F.$ Let $u\varepsilon F$ have irreducible polynomial $f$ over $K$ and let $\sigma\in\mathrm{Aut}_{h}F$ $\sigma(u)$ is a root of $f$ (Theorem 2.2). If $u\varepsilon P$ ,then $f=(x-u)^{m}$ and hence $\sigma(u)=u$ Therefore, $P\subset K_0$ . If $u\in K_0$ and $\upsilon\varepsilon F$ is any other root of $f$, then there is a $K$ -isomorphism $\tau:K(u)\to K(v)$ such that $\tau(u)=v$ (Corollary 1.9). By Theorems 3.8 and 3.14 and Exercise. $3.2\tau$ extends to a $K$ -automorphism of $F$ Since $u\varepsilon K_0$ $K_0$ Ko ,wehave $u$ = $\tau ( u)$ = $v$ .Since $f$ splits in $F[x]$ by normality, this argument shows that $f=(x-u)^m$ for some $m$ . Therefore, $u\in P$ P $P$ and $P\supset K_0$ .Hence $P=K_{0}$ Every $\sigma\varepsilon\mathrm{Aut}_{P}F=\mathrm{Aut}_{K}F$ must send separable elements to separable elements

(Theorem 2.2). Therefore, the assignment $\sigma\vdash\sigma\mid S$ defines a homomorphism $\theta:\mathbf{Aut}_PF\to\mathbf{Aut}_{\kappa}S$ Since $F$ is normal over $S$ S $S,\theta$ 0 $\theta$ is an epimorphism (Theorems 3.8

------------------------------------------------------------------

and 3.14 and Exercise 3.2). Since $F$ is Galois over $P$ $F=SP$ by (v), which implies that $\theta$ is a monomorphism.Hence $\mathsf{Aut}_PF\cong\mathsf{Aut}_hS$ . Finally suppose. $u\in S$ is fixed by all $\sigma\in\mathbf{Aut}_{k}\boldsymbol{S}$ Since $\theta$ is an epimorphism, $u$ is in the fixed field $P$ of $Aut_PF$ ，whence $u\in P\cap S=K$ Therefore, $S$ is Galois over $K$ .■

Corollary 6.8.IfF is a separableextension fieldof EandE is a separable extension fieldof $K$ ,then $F$ is separuble orer K..

PROOF. If $S$ is as in Theorem 6.7, then $E\subset S$ and $F$ is purely inseparable over $S$ .But $F$ is separable over $E$ and hence over $S$ (Exercise 3.12). Therefore, $F=S$ by Theorem 6.2.

Let $F$ be a field of characteristic $p\neq0$ . Lemma 5.5 shows that for each $n\geq1$ ,the set $F^{\eta^{\prime\prime}}=\left\{\begin{array}{c}{u^{\eta^{\prime}}}\\{u\in F}\end{array}\right\}$ is a subfield of $F$ .By Theorem 6.4 (ii), $F$ is purely inseparable. over $F_{1},^{n}$ and hence over any intermediate field as well (Exercise 2)..

Corollary 6.9. Let F be an algebraic extension field of K, with char $\mathbf{K}=\mathbf{p}\neq0$ .IfF is separable orerK,then $\mathbf{F}=\mathbf{KF}^{\mathrm{p}^{\mathrm{n}}}f$ oreach $n\geq1$ .If $[F:K]$ isfinite and $\mathbf{F}=\mathbf{KF}$ then F is separable orer K. In particular, u ε F is separable ocer K if and only $if$ $\mathbf{K}(\mathbf{u}^{\mathrm{p}})=\mathbf{K}(\mathbf{u})$

SKETCH OF PROOF. Let $S$ be as in Theorem 6.7. If $[F:K]$ is fnite, then $F=K(u_1,\ldots,u_n)=S(u_1,\ldots,u_m)$ by Theorem 1.11. Since each $lu_i$ is purely inseparable over $S$ (Theorem 6.7), there is an $n\geq1$ such that $u_i^{\prime\prime}\varepsilon S$ for every i. Since $F=S(u_1,\ldots,u_m)$ um $u_{m}$, ,Exercise Il1.1.11 and Theorem 1.3 imply that $F^{p^n}\subset S$ Clearly every element of $S$ is purely inseparable over $F^{p^n}$ , and hence over $KF^{p^n}$ $S$ is separable over $K$ , and hence over $KF^{p^n}$ . Therefore $S=KF^{p^n}$ by Theorem 6.2. Use the fact that char $K=p$ and Theoreim1.3 to show that for any $1\geq1$ ， $F^{p^l}=$ $[K(u_{1},\ldots,u_{m})]^{p^{t}}=K^{p^{t}}(u_{1}^{p^{t}},\ldots,u_{m}^{p^{t}})$ . Consequently for any $1\geq1$ we have $KF^{p^t}=K(K^{p^t}(u_1^{p^t}$ KFv' = K(KP'(u)p) $KF^{\nu^{t}}=K(K^{p^{t}}(u_{1}^{p^{t}},\ldots,u_{m}^{p^{t}})=K(u_{1}^{p^{t}},\ldots$, umb') =K(uo',... , $u_{m}{}^{p^{l}})=K(u_{1}{}^{p^{l}},\ldots,u_{m}{}^{p^{l}})$ . Note that this argument works for any generators $u_1$ u1 $u_{1},\ldots,u_{m}$ $u_{m}$ Um of $F$ over $K$ . Now if $F=KF^{p}$ ，then $K(u_{1},\:.\:.\:.\:,\:u_{m})\:=\:F\:=\:KF^{n}\:=\:K(u_{1}^{\rho}$ ..... $u_m^{p}$ ). An iterated argument with the generators $u_i^{\nu^l}$ in place of $u_i\left[t\:=\:1,\:2,\:\ldots\:,\:n\right]$ shows that $F=K(u_1,\ldots,u_m)=$ um）= $u_m)=$ $K(u_1^{p^{\prime\prime}}$ .···. $u_{m}^{p^{n}})=KF^{p^{n}}=S$ , whence $F$ is separable over $K$ . Conversely, if $F$ is separable over $K$ , then $F$ is both separable and purely inseparable over $KF^{p^n}$ (for any $n\geq1;$ . Therefore $F=KF^{p^n}$ by Theorem 6.2.

Next we consider separability and inseparability from a somewhat different point of view. Although Proposition 6.12 is used at one point in Section 7, all that is really essential for understanding the sequel is Detinition 6.10 and the subsequent remarks..

Definition 6.10. Let F be un ulgebruic extension field of K und S the lurgest subfield. of F sepuruble orer K (us in Theorem 6.7). The dimension. $|S:K]$ is culled the separable. degree of F ocer K and is denoted $[F:K]_s$ .The dimension $[F:\mathbb{S}]$ is calledtheinseparable degree (or degree of inseparability) of $F$ orer K and is denoted $|F:K|_i$

REMARKS. $[F:K]_{,}=[F:K]$ and $[F:K]_{t}=1$ if and only if $F$ is separable over $K.[F:K]_{\mathrm{s}}=1$ and $[F:K],\:=[F:K]$ if and only if $F$ is purely inseparable over $K$ . In

------------------------------------------------------------------

any case, $[F:K]=[F:K]_s[F:K]_i$ by Theorem 1.2. If $[F:K]$ is finite and char $K$ $=p\neq0$ , then $[F:K]_i$ is a power of $p$ by Corollary 6.5 and Theorem 6.7(ii). The following lemma will enable us to give an alternate description of $[F:K]_s$ and to show that for any intermediate field $E$ $[F:E]_a[E:K]_a=[F:K]_a$

Lemma 6.11. Let F be an extension field of E, E an extension field of K and N a normal extension field of K containing F. If r is the cardinal number of distinct E-monomorphisms $\mathbf{F}\to\mathbf{N}$ and t is the cardinal number o f distinct K-monomorphisms. $E\to\mathbb{N}$ then rt is the cardinal number of distinct K-monomorphisms $\mathbf{F}\to\mathbf{N}$

PROOF. For convenience we assume that $r$ ,I are finite. The same proof will work in the general case with only slight modifications of notation. Let $\tau_1,\ldots,\tau_r$ be all the distinct $E$ -monomorphisms $F\to N$ and $\sigma_1,\ldots,\sigma_l$ all the distinct $K$ -monomorphisms $E\to N.$ Each $\sigma_i$ extends to a $K$ -automorphism of $N$ (Theorems 3.8 and 3.14 and Exercise 3.2) which will also be denoted $\sigma_i$ . Each composite map $\sigma_i\tau_j$ is a $K.$ -monomorphism $F\to N$ . If $\sigma_{i}\tau_{j}=\sigma_{a}\tau_{b}$, then $\sigma_{a}^{-1}\sigma_{i}\tau_{j}=\tau_{b}$ which implies that $\sigma_{a}^{-1}\sigma_{i}\mid E=1_{E}$ . Consequently, we have $\sigma_{i}=\sigma_{a}$ and $i=a$ . Since $\sigma_i$ is injective $\sigma_{i}\tau_{j}=\sigma_{i}\tau_{b}$ implies that $\tau_{j}=\tau_{b}$ and $j=b$ .Therefore, the rt $K$ -monomorphisms $\sigma_{i}\tau_{j}:F\to N(1\leq i\leq\iota,1\leq j\leq r)$ are all distinct. Let $\sigma:F\to N$ be any $K$ -monomorphism. Then $\sigma\mid E=\sigma_{i}$ for some $i$ and $\sigma_i^{-1}\sigma$ is a $K$ -monomorphism $F\to N$ which is the identity on $E$ . Therefore, $\sigma_{i}^{-1}\sigma=\tau_{i}$ for some $j.$ whence $\sigma=\sigma_{i}\tau_{i}$ .Thus the $rt$ distinct maps $\sigma_i\tau_j$ are all of the $K$ -monomorphisms $F\to N.$ ■

Proposition 6.12. Let F be a finite dimensional extension field of K and N a normal. extersion field ofK containing F. The number of distinct K-monomorphisms $\mathbf{F}\to\mathbf{N}$ is precisely $[F:K]_{\mathrm{в}}$, the sepurable degree of F over K.

SKETCH OF PROOF.Let $S$ be the maximal subfield of $F$ separable over $K$ (Theorem 6.7(i)). Every $K$ -monomorphism $S\to N$ extends to a $K$ automorphism of $N$ (Theorems 3.8 and 3.14 and Exercise 3.2) and hence (by restriction) to a $K$ -monomorphism $F\to N$ We claim that the number of distinct $K.$ -monomorphisms $F\to N$ is the same as the number of distinct $K$ -monomorphisms $S\to N$ .This is trivially true if char $K=0$ since $F=S$ in that case. So let char $K=p\neq0$ and suppose $\sigma$ $\tau$ are $K.$ -monomorphisms $F\to N$ such that $\sigma\mid S=\tau\mid S$ .If $u\varepsilon F$ , then $u^{p^n}\varepsilon S$ for some $n\geq0$ by Theorems 6.4 and 6.7(ii). Therefore,

$$\sigma(u)^{p^{n}}=\:\sigma(u^{p^{n}})\:=\:\tau(u^{p^{n}})\:=\:\tau(u)^{p^{n}},$$

whence $\sigma(u)=\tau(u)$ . Thus $\sigma\mid S=\tau\mid S$ implies $\sigma=\tau$ , which proves our claim. Con- sequently, it suffices to assume that $F$ is separable over $K$ (that is, $F=S.$ ), in which case we have $[F:K]=[F:K]_{s},[F:E]=[F:E]_{s}$ and $[E:K]=[E:K]_{s}$ for any intermediate field $E$ (Exercise 3.12). Proceed now by induction on $n=[F:K]=[F:K]$, with the case $n=1$ being

trivial. If $n>1$ choose u& $F-K$ ; then $[K(u):K]=r>1$ . If $r<n$ use the induction hypothesis and Lemma 6.11 (with $E=K(u)$ ）to prove the theorem. If $r=n$ then $F=K(u)$ and $[F:K]$ is the degree of the (separable) irreducible polynomial $f\boldsymbol{\varepsilon}K[x]$ of $u$ . Every $K.$ monomorphism $\sigma:F\to N$ is completely determined by $v=\sigma(u)$

------------------------------------------------------------------

Since $v$ is a root of $f$ (as in Theorem 2.2) there are at most $[F:K]=\deg f$ such $K$ monomorphisms. Since $f$ splits in $N$ by normality and is separable, Corollary 1.9 shows that there are exactly $[F:K]$ distinct $K$ -monomorphisms $F\to N$ .

Corollary 6.13. IfF is an extension field ofE and E is an extension field of K, then

$[F:E]_{\bullet}[E:K]_{\bullet}=[F:K]_{\bullet}$ and $[F:E],[E:K]_{i}=[F:K]_{i}$

PROOF. Exercise: use Lemma 6.11 and Proposition 6.12.

Corollary 6.14. Let f e $K[x]$ be an irreducible monic polynomial ocer a field K,F a splitting field of f over K and. $u_1$ a root of f in F. Then

(i) erery root of f has multiplicity. $[K(u_1):K]_i$ so that in $F[x]$

$$\mathbf{f}=[(\mathbf{x}-\mathbf{u}_{1})\cdots(\mathbf{x}-\mathbf{u}_{n})]^{[\mathbf{K}(\mathbf{u}_{1})\cdot\mathbf{K}]_{i}},$$

where $\mathbf{u}_1,\ldots,\mathbf{u}_n$ are all the distinct roors off and $\mathbf{n}=[\mathbf{K}(\mathbf{u}_{1}):\mathbf{K}]$, (i) $u_{1}^{[K(u_{1})\:K]_{i}}$ is separable over K.

SKETCH OF PROOF. Assume char $K=p\neq0$ since the case char $K=0$ is trivial. (i) For any $i>1$ there is a $K$ -isomorphism $\sigma:K(u_1)\cong K(u_{,})$ with $\sigma(u_1)=u_i$ that extends to a $K$ -isomorphism $\sigma$ of $F$ (Corollary 1.9, Theorem 3.8, and Exercise 3.2). Since $f\varepsilon K[x]$ we have by Theorem 2.2

$$(x-u_1)^n\cdots(x-u_n)^n=f=\sigma f=(x-\sigma(u_1))^n\cdots(x-\sigma(u_n))^n.$$

Since $u_1,\ldots,u_n$ are distinct and $\sigma$ is injective, unique factorization in $K[x]$ implies that $(x-u_{1})^{r_{1}}=(x-\sigma(u_{1}))^{r_{1}}$ ,whence $r_1=r_1$ . This shows that every root of $f$ has multiplicity $r=r_1$ so that $f=(x-u_{1})^{r}\cdots(x-u_{n})^{r}$ and $[K(u_1):K]=\deg f=nr$ Now Corollary 1.9 and Theorem 2.2 imply that there are $n$ distinct $K$ -monomorphisms $K(u_1)\to F$ ,whence $[K(u_1):K]_n=n$ byProposition 6.12 and Theorem 3.14. Therefore,

$$[K(u_1):K]_i=[K(u_1):K]/[K(u_1):K]_s=nr/n=r.$$

(i) Since $r$ is a power of $p=$char $K$ $K$ K ,we have $f=(x-u_1)^r\cdots(x-u_n)^r=$ $(x^{r}-u_{1}^{r})\cdots(x^{r}-u_{n}^{r})$ . Thus $f$ is a polynomial in $x^r$ with coefficients in $K$ ,say $f=\sum_{i=0}^nu_ix^{ri}$ . Conseq uen ly, $u_1r$ is a root of $g( x)$ $= \sum _{i= 0}^{n}a_{i}x^{i}= ( x- u_{1}^{r})$ $(x-u_{n}^{r})$ E $K[x]$ . Since $u_1,\ldots,u_n$ are distinct, $g(x)\in K[.x]$ is separable. Therefore $u_{1}^{r}=$ $u_{1}^{[K\:u_{1})\:K]_{i}}$ is separable over $K$ .■

The following result is independent of the precedingmaterial and is not needed in the sequel.

Proposition 6.15. (Primitire Element Theorem) Let F be a finite dimensional ex tension field of K

------------------------------------------------------------------

(i) IfF is separable over $K$ ,then $F$ is a simple extension ofK. (i) (Artin) More generally,F is a simple extension ofK if andonly ifthere are only finitely many intermediate fields.

REMARK. An element u such that $F=K(u)$ is said to be primitive.

SKETCH OF PROOF OF 6.15. The first paragraph of the proof of Lemma 3.17, which is valid even if the field $K$ is finite, shows that a separable extension has only finitely many intermediate fields. Thus it suffices to prove (i). Since (ii) clearly holds if $K$ is finite (Corollary 5.8), we assume that $K$ is infnite. One implication of (ii) is proved in the second paragraph of the proof of Lemma 3.17. Conversely assume $F=K(u)$ with $u$ algebraic over $K$ (since $[F:K]$ is finite). Let $E$ be an intermediate feld and $g\in E[x]$ the irreducible monic polynomial of $u$ over $E$ . If $g=x^{n}+a_{n-1}x^{n-1}$ $+\cdots+a_1x+a_0$, then $[F:E]=n$ . Show that $E=K(a_{0},a_{1},\ldots,a_{n-1})$ by verifying that $[F:K(a_0,\ldots,a_{n-1})]=n$ .Thus every intermediate field $E$ is uniquely determined by the irreducible monic polynomial $g$ of $u$ over $E$ . If fis the monic irreducible polynomial of $u$ over $K$ , then $g|f$ by Theorem 1.6. Since $f$ factors uniquely in any splitting field (Corollary I11.6.4), fcan have only a finite number of distinct monic divisors. Consequently, there are only a finite number of intermediate fields.

### EXERCISES

Note: Unless stated otherwise $F$ is always an extension feld of a feld $K$

1. Let char $K=p\neq0$ and let $n\geq1$ be an integer such that $(p,n)=1$ .Ifre $F$ and $nv\varepsilon K$ $K$ K ,then $\upsilon\varepsilon K$ 2. If $u\varepsilon F$ is purely inseparable over $K$ , then $lu$ is purely inseparable over any inter. mediate field $E$ . Hence if $F$ is purely inseparable over $K$ , then $F$ is purely inseparable over $E$ 3.If $F$ is purely inseparable over an intermediate field $E$ and $E$ is purely inseparable over $K$ ,then $F$ is purely inseparable over $K$ 4. If $u\varepsilon F$ is separable over $K$ and $\iota\varepsilon F$ is purely inseparable over $K$ ，then $K(u,r)=K(u+c)$ .If $u\neq0$ $c\neq0$ , then $K(u,v)=K(uv)$ 5. If char $K=\eta\neq0$ and $u\in K$ but $a\notin K^{\prime\prime}$ 、 then $x^{\prime\prime\prime}-u\equiv K[.x]$ is irreducible for every $n>1$ 6.If $f\boldsymbol{\varepsilon}K[x]$ is monic irreducible, $\mathbf{deg}f\geq2$ , and fhas all its roots equal (in a splitting feld), then char $K=p\neq0$ and $f=x^{p^{n}}-a$ for some $n\geq1$ and $a\in K$ 7. Let $F,K,S,P$ be as in Theorem 6.7 and suppose $E$ is an intermediate field. Ther (a) $F$ is purely inseparable over $E$ if and only if $S\subset E$ (b) If $F$ is separable over $E$ , then $P\subset E$ (c) If $E\cap S=K$ , then $E\subset P$ 8. If char $K=p\neq0$ and $[F:K]$ is finite and not divisible by $p$ ,then $F$ is separable over $K$ 9. Let char $K=p\neq0$ . Then an algebraic element $11\div F$ is separable over $K$ if and only if $K(u)=K(u^{n^n})$ for all $n\geq1$

------------------------------------------------------------------

10. Let char $K=\mu\neq0$ and let $f\varepsilon K[x]$ be irreducible of degree $n$ . Let $m$ be the largest nonnegative integer such that $f$ is a polynomial in $\chi^{p}^{m}$ but is not a polynomial in $x^{p^{m+1}}$ . Then $n=n_{0}p^{m}$ . If $u$ is a root of $f$, then $[K(u):K]_s=n_0$ and $[K(u):K]_{i}=p^m$

11.If $f\varepsilon K[x]$ is irreducible of degree $m>0$ ,and char $K$ does not divide $m$ ,then fis separable.

12. $F$ is purely inseparable over $K$ if and only if $F$ is algebraic over $K$ and for any ex tension field $E$ of $F$ ，the only $K$ -monomorphism $F\to E$ is the inclusion map

13. (a) The following conditions on a field $K$ are equivalent:

(i) every irreducible polynomial in $K[x]$ is separable; (ii) every algebraic closure $\bar{K}$ of $K$ is Galois over $K$ (ii) every algebraic extension field of $K$ is separable over $K$ (iv) either char $K=0$ or char $K=p$ and $K=K^{p}$

A feld $K$ that satisfies (i)-(iv) is said to be perfect. (b) Every finite field is perfect.

14. $IfF=K(u,v)$ with $u,v$ algebraic over $K$ and u separable over $K$ , then $F$ is a simple extension of $K$

15. Let char $K=p\neq0$ and assume $F=K(u,v)$ where $u^p\varepsilon K$ $\upsilon^p\varepsilon K$ and $[F:K]=p^{2}$ Then $F$ is not a simple extension of $K$ . Exhibit an infnite number of intermediate felds.

16. Let $F$ be an algebraic extension of $K$ such that every polynomial in $K[x]$ has a root in $F.$ Then $F$ is an algebraic closure of $K.$ [Hinr: Theorems 3.14 and 6.7 and Proposition 6.15 may be helpful.]

## 7. CYCLIC EXTENSIONS

The basic idea in Sections 7-9 is to analyze Galois field extensions whose Galois groups have a prescribed structure (for example, cyclic or solvable). In this section we shall characterize most finite dimensional Galois extensions with cyclic Galois groups (Propositions 7.7 and 7.8; Theorem 7.11). In order to do this it is first necessary to develop some information about the trace and norm.

Definition 7.1. Let F be a finite dimensional extension field ofK and $\overline{K}$ an algebraic closure of K containing F. Let $\sigma_{1}$ ..... $\tau_{r}$ be all the distinct K-monomorphisms $\bar{\mathbf{F}}\to\bar{\mathbf{K}}$ Ifu e F, the norm of u, denoted, $N_KF(u)$ is the element

$$\mathrm{N_K^F(u)}=(\sigma_1(u)\sigma_2(u)\cdots\sigma_r(u))^{[F:K]_1}.$$

The trace ofu,denoted $T_KF(u)$ , is the element

$$\mathrm{T_{K}^{F}(u)=[F:K]_{i}(\sigma_{1}(u)+\sigma_{2}(u)+\cdots+\sigma_{r}(u)).}$$

REMARKS. Theorem 7.3 below shows that the definition does not depend on the choice of $K$ . It can be shown that an equivalent definition is obtained if one re-

------------------------------------------------------------------

places $\bar{K}$ by any normal extension of $K$ containing $F$ (Exercise 1). $\bar{K}$ is normal over $K$ (Theorems 3.4 and 3.14), whence $r=[F:K]_{s}$ is finite by Proposition 6.12. If the context is clear $N_{K}F$ and $T_{K}F$ will sometimes be written simply as $N$ and $T$

Note that the trace is essentially the additive analogue of the norm. In many instances this means that a proof involving the one will translate directly into a proof of the analogous fact for the other. There are some exceptions, however. For instance if $F$ is not separable over $K$ , then char $K=p\neq0$ and $[F:K]_i=p^t(t\geq1)$ Consequently, $T_{\kappa}F(u)=0$ for every $u\varepsilon F$, F $F.$ but $N_KF(u)$ may not be zero.

EXAMPLE. Let $F=\mathbf{C}$ ard $K=\mathbf{R}$ and take $\bar{K}=\mathbf{C}$ . It is easy to see that the only R-monomorphisms $\mathbb{C}\to\mathbb{C}$ are the identity and complex conjugation. Consequently $N(a+bi)=[(a+bi)(a-hi)]^1=a^2+b^2$

The principal applications to be given here of the norm and trace occur when $F$ is Galois over $K$ . In this case the Galois group is finite and there is a more convenient description of the norm and trace, which is sometimes taken as a definition

Theorem 7.2. IfF is a finite dimensional Galois extension field ofK and

$$Aut_KF=\left\{\sigma_1,\ldots,\sigma_n\right\},$$

then for any u ε F

$$\begin{aligned}&\mathbf{N}_{\mathbf{K}}^{\mathbf{F}}(\mathbf{u})=\:\sigma_{1}(\mathbf{u})\sigma_{2}(\mathbf{u})\cdots\sigma_{\mathbf{n}}(\mathbf{u});\quad and\\&\mathbf{T}_{\mathrm{K}}^{\mathbf{F}}(\mathbf{u})=\:\sigma_{\mathrm{l}}(\mathbf{u})+\sigma_{2}(\mathbf{u})+\cdots+\sigma_{\mathrm{n}}(\mathbf{u}).\end{aligned}$$

PROOF. Let $\bar{K}$ be an algebraic closure of $K$ which contains $F$ .Since $F$ is normal over $K$ (Corollary 3.15), the $K.$ -monomorphisms $F\to\bar{K}$ are precisely the elements of $Aut_KF$ KF $_{K}F$ by Theorem 3.14. Since $F$ is also separable over $K$ (Corollary 3.15), $[F:K]_{i}=1$ .The conclusion of the theorem now follows directly from Defini tion 7.1.

Suppose $F$ is Galois over $K$ and $\mathrm{Aut}_{K}\boldsymbol{F}=\{\sigma_{1},\ldots,\sigma_{n}\}$ .Since $Aut_KF$ is a group, the elements $\sigma_i\sigma_1$ 0i01 $\sigma _{i}\sigma _{1}$, $\sigma _{i}\sigma _{2}, \ldots$, $\sigma _{i}\sigma _{n}$ TiUn $\sigma_i\sigma_n$ (for any fixed $\sigma _i\varepsilon$ $Aut_KF)$ are simply $\sigma_1,\sigma_2,\ldots,\sigma_n$ in a possibly different order. This implies that for any u e $F$ $N_KF(u)$ and $T_KF(u)$ are fixed by every $\sigma_i\varepsilon Aut_KF$ There fore, $N_KF(u)$ and $T_{\kappa}F(u)$ must lie in $K$ . The next theorem shows that this is true even if $F$ is not Galois over $K.$ The first two parts will be used frequently; the last two parts are not needed in the sequel.

Theorem 7.3.Let F be a finite dimensional extension fieldofK. Then for all u,v ε F

(i $\mathbf{N}_{\mathbf{K}}^{\mathbf{F}}(\mathbf{u})\mathbf{N}_{\mathbf{K}}^{\mathbf{F}}(\mathbf{v})=\mathbf{N}_{\mathbf{K}}^{\mathbf{F}}(\mathbf{u}\mathbf{v})$ and $T_{K}F(u)+T_{K}F(v)=T_{K}F(u+v)$ (i) ifu e K, then $\mathbf{N}_{\mathbf{K}}\mathbf{F}(\mathbf{u})=\mathbf{u}^{[\mathbf{F}:\mathbf{K}]}$ and $\mathbf{T}_{\mathbf{K}}\mathbf{F}(\mathbf{u})=[\mathbf{F}:\mathbf{K}]\mathbf{u}$ (ii) $N_{\mathrm{K}}F(u)$ and $T_{\mathrm{K}}F(u)$ are elements ofK. More precisely,

$$\mathrm{N_KF(u)=((-1)^na_0)^{[F:K(u)]}\varepsilon K~}and\mathrm{T_KF(u)=-[F:K(u)]a_{n-1}\varepsilon K,}$$

where $\mathbf{f}=\mathbf{x}^{n}+\mathbf{a}_{n-1}\mathbf{x}^{n-1}+\cdots+\mathbf{a}_{0}\varepsilon\mathbf{K}[\mathbf{x}]$ is the irreducible polynomial of u; (iv) if E is an intermediate field, then

$$\mathrm{N_{K}^{E}(N_{E}^{F}(u))=N_{K}^{F}(u)~and~T_{K}^{E}(T_{E}^{F}(u))=T_{K}^{F}(u).}$$

------------------------------------------------------------------

SKETCH OF PROOF. (i) and (i) follow directly from Definition 7.1 and the facts that $r=[F:K]_{s}$ and $[F:K]_s[F:K]_i=[F:K].$ (ii) Let $E=K(u)$ .An algebraic closure $\overline{K}$ of $K$ which contains $F$ is also an

algebraic closure of $E$ . The proof of Lemma 6.11 shows that the distinct $K$ -mono- morphisms $F\to\bar{K}$ are precisely the maps $\sigma_k\tau_j(1\leq k\leq l;1\leq j\leq r)$ ,where the o's are all the $K.$ automorphisms of $\bar{K}$ whose restrictions to $E$ are distinct and ther's are all the distinct $E$ -monomorphisms $F\to\bar{K}$ . Thus by Proposition 6.12, $I=[E:K]_{0}$ whence $n=[E:K]=\iota[E:K]_i$ (see Remarks after Definition 6.10). Us i and orolr 1 to sho that $N_{K}F(u)=\left(\prod_{k=1}^{i}\sigma_{k}(u)\right)^{[F:E][E:K]i}$ and

$T_{K}F(u)=[F:E][E:K]_{k}\left(\sum_{k=1}^{i}\sigma_{k}(u)\right)$ Since $\sigma_i:K(u)\cong K(\sigma_i(u))$ Corolary 1.9 implies that $\sigma_1(u),\ldots,\sigma_t(u)$ oe(u) $\sigma_t(u)$ are all the distinct roots of $f.$ By Corollary 6.14

$$\begin{aligned}
\text{f}& =[(x\:-\:\sigma_{1}(u))(x\:-\:\sigma_{2}(u))\cdots(x\:-\:\sigma_{t}(u))]^{[E:K]_{i}} \\
&=\left[x^{\prime}-\left(\sum_{k=1}^{t}\sigma_{k}(u)\right)x^{\prime-1}+\cdots+\left((-1)^{\prime}\prod_{k=1}^{t}\sigma_{k}(u)\right)\right]^{[E:K]i}.
\end{aligned}$$

If $[E:K]_i=1$ ,then $n=1$ and the conclusion is immediate. If $[E:K]_i>1$ ，then $[E:K]_i$ is a positive power of $p=$ char $K$ . It is easy to calculate $a_0$ and to see that $a_{n-1}=0=T_{K}F(u)$ ; use Exercise II1.1.11. (iv) Use the notation in the frst paragraph of the proof of (ii), with $E$ any inter-

mediate field. Apply the appropriate definitions and use Corollary 6.13.

 In addition to the trace and norm we shall need

Definition 7.4. Ler S be a nonempty set of automorphisms of a field F. S is linearly independent provided that for any a1, . . . , $a_n$ ε F and $\sigma_1$ ..... $\sigma_{\mathrm{n}}$ ES $(\mathbf{n}\geq1$

$a_{1}\sigma _{1}$( u) + $\cdots$+ $a_{n}\sigma _{n}$( u) = 0 for all u e $\mathbf{F}$ $\Longrightarrow$ $\mathbf{a_{i}} = 0$ a; = 0 $a_{i}=0$ for every i.

Lemma 7.5. If S is a set of distinct automorphisms of a field F, then S is linearly independent.

PROOF. If $S$ is not linearly independent then there exist nonzero $a_ieF$ F $F$ and distincte $\sigma_i\varepsilon S$ such that

$$a_1\sigma_1(u)+a_2\sigma_2(u)+\cdots+a_n\sigma_n(u)=0\quad\mathrm{for~all}\quad u\in F.$$

Among all such “dependence relations" choose one with n minimal; clearly $n>1$ Since $\sigma_1$ and $\sigma_2$ are distinct, there exists $\upsilon\varepsilon F$ F $F$ with $\sigma_1(v)\neq\sigma_2(v)$ .Applying (1) to the element uv (for any $u\varepsilon F$ ) yields :

$$a_1\sigma_1(u)\sigma_1(v)+a_2\sigma_2(u)\sigma_2(v)+\cdots+a_n\sigma_n(u)\sigma_n(v)=0;$$

and multiplying (1) by $\sigma_1(v)$ gives:

$$a_1\sigma_1(u)\sigma_1(v)+a_2\sigma_2(u)\sigma_1(v)+\cdots+a_n\sigma_n(u)\sigma_1(v)=0.$$

The difference of (2) and (3) is a relation:

$$a_2[\sigma_2(v)-\sigma_1(v)]\sigma_2(u)+a_3[\sigma_3(v)-\sigma_1(v)]\sigma_3(u)+\cdot\cdot\cdot+a_n[\sigma_n(v)-\sigma_1(v)]\sigma_n(u)=0$$

------------------------------------------------------------------

for all $u\varepsilon F.$ Since $a_2\neq0$ and $\sigma_2(v)\neq\sigma_1(v)$ not all the coefficients are zero and this contradicts the minimality of $n$

An extension feld $F$ of a field $K$ is said to be cyclic [resp. abelian] if $F$ is algebraic and Galois over $K$ and $Aut_KF$ is a cyclic [resp. abelian] group. If in this situation $Aut_KF$ is a finite cyclic group of order $n$ , then $F$ is said to be a cyclic extension of degree n (and $[F:K]=n$ by the Fundamental Theorem 2.5). For example, Theorem 5.10 states that every finite dimensional extension of a fnite field is a cyclic extension. The next theorem is the crucial link between cyclic extensions and the norm and trace.

Theorem 7.6. Ler F be a cyclic extension field of K of degree n, α a generaror of $Aut_KF$ and u eF.Then

(i $T_{\mathrm{K}}^{\mathrm{F}}($u)=0 ifand only $if\mathbf{u}=\mathbf{v}-\sigma(\mathbf{v})$ for some v e F;

(i) (Hilbert's Theorem 90) $\mathbf{N}_{\mathbf{K}}\mathbf{F}(\mathbf{u})=\mathbf{1}_{\mathbf{K}}$ if andonlyif $\mathbf{u}=\mathbf{v}\sigma(\mathbf{v})^{-1}$ for some nonzero v ε F.

SKETCH OF PROOF. For convenience write $\sigma(x)=\sigma x$ .Since $\sigma$ generates $Aut_KF$ ,it has order $n$ and $\sigma,\sigma^{2},\sigma^{3},\ldots,\sigma^{n-1},\sigma^{n}=1_{F}=\sigma^{0}$ are $n$ distinct automor phisms of $F$ .By Theorem 7.2, $T(u)=u+\sigma u+\sigma^{2}u+\cdots+\sigma^{n-1}u$ and $N(u)=$ $u(\sigma u)\left(\sigma^{2}u\right)\cdots(\sigma^{n-1}u)$

(i)If $u=v-\sigma v$ , then use the definition and the facts that.

$$T(v-\sigma v)=T(v)-T(\sigma v)\quad\mathrm{and}\quad\sigma^n(v)=v$$

to show that $T(u)=0$ . Conversely suppose $T(u)=0$ . Choose $w\varepsilon F$ such that $T(w)=1_{K}$ as follows. By Lemma 7.5 (since $1_K\neq0$ ) there exists $z\varepsilon F$ such that

$$0\neq1_Fz+\sigma z+\sigma^2z+\cdots+\sigma^{n-1}z=T(z).$$

Since $T(z)\varepsilon K$ by the remarks after Theorem 7.2, we have $\sigma[T(z)^{-1}z]=T(z)^{-1}\sigma(z)$ Consequently, if $w=T(z)^{-1}z$ , then

$$\begin{aligned}T(w)&=T(z)^{-1}z+T(z)^{-1}\sigma z+\cdots+T(z)^{-1}\sigma^{n-1}z\\&=\:T(z)^{-1}T(z)\:=\:1\kappa.\:,\end{aligned}$$

Now let

$$\begin{aligned}v&=uw+(u+\sigma u)(\sigma w)+(u+\sigma u+\sigma^2u)(\sigma^2w)\\&+(u+\sigma u+\sigma^2u+\sigma^3u)(\sigma^3w)+\cdots+(u+\sigma u+\cdots+\sigma^{n-2}u)(\sigma^{n-2}w).\end{aligned}$$

Use thefact that $\sigma$ is an automorphism and that

$$0=T(u)=u+\sigma u+\sigma^2u+\cdots+\sigma^{n-1}u,$$

which implies that $u=-(\sigma u+\sigma^{2}u+\cdots+\sigma^{n-1}u)$ to show that

$$v-\sigma v=uw+u(\sigma w)+u(\sigma^{2}w)+u(\sigma^{3}w)+\cdots+u(\sigma^{n-2}w)\\+\:u(\sigma^{n-1}w)\:=\:uT(w)\:=\:u1_{K}\:=\:u.$$

(i) If $u=v\sigma(v)^{-1}$ ,then since $\sigma$ is an automorphism of order n , $\sigma ^{n}( v^{- 1}) = v^{- 1}$ $\sigma(v^{-1})=\sigma(v)^{-1}$ and for each $1\leq i\leq n-1$ ， $\sigma^i(v\sigma(v)^{-1})=\sigma^i(v)\sigma^{i+1}(v)^{-1}$ .Hence:

$$N(u)=(v\sigma(v)^{-1})(\sigma v\sigma^{2}(v)^{-1})(\sigma^{2}v\sigma^{3}(v)^{-1})\cdots(\sigma^{n-1}v\sigma^{n}(v)^{-1})=1_{K}.$$

------------------------------------------------------------------



------------------------------------------------------------------

by Theorem 7.3(i), whence $\mathbf{l}_{K}=v-\sigma(v)$ for some $\upsilon\varepsilon F$ by Theorem 7.6(i). If $u=-v$ , then $\sigma(u)=u+1_{K}\neq u$ ，whence $u\notin K.$ .Since $[F:K]=p$ there are no intermediate fields, and we must have $F=K(u)$ .Note that $\sigma(u^{p})=(u+1_{K})^{p}$ $=u^{p}+1_{K}^{p}=u^{p}+1_{K}$ which implies that $\sigma(u^{p}-u)=(u^{p}+1_{k})-(u+1_{K})$ $=u^{p}-u$ Since $F$ is Galois over $K$ and $\mathrm{Aut}_KF=\langle\sigma\rangle$ ， $a=u^{p}-u$ must be in $K$ Therefore, $u$ is a root of $x^{p}-x-a\varepsilon K[x]$ $K[x]$ K[x] , which is necessarily the irreducible polynomial of $u$ over $K$ since the degree of $u$ over $K$ is $[K(u):K]=[F:K]=p$ Recall that the prime subfield $Z_{p}$ of $K$ consists of the $p$ distinct elements $0,1=1_{\kappa}$

$2=1_K+1_K,\ldots,p-1=1_K+\cdots+1_K$ (Theorem 5.1). The first paragraph of the proof of Theorem 5.6 shows that $i^p=i$ for all $i\in Z_p$ .Since $u$ is a root of $\chi^{p}-x-a$ , we have for each. $i\varepsilon Z_p{:}(u+i)^p-(u+i)-a=u^{n}+i^p-u-i-$ $a=(u^p-u-a)+(i^p-i)=0+0=0$ Thus $u+i\varepsilon K(u)=F$ is a root of $x^{p}-x-a$ for each $i\varepsilon Z_p$, whence $F$ contains $p$ distinct roots of $x^{p}-x-a$ Therefore, $F=K(u)$ is a splitting field over $K$ of $x^{p}-x-a$ . Finally if $u+i$ $(i\in Z_p\subset K)$ is anyroot of $\chi^{p}-x-a$ ,then clearly $K(u+i)=K(u)=F$ $(\Leftarrow)$ Suppose $F$ is a splitting field over $K$ of $x^{p}-x-a\varepsilon K[x]$ .We shall not as-

sume that $x^{p}-x-a$ is irreducible and shall prove somewhat more than is stated in the theorem. If $u$ is aroot of $x^{p}-x-a$ ,then the preceding paragraph shows that $K(u)$ contains $p$ distinct roots of $x^{p}-x-a:u$ ， $u+1,\ldots,u+(p-1)\varepsilon K(u)$ But $x^{p}-x-a$ has at most $p$ roots in $F$ and these roots generate $F$ over $K$ .Therefore, $F=K(u)$ ,the irreducible factors of $x^{p}-x-a$ are separable and $F$ is Galois over $K$ (Theorem 3.11 and Exercise 3.13).Every $\tau\varepsilon\mathrm{Aut}_KF=\mathrm{Aut}_KK(u)$ is completely determined by $\tau(u)$ .Theorem 2.2 implies that $\tau(u)=u+i$ for some $i\in Z_p\subset K$ Verify that the assignment $\tau\vdash i$ defines a monomorphism of groups $\theta:\operatorname{Aut}_KF\to Z_m$ Consequently, $\operatorname{Aut}_KF\cong\operatorname{Im}\theta$ is either 1 or $Z_p$ If $\mathrm{Aut}_{\kappa}F=1$ , then $[F:K]=1$ by the Fundamental Theorem 2.5, whence $u\varepsilon K$ and $x^{p}-x-a$ splits in $K[x].$ Thus if $x^{p}-x-a$ is irreducible over $K$ ,we must have $\operatorname{Aut}_KF\cong Z_n$ ..In this case, therefore, $F$ is cyclic over $K$ of degree $P$ .

Corollary 7.9. If K is a field of characteristic $\mathfrak{p}\neq0$ and $\mathbf{x}^{\mathrm{p}}-\mathbf{x}-\mathbf{a}\varepsilon\mathbf{K}[\mathbf{x}]$ K[x] $K[x]$, then $\mathbf{x}^{p}-\mathbf{x}-a$ is either irreducible or splits in. $K[x]$

PROOF. We use the notation of Proposition 7.8. In view of the last paragraph of that proof it suffices to prove that if $\mathrm{Aut}_{K}F\cong\mathrm{Im}\:\theta=Z_{p}$ , then $x^{n}-x-a$ is irreducible. If $u$ and $v=u+i\left(i\in Z_{p}\subset K\right)$ are roots of $x^{\prime\prime}-x-a$ ,then there exists $\tau\varepsilon Aut_{K}F$ KF $i_{K}F$ such that $\tau(u)=v$ and hence $\tau:K(u)\cong K(v)$ (choose $\tau$ with $\theta(\tau)=i)$ Therefore, $u$ and $v$ are roots of the same irreducible polynomial in $K[x]$ (Corollary 1.9). Since $v$ was arbitrary this implies that $x^{p}-x-a$ is irreducible.

Proposition 7.8 completely describes the structure of a cyclic extension of the first type mentioned on p.293. In order to determine the structure of a cyclic extension of degree $n$ of the second typeitwillbenecessary to introduce an additional assumption on the ground field $K$ Let $K$ be a field and $n$ a positive integer. An element $\zeta$ E $K$ is said to be an nth root

of unity provided $\zeta^{n}=1_{\kappa}$ (that is, $\zeta$ is a root of $x^{n}-1_{h}\in K[x])$ . It is easy to see that the set of all nth roots of unity in $K$ forms a multiplicative subgroup of the multiplica. tive group of nonzero elemenis of $K$ . This subgroup is cyclic by Theorem 5.3 and has

------------------------------------------------------------------

order at most $n$ by Theorem I11.6.7. S 5 $\zeta\varepsilon K$ is said to be a primitive nth root of unity providede 5 is an nth root of unity and $\zeta$ has order $n$ in the multiplicative group of nth roots of unity. In particular, a primitive nth root of unity generates the cyclic group of all nth roots of unity.

REMARKS. If char $K=p$ and $p\mid n$, then $n=p^km$ with $(p,m)=1$ and $m<n$ Thus $x^{n}-1_{K}=(x^{m}-1_{K})^{p^{k}}$ (Exercise II1.1.11). Consequently the nth roots of unity in $K$ coincide with the mth roots of unity in $K$ .Since $m<n.$ , there can be no primitive nth root of unity in $K$ . Conversely, if char KYn (in particular, if char $K=0$ ),then $nx^{n-1}\neq0$ ,whence $x^n-1_K$ is relatively prime to its derivative. Therefore $x^n-1_K$ has $n$ distinct roots in any splitting feld $F$ of $x^n-1_K$ over $K$ (Theorem III.6.10) Thus the cyclic group of nth roots of unity in $F$ has order $n$ and $F$ (but not necessarily $K)$ contains a primitive nth root of unity. Note that if $K$ does contain a primitive nth root of unity, then $K$ contains $n$ distinct roots of $x^n-1_{\kappa}$ ，whence $F=K$

EXAMPLES. $1_{K}$ is an nth root of unity in the field $K$ for all $n\geq1$ . If char $K=p\neq0$ and $n=p^k$ , then $1_{K}$ is the only nth root of unity in $K$ .The subfield Q(i) of C contains both primitive fourth roots of unity $(\pm i)$ but no cube roots of unity except 1, (the others being $-1/2\pm\sqrt{3}$ $i/2)$ . For each $n>0$ ， $e^{2\pi i/n}\varepsilon\mathbf{C}$ is a primitive nth root of unity.

In order to finish our characterization of cyclic extensions we need

Lemma 7.10. Let n be a positive integer and K a field which contains a primitive nth root of unity $\zeta$

(i) If d|n, then $\zeta^{\mathrm{n/d}}=\eta$ is a primitive dth root of unity in K (i) If d I n and u is a nonzero root of xd $x^{\mathrm{d}}$ $\mathbf{x}^{\mathrm{d}}-\mathbf{a}\varepsilon K[\mathbf{x}]$ ,then $x^d-$ a has d distinct

roots, namely $\mathbf{u},\eta\mathbf{u},\eta^{2}\mathbf{u},\ldots,\eta^{\mathbf{d}-1}\mathbf{u}$ nd-lu $\eta^\mathrm{d-1}$u , where $\eta\varepsilon K$ is a primitive dth root of unity. Fur thermore K(u) is a splitting field of $x^{\mathrm{d}}$ - a over $K$ and is Galois over K.

PROOF. (i) $\zeta$ generates a multiplicative cyclic group of order $n$ by defnition. If $d|n$ , then $\eta=\zeta^{n/d}$ has order $d$ by Theorem I.3.4, whence $\eta$ is a primitive dth root of unity. (i) If $lu$ is a root of $x^d-a$ , then so is $\eta^{i}u.$ The elements n =1k $\eta^{0}=1_{\kappa}$ $\eta^{0}=1_{K},\eta,\ldots,\eta^{d-1}$ are distinct (Theorem I.3.4). Consequently since n $\eta$ $\eta\varepsilon K$ K $K$ , the roots $u,\eta u,\ldots,\eta^{d-1}u$ of $x^d-a$ are distinct elements of $K(u)$ . Thus $K(u)$ is a splitting field of $x^d-a$ over $K$ The irreducible factors of $x^d-a$ are separable since all the roots are distinct,whence $K(u)$ is Galois over $K$ by Theorem 3.11 and Exercise 3.13.

Theorem 7.11.Let n bea positiveinteger and K a fieldwhich contains a primitive nth root of unity 5 . Then the following conditions on an extension field F of K are equivalent.

(i)F is cyclic of degree d,where d | n; (ii) F is a splitting field over K ofa polynomial of the form xn - a e K[x] (in which case $\mathbf{F}=\mathbf{K}(\mathbf{u})$ ,for any root u of $\mathbf{x}^{n}-\mathbf{a})$ ； (i) F is a splitting field over K of an irreducible polynomial of the form $\mathbf{x}^{\mathrm{d}}-\mathbf{b}\equiv\mathbf{K}[\mathbf{x}]$ , where d | n (in which case $\mathbf{F}=\mathbf{K}(\mathbf{v})$ ,for any roor v $ofx^{\mathrm{d}}-b)$

------------------------------------------------------------------

PROOF. (i $\Rightarrow$ → $\mathrm{ii})\Rightarrow(\mathrm{i})$ Lemma 7.10 shows that $F=K(u)$ and $F$ is Galois over $K$ for any root $u$ of $x^{n}-a$ If $\sigma\varepsilon$Aut$i_iF=$Aut$_iK(u)$ , then $\sigma$ is completely determined by $\sigma(u)$ ,which is a root of $x^{n}-u$ by Theorem 2.2. Therefore, $\sigma(u)=\zeta^{i}u$ for some $i\left(0\leq i\leq n-1\right)$ by Lemma 7.10. Verify that the assignment $\sigma\vdash\zeta^i$ defines a monomorphism from $Aut_kF$ to the multiplicative cyclic group (of order $n$ ) of nth roots of unity in $K$ . Consequently, $Aut_kF$ is a cyclic group whose order $d$ divides $n$ (Theorer 1.3.5 and Corollary I.4.6). Hence $F$ is cyclic of degree $d$ over $K$ $(\mathrm{i})\Rightarrow($iii) By hypothesis $Aut_KF$ is cyclic of order $d=[F:K]$ with generator $\sigma$

Let $\eta=\zeta^{n/d}\varepsilon K$ be a primitive dth root of unity. Since $N_{K}^{F}(\eta)=\eta^{[F:K]}=\eta^{d}=1_{K}$ Theorem 7.6(i) implies that $\eta\:=\:w\sigma(w)^{-1}$ for some $w\varepsilon F$ . If $v=w^{-1}$ , then $\sigma(v)=\eta v$ and $\sigma(v^d)=(\eta v)^d=\eta^dv^d=v^d$ .Since $F$ is Galois over $K$ $v^d=b$ must lie in $K$ so that $\upsilon$ is a root of $x^{d}-b\in K[x]$ . By Lemma $7.10\:K(v)\subset F$ and $K(v)$ is a splitting field over $K$ of $x^d-b$ (whose distinct roots are $\upsilon,\eta\iota,\ldots,\eta^{d-1}\upsilon)$ nd-1c) $\eta^{d-1}v)$ .Furthermore for each $i\left(0\leq i\leq d-1\right)$ ， $\sigma^{i}(v)=\eta^{i}v$ so that $\sigma^{i}:K(v)\cong K(\eta^{i}v)$ . By Corollary $1.9c$ and $\eta^iv$ are roots of the same irreducible polynomial over $K$ . Consequently, $x^d-b$ is irreducible in $K[x]$ . Therefore, $[K(v):K]=d=[F:K]$ ,whence $F=K(v)$ (ii) $\Rightarrow$ (i) If $\upsilon\varepsilon F$ is a root of $x^{d}-b\in K[x]$ ,then $F=K(c)$ by Lemma 7.10. Now

$(\zeta v)^{\eta}=\zeta^{n}v^{\eta}=1_{K}v^{d(n/d)}=b^{n/d}\varepsilon K$ so that $\zeta v$ is a root of $x^{n}-a\varepsilon K[x]$ ，where $a=b^{n/d}$ .By Lemma 7.10 again $K(\zeta v)$ is a splitting field of $x^n-a$ over $K$ .But $\zeta$ $\zeta\varepsilon K$ implies that $F=K(v)=K(\zeta v)$ .

It is clear that the primitive nth roots of unity play an important role in the proof of the preceding results. Characterization of the splitting fields of polynomials of the form $x^{n}-a\in K[x]$ is considerably more difficult when. $K$ does not contain a primitive nth root of unity.The case when $a=1_k$ is considered in Section 8.

## EXERCISES

1. If $\overline{K}$ is replaced by any normal extension $N$ of $K$ containing $F$ in Definition 7.1, then this new definition of norm and trace is equivalentto the original one.In particular, the new definition does not depend on the choice of $N.$ See Exercise 3.21.

2. Let $F$ be a finite dimensional extension of a finite field $K$ . The norm $N_{i}F$ and the trace $T_{\kappa}^{k}$ (considered as maps $F\to K$ )are surjective 3. Let $\bar{\mathbf{Q}}$ be a (fixed) algebraic closure of $Q$ and $c\in\overline{\mathbf{Q}},c\neq\mathbf{Q}$ .Let $E$ be a subfeld of $\bar{\mathbf{Q}}$ maximal with respect to the condition $\because\nexists E$ . Prove that every finite dimensional extension of $E$ is cyclic.

4. Let $K$ be a field, $\bar{K}$ an algebraic closure of $K$ and $\sigma\varepsilon Aut_{N}\bar{K}$ . Let

$$F\:=\:\{u\:\varepsilon\:\bar{K}\mid\sigma(u)\:=\:u\}\:.$$

Then $F$ is a field and every finite dimensional extension of $F$ is cyclic.

5.If $F$ is a cyclic extension of $K$ of degree $p^{\prime\prime}$ ( $I^{\prime}$ prime) and $L$ is an intermediate feld such that $F=L(u)$ and $L$ is cyclic over $K$ of degree $p^{n-1}$ , then $F=K(u)$

6. If char $K=p\neq0$ , let $K_{\nu}=\{u^{\nu}-u\mid u\varepsilon K\}$ (a) A cyclic extension field $F$ of $K$ of degree $P$ exists if and only if $K\neq K_p$

------------------------------------------------------------------

(b) If there exists a cyclic extension of degree $P$ of $K$ , then there exists a cyclic extension of degree $p^n$ for every $n\geq1$ . $[Hint$ : Use induction; if $E$ is cyclic over $K$ of degree $P^{n-1}$ with $Aut_KE$ RE $_{K}E$ generated by $\sigma$ , show that there exist $u,v$ E $E$ such that $T_{K}^{E}(v)=1_{K}$ and $\sigma(u)-u=v^{p}-v$ Then $x^{p}-x-u$ E $E[x]$ is irreducible and if $w$ is a root, then $K(w)$ is cyclic of degree $p^n$ over $K$ 1

7.If $n$ is an odd integer such that $K$ contains a primitive nth root of unity and char $K\neq2$ , then $K$ also contains a primitive 2nth root of unity.

8. If $F$ is a fnite dimensional extension of $\mathbf{Q}$ then $F$ contains only a finite number of rootsof unity.

9. Which roots of unity are contained in the following felds: Q(i), $\mathbf{Q}(\sqrt{2}),\mathbf{Q}(\sqrt{3})$ $\mathbf{Q}(\sqrt{5}),\mathbf{Q}(\sqrt{-2}),\mathbf{Q}(\sqrt{-3})$? Q(√=3) $Q(\sqrt{-3})$

10. (a) Let $p$ be a prime and assume either (i) char $K=p$ or (ii) char $K\neq p$ and $K$ contains a primitive pth root of unity. Then $x^{p}-u\varepsilon K[x]$ is either irreducible or splits in $K[x]$ (b) If char $K=p\neq0$ , then for any root u of K[x] $K[x]$ $x^{p}-a\varepsilon K[x],K(u)\neq K(u^{p})$ if and

only if $[K(u):K]=p$

## 8. CYCLOTOMIC EXTENSIONS

Except for Theorem 8.1 this section is not needed in the sequel. We shall examine splitting fields of the polynomial $x^n-1_{N}$ ,with special attention to the case $K=\mathbf{Q}$ These splitting felds turn out to be abelian extensions whose Galois groups are well known..

A splitting field $F$ over a field $K$ of $x^{n}-1_{K}\varepsilon K[x]$ (where $n\geq1$ )is called a cyclotomic extension of order n.If char $K=p\neq0$ and $n=mp^{\prime}$ with $(p,n)=1$ then $x^n-1_{k}=(x^n-1)^{p^{\prime}}$ (Exercise I1.1.11) so that a cyclotomic extension of order 17 coincides with one of order $m$ . Thus we shall usually assume that char $K$ does not divide $n$ (that is, char $K=0$ or is relatively prime to. $n$ ）.

The dimension of a cyclotomic extension field of order $n$ is related to the Euler function 4 of elementary number theory, which assigns to each positive integer $n$ the number $\varphi(n)$ of integers $i$ such that $1\leq i\leq n$ and $(i,n)=1$ . For example, $\varphi(6)=2$ and $\varphi(p)=p-1$ for every prime 10 .Let 7 be the image of $i\varepsilon Z$ under the canonical projection $\mathbf{Z}\to\tilde{Z}_n$ . It is easily verified that $(i,n)=1$ if and only if $\bar{i}$ is a unit in the ring $Z_n$ (Exercise l). Thercfore the multiplicative group of units in $Z_n$ has order $\varphi(n)$ ;for the structure of this group see Exercise 4..

Theorem8.1.Lern be a positireinteger,Ka field such that charK does nor dicide n andF a cyclotomic extension ofKoforder n.

(i) $\mathbf{F}=\mathbf{K}(\zeta)$ ,where $\zeta\varepsilon F$ is a primitice nih root of unity. (i) F is an abelian exiension of dimension d, where d! $\varphi(n)$ $\varphi$ the Euler function),. if n is prime F is uctually a cyclic extension. (i) $Aut_\mathrm{k}F$ is isomorphic to a subgroup of order d of the multiplicatire group of unitsof $\mathbb{Z}_1.$

------------------------------------------------------------------

REMARKS. Recall that an abelian extension is an algebraic Galois extension whose Galois group is abelian. The dimension of $F$ over $K$ may be strictly less than $\varphi(n)$ . For example, if 5 is a primitive 5th root of unity in $C$ ,then $\mathbb{R}\subset\mathbb{R}(\zeta)\subset\mathbf{C}$ whence, $[\mathbf{R}(\zeta):\mathbf{R}]=2<4=\varphi(5)$ .If $K=\mathbf{Q}$ ,then the structure of the group AutoF is completely determined in Exercise 7.

SKETCH OF PROOF OF 8.1. (i) The remarks preceding Lemma 7.10 show that $F$ contains a primitive nth root of unity 5 .By definition $1_{\kappa},\zeta,\ldots,\zeta^{n-1}\varepsilon K(\zeta)$ are the $n$ distinct roots of $x^{n}-1_{K}$ ,whence $F=K(\zeta)$ . (i) and (i). Since the irreducible factors of $x^{n}-1_{K}$ are clearly separable, Theorem 3.11 and Exercise 3.13 imply that $F$ is Galois over $K$ .If $\sigma\varepsilon Aut_{K}F$ $_{K}F$ KF ,then $\sigma$ is completely determined by $\sigma(\zeta)$ . For some $i(1\leq i\leq n-1)$ ， $\sigma(\zeta)=\zeta^{i}$ by Theorem 2.2. Similarly $\sigma^{-1}(\zeta)=\zeta^{i}$ so that $\zeta=\sigma^{-1}\sigma(\zeta)$ $=\zeta^{ij}$ .By Theorem $\mathbf{I}.3.4(\mathbf{v})$ ， $ij\equiv1$ (mod $n$ ) and hence. $\bar{\iota}\varepsilon Z_n$ is a unit (where $i\Vdash\bar{i}$ under the canonical projection $\mathbf{Z}\to Z_n$ ). Verify that the assignment $\sigma\vdash\bar{i}$ defines a monomorphism $f$ from $Aut_KF$ to the (abelian) multiplicative group of units of the ring $Z_n$ (which has order $\varphi(n)$ by Exercise 1). Therefore, $\mathrm{Aut}_KF\cong$Im $f$ is abelian with order $d$ dividing $\varphi(n)$ .Thus $[F:K]=d$ by the Fundamental Theorem 2.5. If $n$ is prime, then $Z_n$ is a feld and $\operatorname{Aut}_{\kappa}F\cong\operatorname{Im}f$ is cyclic by Theorem 5.3.

Let $n$ be a positive integer, $K$ a feld such that char $K$ does not divide $n$ ,and $F$ a cyclotomic extension of order. $n$ of $K$ . The nth cyclotomic polynomial over $K$ is the monic polynomial $g_{n}(x)=(x-\zeta_{1})(x-\zeta_{2})\cdots(x-\zeta_{r})$ where $\zeta_1,\ldots,\zeta_r$ are all the distinct primitive nth roots of unity in $F$

EXAMPLES. $g_{1}(x)=x-1_{K}$ and $g_{2}(x)=(x-(-1_{K}))=x+1_{K}$ . If $K=\mathbf{Q}$ then $g_3(x)=(x-(-1/2+\sqrt{3}i/2))(x-(-1/2-\sqrt{3}i/2))=x^2+x+1$ and $g_{4}(x)=(x-i)(x+i)=x^{2}+1$ . These examples suggest several properties of the cyclotomic polynomials

Proposition 8.2.Letn be a positive integer,K a feld suchthat char K does no1 dividen and $g_n(x)$ the nth cyclotomic polynomial orer K..

$$\mathrm{x^{n}-1_{K}=\prod_{d|n}g_{d}(x).}$$

(ii) The coefficients $of\mathbf{g}_n(\mathbf{x})$ lie in the prime subfield P of K. If char. $K=0$ andPis identified with the field $\mathbf{Q}$ of rationals, then the coefficients are actually integers (ii) Deg $g_{n}( x) = \varphi ( n)$ ,where $\varphi$ is the Euler function

PROOF. (i) Let $F$ be a cyclotomic extension of $K$ oforder $n$ and \$ $\zeta$ $\zeta\varepsilon F$ a primitive nth root of unity. Lemma 7.10 (applied to $F$ ) shows that the cyclic group $G=\langle\zeta\rangle$ of all nth roots of unity contains all dth roots of unity for every divisor $d$ of $n$ . Clearly $\eta\varepsilon G$ is a primitive dth root of unity (where $d\mid n)$ ifandonly if $|\eta|=d.$ . Therefore for each ivisor $d$ of , $g_{d}( x)$ = $\prod _{| \eta | = d}$ ${\prod _{| \eta | = d}}$ $( x- \eta )$ and

$$x^{n}-1_{K}=\prod_{\eta\in G}(x-\eta)=\prod_{d\atop d|\eta|=d}(\prod_{\eta\in G\atop|\eta|=d}(x-\eta))=\prod_{d\atop d|n}g_{d}(x).$$

------------------------------------------------------------------

(ii)We prove the first statement by induction on $n.$ Clearly $g_{1}(x)=x-1_{K}\varepsilon P[x]$ Assime hatis re orae $k<n$ andket $f(x)=\prod_{d\mid n}g_d(x)$ Then $f\varepsilon P[x]$ bythe induction hypothesis and in $F[ x]$, $x^n- 1_K= f( x) g_n( x)$ by (i). On the other hand $x^{n}-1_{K}\varepsilon P[x]$ and $f$ is monic. Consequently, the division algorithm in $P[x]$ implies that $x^{n}-\mathbf{l}_{K}=fh+r$ for some $h,r\in P[x]\subset F[x]$ .Therefore by the uniqueness of quotient and remainder (of the division algorithm applied in $F[x]$ we must have $r=0$ and $g_{n}(x)=h\varepsilon P[x]$ . This completes the induction. If char $K=0$ and $P=\mathbf{Q}$ ,thena similar inductive argument using the division algorithm in $\mathbf{Z}[x]$ and $\mathbf{Q}[x]$ (instead of $P[x],F[x])$ shows that $g_n(x)\in\mathbf{Z}[x]$ (ii) deg $g_n$ is clearly the number of primitive nth roots of unity. Let $\zeta$ be such a

primitive root so that every other(primitive)root is a power of $\zeta$ .Then $\zeta^i(1\leq i\leq n)$ is a primitive nth root of unity (that is, a generator of $G$ ）if and only if $(i,n)=1$ by Theorem I.3.6. But the number of such $i$ is by derinition precisely $\varphi(n)$ .

REMARKS. Part (i) of the theorem gives a recursive method for determining $g_n(x)$ since

$$g_n(x)=\frac{x^n-1_K}{\prod_{d<n}g_d(x)}.$$

For example if $P$ is prime, then $g_{p}(x)=(x^{p}-1_{K})/g_{1}(x)=(x^{p}-1_{K})/(x-1_{K})$ $=x^{p-1}+x^{p-2}+\cdots+x^{2}+x+1_{K}$ . Using the example preceding Theorem 8.2 we have for $K=\mathbf{Q}$

$$\begin{aligned}
g_{6}(x)& =(x^{6}-1)/g_{1}(x)g_{2}(x)g_{3}(x) \\
&=(x^{6}-1)/(x-1)(x+1)(x^{2}+x+1) \\
&=\:x^{2}-x+1;
\end{aligned}$$

similarly

$$\begin{aligned}g_{12}(x)&=(x^{12}-1)/(x-1)(x+1)(x^{2}+x+1)(x^{2}+1)(x^{2}-x+1)\\&=x^{4}-x^{2}+1.\end{aligned}$$

When thebase field is thefield $\mathbf{Q}$ ，we can strengthen the previous results somewhat.

Proposition 8.3. Let F be a cyclotomic extension oforder n of the field Q of rational numbers and $g_n(x)$ the nth cyclotomic polynomial over Q. Then

(i) $g_n(x)$ is irreducible in $Q[x]$ (ii) $[\mathcal{F}:\mathbf{Q}]=\varphi($n) ,where 4 is the Euler function. (ii) AutQF is isomorphicto themultiplicative group of units in the ring $Z_n$

SKETCH OF PROOF. (i) It suffices by Lemma III.6.13 to show that the monic polynomial $g_n(x)$ is irreducible in $\mathbf{Z}[x]$ .Let $h$ be an irreducible factor of $g_n$ in $\mathbf{Z}[x]$ with deg $h\geqslant1$ . Then $g_{n}(x)=$f$(x)h(x)$ with $f,h$ E $\mathbf{Z}[x]$ monic. Let $\zeta$ be a root of $h$ and $P$ any prime integer such that $( p, n)$ = 1

------------------------------------------------------------------

We shall showfirst that $\zeta^{p}$ is also a root of $h$ .Since $\zeta$ is a root of $g_n(x),\zeta$ is a primitive nth root of unity. The proof of Proposition 8.2(i) implies that $\zeta^{p}$ is also a primitive nth root of unity and therefore a root of either for h. Suppose $\zeta^{p}$ is not a root of h. Then $\zeta^{p}$ is a root of $f(x)=\sum_{i=0}^ra_ix^i$ and hence 5 is arootof $f(x^p)=\sum_{i=0}^ra_ix^{ip}$ Since $h$ is irreducible in $\mathbf{Q}[x]$ (Lemma II1.6.13) and has $\zeta$ as a root, $h$ must divide $f(x^p)$ by Theorem 1.6, say $f(x^p)=h(x)k(x)$ with $k\in\mathbf{Q}[x]$ By the division algorithm in $\mathbf{Z}[x],f(x^p)=h(x)k_1(x)+r_1(x)$ with $k_{1,r_{1}\varepsilon}\mathbf{Z}[x]$ .The uniqueness statement of the division algorithm in $\mathbf{Q}[x]$ shows that $k(x)=k_1(x)\varepsilon\mathbf{Z}[x]$ . Recall that the canonical projection $\mathbf{Z}\to\mathbf{Z}_n$ (denoted on elements by $b\mapsto\bar{b}$ induces a ring epimorphism $\mathbf{Z}[x]\to Z_p[x]$ defned by g = ≥ bxi → g = > bxi (Exercise I1.5.1). Consequently, in $Z_p[x],\bar{f}(x^p)=\bar{h}(x)\bar{k}(x)$ . But in $Z_{\mu}[x],\bar{f}(x^{p})=\bar{f}(x)^{p}$ (since char $Z_p=p.$ Therefore,
$$\bar{f}(x)^{p}=\bar{h}(x)\bar{k}(x)\varepsilon Z_{p}[x].$$

Consequently, some irreducible factor of. $\bar{h}(x)$ of positive degree must divide $\bar{f}(x)^p$ and hence $\bar{f}(x)$ in $Z_p[x]$ . On the other hand, since $g_n(x)$ is a factor of $x^n-1$ ,we have $x^{n}-1=g_{n}(x)r(x)=f(x)h(x)r(x)$ for some $r(x)\varepsilon Z[x]$ . Thus in $Z_p[x]$

$$x^{n}-\bar{1}=\overline{x^{n}-1}=\bar{f}(x)\bar{h}(x)\bar{r}(x).$$

Since $\bar{f}$ and $\bar{h}$ have a common factor, $x^{n}-\bar{1}\varepsilon Z_{p}[x]$ must have a multiple root. This contradicts the fact that the roots of $x^n-\bar{1}$ are all distinct since $(p,n)=1$ (see the Remarks preceding Lemma 7.10). Therefore $\zeta^{p}$ is a root of $h(x)$ If $r\varepsilon Z$ $\mathbf{Z}$ Z is such that $1\leq r\leq n$ and $(r,n)=1$ , then $r=p_{1}^{k_{1}}\cdots p_{*}^{k_{e}}$ where $k_i>0$

and each $p_i$ is a prime such that $(p_{i,n})=1$ . Repeated application of the fact that $\zeta^{p}$ is a root of $h$ whenever 5 is, shows that $\zeta^{r}$ is a root of $h(x)$ . But the $\zeta^{\prime}\left(1\leq r\leq n\right.$ and $(r,n)=1\}$ ) are precisely all of the primitive nth roots of unity by the proof of Proposition 8.2(ii). Thus $h(x)$ is divisible by I (x - §) = g(x), whence $g_n(x)=h(x)$ $\prod_{(\tau,n)=1}^{1\leq r\leq n}(x-\zeta^{r})=g_{n}(x)$, Therefore, $g_n(x)$ is irreducible.

(ii) Lemma 7.10 shows that $F=\mathbf{Q}(\zeta)$ ,whence

$$[F:\mathbf{Q}]=[\mathbf{Q}(\zeta):\mathbf{Q}]=\deg g_n\:=\:\varphi(n)$$

by Proposition 8.2 and (i). (ii) is a consequence of (ii), Theorem 8.1, and Exercise 1.

REMARK. A nontrivial theorem of Kronecker states that every abelian exten sion of $\mathbf{Q}$ is contained in a cyclotomic extension

### EXERCISES

1. If i ε Z, let i denote the image of $i$ in $Z_n$ under the canonical projection $\mathbf{Z}\to\mathbf{Z}_n$ Prove that iis a unit in the ring $Z_n$ if and only if $(i,n)=1$ . Therefore the multipli cative group of units in $Z_n$ has order $\varphi(n)$

2. Establish the following properties of the Euler function 4 (a) If $p$ is prime and $n>0$ ,then $\varphi(p^{n})=p^{n}(1-1/p)=p^{n-1}(p-1)$

(b) If $(m,n)=1$ ,then $\varphi(mn)=\varphi(m)\varphi(n)$

1

------------------------------------------------------------------

(c) If $n\:=\:p_{1}^{k_{1}}\cdots p_{r}^{k_{r}}$ $(p_i$ distinctprimes; $k_i>0$ ，then $\varphi(n)\:=$ (d) $\sum_{d|n}\varphi(d)=n$ (e) c(n) = ∑ du(n/d), where $\mu$ is the Moebius function defined by

 e $I$ drse $P$ Cines

3. Let $\varphi$ be the Euler function. (a) $\varphi(n)$ is even for $n>2$

(b) Find all $n>0$ such that $\varphi(n)=2$ (c) Find all pairs $(n,p)$ (where $n,p>0$ ,and $p$ is prime) such that $\varphi(n)=n/p$ [See Exercise 2.]

4. (a) If $P$ is an odd prime and $n>0$ , then the multiplicative group of units in the ring $Z_{p^n}$ is cyclic of order $p^{n-1}(p-1)$ (b) Part (a) is also true if $p=2$ and $1\leq n\leq2$ (c) If $n\geq3$ ,then the multiplicative group of units in $Z_{2^n}$ is isomorphic to $Z_2\oplus Z_{2^{n-2}}$

5. If $f(x)=\sum_{i=0}^ta_ix^i.$ let $f(x^s)$ be the polynomial $\sum_{i=0}^la_ix^{is}$ Establish the folowing properties of the cyclotomic polynomials $g_n(x)$ over $\mathbf{Q}$

(a) If $P$ is prime and $k\geq1$ ,then $g_{pk}(x)=g_{p}(x^{p^{k-1}})$ (b) If $n=p_{1}^{r_{1}}\cdots p_{k}^{r_{k}}\left(p_{k}\right)$ p $\therefore p_i$ distinct primes; $r_i>0$ ,then

$$g_{n}(x)=g_{p_{1}\cdots p_{k}}(x^{p_{1}r_{1}-1\cdots p_{k}r_{k}-1}).$$

(c) If $n$ is odd, then $g_{2n}(x)=g_{n}(-x)$ (d) If $P$ is a prime and pYn ,then $g_{pn}(x)=g_{n}(x^{p})/g_{n}(x)$ (e) gn(x) = (xn/d - 1)μ(d), where $\mu$ is the Moebius function of Exercise 2 (e) $g_{n}(x)=\prod_{d|n}(x^{n/d}-1)^{\mu(d)}$ (f) $g_n(1)=p$ if $n=p^{k}\left(k>0\right)$ 0if $n=1$ , and I otherwise.

6. Calculate the nth cyclotomic polynomials over $Q$ for all positive $n$ with $n\leq20$

7. Let $F_{n}$ be a cyclotomic extension of $\mathbf{Q}$ of order $n$ . Determine the structure of Aut $\mathbf{Q}F_n$ for every $n$ .[Hint: if $U_n^*$ denotes the multiplicative group of units in $Z_n$ then show that U,* = II Up;ni* where $n$ has prime decomposition $n=p_{1}^{n_{1}\ldots}p_{r}^{n_{r}}$ Apply Exercise 4.]

8. Let $F_{n}$ be a cyclotomic extension of $\mathbf{Q}$ of order $n$

(a) Determine $AutQF_5$ and all intermediate fields. (b) Do the same for $F_8$ (c)Do the same for $F_{7}$ ; if 5 is a primitive 7th root of unity what is the irreducible polynomial over $\mathbf{Q}$ of $\zeta+\zeta^{-1}?$

9. If $n>2$ and 5 is a primitive nth root of unity over $Q$ ,then $[\mathbf{Q}(\zeta+\zeta^{-1}):\mathbf{Q}]$ $=\varphi(n)/2$

------------------------------------------------------------------

10. (Wedderburn) A finite division ring $D$ is a field. Here is an outline of the proof (in which $E^*$ denotes the multiplicative group of nonzero elements of a division. ring $E$ ). (a) The center $K$ of $D$ is a field and $D$ is a vector space over $K$ , whence $|D|=q^n$

where $q=|K|\geq2$ (b) If $0\neq a\in D$ , then $N(a)=\left\{d\varepsilon D\mid da=ad\right\}$ is a subdivision ring of $D$

containing $K$ . Furthermore, $|N(a)|=q^r$ where $r\mid n$ (c) If 0≠a $0\neq a$ $0\neq a\varepsilon D-K$ D-K $D-K$ , then $N(a)^*$ is the centralizer of $a$ in the group $D^*$ and $[D^*:N(a)^*]=(q^n-1)/(q^r-1)$ for some $r$ such that $1\leq r<n$ and $r\mid n$ (d) $q^{n}-1=q-1+\sum_{\tau}(q^{n}-1)/(q^{r}-1)$ where the last sum taken over a fnite number of integers $r$ such that $1\leq r<n$ and $r\mid n$ r[n $r\mid n.\left[Hint\right]$ : use the class equation of $D^*$ ; see pp. 90-91.] (e) For each primitive nth root of unity e C, $|q-\zeta|>q-1$ ，where

$|a+bi|=\sqrt{a^{2}+b^{2}}$ for $a+bi\varepsilon C$ . Consequently, $|g_n(q)|>q-1$ , where $g_n$ is the nth cyclotomicpolynomial over Q. (f) The equation in (d) is impossible unless $n=1$ ,whence $K=D$ . [Hint:

Use Proposition 8.2 to show that for each positive divisor $r$ of $n$ with $r\neq n$ $f(x)=(x^{n}-1)/(x^{r}-1)$ is in $\mathbf{Z}[x]$ and $f_{r}(x)=g_{n}(x)h_{r}(x)$ for some $h_r(x)\varepsilon\mathbf{Z}[x]$ Consequently, for each such $rg_n(q)$ divides $f_r(q)$ in $\mathbf{Z}$, whence $g_n(q)\mid(q-1)$ by (d). This contradicts (e).]

## 9. RADICAL EXTENSIONS

Galois theory had its historical origin in a classical problem in the theory of equations, which may be intuitively but reasonably accurately stated as follows. Given a field $K$ , does there exist an explicit "formula" (involving only feld operations and the extraction of nth roots) which gives all the solutions of an arbitrary polynomial equation $f(x)=0\left(f_{\varepsilon}K[x]\right)?$ If the degree of $f$ is at most four, the answer is affirmative (for example, the familiar “quadratic formula” when deg $f=2$ and char $K\neq2$ ;see also Exercise 5).We shall show,however,that the answer is negative in general (Proposition 9.8). In doing so we shall characterize certain field extensions whose Galois groups are solvable (Theorem 9.4 and Proposition 9.6). The first task is to formulate a precise statement of the classical problem-in field-

theoretic terms. Throughout the discussion we shall work in a fixed algebraic closure of the given base feld $K$ .Intuitively the existence of a “formulafor solving a specific polynomial equation. $f(x)=0$ means that there is a finite sequence of steps, each step being a field operation (addition, multiplication, inverses) or the extraction of an nth root, which yields all solutions of the given equation. Performing a feld operation leaves the base field unchanged, but the extraction of an nth root of an element $C$ in a feld $E$ amounts to constructing an extension feld $E(u)$ with $U^n\varepsilon E$ (that is. $u=\sqrt[n]{c}$ 0. Thus the existence of a “formula" for solving $f(x)=0$ would in effect imply the existence of a finite tower of fields.

$$K=E_0\subset E_1\subset\cdots\subset E_n$$

such that $E_n$ contains a splitting field of $f$ over $K$ and for each $i\geq1$ i>1 $i\geq1,E_{i}=E_{i-1}(u_{i})$ with some positive power of $u_{i}$ lying in $E_{i-1}$

------------------------------------------------------------------

Conversely suppose that there exists such a tower offields and that $E_{n}$ contains a splitting field of $f$ (that is, $E_n$ contains all solutions of $f(x)=0$ .Then

$$E_n=K(u_1,\ldots,u_n)$$

and each solution is of the form

$$f(u_1,\ldots,u_n)/g(u_1,\ldots,u_n)\quad(f,g\in K[x_1,\ldots,x_n])$$

by Theorem 1.3. Thus each solution is expressible in terms of a finite number of elements of $K.$ , a finite number of feld operations and $u_1,\ldots,u_n$ (which are obtained by extracting roots). But this amounts to saying that there is a "formula" for the solutions of the particular given equations. These considerations motivate the next two definitions.

Definition 9.1.An extensionfield F of a field $K$ is a radical extension ofK if $\mathbf{F}=\mathbf{K}(\mathbf{u}_{1},\ldots,\mathbf{u}_{n})$ , some power of. $u_1$ liesin $K$ and for each $i\geq2$ , some power of $u_{\mathrm{i}}$ lies in $\mathbf{K}(\mathbf{u}_1,\ldots,\mathbf{u}_{\mathbf{i}-1})$

REMARKS. If $u_i^{m}$ uim $u_{i}^{m}\in K(u_{1},\ldots,u_{i-1})$ then $lu_i$ is a root of

$$x^m-u_i^m\varepsilon K(u_1,\ldots,u_{i-1})[x].$$

Hence $K(u_{1},\ldots,u_{i})$ is finite dimensional algebraic over $K(u_1,\ldots,u_{i-1})$ by Theorem 1.12. Therefore every radical extension $F$ of $K$ is finite dimensional algebraic over $K$ by Theorems 1.2 and 1.11.

Definition 9.2. Ler K be a field and f e $K[x]$ .The equation $f(x)=0$ is solvable by radicals if there exisis a radical extension F ofK and a splitring field E off over K such that $F\supset E\supset K$

Definition 9.2 is thefirst step in the formulation of the classical problem of finding a “formula" for the solutions of $f(x)=0$ that is valid for every polynomial $f\varepsilon K[x]$ of a given degree $r$ (such as the quadratic formula for $r=2.$ ). For whatever. the precise definition of such a“formula’might be, it is clear from the discussion preceding Definition 9.1 that the existence of such a “formula” should imply that every polynomial equation of degree $r$ is solvable by radicals. Thus in order to demonstrate the nonexistence of such a formula, it suffices to

prove that a specificpolynomial equation is notsolvableby radicals.We shall now develop the necessary information in order to do this (Corollary 9.5) and shall leave the precise formulation of the classical problem for the appendix..

Lemma 9.3. IfF is a radical extension field ofK and N is a normal closure ofF ocer K (Theorem 3.16), then $N$ is a radical extension ofK.

SKETCH OF PROOF. The proof consists of combining two facts. (i) If $F$ is any finite dimensional extension of $K$ (not necessarily radical) and $N$ is the normal closure of $F$ over $K.$ ,then $N$ is the composite field $E_1E_2\cdots E_r$, where each $E_{i}$ is a subfield of $N$ which is $K$ -isomorphic to $F$ (i)If $E_{1},\ldots,E_{r}$ E $E_{r}$ are eachradical extensions of

------------------------------------------------------------------

$K$ (as is the case here since $F$ is radical), then the composite field $E_1E_2\cdots E_r$ is a radical extension of $K$ . These statements are justified as follows (i) Let $\{w_1,\ldots,w_n\}$ be a basis of $F$ over $K$ and let $f_i$ be the irreducible poly-

nomial of $w_i$ over $K$ . The proof of Theorem 3.16 shows that $N$ is a splitting feld of $\{f_1,\ldots,f_n\}$ over $K$ . Let $\upsilon$ be any root of $f_i$ in $N$ . Then there is a $K$ -isomorphism $\sigma:K(w_j)\cong K(v)$ such that $\sigma(w_{j})=v$ by Theorem 1.8. By Theorem $3.8\sigma$ extends to a $K$ -automorphism $\tau$ of $N$ . Clearly $\tau(F)$ is a subfield of $N$ which is $K$ -isomorphic to $F$ and contains $\tau(w_{j})=\sigma(w_{j})=v$ . In this way we can find for every root $\upsilon$ of every $f_i$ a subfield $E$ of $N$ such that $\upsilon\varepsilon E$ $E$ E and $E$ is $K$ -isomorphic to $F$ . If $E_{\mathrm{l}},\ldots,E_{\mathrm{r}}$ are the subfields so obtained, then $E_1E_2\cdots E_r$ is a subfield of $N$ which contains alltheroots of $f_1,f_2,\ldots,f_n$, whence $E_{1}E_{2}\cdots E_{r}=N$ (ii) Suppose $r=2$ ， $E_{\mathrm{l}}=K(u_{\mathrm{l}},\ldots,u_{k})$ and $E_{2}=K(v_{1},\ldots,v_{m})$ as in Definition

9.1. Then $E_1E_2=$ $K( u_1, \ldots , u_k, v_1, \ldots , v_m)$ is clearly a radical extension of $K$ . The general case is similar.

Theorem 9.4.IfF is a radical extensionfieldofK and E isan intermediate field,then $Aut_{\mathrm{K}}E$ is a solvable group.

PROOF. If $K_0$ is the fixed field of $E$ relative to the group $Aut_KE$ ,then $E$ is Galois over Ko, $K_0$, $K_0,\mathrm{~Aut}_{K_0}E=\mathrm{Aut}_KE$ and $F$ is a radical extension of $K_0$ (Exercise 1). Thus we may assume to begin with that $E$ is algebraic Galois over $K$ .Let $N$ be a normal closure of $F$ over $K$ (Theorem 3.16). Then $N$ is a radicalextension of $K$ by Lemma 9.3 and $E$ is a stable intermediate field by Lemma 2.13. Consequently, restriction $(\sigma\vdash\sigma\mid E)$ induces a homomorphism $\theta:\mathrm{Aut}_KN\to\mathrm{Aut}_KE$ .Since $N$ is a splitting field over $K$ (and hence over $E$ )every $\sigma\varepsilon Aut_KE$ KE $_{.K}E$ extends to a $K$ -automorphism of $N$ by Theorem 3.8. Therefore $\theta$ is an epimorphism. Since the homomorphic image of a solvable group is solvable (Theorem II.7.11), it suffices to prove that $\mathrm{Aut}_{K}N$ is solvable. If $K_1$ is the fixed field of $N$ relative to $\mathbf{Aut}_{K}N$ , then $N$ is a radical Galois extension of $K_{1}$ (Exercise 1) and $\mathrm{Aut}_{K_{1}}N=\mathrm{Aut}_{K}N.$ . Therefore, we may return to our original notation and with no loss of generality assume that $F=E$ and $F$ is a Galois radical extension of $K$ If $F=K(u_{1},\ldots,u_{n})$ with $u_{1}^{m_{1}}\varepsilon K$ and $u_{i}^{m_{i}}\varepsilon K(u_{1},\ldots,u_{i-1})$ for $i\geq2$ , then we

may assume that char $K$ does not divide $m_i$ . This is obvious if char $K=0.$ If char $K$ $=p\neq0$ and $m_{i}=rp^{t}$ with $(r,p)=1$ , then $u_{i}^{rp^{t}}\varepsilon K(u_{1},\ldots,u_{i-1})$ so that $u_i^r$ is purely inseparable over $K(u_{1},\ldots,u_{i-1})$ .But $F$ is Galois and thus separable over $K$ (Theorem 3.11), whence $F$ is separable over $K(u_1,\ldots,u_{i-1})$ (Exercise 3.12). Therefore $u_{i}^{r}\varepsilon K(u_{1},\ldots,u_{i-1})$ by Theorem 6.2, and we may assume $m_{i}=r$ If $m=m_{1}m_{2}\cdots m_{n}$ , then by the previous paragraph char = = $K\left(=\text{char }F\right)$ F $F$ doesnot

divide $m$ . Consider the cyclotomic extension $F(\zeta)$ of $F$ ,where $\zeta$ is a primitive mth root of unity (Theorem 8.1). The situation is this:

![](https://storage.simpletex.cn/view/fdPME5Z6I7BcWhSfOAPf3dMstmLsZzVDK)

------------------------------------------------------------------

where $F(\zeta)$ is Galois over $F$ (Theorem 8.1) and hence over $K$ as well (Exercise 3.15(b)). The Fundamental Theorem 2.5 shows that $\mathrm{Aut}_KF\cong\mathrm{Aut}_KF(\zeta)/\mathrm{Aut}_FF(\zeta)$ Consequently, it suffices by Theorem II.7.11 to prove that $\mathrm{Aut}_KF(\zeta)$ is solvable. Observe that $K(\zeta)$ is an abelian Galois extension of $K$ (Theorem 8.1), whence $\mathrm{Aut}_KK(\zeta)\cong\mathrm{Aut}_KF(\zeta)/\mathrm{Aut}_{K(\zeta)}F(\zeta)$ by the Fundamental Theorem 2.5. If we knew that $\mathrm{Aut}_{K(\zeta)}F(\zeta)$ were solvable, then Theorem II.7.11 would imply that $\mathrm{Aut}_KF(\zeta)$ is solvable (since $\mathrm{Aut}_{K}K(\zeta)$ is abelian, hence solvable). Thus we need only prove that $\mathrm{Aut}_{K(5)}F(\zeta)$ is solvable. By assumption, $F(\zeta)$ is Galois over $K$ and hence over any intermediate field. Let

$E_{0}=K(\zeta)$ and

$$E_{i}=\:K(\zeta,u_{1},\ldots,u_{i})\quad(i=1,2,\ldots,n)$$

so that $E_{n}=K(\zeta,u_{1},\ldots,u_{n})=F(\zeta)$ . Let $H_{i}=\mathrm{Aut}_{E_{i}}F(\zeta)$ the corresponding subgroup of $\mathrm{Aut}_{K(5)}F(\zeta)$ under the Galois correspondence. Schematically we have:

$$F(\zeta)=E_n|\longrightarrow\to H_n=1$$
· EH=AuteF) U EH=AutF
$$K(\zeta)=E_0\longmapsto\longrightarrow H_0=\mathrm{Aut}_{K(\zeta)}F(\zeta)$$

By Lemma 7.10(i) $K(\zeta)$ contains a primitive $m_ith$ root of unity for each $i\left(i=1,2,\ldots,n\right)$ . Since $u_{i}^{mi}\varepsilon E_{i-1}$ and $E_{i}=E_{i-1}(u_{i})$ ,each $E_i$ is a cyclic extension of $E_{i-1}$ by Lemma 7.10 (ii) (with $d=m_i$ )and Theorem 7.11(ii) (with $n=m_i$ ). In par ticular, $E_{2}$ is Galois over $E_{i-1}$ . The Fundamental Theorem 2.5 implies that for each $i=1,2,\ldots,n\: H_{i}\lhd H_{i-1}$ H,< H- $H_i\lhd H_{i-1}$ and $H_{i-1}/H_{i}\cong\mathrm{Aut}_{E_{i-1}}E_{i}$, whence $H_{i-1}/H_{i}$ is cyclic abelian. Consequently,

$$1=H_n<H_{n-1}<\cdots<H_0=\mathrm{Aut}_{K(\zeta)}F(\zeta)$$

is a solvable series (Definition II.8.3). Therefore, $\mathrm{Aut}_{K(5)}F(\zeta)$ is solvable by Theorem I1.8.5.

Corollary 9.5. Let K be a field and f e K[x]. If the equation $\mathbf{f}(\mathbf{x})=0$ is solvable by radicals, then the Galois group of f is a solvable group.

PROOF. Immediate from Theorem 9.4 and Definition 9.2.

EXAMPLE. The polynomial $f=x^{5}-4x+2\varepsilon\mathbf{Q}[x]$ has Galois group $S_5$ (see the example following Theorem 4.12), which is not a solvable group (Corollary 11.7.12). Therefore, $x^{5}-4x+2=0$ is not solvable by radicals and there can be no "formula" (involving only field operations and extraction of roots) for its solutions.

------------------------------------------------------------------

Observe that the base field plays an important role here. The polynomial $x^{5}-4x+2=0$ is not solvable by radicals over Q,but it is solvable by radicals over the field R of real numbers. In fact, every polynomial equation over R is solvable by radicals since all the solutions lie in the algebraic closure $\mathbf{C}=\mathbf{R}(i)$ which is a radical extension of R.

We close this section by proving a partial converse to Theorem 9.4. There is no difficulty if $K$ has characteristic zero. But if char $K$ is positive, it will be necessary to place some restrictions on it (or alternatively to redefine *"radical extension" - see Exercise 2).

Proposition 9.6. Let E be a finite dimensional Galois extension field of K with solvable Galois group $Au\iota_\mathrm{K}E$ .Assume that char $K$ does not divide $[E:K]$ .Then there exists a radical extension $F$ ofK such that $F\supset E\supset K$ .

REMARK. The requirement that $E$ be Galois over $K$ is essential (Exercise 3).

SKETCH OF PROOF OF 9.6. Since $Aut_KE$ KE $\kappa E$ is a fnite solvable group, it has a normal subgroup $H$ of prime index $p$ by Proposition I1.8.6. Since $E$ is Galois over $K$ $|\mathrm{Aut}_KE|=|E:K]$ (Theorem 2.5), so that char KXp . Let $N=E(\zeta)$ be a cyclotoinic extension of $E$ ,where $\zeta$ is a primitive pth root of unity (Theorem 8.1). Let $M=K(\zeta)$ then we have

![](https://storage.simpletex.cn/view/f1ZovOGUHR2wZ7hNMB2fIaMeKK9fTMPaI)

$N$ is finite dimensional Galois over $E$ (Theorem 8.1) and hence over $K$ as well Exercise 3.15(b)). Now $M$ is clearly aradical extension of $K$ . Consequently, it will suffice. (by Exercise 4) to show that there is a radical extension of $M$ that contains $N$ First observe that $E$ is a stable intermediate feld of $N$ and $K$ (Lemma 2.13). Thus

restriction $(\sigma\mid\sigma\mid E)$ induces a homomorphism $\theta:\mathrm{Aut}_MN\to\mathrm{Aut}_KE$ .Ifo $:\mathbf{A}_{\mathrm{ut}_{M}}N$ then $\sigma(\zeta)=\zeta$ .Hence if $\sigma\varepsilon Ker\theta$ 0 $\theta$ ,wehave $\sigma=1_{x}$ . Therefore $\theta$ is a monomorphism

We now prove the theorem by induction on. $n=[E:K]$ . The case $n=1$ is trivial Assume the theorem is true for all extensions of dimension $k<n$ and consider the two possibilities:

(i) $\mathbf{Aut}_MN$ is isomorphic under $\theta$ to a proper subgroup of $Aut_KE$ (i) $\theta:\mathrm{Aut}_MN\cong\mathrm{Aut}_KE$

In either case $\mathbf{Aut}_{M}N$ is -solvable (Theorem II.7.11) and $N$ is a fnite dimensional Galois extension of $K$ and hence of $M$ . In case (i) $[N:M]=|\mathrm{Aut}_MN|<|\mathrm{Aut}_KE|$ $=[E:K]=n$ , whence the inductive hypothesis implies that there is a radical extension of $M$ that contains $N$ .As remarked in the frst paragraph,this proves the theorem in case (i). In case (ii), let $J=\theta^{-1}(H)$ .Since $H$ is normal of index $p$ in $\mathbf{Aut}_{\mathcal{\Lambda}}E,J$ is normal of index $p$ in $\mathrm{Aut}_MN$ . Furthermore $J$ is solvable by Theorem I1.7.11. If $P$ is the fixed field of $J$ (relative to $\mathbf{Aut}_{M}N$ ,then wehave：

------------------------------------------------------------------

![](https://storage.simpletex.cn/view/fAdgg0ZVgSFdS1GQLQsXvF3PlIdIw6RzE)

The Fundamental Theorem 2.5 implies that $P$ is Galois over $M$ and that $\mathrm{Aut}_MP\cong\mathrm{Aut}_MN/J.$ But $[\mathrm{Aut}_MN:J]=p$ by construction, whence $\mathrm{Aut}_MP\cong Z_p$ Therefore, $P$ is a cyclic extension of $M$ and $P=M(u)$ , where $u$ is a root of some (irreducible) $\chi^{p}-a\varepsilon M[x]$ M[x] $M[x]$ (Theorem 7.11). Thus $P$ is a radical extension of $M$ and $[N:P]<[N:M]=[F:K]=n.$ Since $\mathrm{Aut}_PN=J$ is solvable and $N$ is Galois over $P$ (Theorem 2.5), the induction hypothesis implies that there is a radical extension $F$ of $P$ that contains N. $F$ is a clearly radical extension of $M$ (Exercise 4). This completes the proof of case (ii).

Corollary 9.7. Let K be a field and f ε K[x] a polynomial of degree $n>0$ ,where char K does not divide n! (which is always true when char $K=0$ ). Then the equation. $f(x)=0$ is solvable by radicals if and only if the Galois group of f is solvable

SKETCH OF PROOF. $(\Leftarrow)$ Let $E$ be a splitting field of $f$ over $K$ . In view of Proposition9.6 we need only show that $E$ is Galois over $K$ and char $KX[E:K]$ .Since char $K\nmid n!$ the irreducible factors of fare separable by Theorem IIl.6.10 and Exercise 111.6.3, whence $E$ is Galois over $K$ (Theorem 3.11 and Exercise 3.13). Since every prime that divides $[E:K]$ necessarily divides. $n$ !(Theorem 3.2), we conclude that char $KX[E:K]$

### APPENDIX:THE GENERAL EQUATION OF DEGREE n

The motivation for our discussion can best be seen by examining polynomial equations of degree 2 over a field $K$ with char $K\neq2$ .Here and below there will be no loss of generality in restricting consideration to monic polynomials. If $r_1$ and $t_2$ are indeterminates, then the equation

$$x^2-t_1x+t_2=0$$

over the field $K(t_1,t_2)$ of rational functions in $t_1,t_2$ is called the general quadratic equation over $K$ . Any (monic) quadratic equation over $K$ may be obtained from the general quadratic equation by substituting appropriate elements of $K$ for $I_1$ and $I_2$ . It is easy to verify that the solutions of the general quadratic equation (in some algebraic closure of $K(t_1,t_2))$ are given by:

$$x=\frac{t_1\pm\sqrt{t_1^2-4t_2}}{2},$$

------------------------------------------------------------------

where $n=n1_{K}$ for n e Z. This is the well known quadratic formula. It shows that the solutions of the general quadratic equation lie in the radical extension field $K(t_1,t_2)(u)$ with $u^{2}=t_{1}^{2}-4t_{2}$ . In order to find the solutions of $x^{2}-bx+c=0\left(b,c\in K\right)$ one need only substitute $b,c$ for $t_1,t_2$ Clearly the solutionslie in the radical extension $K(u)$ with $u^{2}=b^{2}-4c\varepsilon K$ . We now generalize these ideas to polynomial equations of arbitrary degree.

Let $K$ be a feld and n a positive integer. Consider the field $K(t_1,\ldots,t_n)$ ofrational functions over $K$ in the indeterminates $t_1,\ldots,t_n$ . The polynomial

$$p_{n}(x)=x^{n}-t_{1}x^{n-1}+t_{2}x^{n-2}+\cdots+(-1)^{n-1}t_{n-1}x+(-1)^{n}t_{n}\varepsilon K(t_{1},\ldots,t_{n})[x]$$

is called the general polynomial of degree n over $K$ and the equation $p_n(x)=0$ is called the general equation of degree n over $K$ .3 Note that any (monic) polynomial of degree $n$ in $K[x]$, say $f(x)=x^n+a_1x^{n-1}+\cdots+a_{n-1}x+a_n$ may be obtained from the general polynomial $p_n(x)$ by substituting $(-1)^{i}a_{i}$ for $t_i$

The preceding discussion makes the following definition quite natural. We say that there is a formula for the solutions of the general equation of degree $n$ provided that this equation is solvable by radicals over the field $K(t_1,\ldots,t_n)$ . If $p_{n}(x)=0$ is solvable by radicals, then the solutions of any (monic) polynomial equation of degree $n$ over $K$ may be found by appropriate substitutions in the solutions of $p_n(x)=0$ Having precisely formulated it, we can now settle the classical problem with which this section was introduced

Proposition 9.8.(Abel) Ler K be a field and n a positice integer.The generul eyuation of degreen is solvableby radicals only if $n\leq4$

REMARKS. The words "only if"in Proposition 9.8 may be replaced by "if and only if'when char $K=0$ .Ifradical extensions are defined as in Exercise 2, then “only if" may be replaced by "if and only if" for every characteristic. The fact that thegeneral equation of degree $n$ is not solvable by radicals for $n\geq5$ does notexclude the possibility that a particular polynomial equation over $K$ of degree $n\geq5$ is solvable by radicals.

SKETCH OF PROOF OF 9.8. Let the notation be as above and let $u_1,\ldots,u_n$ be the roots of $p_n(x)$ in some splitting field $F=K(t_1,\ldots,t_n)(u_1,\ldots,u_n)$ .Since $p_{n}(x)=(x-u_{1})(x-u_{2})\cdots(x-u_{n})$ in $F$ , a direct calculation shows that

$$t_1=\sum_{i=1}^nu_i;t_2=\sum_{1\leq i<j\leq n}u_iu_j;\ldots,t_n=u_1u_2\cdots u_n;$$

that is, $t_{i}=f_{i}(u_{1},\ldots,u_{n})$ where $f_{1},\ldots,f_{n}$ are the elementary symmetric functions in $n$ indeterminates (see the appendix to Section 2). It follows that $F=K(u_1,\ldots,u_n)$ Now consider a new set of indeterminates $\{x_1,\ldots,x_n\}$ and the field $K(x_{1},\ldots,x_{n})$ Let $E$ be the subfield of all symmetric rational functions in $K(x_1,\ldots,x_n)$ . The basic idea of the proof is to construct an isomorphism of fields $F\cong K(x_1,\ldots,x_n)$ such that $K(t_1,\ldots,t_n)$ is mapped onto $E$ .Then the Galois group Aut $t_{K(t_{1},\ldots,t_{n})}F$ ,of $p_n(x)$ will be isomorphic to $\mathrm{Aut}_EK(x_1,\ldots,x_n)$ . But $\mathrm{Aut}_{k^{\prime}}K(x_1,\ldots,x_n)$ is isomorphic to

------------------------------------------------------------------

$S_n$ (see p. 253). $S_n$ is solvable if and only if $n\leq4$ (Corollary I1.7.12 and Exercise 11.7.10). Therefore, if $p_{n}(x)=0$ is solvable by radicals then $n\leq4$ by Corollary 9.5. [Conversely if $n\leq4$ and char $K=0$ , then $\mu_{n}(x)=0$ is solvable by radicals by Corollary 9.7.] In order to construct the isomorphism $F\cong K(x_1,\ldots,x_n)$ we first observe that

the subfield $E$ of $K(x_1,\ldots,x_n)$ is precisely $K(f_1,\ldots,f_n)$ by Theorem 2.18,where $f_{1},\ldots,f_{n}$ are the elementary symmetric functions. Next we establish a ring isomor. phism $K[r_1,\ldots,t_n]\cong K[f_1,\ldots,f_n]$ as follows. By Theorem Il1.5.5 the assignment $g(t_1,\ldots,t_n)\vdash g(f_1,\ldots,f_n)$ (in particular $\iota_i\vdash f_i)$ defines an epimorphism of rings $\theta:K[t_1,\ldots,t_n]\to K[f_1,\ldots,f_n]$ . Suppose $g(t_1,\ldots,t_n)\vdash0$ ,so that $g(f_1,\ldots,f_n)=0$ in $K[f_1,\ldots,f_n]\subset K(x_1,\ldots,x_n)$ . By definition
$$f_k=f_k(x_1,\ldots,x_n)=\sum_{1\leq i_1<\ldots<i_k\leq n}x_{i_1}x_{i_2}\cdots x_{i_k}$$

and hence $0=\mathbf{g}(f_1,\ldots,f_n)=g(f_1(x_1,\ldots,x_n),\ldots,f_n(x_1,\ldots,x_n))$ fn(x1,...,xn)) $f_{n}(x_{1},\ldots,x_{n}))$ .Since $g(f_1,\ldots,f_n)$ is a polynomial in the indeterminates $x_{1},\ldots,x_{n}$ over $K$ and $F=K(u_{1},\ldots,u_{n})$ is a feld containing $K.$ , substitution of $u_i$ for $x_i$ yields

$$0=g(f_1(u_1,...,u_n),...,f_n(u_1,...,u_n))=g(t_1,...,t_n);$$

thus $\theta$ is a monomorphism and hence an isomorphism. Furthermore $\theta$ extends to an isomorphism of quotient fields $\theta:K(t_1,\ldots,t_n)\cong K(f_1,\ldots,f_n)=E$ (Exercise I11.4.7). Now $F=K(u_1,\ldots,u_n)$ is a splitting feld over $K(t_1,\ldots,t_n)$ of $p_n(x)$ and under theobvious map onpolynomials induced by $\theta,p_{n}(x)|\mapsto\bar{p}_{n}(x)=x^{n}-f_{1}x^{n-1}+$ $f_{2}x^{n-2}-\cdots+(-1)^{n}f_{n}=(x-x_{1})(x-x_{2})\cdots(x-x_{n})$ (see p.252).Clearly $K(x_1,\ldots,x_n)$ is a splitting feld of $\bar{p}_n(x)$ over $K(f_1,\ldots,f_n)=E$ . Therefore by Theo-. rem 3.8 the isomorphism $\theta$ extends to an isomorphism $F\cong K(x_1,\ldots,x_n)$ which by construction maps $K(t_1,\ldots,t_n)$ onto $E$ as desired.

### EXERCISES

1.If $F$ is a radical extension field of $K$ and $E$ is an intermediate field, then $F$ is a radical extension of $E$

2. Suppose that "radical extension"is defined as follows: $F$ is a radicalextension of $K$ if there is a fnite tower of fields $K=E_{0}\subset E_{\mathrm{l}}\subset\cdots\subset E_{n}=F$ such that for each $1\leq i\leq n$, $E_{i}=E_{i-1}(u_{i})$ and one of the following is true: (i) $u_{i}^{m_{i}}\varepsilon E_{i-1}$ for some $m_{i}>0$ ; (ii) char $K=p$ and $u^{n}-u\varepsilon E_{i-1}$ .State and prove the analogues of Theorem 9.4. Proposition 9.6, Corollary 9.7, and Proposition 9.8.

3. Let $K$ be a field, $f\varepsilon K[x]$ an irreducible polynomial of degree. $n\geq5$ and $F$ a. splitting field of $f$ over $K$ Assume that $\operatorname{Aut}_\kappa F\cong S_n$ . (See the example following Theorem 4.12). Let $u$ be a root of $f$in $F.$ F $F$ Then (a) $K(u)$ is not Galois over K; $[K(u):K]=n$ and $\mathrm{Aut}_{K}K(u)=1$ (and hence is

solvable). (b) Every normal closure over $K$ that contains $u$ also contains an isomorphic

copy of $F$ (c) There is no radical extension field $E$ of $K$ such that $E\supset K(u)\supset K$

4.If $F$ is a radical extension field of $E$ and $E$ is a radical extension field of $K$ , then $F$ is a radical extension of $K$

------------------------------------------------------------------

!

5. (Cardan) Let $K$ be a feld with char $K\neq2,3$ and consider the cubic equation $x^{3}+a_{1}x^{2}+a_{2}x+a_{3}=0\left(a_{i}\varepsilon K\right)$ Let $p=a_2-\frac{a_1^2}3$ and $q=\frac{2a_{1}^{3}}{27}-\frac{a_{1}a_{2}}{3}+a_{3}$ Let $P=\sqrt[3]{-q/2+\sqrt{p^{3}/27+q^{2}/4}}$ and $Q=\sqrt[3]{-q/2-\sqrt{p^{3}/27+q^{2}/4}}$ (with cube roots chosen properly). Then the solutions of the given equation are $P+Q-a_1,/3;\omega P+\omega^2Q-a_1/3$ ; and $\omega^{2}P+\omega Q-a_{1}/3$ where $\omega$ is a primitive cube root of unity.

------------------------------------------------------------------

# THE STRUCTURE OF FIELDS

In this chapter we shall analyze arbitrary extensionfields of a givenfield.Since algebraic extensions were studied in some detail in Chapter V, the emphasis here will be on transcendental extensions. As the first step in this analysis, we shall show that every field extension $K\subset F$ is in fact a two-step extension $K\subset E\subset F$ with $F$ algebraic over $E$ and $E$ purely transcendental over $K$ (Section 1). The basic concept used here is that of a transcendence base, whose cardinality (called the transcendence degree) turns out to be an invariant of the extension of $K$ by $F$ (Section 1). The notion of separability is extended to (possibly) nonalgebraic extensions in Section 2 and separable extensions are characterized in several ways.

## 1. TRANSCENDENCE BASES

The first part of this section is concerned with the concept of algebraic independence, which generalizes the idea of linear independence. A transcendence base of a field $F$ over a subfield $K$ is the analogue (with respect to algebraic independence) of a voctor space basis of $F$ over $K$ (with respect to linear independence). The cardinality of a transcendence base of $F$ over $K$ (the transcendence degree) is shown to be an invariant and its properties are studied. In this section we shall frequently use the notation $u/v$ for $uv^{-1}$ ,where $u,v$ are elements of a field and $v\neq0$ . Throughout this section $K$ denotes a field.

Definition 1.1. Let F be an extension field ofK and S a subset of F. S is algebraically dependent overK if for some positiveintegernthere exisis a nonzero polynomial fe $\mathbf{K}[\mathbf{x}_1,\ldots,\mathbf{x}_n]$ such that f( $s_{1}$, $\ldots$, $s_{n}$) = 0 for some distinct si, ... , $s_n$ ES.S is algebraically independent over K if'S is not algebraically dependent over K.

------------------------------------------------------------------

REMARKS. The phrase “over $K^{,,}$ is frequently omitted when the context is clear. A subset $S$ of $F$ is algebraically independent over $K$ if for all $n>0$ $f\varepsilon K[x_1,\ldots,x_n]$ and distinct $s_1,\ldots,s_n\in S$

$$f(s_1,\ldots,s_n)=0\quad\Rightarrow\quad f=0.$$

Every subset of an algebraically independent set is algebraically independent. In particular, the null set is algebraically independent. Every subset of $K$ is clearly algebraically dependent. The set $\{u\}$ is algebraically dependent over $K$ if and only if $u$ is algebraic over $K$ . Clearly every element of an algebraically independent set is necessarily transcendental over $K$ .Hence if $F$ is algebraic over $K$ , the null set is the only algebraically independent subset of $F$

Algebraic (in)dependence may be viewed as an extension of the concept of linear (in)dependence. For a set $S$ is linearly dependent over $K$ provided that for some positive integer $n$ there is a nonzero polynomial fof degree one in $K[x_1,\ldots,x_n]$ such that $f(s_1,\ldots,s_n)=0$ for some distinct $s_i\varepsilon S$ . Consequently, every algebraically independent set is also linearly independent, but not vice versa; (see the Example after Definition 1.4 below).

EXAMPLE. Let $K$ be a field. In the field of rational functions $K(x_1,\ldots,x_n)$ the set of indeterminates $\{x_1,\ldots,x_n\}$ is algebraically independent over $K$ .More generally, we have:

Theorem 1.2. Let F be an extension field ofK and $\{\mathbf{s}_1,\ldots,\mathbf{s}_n\}$ a subset ofFwhich is algebraically independent over K. Then there is K-isomorphism $K(s_1,\ldots,s_n)\cong$ $\mathbf{K}(\mathbf{x}_{1},\ldots,\mathbf{x}_{\mathrm{n}})$

SKETCH OF PROOF. The assignment $x_i\vdash s_i$ defines a $K$ -epimorphism of rings $\theta:K[x_1,\ldots,x_n]\to K[s_1,\ldots,s_n]$ by Theorems Il1.5.5 and V.1.3. The algebraic independence of $\{s_1,\ldots,s_n\}$ implies that $\theta$ is a monomorphism. By Corollary1I1.4.6 $\theta$ extends to a $K$ -monomorphism of fields (also denoted $\theta$ $K(x_1,\ldots,x_n)\to K(s_1,\ldots,s_n)$ such that $\theta(f/g)=f(s_{1},\ldots,s_{n})/g(s_{1},\ldots,s_{n})=$ $f(s_1,\ldots,s_n)g(s_1,\ldots,s_n)^{-1}$ $\theta$ is an epimorphism by Theorem V.1.3(v).

1

Corollary 1.3. For $\mathbf{i}=1,2$ let $F_{i}$ be an extensionfield of $K_{i}$ and $S_{\mathrm{i}}\subset F_{\mathrm{i}}$ with $S_{\mathrm{i}}$ algebraically independent over. $K_{\mathrm{i}}$ .If $\varphi:\mathcal{S}_1\to\mathcal{S}_2$ is an injective map of sets and. $\sigma:\mathbf{K}_1\to\mathbf{K}_2$ a monomorphism of felds,then o extends to a monomorphism of fields $\bar{\sigma}:\mathbf{K}_1(\mathcal{S}_1)\to\mathbf{K}_2(\mathcal{S}_2)$ such that $\bar{\sigma}(s)=\varphi(s)$ for every s e $S_{\mathrm{l}}$ . Furthermore if is bijective and $\sigma$ an isomorphism, then $\bar{\sigma}$ is an isomorphism

REMARK. In particular, the corollary implies that every permutation of an algebraically independent set. $S$ over a field $K$ extends to a $K$ -automorphism of $K(S)$ (just let $K_{1}=K=K_{2}$ and $\sigma=1_{K}$

SKETCH OF PROOF OF 1.3.For each $n\geq1\sigma$ induces a monomorphism of rings $K_{1}[x_{1},\ldots,x_{n}]\to K_{2}[x_{1},\ldots,x_{n}]$ (also denoted $\sigma$ ; see p. 235). Every element of

------------------------------------------------------------------

$K_1(S_1)$ is of the form $f(s_1,\ldots,s_n)/g(s_1,\ldots,s_n)\left(s_i\varepsilon S_1\right)$ (Si eS1) $(s_i\varepsilon S_1)$ by Theorem V.1.3. For convenience we write $\varphi s$ for $\varphi(s)$ and define $\bar{\sigma}:K_1(S_1)\to K_2(S_2)$ by

$$f(s_1,\ldots,s_n)/g(s_1,\ldots,s_n)\mapsto\sigma f(\varphi s_1,\ldots,\varphi s_n)/\sigma g(\varphi s_1,\ldots,\varphi s_n)\varepsilon K(S_2).$$

For any fnite subset $\{s_1,\ldots,s_r\}$ of $S_1$ the restriction of $\bar{\sigma}$ to $K_1(s_1,\ldots,s_r)$ is the composition

$$K_{1}(s_{1},\ldots,s_{r})\stackrel{\theta_{1}-1}{\to}K_{1}(x_{1},\ldots,x_{r})\stackrel{\hat{\sigma}}{\to}K_{2}(x_{1},\ldots,x_{r})\stackrel{\theta_{2}}{\to}K_{2}(\varphi s_{1},\ldots,\varphi s_{r}),$$

where the $\theta_i$ are the $K_i$ -isomorphims of Theorem 1.2 and $\hat{\sigma}$ is the unique monomorphism of quotient fields inducedby $\sigma{:}K_{\mathrm{l}}[x_{\mathrm{l}},\ldots,x_{\mathrm{r}}]\to K_{2}[x_{\mathrm{l}},\ldots,x_{\mathrm{r}}]$ and given by $\hat{\sigma}(f/g)=(\sigma f)/(\sigma g)$ (Corollary III.4.6). It follows that $\bar{\sigma}$ is a well-defined monomorphism of fields.By construction $\bar{\sigma}$ extends $\sigma$ and agrees with $\varphi$ on $S_{1}$ . If $\sigma$ is an isomorphism then so is each $\hat{\sigma}$ ,whence each $\theta_2\hat{\sigma}\theta_1^{-1}$ is an isomorphism. If $\varphi$ is bijective aswell then itfollows that $\bar{\sigma}$ is an isomorphism. 

Definition 1.4. Let F be an extension field of K. A transcendence base (or basis) of F over K is a subset S of F which is algebraically independent over K and is maximal (with respect to set-theoreticinclusion) in the set of all algebraically independent sub sets of F.

The fact that transcendence bases always exist follows immediately from a Zorn's Lemma argument (Exercise 2). If we recall the analogy between algebraic and linear independence, then a transcendence base is the analogue of a vector-space basis (since such a basis is precisely a maximal linearly independent subset by Lemma IV.2.3). Note, however, that a transcendence base is not a vector-space basis, although as a linearly independent set it is contained in a basis (Theorem IV.2.4)

EXAMPLE. If $f/g=f(x)/g(x)\varepsilon K(x)$ with $f,g\neq0$ ,then the nonzero polynomial $h(y_{1},y_{2})=g(y_{1})y_{2}-f(y_{1})\varepsilon K[y_{1},y_{2}]$ is such that $h(x,f/g)=g(x)[f(x)/g(x)]-$ $f(x)=0$ .Thus $\{x,f/g\}$ is algebraically dependent in $K(x)$ . This argument shows that $\{x\}$ is a transcendence base of $K(x)$ over $K$ . The set $\{x\}$ is not a basis since $\{1_{K},x,x^2,x^3,\ldots\}$ is linearly independent in $K(x)$

In order to obtain auseful characterization of transcendence bases we need

Theorem 1.5. Ler F be an extension field ofK, S a subset ofF algebraically independent overK,and u e F -K(S). Then S U {u} is algebraically independent over K. if and only if u is transcendental over K(S).

PROOF. $(\Leftarrow)$ If there exist distinct $s_{1},\ldots,s_{n-1}\varepsilon S$ and an $f\varepsilon K[x_1,\ldots,x_n]$ such that $f(s_1,\ldots,s_{n-1},u)=0$ ,then $u$ is a root of $f(s_{1},\ldots,s_{n-1},x_{n})\epsilon K(S)[x_{n}]$ .Now $f\varepsilon$ $K[ x_1, \ldots , x_n] = K[ x_1, \ldots , x_{n- 1}] [ x_n$ Xn~i][xn $x_{n-1}][x_n]$ ， whence $f=$ $h_{r}x_{n}^{r}+$ $h_{r- 1}x_{n}^{r- 1}+ \cdots +$ $h_{1}x_{n}+h_{0}$ with each $h_{i}\varepsilon K[x_{1},\ldots,x_{n-1}]$ .Since $u$ is transcendental over $K(S)$ ,we have $f(s_{1},\ldots,s_{n-1},x_{n})=0$ . Consequently, $h_{i}(s_{1},\ldots,s_{n-1})=0$ for every i. The algebraic independence of $S$ implies that $h_{\mathrm{i}}=0$ for every $i$ whence $f=0$ . Therefore $SU\{u\}$ is algebraically independent

------------------------------------------------------------------

$(\Rightarrow)$ Suppose $f(u)=0$ where $f=\sum_{i=0}^{n}a_{i}x^{i}\varepsilon K(S)[x]$ By Theorem V.1.3 there is a finite subset $\{s_1,\ldots,s_r\}$ of $S$ such that $a_{i}\in K(s_{1},\ldots,s_{r})$ for every $i$ whence $a_{i}=f_{i}(s_{1},\ldots,s_{r})/g_{i}(s_{1},\ldots,s_{r})$ for some $f_{i,g_{i}\in K[x_{1},\ldots,x_{r}]}$ .Let $g=g_{1}g_{2}\cdots g_{n}$ $\varepsilon K[x_{1},\ldots,x,]$ and for each i let $\bar{f}_{i}=f_{i}g_{1}\cdots g_{i-1}g_{i+1}\cdots g_{n}\varepsilon K[x_{1},\ldots,x_{r}]$ . Then $a_{i}=$ $\bar{f}_{i}(s_{1},\ldots,s_{r})/g(s_{1},\ldots,s_{r})$ and
$$\begin{aligned}
\text{||} \\
f(x)& =\sum a_{i}x^{i}=\sum\bar{f}_{i}(s_{1},\ldots,s_{r})/g(s_{1},\ldots,s_{r})x^{i} \\
&=\:g(s_{1},\ldots,s_{r})^{-1}(\sum\bar{f}_{i}(s_{1},\ldots,s_{r})x^{i}).
\end{aligned}$$

(All wehave done istofactor out a“common denominator"for the coefficients of $jf.$ Let $h(x_1,\ldots,x_r,x)=\sum\bar{f}_i(x_1,\ldots,x_r)x^i\varepsilon K[x_1,\ldots,x_r,x]$ Since $f(u)=0$ and $g(s_{1},\ldots,s_{r})^{-1}\neq0$ ,we must have $h(s_1,\ldots,s_r,u)=0$ . The algebraic independence of $S\cup\{u\}$ implies that $h=0$ , whence $\bar{f}_{i}=0$ for every $i.$ .Thus each $a_i=0$ and $f=0$ . Therefore $u$ is transcendental over $K(S)$ .

Corollary 1.6. Let F be an extension field ofK and S a subset ofF that is algebraically. independent over K. Then S is a transcendence base of F over K if and only if F is algebraic over K(S).

### PROOF. Exercise.

REMARKS.A field $F$ is called a purely transcendental extension of a feld $K$ if $F=K(S)$ ,where $S\subset F$ and $S$ is algebraically independent over $K$ . In this case $S$ is necessarily a transcendence base of $F$ over $K$ by Corollary 1.6. If $F$ is an arbitrary extension field of $K.$ ,let $S$ be a transcendence base of $F$ over $K$ and let $E=K(S)$ Corollary 1.6 shows that $F$ is algebraic over $E$ and $E$ is purely transcendental over $K.$ Finally Corollary 1.6 and the remarks afterDefinition 1.1 show that $F$ is an algebraic extension of $K$ if and only if the null set is a transcendence base of $F$ over $K$ . In this case thenull setis clearly the unique transcendencebase of $F$ over $K$

Corollary 1.7. If F is an extension field of K and F is algebraic over K(X) for some subset X of F (in particular, $if\mathbf{F}=\mathbf{K}(\mathbf{X})$ ,then $\mathbf{X}$ contains a transcendence base of F over K.

PROOF.Let S be a maximal algebraically independent subset of X $X$ $X(S$ exists by a routine Zorn's Lemma argument). Then every $u_{\varepsilon}X-S$ is algebraic over $K(S)$ by Theorem 1.5, whence $K(X)$ is algebraic over $K(S)$ by Theorem V.1.12. Consequently $F$ is algebraic over $K(S)$ by Theorem V.1.13. Therefore, $S$ is a transcendence base of $F$ over $K$ by Corollary 1.6.

As one might suspect from the analogy with linear independence and bases, any two transcendence bases have the same cardinality.As in the case of vector spaces, we break the proof into two parts.

Theorem1.8.Let F be an extensionfield ofK.If S is a finite transcendencebase of F over K, then every transcendence base of F over K has the same number of elements as S.

------------------------------------------------------------------

SKETCH OF PROOF. Let $S=\{s_{1},\ldots,s_{n}\}$ and let $T$ be any transcendence base. We claim that some $t_1$ E $T$ is transcendental over $K(s_2,\ldots,s_n)$ . Other wise every element of $T$ is algebraic over $K(s_2,\ldots,s_n)$ ,whence $K(s_2,\ldots,s_n)(T)$ is algebraic over $K(s_2,\ldots,s_n)$ by Theorem V.1.12. Since $F$ is algebraic over $K(T)$ by Corollary 1.6, $F$ is necessarily algebraic over $K(T)(s_2,\ldots,s_n)=K(s_2,\ldots,s_n)(T)$ . Therefore, $F$ is algebraic over $K(s_2,\ldots,s_n)$ by Theorem V.1.13. In particular, $s_1$ is algebraic over $K(s_2,\ldots,s_n)$ , which is a contradiction (Theorem 1.5). Hence some $\iota_1\varepsilon T$ is transcendental over $K(s_{2},\ldots,s_{n})$ . Consequently, $\{t_1,s_2,\ldots,s_n\}$ is algebraically independent by Theorem 1.5. Now if $s_1$ were transcendental over $K(t_1,s_2,\ldots,s_n)$ , then $\{t_1,s_1,s_2,\ldots,s_n\}$ would

be algebraically independent byTheorem 1.5. This is obviously impossible since $S$ is a transcendence base. Therefore,. $s_1$ is algebraic over $K(t_1,s_2,\ldots,s_n)$ . Consequently, $K(S)(t_1)=K(t_1,s_2,\ldots,s_n)(s_1)$ is algebraic over $K(t_1,s_2,\ldots,s_n)$ (TheoremV.1.12), whence $F$ is algebraic over $K(t_1,s_2,\ldots,s_n)$ (Theorem V.1.13 and Corollary 1.6). Therefore, $\{\iota_{1},s_{2},\ldots,s_{n}\}$ is a transcendence base of $F$ over $K$ by Corollary 1.6. A similar argument shows that some $\iota_2\varepsilon T$ is transcendental over $K(t_1,s_3,\ldots,s_n)$

whence $\{t_2,t_1,s_3,\ldots,s_n\}$ is a transcendence base. Proceeding inductively (inserting a $I_i$ and omitting an $S_i$ at each stage) we eventually obtain $\iota_1,\iota_2,\ldots,\iota_n\in T$ such that $\{t_1,\ldots,t_n\}$ is a transcendence base of $F$ over $K$ .Clearly, we must have $T=\{t_{1},\ldots,t_{n}\}$ and hence $|S|=|T|$

Theorem 1.9. Let F be an extension field ofK. IfS is an infinite transcendence base of F over K, then every transcendence base ofF over K has the same cardinality as S.

PROOF. If $T$ is another transcendence base, then $T$ is infnite by Theorem 1.8. If $s\varepsilon S$ ,then $s$ is algebraic over $K(T)$ by Corollary 1.6. The coefficients of the irreducible polynomial $f$ of $s$ over $K(T)$ all lie in $K(T_s)$ for some finite subset $T_{s}$ of $T$ (Theorem V.1.3). Consequently, $f_{\varepsilon}K(T_s)[x]$ and $s$ is algebraic over $K(T_s)$ . Choose such a finite subset $T_s$ of $T$ for each $s\varepsilon S$

We shall how that $\bigcup_{seS}T_s$ T. $T_{s}$ is a transcendence base of $F$ over $K$ . Since $\bigcup_{s}T,\subset T.$ this will imply that $\bigcup_{s}T_{s}=T$ . As a subset of $T$ the set $\bigcup_{s}T_i$ T. $T_{i}$ is algebraically independent. Furthermore every element of $S$ is algebraic over K(U T). Consequently, $K(\bigcup_{s}T_s)(S)$ is alebraic over $K(\bigcup T_s)$ by Thorem V.1.12.Since $K(S)\subset$ $K(\bigcup_{j}T_s)(S)$ , every element of $K(S)$ is algebraic over $K(\bigcup T_s)$ .Since $F$ is algebraic over $K(S)$ by Corollary 1.6, $F$ is also algebraic over $K(\bigcup T_s)$ (see Theorem V.1.13). Therfre ye orolaryl ete U $|T|\leq|S|$ $\bigcup_sT_s$ $T_s$ is tes $T_{s}$ cene bas hene $\bigcup_{s}T_{s}=T.$

and we remedy this as follows. Well order the set $S$ (Introduction, Section 7) and denote its first element by 1. Let $T_{1}^{\prime}=T_{1}$ and for each $1<s\in S$ , define $T_{s}^{\prime}=T_{s}-$ $\bigcup_{i\leq s}T_i$ . Clearly each $T_{s}^{\prime}$ is finite. Verify that $\bigcup_{s}T_{s}=\bigcup_{s}T_{s}^{\prime}$ and that the $T_{s}^{\prime}$ are i<s mutually disjoint. For each $s\epsilon S$ ,choose a fixed ordering of the elements of $T_s^{\prime}:t_1,t_2$,

------------------------------------------------------------------

$\ldots,t_{k_{8}}.$ The assignment $t_i\mapsto(s,i)$ defines an injective map U T' →S X N*. Therefore by Definitions 8.3 and 8.4 and Theorem 8.11 of the Introduction we have:

$$|T|=|\bigcup_{s}T_{s}|=|\bigcup_{s}T_{s}^{\prime}|\leq|S\times\mathbf{N}^{*}|=|S||\mathbf{N}^{*}|=|S|\mathbf{N}_{0}=|S|.$$

Reversing the roles of $S$ and $T$ in the preceding argument shows that $|S|\leq|T|$ whence $|S|=|T|$ by the Schroeder-Bernstein Theorem 8.6 of the Introduction.

Definition 1.10. Ler F be an extension field ofK. The transcendence degree ofF over K (denoted tr.d.F /K) is the cardinal number |Sl,where S is any transcendence base ofF over K.

The two preceding theorems show that tr.d. $.F/K$ is independent of the choice of S. In the analogy between algebraic and linear independence tr.d. $F/K$ is the analogue of the vector space dimension $[F{:}K]$ . The remarks and examples after Definition 1.4 show that tr.d. $F/K\leq[F:K]$ and that tr.c $1.F/K=0$ if and only if $F$ is algebraic over $K$

Theorem 1.11. If F is an extension feld ofE and E an extension field of K, then

$$tr.d.F/K=(tr.d.F/E)+(tr.d.E/K).$$

PROOF. Let $S$ be a transcendence base of $E$ over $K$ and $T$ a transcendence base of $F$ over $E.$ Since $S\subset E,S$ $S$ S is algebraically dependent over $E$ whenceS $T=\varnothing$ It suffices to show that $S$ U $T$ is a transcendence base of $F$ over $K$ , since in that case Definition 1.10 and Definition 8.3 of the Introduction imply

$$\mathrm{tr.d.}F/K=|S\cup T|=|T|+|S|=(\mathrm{tr.d.}F/E)+(\mathrm{tr.d.}E/K).$$

First of all every element of $E$ is algebraic over $K(S)$ (Corollary 1.6) and hence over $K(S\cup T)$ .Thus $K(S\cup T)(E)$ is algebraic over $K(S\cup T)$ by Theorem V.1.12. Since

$$K(S\bigcup T)=K(S)(T)\subset E(T)\subset K(S\bigcup T)(E),$$

$E(T)$ is algebraic over $K(S\cup T)$ .But $F$ is algebraic over $E(T)$ (Corollary 1.6) and therefore algebraic over $K(S\cup T)$ by Theorem V.1.13. Consequently, it suffices by Corollary 1.6 to show that $SUT$ T $T$ is algebraically independent over $K.$ Let $f$ be a polynomial over $K$ in $n+m$ variables (denoted for convenience

$x_1,\ldots,x_n,y_1,\ldots,y_m)$ such that $f(s_1,\ldots,s_n,t_1,\ldots,t_m)=0$ for some distinct S,..., $s_{1},\ldots,s_{n}\in S$, $s_n\varepsilon S$ $s_{1},\ldots,s_{n}\varepsilon S,\:t_{1},\ldots,t_{m}\varepsilon.T.$ tm $t_{m}$ Let $g=g(y_{1},\ldots,y_{m})=f(s_{1},\ldots,s_{n},y_{1},\ldots,y_{m})$ $K(S)[y_1,\ldots,y_m]\subset E[y_1,\ldots,y_m]$ .Since $g(t_1,\ldots,t_m)=0$ , the algebraic independence of $\boldsymbol{T}$ over $E$ implies that $g=0$ .Now $f=f(x_1,\ldots,x_n,y_1,\ldots,y_m)$ Hence
$$=\sum_{i=1}^{r}h_{i}(x_{1},\ldots,x_{n})k_{i}(y_{1},\ldots,y_{m})\mathrm{~with~}h_{i}\varepsilon K[x_{1},\ldots,x_{n}],k_{i}\varepsilon K[y_{1},\ldots,y_{m}].\\0=g(y_{1},\ldots,y_{m})=f(s_{1},\ldots,s_{n},y_{1},\ldots,y_{m})\quad\mathrm{implies~that~}h_{i}(s_{1},\ldots,s_{n})=$$
for $f(x_1,\ldots,x_n,y_1,\ldots,y_m)=0$ .Therefore $S$ S $SUT$ T $T$ is algebraically independen over $K$

1

1

------------------------------------------------------------------

If $K_1$ and $K_2$ are fields with algebraic closures, $F_1,F_2$ respectively, then Theorem V.3.8 implies that every isomorphism $K_{1}\cong K_{2}$ extends to an isomorphism $F_{1}\cong F_{2}$ Under suitable hypotheses this result can now be extended to the case where the fields $F_{i}$ are algebraically closed, but not necessarily algebraic over $K_i$

Theorem 1.12. Let $F_{1}$ [resp. $F_2]$ be an algebraically closed field extension of a field $K_1$ [resp. $K_2]$ .If $r.d.F_{1}/K_{1}=tr.d.F_{2}/K_{2}$, then every isomorphism of felds $\mathbf{K}_1\cong\mathbf{K}_2$ extends to an isomorphism $\mathbf{F}_{\mathrm{l}}\cong\mathbf{F}_{2}$

PROOF. Let $S_i$ be a transcendence base of $F_{i}$ over $K_i$ . Since $|S_1|=|S_2|$ $\sigma:K_1\cong K_2$ extends to an isomorphism $\bar{\sigma}:K_1(S_1)\cong K_2(S_2)$ by Corollary 1.3. $F_{i}$ is algebraically closed and algebraic over $K_i(S_i)$ (Corollary 1.6) and hence an algebraic closure of $K_i(S_i)$ . Therefore $\bar{\sigma}$ extends to an isomorphism $F_{1}\cong F_{2}$ by Theorems V.3.4 and v.3.8.

## EXERCISES

Note: $F$ is always an extensionfield of a field $K$

1. (Exchange property) Let $S$ be a subset of $F$ .If $u\varepsilon F$ F $F$ is algebraic over $K(S)$ and $u$ is not algebraic over $K(S-\{v\})$ where $v\varepsilon S$ ，then $v$ is algebraic over $K((S-\{v\})\cup\{u\})$

2. (a) Use Zorn's Lemma to show that every field extension possesses a transcendence base. (b) Every algebraically independent subset of $F$ is contained in a transcendence base.

3. $\{x_1,\ldots,x_n\}$ is a transcendence base of $K(x_1,\ldots,x_n)$

4. If $E_1,E_2$ are intermediate fields, then

(i) tr. d. $E_{1}E_{2}/ K\geq$tr.d.$E_i/K$ for $i=1,2$ (i) .EE2/K≤ $.E_{1}E_{2}/K\leq$ tr. d. $E_{1}E_{2}/ K\leq ($tr.d.$E_1/K)+($tr.d.$E_2/K)$

5.If $F=K(u_{1},\ldots,u_{n})$ is a finitely generated extension of $K$ and $E$ is an inter. mediate field, then $E$ is a finitely generated extension of $K$ . [Note: the algebraic case is trivial by Theorems V.1.11 and V.1.12.]

6. (a) If S is a transcendence base of the field C of complex numbers over the field Q of rationals, then $S$ is infinite. [Hinr: Show that if $S$ is finite, then

$$|\mathbf{Q}(S)|=|\mathbf{Q}(x_1,\ldots,x_n)|=|\mathbf{Q}[x_1,\ldots,x_n]|=|\mathbf{Q}|<|\mathbf{C}|$$

(see Exercises 8.3 and 8.9 of the Introduction and Theorem 1.2). But Lemma V.3.5 implies $|\mathbf{Q}(S)|=|\mathbf{C}|.$ (b) There are infinitely many distinct automorphisms of the field C. (c) $\mathbf{tr.d.C/Q=|C|.}$

7.If $F$ is algebraically closed and $E$ an intermediate field such that $\mathbf{tr.d.E/K}$ is finite, then any $K.$ -monomorphism $E\to F$ extends to a $K$ -automorphism of $F$

8. If $F$ is algebraically closed and tr.d. $F/K$ is finite, then every $K$ -monomorphism $F\to F$ is in fact an automorphism

------------------------------------------------------------------

## 2. LINEAR DISJOINTNESS AND SEPARABILITY

The chief purpose of this section is to extend the concept of separability to (possibly) nonalgebraic field extensions. This more general concept of separability will agree with our previous definition in the case of algebraic extensions (Theorem 2.8). We first introduce the idea of linear disjointness and develop its basic properties (Theorems 2.2-2.7). Separability is defined in terms of linear disjointness and characterized in several ways (Theorem 2.10). Other properties of separability are developed in the corollaries of Theorem 2.10. In the following discussion all fields are assumed to be subfields of some (fixed)

algebraically closed field $C$

Definition 2.1. Let C be an algebraically closed field with subfields K,E,F such that K C E M F. E and F are linearly disjoint orer K if every subser ofE which is linearly independent over K is also linearly independent orer F.

REMARKS. An alternate definition in terms of tensor products is given in Exercise 1. Note that a subset $X$ of $E$ is linearly independent over a subfield of $C$ if and only if every finite subset of $X$ is. Consequently, when proving linear disjointness, we need only deal with finite linearly independent sets.

EXAMPLE. If $K\subset E$ then $E$ and $K$ are trivially linearly disjoint over $K$ . This fact will be used in several proofs. Other less trivial examples appear in the theorems and exercises below.

The wording of Definition 2.1 suggests that the definition of linear disjointness is in fact symmetric in $E$ and $F$ .We now prove this fact.

Theorem 2.2. Ler C be an algebraically closed feld with subfelds K,E,F such thal $K\subset E\cap$ F.Then E and F are linearly disjoint orer K if and only ifF and E are linearly disjoint ocer K.

PROOF. It suffices to assume $E$ and $F$ linearly disjoint and show that $F$ and $E$ are linearly disjoint. Suppose $X\subset F$ is linearly independent over $K$ ,but not over $E$ SO that $r_1u_1+\cdots+r_nu_n=0$ for some $u_2\in X$ and $r_i\varepsilon E$ E $E$ not all zero. Choose a subset of $\{r_1,\ldots,r_n\}$ which is maximal with respect to linear independence over $K$ ; reindex if necesary s that hise is $\{r_1,r_2,\ldots,r_l|(t\geq1)$ . Then for cach $j>t,r_{i}=\sum_{i=1}^{t}a_{ij}r_{i}$ with $a_{ij}\in K$ K $K$ (Exercise IV.2.1). After a harmless change of index we have:

$$\begin{aligned}\text{0}&=\sum_{j=1}^{n}r_{j}u_{j}=\sum_{j=1}^{t}r_{j}u_{j}+\sum_{j=t+1}^{n}\left(\sum_{i=1}^{t}a_{i},r_{i}\right)u_{j}\\&=\sum_{k=1}^{t}\left(u_{k}+\sum_{j=t+1}^{n}a_{k},u_{j}\right)r_{k}.\end{aligned}$$

Since $E$ and $F$ are linearly disjoint, $\{r_1,\ldots,r_l\}$ is linearly independent over $F$ which

------------------------------------------------------------------

implies that $u_{k}+\sum_{j=t+1}^{n}a_{kj}u_{j}=0$ for every $k\leq t.$ This contradicts the linear inde pendence of $X$ over $K$ . Therefore $X$ is linearly independent over $E$ .■

The following lemma and theorem provide some useful criteria for two fields to be linearly disjoint.

Lemma 2.3. Let C be an algebraically closed field with subfields K,E,F such that K C E F. Let R be a subring ofE such that $\mathbf{K}(\mathbf{R})=\boldsymbol{E}$ and $K\subset\mathbb{R}$ (which implies that R is a vector space over K). Then the following conditions are equivalent:

(i)E and F are linearly disjoint overK; (i)every subset of R that is linearly independent over K is also linearly inde

pendent ouer F; (ii) there exists a basis of R over K which is linearly independent over F.

REMARK. The lemma is true with somewhat weaker hypotheses (Exercise 2) but this is all that we shall need.

PROOF OF 2.3. (i$) \Rightarrow$ (ii) and (i$) \Rightarrow$ (ii) are trivial. (ii) $1\Longrightarrow ($i) Let $X=\{u_{1},\ldots,u_{n}\}$ be a finite subset of $E$ which is linearly independent over $K$ .We must show that $X$ is linearly independent over $F$ .Since $u_i\varepsilon E=K(R)$ each $u_i$ is of the form $u_{i}=c_{i}d_{i}^{-1}$ $=c_i/d_i$ ，where $c_{1}=f_{i}(r_{1},\ldots,r_{ti})$ ， $0\neq d_{1}=g_{i}(r_{1},\ldots,r_{ti})$ with $r_j\varepsilon R$ and $f_{i,g_i\varepsilon}$ $K[x_{1},\ldots,x_{t_{i}}]$ (Theorem V.1.3). Let $d=d_1d_2\cdots d_n$ and for each $i$ let $v_{i}=$ $c_{i}d_{1}\cdots d_{i-1}d_{i+1}\cdots d_{n}\in R$ . Then $u_{i}=v_{i}d^{-1}$ and the subset $X^{\prime}=\{v_1,\ldots,v_n\}$ of $R$ is linearly independent over a subfeld of $C$ if and only if $X$ is. By hypothesis $X$ and hence $X^{\prime}$ is linearly independent over. $K$ .Consequently, (i) implies that $X^{\prime}$ is linearly independent over $F$ ,whence $X$ is linearly independent over $F$ (i $\Longrightarrow$ → i$) \Rightarrow ($ii) Let $U$ be a basis of $R$ over $K$ which is linearly independent over $F$ We

must show that every finite subset $X$ of $R$ that is linearly independent over $K$ is also linearly independent over $F$ . Since $X$ is finite, there is a finite subset $U_{1}$ of $U$ such that $X$ is contained in the $K$ -subspace $V$ of $R$ spanned by $U_{1}$ ; (note that $U_{1}$ is a basis of $V$ over $K$ ). Let $V_{1}$ be the vector space spanned by $U_{1}$ over $F$ $U$ and hence $U_{1}$ is linearly independent over $F$ by (ii). Therefore $U_{1}$ is a basis of $V_1$ over $F$ and $\dim_KV=\dim_FV_1$ Now $X$ is contained in some finite basis $W$ of $V$ over $K$ (Theorem IV.2.4). Since $W$ certainly spans $V_{1}$ as a vector space over $F$ $W$ contains a basis $W_{1}$ of $V_{1}$ over $F$ .Thus $|W_{\mathrm{i}}|\leq|W|=\dim_{\mathrm{i}}V=\dim_{\mathrm{i}}V_{\mathrm{i}}=|W_{\mathrm{i}}|$ ,whence $W=W_{1}$ . Therefore, the subset $X$ of $W$ is necessarily linearly independent over $F$

------------------------------------------------------------------



------------------------------------------------------------------

SKETCH OF PROOF. Every $a\varepsilon K$ is of the form $a=v^{p^n}$ for some $v$ E $K^{1/p^n}$ (Exercise 5). For the first statement note that $\sum_ia_iu_i^{p^n}=0$ $(a_{i}\varepsilon K;\:u_{i}\varepsilon X)\Leftrightarrow$ $\sum_{i}v_{i}^{p^n}u_{i}^{p^n}=0$ $(v_{i}\in K^{1/p^{n}}$ and $v_{i}^{p^{n}}=\:a_{i})\Leftrightarrow(\sum_{i}\:v_{i}u_{i})^{p^{n}}=0\Leftrightarrow\sum_{i}\:v_{i}u_{i}=0$ For the second satemet oserve that if $\sum_{i=1}^{t}w_{i}u_{i}=0\:(w_{i}\varepsilon\:K^{1/p^{\infty}};\:u_{i}\:\varepsilon X)$ , then fo a large enough $n,\:w_{1},\ldots,w_{t}\in K^{1/p^{n}}$ Wt E K1/pn $w_{t}\in K^{1/p^n}$

Theorem 2.7.Let F be a field contained in an algebraically closed field C. IfF is a purely transcendental extension of a field K of characteristic $\mathbf{p}\neq0$ ,then $F$ and $K1/p^n$ are linearly disjoint over Kfor all $n\geq0$ and F and $K1/p\varpi$ are linearly disjoint over K.

PROOF. Let $F=K(S)$ with $S$ a transcendence base of $F$ over $K.$ If $S=\varnothing$ , then $F=K$ and every linearly independent subset of $F$ over $K$ consists of exactly one nonzero element of $K$ .Such a nonzero singleton is clearly linearly independent over any subfield of $C$ whence the theorem is true if $S=\varnothing$ . If $S$ is not empty let $M$ be the set of monomials over $S$ (that is, the set of all finite products of elements of $S$ ).Then $M$ is linearly independent over $K$ since $S$ is algebraically independent over $K$ By Theorem $\mathbf{V}.1.3\:M$ M $M$ spans the subring $K[S]$ (considered as a vector space over $K$ ). Therefore, $M$ is a basis of $K[S]$ over $K.$ The algebraic independence of $S$ implies that for every $n\geq0$ $M^{p^n}=\{m^{p^n}\mid m\varepsilon M\}$ is linearly independent over $K$ .By Lemma 2.6 $M$ is linearly independent over $K^{1/p^n}$ for every $n$ and hence over $K^{1/p^{\circ}}$ . Therefore, for each $0\leq n\leq\infty$, $F$ and $K^{1/p^n}$ are linearly disjoint over $K$ by Lemma 2.3 (with $K[S]$ $F,K^{1/p^n}$ in place of $R,E,F$ F $F$ respectively).

The next theorem shows the connection between linear disjointness and separable algebraic extensions and will motivate a definition of separability in the case of arbitrary (possibly nonalgebraic) extensions

Theorem 2.8. Let F be an algebraic extension field of a field K of characteristic $\mathbf{p}\neq0$ and C an algebraically closed field containing F. Then F is separable over K if and only ifF and $K1/p$ are linearly disjoint orer K.

PROOF. We shall prove here only that separability implies that $F$ and $K^{1/p}$ are linearly disjoint. The other half of the proof will be an easy consequence of a result below (see the Remarks after Theorem 2.10). Let $X=\left\{u_{1},\ldots,u_{n}\right\}$ be a finite subset of $F$ which is linearly independent over $K$ . We must show that $X$ is linearly independent over $K^{1/n}$ . The subfield $E=K(u_1,\ldots,u_n)$ is finite dimensional over $K$ (Theorem V.1.12) and has a basis $\{u_{1},\ldots,u_{n},u_{n+1},\ldots,u_{r}\}$ which contains $X$ (Theorem,IV.2.4) If $c\varepsilon E$ $E$ E and $k$ is psiv ineger then $v^{k}=\sum_{i=1}^{r}a_{i}u_{i}\left(a_{i}\varepsilon K\right)$ and hence $v^{k_{p}}=(\sum_{i}\omega_{i}u_{i})^{\prime\prime}=\sum a_{i}^{p}u_{i}^{\prime\prime}$ . Since $v$ is separable over $K,\:K(v)$ is both separable algebraic and purely inseparable over $K(c^n)$ (Theorem V.6.4 and Lemma V.6.6) whence $K(v)=K(v^p)=K[v^p]$ (Theorems V.1.6 and V.6.2). Thus $\upsilon$ is a linear combination of the $c^{k_1,}$ and hence of the $u_ir$ . Therefore $E$ is spanned by $\{u_1^p,\ldots,u_r^n\}$ Since $[E:K]=r$, $\{u_{1}^{p},\ldots,u_{r}^{p}\}$ must be a basis by Theorems IV.2.5 and IV.2.7.

------------------------------------------------------------------

Thus $\left\{\begin{array}{c}{u_1}^{n},\ldots,u_r^{p}\\\end{array}\right\}$ and hence $X^{p}$ is linearly independent over $K$ .By Lemma $2.6X$ is linearly independent over. $K^{1/\eta}$ , whence $F$ and $K^{1/p}$ are linearly disjoint over $K$ .

Definition 2.9. Let F be an extension field ofK. A transcendence base S ofF over K is called a separating transcendence base of F over K if F is separable algebraic over K(S). IfF has a separating transcendence base over K, then F is said to be separably generated over K.

REMARKS. Recall that $F$ is algebraic over $K(S)$ (Corollary 1.6). If $F$ is separably generated over $K$ , it is not true that every transcendence base of $F$ over $K$ is neces sarily a separating transcendence base (Exercise 8).

EXAMPLES. If $F$ is separable algebraic over $K$ , then the null set is a separating transcendence base. Every purely transcendental extension is trivially separably generated since $F=K(S)$

In order to make the principal theorem meaningful in the case of characteristic zero we define (for any field $K$ of characteristic O) $K^{1/0}=K^{1/0^n}=K^{1/0^\infty}=K$

Theorem 2.10.IfF is an extension field of afield K of characteristic $p\geq0$ and C is an algebraically closed field containing F, then the following conditions are equivalent

(i) F and $K1/p$ are linearly disjoint over K; (i) $F$ and $K^{1/pn}$ are linearly disjoint over K for some $n\geq1$ ;

(ii) F and $K^{1/p\varpi}$ are linearly disjoint overK；

(iv) every finitely generated intermediate field E is separably generated orer K;

(v) $K_0$ and F are linearly disjoint over $K$ , where $K_0$ is the fixed field (relative to C and K) of $Aut_\mathrm{K} \mathbf{C}$

REMARKS. The theorem is proved below.The implication (i$) \Rightarrow ($iv) provides a proof of the second half of Theorem 2.8 as follows. For every $u\in F,K(u)$ is a fnitely generated intermediate feld and thus separably generated over $K$ .But $F$ (and hence $K(u))$ is assumed algebraic over $K$ and the only transcendence base of an algebraic extension is the null set. Therefore $K(u)$ is separable algebraic over $K(\varnothing)=K$ Hence every $u\varepsilon F$ F $F$ is separable algebraic over $K$

SKETCH OF PROOF OF 2.10.Except in proving (ii) $\Leftrightarrow(\mathbf{v})$ we shall assume that char $K=p\neq0$ since the case when char $K=0$ is trivial otherwise. (iii$) \Rightarrow$ = $\Rightarrow$ (ii$) \Rightarrow ($i) is immediate since $K^{1/p}\subset K^{1/p^n}\subset K^{1/p^\infty}$ for every $n\geq1$

(i$) \Rightarrow ($iv) Let $E=K(s_1,\ldots,s_n)$ and tr $.\mathbf{d}.E/K=r$ .By Corollary $1.7r\leq n$ and some subset of $\left|s_{1},\ldots,s_{n}\right|$ is a transcendence basis of $E$ over $K$ ,say $\{s_1,\ldots,s_r\}$ If $r=n$ , then $\{s_1,\ldots,s_n\}$ is trivially a separating transcendence base, whence (iv) holds. If $r<n$ , then $s_{r+1}$ is algebraic over $K(s_1,\ldots,s_r)$ (Corollary 1.6) and therefore the ro of nireducble monie plsnormal $f(x)=\sum_{i=1}^{m}a_{i}x^{i}\varepsilon K(s_{1},\ldots,s_{r})[x]$ A “"least common denominator argument" such as that used in the proof of Theorem

i

1

|

------------------------------------------------------------------

$$\begin{gathered}
\mathrm{ws~that~}f(x)=d^{-1}\biggl(\sum_{i=1}^{m}v_{i}x^{i}\biggr)\:\mathrm{with~}0\neq d\varepsilon\:K[s_{1},\ldots,s_{r}],\:v_{i}=h_{i}(s_{1},\ldots,s_{1}) \\
i\:\varepsilon\:K[x_{1},\ldots,x_{r}].\quad\mathrm{Thus}\quad f_{1}=\sum_{i=0}^{m}h_{i}(x_{1},\ldots,x_{r})x_{r+1}^{i}\:\varepsilon\:K[x_{1},\ldots,x_{r+1}]\quad\mathrm{ar} 
\end{gathered}$$
and least positive degree such that $g(s_{1},\ldots,s_{r+1})=0$ . Clearly $g$ is irreducible in $K[x_1,\ldots,x_{r+1}]$ Recall that $x_{i}$ is said to occur in $g(x_1,\ldots,x_n)$ if some nonzero term of $g$ contains a factor $x_i^m$ with $m\geq1$ We claim that some $x_i$ occurs in $g$ with an exponent that is not divisible by $P$

Otherwise $g=c_{0}+c_{1}m_{1}(x_{1},\ldots,x_{r+1})^{p}+\cdots+c_{k}m_{k}(x_{1},\ldots,x_{r+1})^{p}$ ，where $c_{i}\in K.$ the $c_i$ are not all zero, and each $m_{j}(x_{1},\ldots,x_{r+1})$ is a monomial in $x_1,\ldots,x_{r+1}$ Xr+1 $x_{r+1}.$ Let $m_{l0}(x_{1},\ldots,x_{r+1})=1_{K}$ and for each $j\geq0$ choose $d_{i}\in K^{1/\eta}$ such that $d_{j}^{p}=c_{i}$ . Then $g=\left(\sum_{j=0}^{k}d_{i}m_{i}(x_{1},\ldots,x_{r+1})\right)^{p}$ and $g(s_{1},\ldots,s_{r+1})=0$ imply that

$$\sum_{j=0}^k\:d_im_i(s_1,\ldots,s_{r+1})\:=\:0,$$

whence the subset $\{m_{j}(s_{1},\ldots,s_{r+1})\mid j\geq0\}$ of $F$ is linearly dependent over $K^{1/p}$ . But $\{m_{j}(s_{1},\ldots,s_{r+1})\mid j\geq0\}$ is necessarily linearly independent over. $K$ (otherwise there would exist a $g_{1}\varepsilon K[x_{1},\ldots,x_{r+1}]$ with deg $g_{1}<\deg g$ g $g$ and $g_{1}(s_{1},\ldots,s_{r+1})=0)$ .This fact contradicts the linear disjointness of $F$ and $K^{1/p}$ .Therefore some $X_i$, say $x_{1}$ occurs in $g$ with an exponent that is not divisible by $p$ The polynomial $g(x,s_2,\ldots,s_{r+1})\varepsilon K(s_2,\ldots,s_{r+1})[x]$ is necessarily nonzero.

Otherwise, since $x_1$ occurs in $g(x_1,\ldots,x_{r+1})$ by the previous paragraph, we could obtain a polynomial $g_{2}\varepsilon K[x_{1},\ldots,x_{r+1}]$ $x_{r+1}]$ Xr+1] such that 0< deg $g_2<\deg g$ and $g_{2}(s_{1},s_{2},\ldots,s_{r+1})=0$ .Such a $g_2$ would contradict the choice of $g$ .Therefore, $g(x,s_{2},\ldots,s_{r+1})\neq0$ Since $g(s_{1},s_{2},\ldots,s_{r+1})=0.$ $s_{1}$ is algebraic over $K(s_{2},\ldots,s_{r+1})$ But $s_2,\ldots,s_{r+1}$ $s_{r+1}$ Sr+1 are obviously algebraic over $K(s_2,\ldots,s_{r+1})$ and $E$ is algebraic over $K(s_{1},\ldots,s_{r+1})$ . By Theorems V.1.12 and $\mathbf{V}.1.13E$ is algebraic over $K(s_{2},\ldots,s_{r+1})$ Since tr.d. $E/K=r$ $\{s_2,\ldots,s_{r+1}\}$ is a transcendence base of $E$ over $K$ (Corollary 1.7). The proof of Theorem 1.2 shows that the assignment $x_i\vdash s_i$ determines a $K$ -iso-

morphism $\phi:K[x_2,\ldots,x_{r+1}]\cong K[s_2,\ldots,s_{r+1}]$ . Clearly $\phi$ extends to a $K$ -isomorphism $K[x_{1},x_{2},\ldots,x_{r+1}]=K[x_{2},\ldots,x_{r+1}][x_{1}]\cong K[s_{2},\ldots,s_{r+1}][x_{1}]$ X+il[x] ≤ K[s2,... , S+l[ $x_{r+1}][x_{1}]\cong K[s_{2},\ldots,s_{r+1}][x]$ such that $x_1\mapsto x$ and $g(x_{1},\ldots,x_{r+1})\vdash g(x,s_{2},\ldots,s_{r+1})$ . Since $\phi$ is an isomorphism, $g(x,s_2,\ldots,s_{r+1})$ must be irreducible in $K[s_{2},\ldots,s_{r+1}][x]$ . Consequently $g(x,s_2,\ldots,s_{r+1})$ is primitive in $K[s_2,\ldots,s_{r+1}][x]$ and hence irreducible in $K(s_2,\ldots,s_{\tau+1})[x]$ by Lemma I11.6.13 and Theorem I1.6.14. Since $\phi$ is an isomorphism $x$ must occur in $g(x,s_2,\ldots,s_{r+1})$ with an exponent not divisible by $p$ . Thus the derivative of $g(x,s_2,\ldots,s_{r+1})$ is nonzero (Exercise I11.6.3), whence $g(x,s_2,\ldots,s_{t+1})$ is separable by Theorem I1l.6.10. Therefore $s_1$ is separable algebraic over $K(s_{2},\ldots,s_{r+1})$ and hence over $K(s_{2},\ldots,s_{n})$ In particular, $E=K(s_1,\ldots,s_n)$ is separable algebraic over $K(s_2,\ldots,s_n)$ by Lemma V.6.6. Thus if $\{s_{2},\ldots,s_{n}\}$ is a transcendence base of $E$ ovel $K$ , then $E$ is separably generated over $K$ . If not, then $\{s_2,\ldots,s_n\}$ contains a transcendence base (Corollary 1.7), which we may assume (after reindexing if necessary) to be $\{s_2,\ldots,s_{r+1}\}$ .A repetition of the preceding argument (with $s_{i+1}$ in place of $s_i$ for $i=1,2,\ldots,r+1$ and possibly more reindexing) shows that $s_2$ (and hence $K(s_2,\ldots,s_n))$ is separable algebraic over $K(s_{3},\ldots,s_{n})$ .Hence $E$ is separable algebraic over $K(s_3,\ldots,s_n)$ by Corollary V.6.8. Continuing this process we must eventually find $s_1,\ldots,s_t$ such that $E$ is separable algebraic over $K(s_{t+1},\ldots,s_n)$

------------------------------------------------------------------

and $\{s_{t+1},\ldots,s_n\}$ is a transcendence base of $E$ over $K$ . Therefore $E$ is separably generated over $K$ (iv$)\Rightarrow$ → $\Rightarrow$ (ii) Let $W$ be a finite subset of $F$ that is linearly independent over $K$ We

must show that $W$ is linearly independent over $K^{1/p^{\varpi}}$ . Let $E=K(W)$ .Weneed only show that $E$ and $K^{1/p^{\varpi}}$ are linearly disjoint over $K$ , since this fact immediately implies. that $W$ is linearly independent over $K^{1/p^{\infty}}$ . Since $W$ is finite, $E$ has a separating tran- scendence base $S$ over $K$ by (iv). We shall prove the linear disjointness of $E$ and $K^{1/p^\infty}$ by applying Theorem 2.4 to the extensions $K\subset K^{1/p^{\varpi}}$ and $K\subset K(S)\subset E$ as follows. $K(S)$ and $K^{1/p^{\infty}}$ are linearly disjoint over $K$ by Theorem 2.7. Let $X$ be a subset of $E$ that is linearly independent over $K(S)$ .Since $E$ is separable algebraic over $K(S),X$ is linearly independent over $K(S)^{1/p}$ by the half of Theorem 2.8 already proved. Therefore $X^p$ is linearly independent over $K(S)$ by Lemma 2.6. The last three sentences form the heart of an inductive argument which shows that $X^{pm}$ is linearly independent over $K(S)$ for all $m\geq0$ ; (note that $(X^{p^r})^p=X^{p^{r+1}}$ ).Hence $X$ is linearly independent over $K(S)^{1/p^m}$ for all $m\geq0$ by Lemma 2.6 again. Therefore $X$ is linearly independent over $K(S)^{1/p^{\varpi}}$ and hence over its subfeld $K^{1/p^{\infty}}K(S)$ . We have proved that $E$ and $K^{1/p^{\infty}}K(S)$ are linearly disjoint over $K(S)$ . Consequently $E$ and $K^{1/r^{\infty}}$ are linearly disjoint over $K$ by Theorem 2.4. (ii) $\Longleftrightarrow(\mathbf{v})$ . It suffices to prove that $K_{0}=K^{1/p^{\mathrm{o}}}$ . Let ue $K_0$ .If $u$ is transcendental

over $K$ , then there exists $\upsilon\varepsilon C$ with $v\neq u$ and $v$ transcendental over $K$ (for example, take $v=u^{2}$, 0. The composition $K(u)\cong K(x)\cong K(v)$ (where the isomorphisms are given by Theorem V.1.5) is a $K$ -isomorphism $\sigma$ such that $\sigma(u)=v$ .We thus have $\mathbf{l}=$tr.d.K$(x)/K=$tr.d.$K(u)/K=$tr.d.$K(v)/K$ . Theorem 1.11 (and Introduction Lemma 8.9 if tr.d $\mathbf{l.C/K}(u)$ is infinite) implies that tr.d. $C/K(u)=$tr.d.$C/K(v)$ . Therefore $\sigma$ extends to a $K$ automorphism of $C$ by Theorem 1.12. But $\sigma(u)=v\neq u$ ,which contradicts the fact that $u\varepsilon K_0$ Ko $K_0$ . Therefore, $u$ must be algebraic over $K$ with irreducible polynomial $f\varepsilon K[x]$ . If $\upsilon\varepsilon C$ C $C$ is another root of $f$, then there is a $K$ -isomorphism $\tau:K(u)\cong K(v)$ such that $\tau(u)=v$ (Corollary V.1.9). An argument similar to the one in the transcendental case shows that $\tau$ extends to a $K.$ -automorphism of. $C$ Since u ε $K_0$ we must have $u=\tau(u)=v$, whence $f$ has only one root in $C$ . Thus $u$ is purely inseparable over $K$ . If char $K=0$ , then $f$ (which is necessarily separable). must have degree 1. Hence u E $K=K^{1/0^{\mathrm{oo}}}$ . If char $K=p\not\doteq0$ then $u^{p^n}\varepsilon K$ for some $n\geq0$ by Theorem V.6.4. Thus u e $K^{1/p^n}\subset K^{1/p^{\infty}}$ . We have proved that $K_0\subset K^{1/p^{\infty}}$ Conversely suppose that char $K=p\neq0$ ,ue $K^{1/p^n}\subset K^{1/p^\infty}$ and $\sigma\varepsilon Aut_KC$ $_{K}C$ KC . Then $\sigma ( u) ^{p^{n}}=$ $\sigma ( u^{p^{n}}) =$ $u^{p^{n}}$ ，whence $0=\sigma(u)^{p^{n}}-u^{p^{n}}=(\sigma(u)-u)^{p^{n}}$ and $\sigma(u)=u$ Therefore, $K^{1/p^{\varpi}}\subset K_{0}$ .

Definition 2.11. An extension field F ofa field K is said to be separable over K (or a separable extension of K) if F satisfies the equivalent conditions of Theorem 2.10.

REMARKS. Theorem 2.8 shows that this definition is compatible with our previous use of the term “separable" in the case of algebraic extensions (Definition V.3.10). Since the first condition of Theorem 2.10 is trivially satisfied when char $K=0$ , every extension field of characteristic O is separable.

------------------------------------------------------------------

Corollary 2.12. (Mac Lane's Criterion) IfF is an extension field of afieldK andF is separably generated over $K$ ,then $F$ is separable over K. Conversely, if F is separable and finitely generated over $K$ ,say $\mathbf{F}=\mathbf{K}(\mathbf{u}_{1},\ldots,\mathbf{u}_{\mathrm{n}})$ ,then $F$ is separably generated over K. In fact some subset 0 $f\left\{\mathrm{u}_{1},\ldots,\mathrm{u}_{\mathrm{n}}\right\}$ is a separating transcendence base of F over K.

SKETCH OF PROOF. The proof of (iv$)\Rightarrow($iii$)\Rightarrow($i) in Theorem 2.10 is valid here with $F=E$ since it uses only the fact that $E$ is separably generated.The last two statements are consequences of theproof of $(\mathbf{i})\Rightarrow(\mathbf{i}\mathbf{v})$ in Theorem 2.10.

Corollary 2.13. Let F be an extension field of K and E an intermediate field.

(i) IfF is separable over K, then E is separable over K; (i) ifF is separable over E andE is separable overK,then $F$ is separable overK; (i) ifF is separable over K and E is algebraic over K, then F is separable over E.

REMARK. (iii) may be false if $E$ is not algebraic over $K$ (see Exercise 8).

SKETCH OF PROOF OF 2.13. (i) Use Theorems 2.4 and 2.10.(i) If char $K$ $=p\neq0$ , let $X$ be a subset of $F$ which is linearly independent over $E$ . Extend $X$ to a basis $U$ of $F$ over $E$ and let $V$ be a basis of $E$ over $K$ .The proof of Theorem IV.2.16 shows that $UV=\{uv\mid u\varepsilon U,v\varepsilon V\}$ is a basis of $F$ over $K$ ,whence $UV$ is linearly inde- pendent over $K^{1/p}$ by separability. Lemma 2.6 implies that $(UV)^{p}=\{u^{p}{\mathcal{C}}^{p}\mid u\varepsilon U,v\varepsilon V\}$ is linearly independent over $K$ . We claim furthermore that $Vp$ is a basis of $E$ over $K$ For $E$ is separable over $K$ by (i). Consequently, the linear disjointness of $E$ and $K^{1/p}$ shows that $V$ is linearly independent over $K^{1/I}$, , whence $Vp$ is linearly independent over $K$ by Lemma 2.6. Since $E=KE^p$ by Corollary V.6.9, $Vp$ necessarily spans $E$ over $K$ . Therefore,. $Vp$ is a basis of $E$ over $K$ .Tocomplete the proof we must show that $X$ is linearly independent over $E^{1/p}$ . If $\sum_ia_iu_i=0$ ∑au =0 $\sum_{i}a_{i}u_{i}=0\:(a_{i}\varepsilon E^{1/p};u_{i}\varepsilon X\subset U)$ (ai e Elp;μu X C U) $(a_{i}\varepsilon E^{1/p};u_{i}\varepsilon X\subset U)$ , then $\sum_ia_iu_i^pu_i^p=0$ . Since each $a_i\nu\varepsilon E$ is of the form $\sum_{j}c_{ij}v_{i}^{p}\left(c_{ij}\varepsilon K;v_{i}\varepsilon V\right)$ we have $0=\sum_{i}(\sum_{j}c_{i,j}v_{j}^{p})u_{i}^{p}=\sum_{i,j}c_{i,j}u_{i}^{p}v_{j}^{p}$ .The linear independence of $(UV)^p$ implies that $c_{ij}=0$ for all $i,j$ and hence that $a_i=0$ for all $i.$ Therefore, $X$ is linearly inde pendent over. $E^{1/p}$

### EXERCISES

Note. $E$ and $F$ are always extension fields of a field $K$ , and $C$ is an algebraically closed feld containing $E$ and $F$

1. The subring $E[F]$ generated by $E$ and $F$ is a vector space over $K$ in the obvious way. The tensor product $E\otimes_{K}F$ is also a $K$ -vector space (see Theorem IV.5.5 and Corollary IV.5.12). $E$ and $F$ are linearly disjoint over $K$ if and only if the $K.$ -linear transformation $E\otimes_{K}F\to E[F]$ (given on generators of $E\otimes_KF$ by $a\otimes b\vdash ab)$ is an isomorphism. 2. Assume $E$ and $F$ are the quotient fields of integral domains $R$ and $S$ respectively Then $C$ is an $R$ -module and an $S$ -module in the obvious way.

------------------------------------------------------------------

(a) $E$ and $F$ are linearly disjoint over $K$ if and only if every subset of $R$ that is linearly independent over $K$ is also linearly independent over $S$ (b) Assume further that $R$ is a vector space over $K.$ Then $E$ and $F$ are linearly disjoint over $K$ if and only if every basis of $R$ over $K$ is linearly independent over $F$ (c) Assume that both $R$ and $S$ are vector spaces over $K$ . Then $E$ and $F$ are linearly disjoint over $K$ if and only if for every basis $X$ of $R$ over $K$ and basis $Y$ of $S$ over $K$ ,the set $\{uv\mid u\varepsilon X;v\varepsilon Y\}$ is linearly independent over $K$

3.UseExercise 1 to prove Theorem 2.2.

4. Use Exercise 1 and the associativity of the tensor product to prove Theorem 2.4.

5. If char $K=p\neq0$ ,then (a) $K^{1/p^n}$ is a feld for every $n\geq0$ . See Exercise II1.1.11. (b) $K^{1/p^{\varpi}}$ is a feld. (c) $K^{1/p^n}$ is a splitting field over $K$ of $\{x^{n^{n}}-k\mid k\in K\}$

6. If $\{u_{1},\ldots,u_{n}\}$ is algebraically independent over $F$ ,then $F$ and $K(u_{1},\ldots,u_{n})$ are linearly disjoint over $K$

7. If $E$ is a purely transcendental extension of $K$ and $F$ is algebraic over $K$ , then $E$ and $F$ are linearly disjoint over $K$

8. Let K =Zp $K=Z_{p}$ $K=Z_{p},F=Z_{p}(x)$ ,and $E=Z_{p}(x^{p})$ (a) $F$ is separably generated and separable over $K$ (b) $E\neq F$ (c) $F$ is algebraic and purely inseparable over $E$ (d) $\{x^p\}$ is a transcendence base of $F$ over $K$ which is not a separating transcendence base.

9. Let char $K=p\neq0$ and let $u$ be transcendental over $K$ . Suppose $F$ is generated over $K$ by $\{u,v_1,v_2,\ldots\}$ , where $v_{i}$ is a root of $x^{\nu^{i}}-u\in K(u)[x]$ for $i=1,2,\ldots.$ Then $F$ is separable over $K$ ,but $F$ is not separably generated over $K$

10. (a) $K$ is a perfect field if and only if every field extension of $K$ is separable (see Exercise V.6.13) (b) (Mac Lane) Assume $K$ is a perfect field, $F$ is not perfect and tr.d $.F/K=1$ Then $F$ is separably generated over $K$

11. $F$ is purely inseparable over $K$ if and only if the only $K$ -monomorphism $F-,C$ is the inclusion map.

12. $E$ and $F$ are free over $K$ if every subset $X$ of $E$ that is algebraically independent over $K$ is also algebraically independent over $F$ (a) The definition is symmetric (that is, $E$ and $F$ are free over $K$ if and only if

$F$ and $E$ are free over $K$ ). (b) If $E$ and $F$ are linearly disjoint over $K$ , then $E$ and $F$ are free over $K$ .Show by example that the converse isfalse. (c) If $E$ is separable over $K$ and $E$ and $F$ are free over $K$ , then $EF$ is separable over $F$ (d) If $E$ and $F$ are free over $K$ and both separable over $K$ , then $EF$ is separable over $K$

------------------------------------------------------------------

# CHAPTER VII

# LINEAR ALGEBRA

Linear algebra is an essential tool in many branches of mathematics and has wide applications. A large part of the subject consists of the study of homomorphisms of (finitely generated) free modules (in particular, linear transformations of finite dimensional vector spaces). There is a crucial relationship between such homomorphisms and matrices (Section 1). The investigation of the connection between two matrices that represent the same homomorphism (relative to differentbases) leads to the concepts of equivalence and similarity of matrices (Sections 2 and 4). Certain important invariants of matrices under similarity are considered in Section 5. Determinants of matrices (Section 3) are quite useful at several points in the discussion Since there is much interest in the applications of linear algebra, a great deal of

material of a calculational nature is included in this chapter. For many readers the inclusion of such material will bewell worth theburden of additional length.However, the chapter is so arranged that the reader who wishes only to cover the important basic facts of the theory may do so in a relatively short time. He need only omit those results labeled as propositions and observe the comments in the text as to which material is needed in the sequel. The approximate interdependence of the sections of this chapter is as follows:

$$\underbrace{3+4+-2}_{\sqrt{5}}$$

------------------------------------------------------------------

## 1. MATRICES AND MAPS

The basic properties of matrices are briefly reviewed. Then the all important relationship between matrices and homomorphisms of free modules is explored. Except in Theorem 1.1 all rings are assumed to have identity, but no other restrictions are imposed. Except for the discussion of duality at the end of the section all of this material is needed in the remainder of the chapter..

Let $R$ be a ring. An array of elements of the form

![](https://storage.simpletex.cn/view/fVyhTZmG27dzrZAymGO5V2eQ9sW76CFh7)

with $a_{i,\varepsilon}R$ $n$ rows (horizontal), and $m$ columns (vertical), is called an n X m matrix over $R$ .An $n\times n$ matrix is called a square matrix. For brevity of notation an arbi. trary matrix is usually denoted by a capital letter, $A,B,C$ or by $(a_{ij})$ , which indicates that the i-jth entry (row i, column j) is the element $a_{ij}$ dij $a_{ij}\in R.$ R $R.$ Two $n\times m$ matrices $(a_{ij})$ and $(b_{ij})$ are equal if and only if $a_{ij}=b_{ij}$ in $R$ for all $i,j$ . The elements $a_{11},a_{22},a_{33},\ldots$ are said to form the main diagonal of the matrix $(a_{ij})$ .An $n\times n$ matrix with $a_{ij}=0$ for all $i\neq j$ is called a diagonal matrix. If $R$ has an identity element, the identity matrix $I_n$ is the $n\times n$ diagonal matrix with $1_{R}$ in each entry on the main diagonal that is, $I_{n}=(\delta_{i,j})$ where $\delta$ is the Kronecker delta. The $n\times m$ matrices with all entries O are called zero matrices. The set of all $n\times n$ matrices over $R$ is denoted $Mat_nR$ The transpose of an $n\times m$ matrix $A\:=(a_{ij})$ is the $m\times n$ matrix $A^{t}=(b_{ij})$ (note size!) such that $b_{ij}=a_{ji}$ for all $i,j$ If $A=(a_{ij})$ and $B=(b_{ij})$ are $n\times m$ matrices, then the sum $A+B$ is defined to

be the $n\times m$ matrix $(c_{ij})$ , where $c_{ij}=a_{ij}+b_{ij}$ . If $A\:=(a_{ij})$ is an $m\times n$ matrix and $B=(b_{ij})$ is an $n\times p$ matrix then the product $AB$ is defined to be the $m\times p$ matrix $(c_{ij})$ where $c_{ij}=\sum_{k=1}^{n}a_{ik}b_{kj}$ . Multiplication is not commutativ in general. If $A=(a_{ij})$ is an $n\times m$ matrix and $r\in R,rA$ is the $n\times m$ matrix $(ra_{ij})$ and $Ar$ is the $n\times m$ matrix $(a_{ij}r);rI_n$ is called a scalar matrix. If the matrix product $AB$ is defined, then so is the product of transpose matrices.

$B^tA^t$ . If $R$ is commutative, then $(AB)^{\prime}=B^{\prime}A^{\prime}$ . This conclusion may be false if $R$ is noncommutative (Exercise 1).

Theorem 1.1.If R is a ring,then the set of all $n\times m$ matrices overR formsan R-R bimodule under addition, with the $n\times m$ zero matrix as the additive identity Multiplication of matrices, when defined, is associative and distributive over addition. For each $n>0$ $Mat_n\mathbb{R}$ is a ring. If R has an identity, so does $Mat_n\mathbf{R}$ (namely the identity matrix. $\mathbf{I}_{\mathrm{n}}$ .

PROOF. Exercise.

One of the important uses of matrices is in describing homomorphisms of free modules.

------------------------------------------------------------------



------------------------------------------------------------------

Theorem 1.3.Let R be a ring with identity andlet E,F,G,befree left R-modules with finite ordered bases. $\mathbf{U}=\{\mathbf{u}_{1},\ldots,\mathbf{u}_{n}\}$ ， $\mathbf{V}=\{\mathbf{v}_{\mathrm{I}},\ldots,\mathbf{v}_{\mathrm{m}}\}$ ， $\mathbf{W}=\{\mathbf{w}_{1},\ldots,\mathbf{w}_{\mathrm{p}}\}$ respectively. If f e. $Hom_{\mathbb{R}}(\mathbb{E},\mathbb{F})$ has $n\times m$ matrix A (relatire to bases $U$ and $V$ ）and geHom $_{\mathrm{R}}($F,G) has $m\times p$ matrix B (relatire to bases V and W), then gf e Hom. $_{\mathrm{R}}(\mathbb{E},\mathbb{G})$ has $n\times p$ matrix AB (relaticetobasesU and W)

PROOF. If $A\:=\:(r_{ij})$ and $B=(s_{k})$ , then for each $i=1,2,\ldots,n$
$$\begin{aligned}
gf(u_{i})& =g\biggl(\sum_{k=1}^{m}r_{ik}v_{k}\biggr)=\sum_{k=1}^{m}r_{ik}g(c_{k})\:=\:\sum_{k=1}^{m}r_{ik}\biggl(\sum_{j=1}^{p}\:s_{kj}w_{j}\biggr) \\
&=\sum_{j=1}^{p}\left(\sum_{k=1}^{m}r_{ik}s_{kj}\right)w_{j}.
\end{aligned}$$

Therefore the matrx of $gf$ relative to $U$ and $W$ has i-jth entry ≥, risSkhs.But this is precisely the i-jth entry of the matrix. $AB$ .■

Let $R$ be a ring with identity and $E$ a free left $R$ -module with a finite basis $U$ of $n$ elements. Then $\mathrm{Hom}_{\mathcal{R}}(E,E)$ is a ring with identity. where the product of maps fand $g$ is simply the composite function $fg:E\to E$ (Exercise IV.1.7). We wish to note for future reference the connection between the ring $\mathrm{Hom}_{k}(E,E)$ and the matrix ring $Mat_nR$ $.nR$ nR If $S$ and $T$ are any rings, then a function $0:S\to T$ is said to be an antiisomorphism if $\theta$ is an isomorphism of additire groups such that. $\theta(s_{1}s_{2})=\theta(s_{2})\theta(s_{1})$ for all $s_i\varepsilon S.$ .The map $\mathrm{Hom}_{k}(E,E)\to\mathrm{Mat}_{n}R$ which assigns to each $f\varepsilon\text{Hom}_{ll}(E,E)$ its matrix (relative to $U$ ) is an anti-isomorphism of rings by Theorems 1.2 and 1.3. It would be convenient if $\mathrm{Hom}_{R}(E,E)$ were actually isomorphic to some matrix ring. In. order to show that this is indeed the case, we need a new concept. If $R$ is a ring, then the opposite ring of $R$ , denoted $R^{np}$ , is the ring that has the same

set of elements as $R$ ,the same addition as $R$ , and multiplication o given by

$$a\circ b=ba,$$

where ba is the product in $R$ ; (see Exercise II1.1.17). The map given by $r\vdash r$ is clearly an anti-isomorphism $R\to R^{op}$ . If $A=(a_{i},)$ and $B=(b_{i})$ are $n\times n$ matrices over $R$ , then $A$ and $B$ may also be considered to be matrices over $R^{\omega\pi}$ . Note that in $Mat_nR$ ， $AB=(c_{ij})$ Where Ci = > aubki; but in $\mathbf{Mat}_nR^{\omega p}$ ， $AB=(d_{ij})$ ，where

$$d_{ij}=\sum_{k=1}^n\:a_{ik}\circ b_{kj}=\sum_{k=1}^n\:b_{kj}a_{ik}.$$

Theorem 1.4. Let R be a ring with identity and E a free left R-module with a finite. basis of n elements. Then there is an isomorphism of rings..

$$Hom_R(E,E)\cong Mat_n(\mathbb{R}^{\mathrm{op}}).$$

In particular, this isomorphism exists for every n-dimensional vector space E over a division ring R,in which case $R^{\mathrm{op}}$ is also a division ring

REMARK. The conclusion of Theorem 1.4 takes a somewhat nicer form when $R$ is commutative, since in that case $R=R^{op}$

------------------------------------------------------------------

SKETCH OF PROOF OF 1.4. Let $\phi:\operatorname{Hom}_R(E,E)\to\operatorname{Mat}_nR$ be the antiisomorphism that assigns to each map fits matrix relative to the given basis. Verify that the map $\psi:\mathrm{Mat}_nR\to\mathrm{Mat}_nR^{op}$ given by $\psi(A)=A^t$ is an anti-isomorphism of rings. Then the composite map $\psi\phi:\operatorname{Hom}_k(E,E)\to\operatorname{Mat}_nR^{\circ p}$ is an isomorphism of rings.The last statement of the theorem is a consequence of TheoremIV.2.4 and Exercise II1.1.17.

Let $R$ be a ring with identity and $A_{\varepsilon}$ Mat$_nR.A$ is said to be invertible or nonsingular if there exists $B\varepsilon Mat_nR$ such that $AB=I_{n}=BA$ . The inverse matrix $B$ , if it exists, is easily seen to be unique; it is usually denoted $A^{-1}$ . Clearly $B=A^{-1}$ is invertible and $(A^{-1})^{-1}=A$ The product $AC$ of two invertible matrices is invertible with $(AC)^{-1}=C^{-1}A^{-1}$ If $A$ is an invertible matrix over a commutative ring, then so is its transpose and $(A^{l})^{-1}=(A^{-1})^{l}$ (Exercise 1). The matrix of a homomorphism of free $R$ -modules clearly depends on the choice

of (ordered) bases in both the domain and range. Consequently, it will be helpful to know the relationship between matrices that represent the same map relative to different pairs of ordered bases.

Lemma 1.5.Let R be a ring with identity and E,F free left R-modules with ordered bases U,V respectively such that $|U|=n=|V|.$ Let Ae $Mat_n\mathbb{R}$ . Then A is invertible if and only ifA is the matrix of an isomorphism f:. $E\to F$ relative to U and V. In this. case $A^{-1}$ is thematrixof $\mathbf{f}^{-1}$ relative to $V$ andU

SKETCH OF PROOF. An $R$ -module homomorphism $f{:}E\to F$ is an isomorphism if and only if there exists an $R$ -module homomorphism $f^{-1}:F\to E$ such that $f^{-1}f=1_{E}$ and $ff^{-1}=1_{F}$ (see Theorem I.2.3). Suppose $f$ is an isomorphism with matrix $A$ relative to $U$ and $V$ . Let $B$ be the matrix of $f^{-1}$ relative to $V$ and $U$ .Sche matically we have

![](https://storage.simpletex.cn/view/fOV9RNbhr9IiGgvH8nKZ8ZOeN8CyyCgVC)

By Theorem $1.3AB$ is the matrix of $f^{-1}f=1_{E}$ relative to $U$ .But $I_n$ is clearly the matrix of $1_{E}$ relative to $U.$ Hence $AB=I_n$ by the proof of Theorem 1.2. Similarly $BA=I_n$ whence $A$ is invertible and $B=A^{-1}$ . The converse implication is left as an exercise.

Theorem1.6.Let Rbe a ringwith identity.Let Eand Fbefree left R-modules with finite ordered bases U and $V$ respectively such that $|\mathbf{U}|=\mathbf{n}$, $|\mathbf{V}|=\mathbf{m}$ . Let f $\varepsilon$ $Hom_{\mathrm{R} }( \mathbb{E} , \mathbb{F} )$ have $n\times m$ matrix A relative to U and V. Then f has nXm matrixB relative io another pair of ordered bases of E and F if and only if = $i=$ $^{r}\mathbf{B}=\mathbf{PAQ}$ forsome invertible matrices P and Q..

PROOF. $(\mathbf{\neg})$ If $B$ is the $n\times m$ matrix of frelative to the bases $U^{\prime}$ of $E$ and $V^{\prime}$ of $F$ , then $|U^{\prime}|=n$ and $|V^{\prime}|=m$ .Let $P$ be the $n\times n$ matrix of the identity map $1_{E}$ rela-

------------------------------------------------------------------

tive to the ordered bases $U^{\prime}$ and $U.P$ $P$ P is invertible by Lemma 1.5. Similarly let $Q$ be the $m\times m$ invertible matrix of $1_{F}$ relative to $V$ and $V^{\prime}$ (note order). Schernatically we have:

map: module:
$$\begin{array}{ccccc}E\xrightarrow{1_E}E\xrightarrow{f}F\xrightarrow{1_F}F\\U^{\prime}&U&V&V^{\prime}\\P&A&Q\end{array}$$
basis: matrix:

By Theorem 1.3 the matrix of $f=1_{F}f\mathbf{l}_{E}$ relative to $U^{\prime}$ and $V^{\prime}$ is precisely $PAQ$ Therefore $B=PAQ$ by the proof of Theorem 1.2.

$(\Leftarrow)$ We are given $U,V,f,A$ as above and $B=PAQ$ with $P,Q$ invertible. Let $g:E\to E$ be the isomorphism with matrix $P$ relative to $U$ and $h:F\to F$ the isomorphism with matrix $Q^{-1}$ relative to $V$ (Lemma 1.5): If $U=\{u_{1},\ldots,u_{n}\}$ ,then $g(U)=\{g(u_{1}),\ldots,g(u_{n})\}$ is also an ordered basis of $E$ and $P$ is the matrix of $1_{E}$ relative to the orderedbases $g(U)$ and $U$ . Similarly $Q^{-1}$ is the matrix of $1_{F}$ relative to the ordered bases $h(V)$ and $V$ ,whence $Q=(Q^{-1})^{-1}$ is the matrix of $1_{F}$ relative to $V$ and $h(V)$ (Lemma 1.5). Schematically we have

![](https://storage.simpletex.cn/view/fLx8wlkrihupOHuVZsxAmRItrsgS97ouT)

By Theorem 1.3 the matrix of $f=1_{F}f1_{E}$ relative to the ordered bases $g(U)$ and $h(V)$ is $PAQ=B$ .

Corollary 1.7 Let R be a ring with identity and E a free left R-module with an ordered basis U of finite cardinality n. Let A be the $n\times n$ matrix off e Homk(E,E) relative to U. Then f has $n\times n$ matrix B relative to another ordered basis of E if and. only $ifB= PAP^{- 1}$ for some invertible matrixP

SKETCH OF PROOF. If $E=F,U=V$ ,and $U^{\prime}=V^{\prime}$ in theproof of Theorem 1.6, then $Q=P^{-1}$ by Lemma 1.5.

The preceding results motivate:

Definition 1.8.Let R be a ring with identity.Two matrices A,B e $Mat_n\mathbb{R}$ are said to be similar if there exists an invertible matrix $P$ such that $\mathbf{B}=\mathbf{PAP}^{-1}$ . Two $n\times m$ matrices C,D are said to be equivalent if there exists invertible matrices. $P$ and Q such that $\mathbf{D}=\mathbf{PCQ}$

Theorem 1.6 and Corollary 1.7 may now be reworded in terms of equivalence and similarity. Equivalence and similarity are each equivalence relations (Exercise 7) and will be studied in more detail in Sections 2 and 4..

------------------------------------------------------------------

We close this section with a discussion of right modules and duality. If $R$ is commutative, then the preceding results are equally valid for right $R$

modules. There are important cases, however, in which $R$ is not commutative (for example, vector spaces over a division ring). In order to prove the analogue of Theorem 1.3 for right modules in the noncommutative case it is necessary to define the matrix of a homomorphism somewhat differently. Let $R$ be a ring with identity and let $E$ and $F$ be free right $R$ -modules with finite

ordered bases $\boldsymbol{U}=\{u_1,\ldots,u_n\}$ and $V=\{v_{1},\ldots,v_{m}\}$ respectively. The matrix of the homomorphism $f\varepsilon\mathrm{~Hom}_{h}(E,F)$ relative to $U$ and $V$ is defined to be the $m\times n$ matrix (note size):

![](https://storage.simpletex.cn/view/fRcO3bIgn11SQekPat2qpaFlTcSTbGt2W)

where the $s_{ij}\varepsilon R$ are uniquely determined by the equations:
$$\begin{aligned}&f(u_{1})\:=\:v_{1}s_{11}\:+\:v_{2}s_{21}\:+\:v_{3}s_{31}\:+\:\cdots\:+\:c_{m}s_{m1}\\&f(u_{n})\:=\:v_{1}s_{1n}\:+\:v_{2}s_{2n}\:+\:v_{3}s_{3n}\:+\:\cdots\:+\:v_{m}s_{mn}.\end{aligned}$$

Thus the coefficients of $f(u_i)$ with respect to the ordered basis $V$ form the jth column of the $m\times n$ matrix $(s_{ij})$ of $f$ (compare the proof of Theorem 1.2).

The action of $f$may be described in terms of matrices as follows. Let $u=u_{1}x+$ $u_2x_2+\cdots+u_nx_n$ $(x_i\in R)$ be any element of $E$ and let $X$ be the $n\times1$ matrix (or

Mo $\begin{pmatrix}x_1\\.\\.\\x_n\end{pmatrix}.$ a $A$ Mao $f$ Mi $U$ m $V$ 1

$f(u)=\tau_{1}v_{1}+v_{2}y_{2}+\cdots+v_{m}y_{m}$, H $y_i\varepsilon R$ $\begin{pmatrix}y_1\\.\\.\\y_m\end{pmatrix}$ h $m\times1$ (column vector) $AX$

The analogues of results 1.2-1.5 above are now easily proved, in particular.

Theorem1.9.Let R be a ring with identity and E,Ffree right R-modules withfinite bases U and V of cardinality n and m respecticely. Let N be the right R-module of al $m\times n$ matrices over R.

(i) There is an isomorphism of abelian groups Ho $m_{\mathrm{R}}($E,F$)\cong\mathbb{N}$ , which is an iso morphism of right R-modules if R is commutatice;

------------------------------------------------------------------



------------------------------------------------------------------

2. A matrix (aii) $(a_{ij})$ $(a_{ij})\in\mathrm{Mat}_nR$ is said to be

$$\text{(upper) triangular}\Leftrightarrow a_{ij}=0\quad\mathrm{for}\quad j<i;\\\text{strictly triangular}\Leftrightarrow a_{ij}=0\quad\mathrm{for}\quad j\leq i.$$

Prove that the set of all diagonal matrices isa subring of $Mat_nR$ which is (ring) isomorphic to $R\times\cdots\times R(n$ factors). Show that the set $T$ of all triangular matrices is a subring of $Mat_nR$ and the set $I$ of all strictly triangularmatrices is an ideal in T. Identify the quotient ring $T/I$

3. (a) The center of the ring $Mat_nR$ consists of all matrices of the form $rI_n$ ,where $r$ is in the center of $R$ . [Hint: every matrix in the center of $Mat_nR$ must commute with each of the matrices $B_{r.s}$ ，where $B_{r,s}$ has $1_{R}$ in position $(r,s)$ and 0 elsewhere. (b) The center of $Mat_nR$ is isomorphic to the center of $R$

4. The set of all $m\times n$ matrices over $R$ is a free $R$ -module with a basis of mn elements.

5. A matrix $A\in Mat_nR$ is symmetric if $A=A^{t}$ and skew-symmetric if $A=-A^{\prime}$ (a) If $A$ and $B$ are [skew] symmetric, then $A+B$ is [skew] symmetric. (b) Let $R$ be commutative. If $A,B$ are symmetric, then $AB$ is symmetric if and

only if $AB=BA$ .Also show that for any matrix $B\varepsilon\text{ Mat}_nR,BB^t$ nR $nR$ BB $BB^t$ and $B+B^t$ are symmetric and $B-B^t$ is skew-symmetric

6. If $R$ is a division ring and $A,B\in Mat_nR$ are such that $BA=I_{n}$ , then $AB=I_{n}$ and $B=A^{-1}$ . [Hinr: use linear transformations.]

7. Similarity of matrices is an equivalence relation on $Mat_nR$ .Equivalence of matrices is anequivalence relation on the set of all $m\times n$ matrices over $R$

8. Let $E,F$ be finite dimensional (left) vector spaces over a field and consider the dual spaces to be left vector spaces in the usual way. If $A$ is the matrix of a linear transformation $f:E\to F$ then $A^t$ is the matrix of the dual map $\bar{f}:F^*\to E^*$

## 2. RANK AND EQUIVALENCE

The main purpose of this section is to find necessary and sufficient conditions for matrices over a division ring or a principal ideal domain to be equivalent. One such condition involves the concept of rank. In addition, useful sets of canonical forms for such matrices are presented (Theorem 2.6 and Proposition 2.11). Finally, practical techniques are developed for finding these canonical forms and for calculating the inverse of an invertible matrix over a division ring. Applications to finitely generated abelian groups are considered in an appendix, which is not needed in the sequel.

Definition 2.1. Ler f : $E\to F$ be a linear trans formation of(le ft) cector spaces orer a divisionringD.The rank off is the dimensionof Imf and the nullity off is the dimension of Ker f.

REMARK. If $f:E\to F$ is as in Defnition 2.1, then by Corollary IV.2.14, (rank $f)+$ (nullity $f)=\dim_DE$

------------------------------------------------------------------

If $R$ is a ring with identity and $n$ a positive integer, then $R^n$ will denote thefree $R$ -module $R\oplus\cdots\oplus R$ (n summands). The standard (ordered) basis of $R^n$ consists of the elements $\varepsilon_{1}=(1_{R},0,\ldots,0)$ , E2 = (0,1r,0,...,0), ..., $\varepsilon_{n}=(0,\ldots,0,1_{R})$

Definition 2.2. The row space [resp.column space] ofan $n\times m$ matrix A over a ring R with identity is the submodule of the free left[resp.right] module $R^m$ [resp. $R^n]$ generated by the rows [resp. columns] of A considered as elements of $\dot{R}^m$ [resp. R]. If R is a division ring,then the row rank[resp.columnrank] of A is the dimension of the row[resp.column]space of A

Theorem 2.3. Let $\mathbf{f}:\mathbf{E}\to\mathbf{F}$ be a linear transformation of finite dimensional left [resp. right] vector spaces over a division ring D. If A is the matrix off relative to some pair of ordered bases, then the rank of f is equal to the row [resp. column] rank of A.

REMARK. "Row rank" is replaced by "column rank" in the case of right vector spacesbecause of the definitionof the matrix of a map of rightvector spaces (p. 333))

PROOF OF 2.3. Let $A$ be the $n\times m$ [resp. $m\times n]$ matrix of $f$ relative to ordered bases $U=\{u_{1},\ldots,u_{n}\}$ of $E$ and $V=\{v_{1},\ldots,v_{m}\}$ of $F$ .Then under theusual isomorphism $F\cong D^{m}$ given by $\sum_ir_iv_i\vdash(r_1,\ldots,r_m)$ the elements $f(u_1),\ldots,f(u_n)$ are mapped onto the rows [resp. columns] of $A$ (considered as vectors in $D^m$ ).Since Im $f$ is spanned by $f(u_1),\ldots,f(u_n)$ Im $f$ is isomorphic to the row [resp. column] space of $A.$ , whence the rank of $f$ is equal to the row[resp.column]rank of $A$ .

We now digress briefly to prove that the row and column rank of a matrix over a division ring are in fact equal. This fact, which is proved in Corollary 2.5, is not essential for understanding the sequel since "row rank' is all that is actually used hereafter.

Proposition 2.4. Any linear transformation $\mathbf{f}:\mathbf{E}\to\mathbf{F}$ of finite dimensional left vector spaces over a division ring D hasthesamerank as iis dual map $\tilde{\mathbf{f}}:\mathcal{F}^*\to\mathcal{E}^*$

The dual map is defined in Theorem IV.4.10.

PROOF OF 2.4. Let rank $f=r$ .By Corollary IV.2.14 there is abasis $X=\{u_1,\ldots,u_n\}$ such that $\{u_{r+1},\ldots,u_{n}\}$ is a basis of Ker $f$ and $Y_{1}=$ $\{\:f(u_1),\ldots,f(u_r)|$ is a basis of Im $f.$ Extend $Y_{1}$ to a basis $Y=\{t_{1}=f(u_{1}),\ldots,t_{r}=$ $f(u_r),t_{r+1},\ldots,t_m\}$ of $F$ Consider the dual bases $X^*$ of $E^{*}$ and $Y^{\ast}$ of $F^*$ (Theorerr IV.4.11). Verify that for each $i=1,2,\ldots,m$

$$\bar{f}({t_i}^*)(u_j)={t_i}^*(f(u_j))=\begin{cases}{t_i}^*(t_i)=\delta_{ij}\:\mathrm{if}\:j=1,2,\ldots,r;\\{t_i}^*(0)=0\:\mathrm{if}\:j=r+1,r+2,\ldots,n.\end{cases}$$

where $\delta_{ij}$ is the Kronecker delta. Consequently for each $j=1,2,\ldots,n$

$$\bar{f}({\iota_i}^*)(u_i)=\left\{\begin{matrix}\delta_{ij}={u_i}^*(u_j)&\text{if}\quad i=1,2,\ldots,r\\0&\text{if}\quad i=r+1,r+2,\ldots,m.\end{matrix}\right.$$

------------------------------------------------------------------

Therefore, $\bar{f}(t_{i}^{*})=u_{i}^{*}$ for $i=1,2,\ldots,r$ and $\bar{f}(t_{i}^{*})=0$ for $i=r+1,\ldots,m$ Im $\bar{f}$ is spanned by $\bar{f}(Y^*)$ and hence by $\{u_{1}^{*},\ldots,u_{r}^{*}\}$ . Since $\left\{u_{1}^{*},\ldots,u_{r}^{*}\right\}$ is a subset of $X^*$ , it is linearly independent in $E^*$ . Therefore $\left\{u_1^*,\ldots,u_r^*\right\}$ is a basis of $Im\bar{f}$, whence rank $\bar{f}=r=$rank $f$ f $f.$

Corollary 2.5. If A is an $n\times m$ matrix over a division ring D, then row rank $\mathbf{A}=$ column rank A.

PROOF. Let $f:D^n\to D^m$ be a linear transformation of left vector spaces with matrix $A$ relative to the standard bases. Then the dual map Fof right vector spaces also has matrix $A$ (Proposition 1.10). By Theorem 2.3 and Proposition 2.4 row rank $A=$ rank $f=$ rank $\bar{f}=$ column rank A.

REMARK. Corollary 2.5 immediately implies that row rank. $A=$ row rank $A^t$ for any matrix $A$ over a field. In view of Corollary 2.5 we shall hereafter omit the adjectives “row" and

"column' and refer simply to the rank of a matrix over a division ring

In Theorem 2.6 below equivalent matrices over a division ring $D$ will be char acterized in terms of rank and in terms of the following matrices. If $m,n$ are positive integers, then $E_0^n,m$ is defined to be the $n\times m$ zero matrix. For each $r\left(1\leq r\leq\min\left(n,m\right)\right),E_{r}^{n.m}$ En.m $E_r^{n.m}$ is defined to be the $n\times m$ matrix whose first rrows are the standard basis vectors $\varepsilon_{\mathrm{l}},\ldots,\varepsilon_{\mathrm{r}}$ of $D^m$ and whose remaining rows are zero:

$$E_r^{n,m}=\begin{pmatrix}1_R&0&0&\cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots&0\\0&1_R&0&\cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots&0\\.&&&&.\\.&&&&.\\0&\cdots\cdots\cdots\cdots&0&1_R&0&\cdots\cdots&0\\0&\cdots\cdots\cdots\cdots&0&0&\cdots\cdots&0\\.&&&&&.\\.&&&&&.\\0&\cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots&\cdots&0\end{pmatrix}=\begin{pmatrix}I_r&0\\0&0\end{pmatrix}.$$

Clearly rank $E_{r}^{n,m}=r$ .Furthermore if $E_r^{n,m}$ is the matrix of an $R$ -module homo morphism $f:E\to F$ of free $R$ -modules, relative to bases $\{u_1,\ldots,u_n\}$ of $E$ and $\{v_{1},\ldots,v_{m}\}$ of $F$ ，then

$$f(u_i)=\begin{cases}v_i&\text{if}\quad i=1,2,\ldots,r;\\0&\text{if}\quad i=r+1,r+2,\ldots,n.\end{cases}$$

An immediate consequence of Theorem 1.6 and Theorem 2.6 below is that every linear transformation of finite dimensional vector spaces has this convenient form for some pair of bases (Exercise 6)..

A set of canonical forms for an equivalence relation $R$ on a set $X$ is a subset $C$ of $X$ that consists of exactly one element from each equivalence class of. $R$ . In other words. for every $x\in X$ there is a unique $c$ E $C$ such that $x$ is equivalent to $c$ under $R$ .Wenow show that the matrices $E_r^{n,m}$ form a set of canonical forms for the relation of equiva-. lence on the set of all $n\times m$ matrices over a division ring.

------------------------------------------------------------------

Theorem 2.6. Ler M be the set of all $n\times m$ matrices overa dicisionringD and let A,B e M.

(i)A is equivalent to Enm if and only if rank $\mathbf{A}=\mathbf{r}$ (i)A is equicalent to B if and only if rank $\mathbf{A}=$ rank B. (ii) The matrices Ep.m $(\mathbf{r}=1,2$ ..., min. $(n,m)$ ) constitute a set of canonical forms for the relation of equiralence on M..

SKETCH OF PROOF. (i) $A$ is the matrix of some linear transformatior $f:D^n\to D^{\pi}$ relative to some pairof bases byTheorem 1.2.If rank $A=r$ ,then Corollary IV.2.14 implies that there exist bases $U=\left\{u_{1},\ldots,u_{n}\right\}$ of $D^n$ and $V=\{v_{1},\ldots,v_{m}\}$ of $D^{m}$ such that $f(u_i)=v_i$ for $i=1,2,\ldots,r$ and $f(u_{i})=0$ for $i=r+1,\ldots,n.$ Clearly the matrix of frelative to. $U$ and $V$ is $E_r^n.m$ . Therefore $A$ is equivalent to $E_r^n,m$ by Theorem 1.6. Conversely suppose $A$ is equivalent to $E_r^n,m$ .By Theorem1.6 there is a linear transformation $g:D^n\to D^m$ such that $A$ is thematrixof $g$ relative to one pair of bases and $E_r^{n,m}$ is the matrix of $g$ relative to another pair of bases. Consequently, rank $A=$ rank $g=$ rank $E_{r}^{n,m}=r^{2}$ by Theorem 2.3. (ii) and (ii) are consequences of (i).

The following definition, theorem, and corollaries have a number of useful consequences, including practical methods for constructing: (i) canonical forms under equivalence for matrices over a principal ideal do-

main (Proposition 2.11);

(i) the canenica formis $E_r^{n.m}$ bnder e rris erision in

Proposition 2.11 is used only in the proof of Proposition 4.9 below. The remainder of the material is independent of Proposition 2.11 and is not needed in the sequel.

We shall frequently consider the rows [resp. columns] of a given $n\times m$ matrix over a ring $R$ as being elements of $R^m$ [resp. $R^n]$ . We shall speak of adding a scalar multiple of one row [resp. column] to another; for example.

$$r(a_1,a_2,\ldots,a_m)+(b_1,\ldots,b_m)=(ra_1+b_1,\ldots,ra_m+b_m).$$

Definition 2.7. Let A be a matrix over a ring R with identity. Each ofthe followiig is called an elementary row operation on A:

(i) interchange rwo rows of A; (i) left multiply a row of A by a unit c ε R; (ii) for r ε R and $i\neq j$ , add 1 times row j to row i.

Elementary column operations on A are defined analogously (with left multiplication in (ii), (ii) replaced by right multiplication). An $n\times n$ elementary (transformation) matrix is a matrix that is obtained by performing exactly one elementary row (or column) operation on the identity matrix $I_n$

Theorem 2.8. Let A be an $n\times m$ matrix over a ring R with identity and let $E_{\mathrm{n}}$ [resp. $E_{m}]$ be the elementary matrix obtained by performing an elementary row [resp. column] operation T on $I_n$ [resp. $\mathbf{I}_{m}]$ . Then $E_nA$ [resp. $AE_n.$ ]is the matrix obtained by per forming the operation $T$ onA.

------------------------------------------------------------------

Corollary 2.9. Every n $n\times n$ elementary matrix E over a ring R with identity is in vertible and its inverse is an elementary matrix..

SKETCH OF PROOF. Verify that $I_{r}$ may be obtained from $E$ by performing a single elementary row operation $T.$ If $F$ is the elementary matrix obtained by performing $T$ on $I_n$ , then $FE=I_{n}$ by Theorem 2.8. Verify directly that $EF=I_{n}$ .

Corollary 2.10. If B is the matrix obtained from an $n\times m$ matrix A ocer a ring R with identity by per forming a finite seyuence ofelementary row and column operations then B is equiralent to A..

PROOF. Since each row [column] operation used to obtain $B$ from $A$ is given by. left [right] multiplication by an appropriate elementary matrix (Theorem 2.8), we have $B=(E_p\cdots E_1)A(F_1\cdots F_q)=PAQ$ with each $E_iF_j$ an elementary matrix and $P=E_{p}\cdots E_{1}$ ， $Q=F_1\cdots F_q.$ $P$ and $Q$ are products of invertible matrices (Corollary. 2.9) and hence invertible.

We now consider canonical forms under equivalence of matrices over a principal. ideal domain $R$ . The rank of a free module over $R$ is a well-defined invariant by Corollary IV.2.12. Since every submodule of a free $R$ -module is free (Theorem IV.6.1), we may define the rank of a homomorphism $f:E\to F$ of free $R$ -modules to be the rank of $Imf.$ Similarly therowrank of amatrix $A$ over $R$ is defined to be the rank of the row space $A$ (see Definition 2.2). The proof of Theorem 2.3 is easily seen to bevalid here,whence the rank of a map fof finitelygeneratedfree $R$ -modules is. the row rank of any matrix of frelative to some pair of bases. Consequently, if $A$ is equivalentto a matrix $B$ , then row rank. $A=$ rowrank $B$ .For $A$ and $B$ are matrices of the same homomorphism $f:R^n\to R^m$ relative to different pairs of bases by Theo-. rem 1.6, whence row rank $A=$ rank $f=$ row rank $B$ .Here is the analogue of Theorem 2.6 for matrices over a principal ideal domain.

Proposition 2.11. If A is an $n\times m$ matrix ofrank $r>0$ over a principal ideal domain , then is equiolent to mari of th form $\begin{pmatrix}\mathbf{L}_{\mathrm{r}}&0\\0&0\end{pmatrix}$ , where Lis an r $\times$ r diagonal matrix with nonzero diagonal entries. $d_1$ ..... $\mathbf{d}_{\mathrm{r}}$ such that. $d_1\mid d_2\mid\cdots\mid d_r$ .The ideals (d),...,(d) in R are uniquely determined by the equivalence class of A.

REMARKS. The proposition provides sets of canonical forms for the relation of equivalence on the set of $n\times m$ matrices over a principalideal domain (Exercise 5). If $R$ is actually a Euclidean domain, then the following proof together with Exercise 7 and Theorem 2.8 shows that the matrix $\begin{pmatrix}L_r&0\\0&0\end{pmatrix}$ may be obtaindfrom $A$ by a finite sequence of elementary row and column operations

SKETCH OF PROOF OF 2.11. (i) Recall that $a,b\varepsilon R$ are associates if $a\mid b$ and $b\mid a$ . By Theorem $\mathbf{III}.3.2\:a$ and $b$ are associates if and only if $a=bu$ with $u$ a unit. We say that $c\varepsilon R$ $R$ R is a proper divisor of a e $R$ if $c\mid a$ and $c$ is not an associate of $a$ (that is, aXc ). By a slight abuse of language we say that two proper divisors. $c_1$ and $c_2$

------------------------------------------------------------------

of an element $a$ are distinct if $c_1$ and $c_2$ are not associates. Now $R$ is a unique factorization domain by Theorem Ill.3.7. If $a=p_{1}^{n\:1}p_{2}^{n\:2}\ldots p_{t}^{n\:t}$ $(p_i$ distinct irreducibles and each $n_i>0$ ), then every divisor of $a$ is an associate of an element of the form $p_{1}^{k_{1}}p_{2}^{k_{2}}\ldots p_{t}^{k_{t}}$ with $0\leq k_i\leq n_i$ for each i. Consequently a nonzero element of $R$ has only finitely many distinct proper divisors. (i) If $a$ and $b$ are nonzero elements of $R$ , let $c$ be their greatest common divisor.

By Definition II1.3.10 and Theorem III.3.11 there exist $r,s\in R$ R $R$ such that $ar+bs=c$ $ca_{1}=a$ and $cb_{1}=b$ , whence $a_{1}r+b_{1}s=1_{R}$ and $ba_1-ab_1=0$ . Consequently the $m\times m$ matrix

$$T=\begin{pmatrix}r&&-b_1&\\s&&a_1&0\\&0&&I_{m-2}\end{pmatrix}$$

is invertible with inverse.

$$T^{-1}=\begin{pmatrix}a_1&&b_1&&0\\-s&&r&&0\\&0&&&I_{m-2}\end{pmatrix}.$$

If the first row of $A$ is $(a,b,a_{13},\ldots,a_{1n_l})$ , then $A$ is equivalent to $AT=I_nAT$ whose first row is $(c,0,a_{13},\ldots,a_{1m})$ .If the first column' of $A$ is $(a,d,a_{31},\ldots,a_{n1})^{t}$ , then an analogous procedure yields an invertible matrix $S$ such that $A$ is equivalent to $SA$ and $SA$ has first column $(e,0,a_{31},\ldots,a_{n1})^{t}$ ,where $e$ is the greatest common divisor of $a$ and $d.$ A matrix such as $S$ or $T$ is called a secondary matrix. (ii) Since $A\neq0$ a suitable sequence of row and column interchanges and multi-

plications on the right by secondary matrices changes $A$ into a matrix $A_1$ which has first row $(a_1,0,0,\ldots,0)$ with $a_1\neq0$ A is equivalent to $A_1$ by (ii) and Corollary 2.10. (iv) If $a_1$ divides all entries in the frst column of $A_1$, then a finite sequence of

elementary row operations produces a matrix $B$ of the form

![](https://storage.simpletex.cn/view/fGSmGKkpecimZewygeNFw1VlsMGAYcs6k)

which is equivalent to $A_1$ , and hence to $A$ , by Corollary 2.10. (v) If $a_1$ does not divide some frst column entry $b$ of $A_1$ , then a sequence of row.

and column interchanges and multiplications on the left by secondary matrices changes $A_1$ into a matrix $A_2$ which has first column. $(a_2,0,0,\ldots,0)$ with $a_2$ acommon divisor of $a_1$ and $b$ (see (i). Note that $A_2$ may well have many nonzero entries in the

1For typographical convenience we shall frequently write an $n\times1$ column vector as the transpose of a $1\times n$ row vector; for example, $\begin{pmatrix}a_1\\a_2\end{pmatrix}=(a_1a_2)^t$

------------------------------------------------------------------

frst row. However since $a_2\mid a_1,a_2\mid b$ and $a_1Yb$ $a_2$ is a proper divisor of $a_1$ by (i). $A_2$ is equivalent to $A_1$ , and hence to $A$ , by (ii) and Corollary 2.10. (vi) If $a_2$ divides every entry in the first row of $A_2$ then a sequence of elementary

column operations produces a matrix equivalent to $A$ and of the same general form as $B$ above. (vii) If $a_2$ fails to divide some entry $k$ in the frst row of $A_2$ , then repeat (ii) and

obtain a matrix $A_3$ which is equivalent to $A$ and has frst row $(a_3,0,0,\ldots,0)$ with $a_3$ a common divisor of $a_2$ and $k$ . $A_3$ may have nonzero entries in its first column.But since $a_3\mid a_2,a_3\mid k$ and $a_2Xk$ $a_3$ is a proper divisor of $a_2$ by (i). Furthermore, $a_2$ and $a_3$ are distinct proper divisors of $a_{1}$ by (v). $A_3$ is equivalent to $A_2$ , and hence to $A$ ,by (ii) and Corollary 2.10. (vii) Since $a_1$ has only finitely many distinct proper divisors, a finite number of

repetitions of (ii)-(vii) must yield a matrix $C$ which is equivalent to $A$ and has the form

$$C=\begin{pmatrix}s_1&0&\cdots&0\\0&c_{22}&\cdots&c_{2m}\\.&.&&.\\.&.&&.\\.&.&&.\\0&c_{n2}&\cdots&c_{nm}\end{pmatrix}$$

with $s_1\neq0$

(ix) If $s_1$ does not divide some $c_{ij}$ , add row i to row 1 and repeat (iii)-(vii). The result is a matrix $D$ that is equivalent to $A$ , has the same general form as the matrix $C$ above, and has for its (1,1) entry an element $s_2$ which is a common divisor of $s_1$ and $c_{ij}$ and a proper divisor of $s_1$ $(x)$ If $s_2$ does not divide every entry in $D$ , then a repetition of (ix) yields a matrix

that is equivalent to $A$ ,has the same general form as $C$ and has (1,1) entry $s_3$ such that $s_3$ is a proper divisor of $s_2$, whence $s_2$ and $s_3$ are distinct proper divisors of $s_1$ .Since $s_1$ has only fnitely many distinct proper divisors, a finite number of repetitions of this process produces a matrix that is equivalent to $A$ ,has the same general form as $C_{:}$ and has a (1,1) entry which divides all other entries of the matrix. (xi) Use induction and $(\mathbf{x})$ to show that $A$ is equivalent to a diagonalmatrix

$F=\begin{pmatrix}L,&0\\0&0\end{pmatrix}$ as i te tatement o thetheoremn Sine the rank of $F$ is obvously $r.$ ,the rank of $A$ is $r$ by Theorem 2.6.

$(\mathbf{x}$ii) (uniqueness) Let $A$ and $F$ be as in $(\mathbf{x}\mathbf{i})$ ，with $d_{1},\ldots,d_{r}$ ,the diagonal elements of $L$ r. Suppose $M$ is a matrix equivalent to $A$ (so that rank $M=r.$ and $N$ is a matrix equivalen to $M$ of the form $\begin{pmatrix}L_r'&0\\0&0\end{pmatrix}$ where $L_{r}^{\prime}$ is an $r\times r$ diagonal matrix with nonzero diagonal entries $k_i$ such that $k_{1}\mid k_{2}\mid\cdots\mid k$, . By Theorem $1.2F$ is the matrix of a homomorphism $f:R^{m}\to R^{n}$ relative to bases $\{u_1,\ldots,u_n\}$ of $R^n$ and $\{v_1,\ldots,v_m\}$ of $R^m$ . Consequently, $f(u_{i})=d_{i}v_{i}$ for $i=1,2,\ldots,r$ r $r$ and $f(u_{i})=0$ for $i=r+1,\ldots,n$ ，whence Im $f=\:Rd_{1}v_{1}\oplus\cdots\oplus Rd_{r}v_{r}$ .By the analogue for modules of Corollary I.8.11, $R^{m}/$Im$f\cong Rv_1/Rd_1v_1\oplus\cdots\oplus Rv_r/Rd,v_r\oplus Rv_{r+1}$ $\oplus\cdots\oplus$ ···田$\cdots\oplus Rv_n\cong R/(d_1)\bigoplus\cdots\bigoplus R/(d,)\bigoplus R\bigoplus\cdots\bigoplus R/(n)$ n summands; $d_1|d_2|\cdots|d_r)$ . Since $F$ is equivalent to $N$ by hypothesis, Theorem 1.6 implies that $N$ is the matrix of $f$ relative to a different pair of bases. A repetition of the preceding argument then shows that $R^{m}/$Im $f\cong R/(k_1)\oplus\cdots\oplus R/(k,)\oplus R\oplus\cdots\oplus R$

------------------------------------------------------------------

$m$ summands; $k_1|k_2|\cdots|k_r)$ The structure Theorem IV.6.12 for modules over a principal ideal domain implies that $(d_i)=(k_i)$ for $i=1,2,\ldots,r$

A simplified version of the techniques used in the proof of Proposition 2.11 may be used to obtain the canonical form $E_r^{n,m}$ of an $n\times m$ matrix $A$ over a division ring $D.$ If $A=0=E_{0}^{n.m}$ , there is nothing to prove. If $a_{ij}$ is a nonzero entry in $A$ , then interchanging rows i and 1 and columns $j$ and 1 moves $a_{ij}$ to position (1,1). Multiplying row 1 by $a_{ij}^{-1}$ yields a matrix with first row of the form $(1_{R},c_2,\ldots,c_m)$ .Subtract suitable multiples of row 1 [resp. column 1] from each subsequent row [resp. column] and obtain a matrix of the form:

$$\begin{pmatrix}1_R&0&\cdots&0\\0&c_{22}&\cdots&c_{2m}\\.\\.\\0&c_{n2}&\cdots&c_{nm}\end{pmatrix}.$$

If every $c_{ij}=0$ , we are done. If some $c_{ij}\neq0$ , then we may repeat the above procedure on the $(n-1)\times(m-1)$ submatrix $(c_i,)$ . Since row [column] operations on rows $2,\ldots,n$ n $n$ [columns $2,\ldots,m]$ do not affect the first row or column, we obtain a matrix

$$\begin{pmatrix}1_R&0&0&\cdots&0\\0&1_R&0&\cdots&0\\0&0&d_{33}&\cdots&d_{3m}\\.\\.\\0&0&d_{n3}&\cdots&d_{nm}\end{pmatrix}_.$$

Continuing this process eventually yields the matrix $E_r^{n,m}$ for some $r$ .By Corollary $2.10A$ is equivalent to $E_r^{n,m}$ , whence $r=$ rank $A$ and $E_r^{n,m}$ is the canonical form of $A$ under equivalence by Theorem 2.6.

A modified version of the preceding technique gives a constructive method for finding the inverse of an invertible matrix, as is seen in theproof of:

Proposition 2.12. The following conditions on an $n\times n$ matrix A over a division ring D are equivalent:

(i) rank $\mathbf{A}=\mathbf{n}$ (i) A is equivalent to the identity matrix $I_n$ (ii) A is invertible; (iv) A is the product of elementary transforination matrices.

SKETCH OF PROOF. $(\mathrm{i})\Leftrightarrow(\mathrm{ii})$ by Theorem 2.6 since $E_{n}^{n,n}=I_{n}$ . $(\mathrm{i})\Rightarrow$ (ii) The rows of any matrix of rank $n$ are necessarily linearly independent (see Theorem IV.2.5 and Definition 2.2.) Consequently, the frst row of $A=(a_{ij})$ is not the zero vector and $a_{1j}\neq0$ for some $j$ . Interchange columns $j$ and 1 and multiply the new column 1 by $a_{1j}^{-1}$ .Subtracting suitable multiples of column 1 from each succeeding column yields a matrix

------------------------------------------------------------------

$$B=\begin{pmatrix}1_D&0&\ldots&0\\b_{21}&b_{22}&\cdots&b_{2n}\\.\\.\\.\\b_{n1}&b_{n2}&\cdots&b_{nn}\end{pmatrix}.$$

$B$ is equivalent to $A$ by Corollary 2.10. Assume inductively that there is a sequence of elementary column operations that changes $A$ to a (necessarily equivalent) matrix

$$C=\begin{pmatrix}&l_{k-1}&&0\\c_{k1}&\cdots&c_{kk}&\cdots&c_{kn}\\.&&&&.\\.&&&&.\\c_{n1}&\cdots&c_{nk}&\cdots&c_{nn}\end{pmatrix}.$$

For some $j\geq k$ ， $c_{ki}\neq0$ since otherwise row $k$ would be a linear combination of rows $1,2,\ldots,k-1$ k-1 $k-1$ This would contradict the fact that rank $C=$ rank $A=n$ by Theorem 2.6. Interchange columns $j$ and $k$ , multiply the new column $k$ by $c_{kj}^{-1}$ and subtract a suitable multiple of column $k$ from each of columns $1,2,\ldots,k-1$, $k+1,\ldots,n$ . The result is a matrix $D$ that is equivalent to $A$ (Corollary 2.10):

$$D=\begin{pmatrix}&I_k&&0\\d_{k+1\:1}&\cdots&d_{k+1\:k+1}&\cdots&d_{k+1\:n}\\.&&&&.\\.&&&&.\\d_{n1}&\cdots&d_{n\:k+1}&\cdots&d_{nn}\end{pmatrix}_.$$

This completes the induction and shows that when $k=n,A$ is changed to $I_n$ by a finite sequence of elementary column operations. Therefore by Theorem 2.8 $A(F_1F_2\cdots F_l)=I_n$ with each $F_i$ an elementary matrix.The matrix $F_1F_2\cdots F_t$ is a twosided inverse of $A$ by Exercise 1.7, whence $A$ is invertible. Corollary 2.9 and the fact that $A=F_{l}^{-1}\cdots F_{2}^{-1}F_{1}^{-1}$ show that $(\mathrm{i})\Rightarrow(\mathrm{iv})$ . (ii) $\therefore\Longrightarrow(\mathrm{i})$ by Lemma 1.5 and Theorem 2.3. (iv) $\Rightarrow$ (i) by Corollary 2.9.

REMARK. The proof of $(\mathrm{i})\Rightarrow(\mathrm{iii})$ shows that $A^{-1}=F_{1}F_{2}\cdots F_{t}$ is the matrix obtained by performing on $I_n$ the same sequence of elementary column operations used to change $A$ to $I_n$ .As arule thisis amore convenient way ofcomputing inverses than the use of determinants (Section 3).

## APPENDIX: ABELIAN GROUPS DEFINED BY GENERATORS AND RELATIONS

An abelian group $G$ is said to be the abelian group defined by the generators $a_{1},\ldots,a_{m}\left(a_{i}\varepsilon\:G\right)$ am $a_m$ (a;e G) $(a_i\varepsilon G)$ and the relations

------------------------------------------------------------------

r11a1 + r12a2 +..·+ rimam = 0, r21a1 + r22a2 + ...+ r2mam = 0,
$$r_{n1}a_1+r_{n2}a_2+\cdots+r_{nm}a_m=0,$$

$(r_{ij}\in\mathbf{Z})$ provided that $G\cong F/K$ ,where $F$ is the free abelian group on the set $\{a_1,\ldots,a_m\}$ and $K$ is the subgroup of $F$ gencrated by $b_{1}=r_{11}a_{1}+\cdots+r_{1m}a_{m}$ $b_{2}=r_{21}a_{1}+\cdots+r_{2m}a_{m}$ .···. $b_{n}=r_{n1}a_{1}+\cdots+r_{nm}a_{m}$ . Note that the same symbol $a_i$ denotesboth an element of thegroup $G$ and a basis element of the free abelian group $F$ (see Theorem II.1.1). This definition is consistent with the concept of generators and relations discussed in Section I.9 (see Exercise 10). The basic problem is to determine the structure of the abelian group $G$ defined by

a given finite set of generators and relations. Since $G$ is fnitely generated, $G$ is necessarily a direct sum of cyclic groups (Theorem II.2.1). We shall now determine the orders of these cyclic summands Let $G$ be the group defined by generators $a_{\mathrm{l}},\ldots,a_{m}$ and relations ∑ ria; = 0

as above.We shall denote this situation by the $n\times m$ matrix $A=(r_{i_{l}})$ . The rows of $A$ represent the generators $b_1,\ldots,b_n$ bn $b_n$ of the subgroup $K$ relative to the ordered basis $\{a_1,\ldots,a_m\}$ of $F$ .We claim that elementary row and column operations performed on $A$ have the following effect. (i) If $B=(s_{ij})$ is obtained from $A$ by an elementary row operation, then the

elements $c_{1}=s_{11}a_{1}+\cdots+s_{1m}a_{m},\ldots,c_{n}=s_{n1}a_{1}+\cdots+s_{nm}a_{m}$ of $F$ (that is, the rows of $B$ )generate the subgroup $K$ . (Exercise 1l (a)). (i) If $B=(s_{ij})$ is obtained from $A$ by an elementary column operation, then

there is an easily determined basis $\{a_{1}^{\prime},\ldots,a_{m}^{\prime}\}$ of $F$ such that $b_{i}=s_{i1}a_{1}{}^{\prime}+s_{i2}a_{2}{}^{\prime}+$ $\cdots+s_{im}a_m^{\prime}$ for every $i$ (Exercise 11 (b), (c)) If $K\neq0$ , then by Proposition 2.11 and Exercise 7, $A$ may be changed via a finite

sequence of elementary row and column operations, to a diagonal matrix

![](https://storage.simpletex.cn/view/f27NPgm2yaVZrcfkRMgmFGcApUkvtCMda)

such that $d_i\neq0$ for all $i$ and $d_{1}\mid d_{2}\mid d_{3}\mid\cdots\mid d_{r}$ . In other words a finite sequence of elementary operations yields a basis $\{u_1,\ldots,u_m\}$ of $F$ such that $\{d_1u_1,d_2u_2,\ldots,d_ru_r\}$ generates $K$ . Consequently by Corollary I.8.11

$$\begin{aligned}
G\cong F/K& \cong(\mathbf{Z}u_1\oplus\cdots\oplus\mathbf{Z}u_m)/(\mathbf{Z}d_1u_1\oplus\cdots\oplus\mathbf{Z}d_ru_r\oplus0\oplus\cdots\oplus0)  \\
&\cong\mathbf{Z}/d_1\mathbf{Z}\oplus\cdots\oplus\mathbf{Z}/d_1\mathbf{Z}\oplus\mathbf{Z}/0\oplus\cdots\oplus\mathbf{Z}/0 \\
&\cong Z_{d_1}\oplus\cdots\oplus Z_{d_r}\oplus Z\oplus\cdots\oplus Z,
\end{aligned}$$

where the rank of $(\mathbf{Z}\oplus\cdots\oplus\mathbf{Z})$ is $m-r$ and $d_1\mid d_2\mid\cdots\mid d_r$ (see Theorem II.2.6)

------------------------------------------------------------------

EXAMPLE. Determine the structure of the abelian group $G$ defined by genera tors $a,b,c$ and relations $3a+9b+9c=0$ and $9a-3b+9c=0$ .Let $F$ be the free abelian group $\mathbf{Z}a+\mathbf{Z}b+\mathbf{Z}c$ and $K$ the subgroup generated by $b_1=3a+9b+9c$ and $b_{2}=9a-3b+9c$ .Then $G$ is isomorphic to $F/K$ and we have the matrix

$$A=\begin{pmatrix}3&9&9\\9&-3&9\end{pmatrix}.$$

We indicate below the various stages in the diagonalization of the matrix $A$ byele mentary operations; (sometimes several operations are performed in a single step) At eachstage weindicate thebasis of $F$ and the generators of $K$ represented by the given matrix; (this can be tricky; see Exercise 11).

<table>
	<tbody>
		<tr>
			<th> </th>
			<th colspan="2">Matrix</th>
			<th>Ordered basis of F</th>
			<th rowspan="2">Generators of K, expressed as linear combinations of this basis $b_{\mathrm{l}}=3a+9b+9c$ $b_{2}=9a-3b+9c$</th>
		</tr>
		<tr>
			<th>3 9</th>
			<th>9 3 一</th>
			<th>$9'$ 9</th>
			<th>$a;b;c$</th>
		</tr>
		<tr>
			<td>3 9</td>
			<td>0 30 一</td>
			<td>$9\rangle$ 9,</td>
			<td>$a+3b;b;c$</td>
			<td>$b_{\mathbf{l}}=3(a+3b)+9c$ $b_{2}=9(a+3b)-30b+9c$</td>
		</tr>
		<tr>
			<td>3 9</td>
			<td>0 一 30 $\frac{1}{2}=\frac{1}{2}=\frac{1}{2}$</td>
			<td>0 18 一</td>
			<td>$a+3b+3c;b;c$</td>
			<td>$b_{1}=3(a+3b+3c)$ $b_{2}=9(a+3b+3c)-30b-18c$</td>
		</tr>
		<tr>
			<td>3 0</td>
			<td>0 -5 30 </td>
			<td>0 18 一</td>
			<td>$a+3b+3c;b;\boldsymbol{c}$</td>
			<td>$b_{\mathbf{l}}=3(a+3b+3c)$ $b_{2}-3b_{1}=-30b-18\boldsymbol{c}$</td>
		</tr>
		<tr>
			<td>1/3 0</td>
			<td>0 18 3</td>
			<td>0 0.</td>
			<td>$a+3b+3c;c;b$</td>
			<td>$b_{1}=3(a+3b+3c)$ $-(b_{2}-3b_{1})=18c+30b$</td>
		</tr>
		<tr>
			<td>3 0</td>
			<td>0 18 1</td>
			<td>$0^{\cdot}$ 2</td>
			<td>$a+3b+3c;c+b;b$</td>
			<td>$b_{1}=3(a+3b+3c)$ $-b_{2}+3b_{1}=18(c+b)+12b$</td>
		</tr>
		<tr>
			<td>1/3 0</td>
			<td>0 6 1</td>
			<td>$9^{\prime}$ 2.</td>
			<td>$a+3b+3c;c+b;$ $b+(c+b)$</td>
			<td>$b_{\mathbf{l}}=3(a+3b+3c)$ $-b_{2}+3b_{1}=6(c+b)+12(2b+c)$</td>
		</tr>
		<tr>
			<td>3 0</td>
			<td>0 0 6 0</td>
			<td> </td>
			<td>$a+3b+3c;5b+3c;$ $2b+c$</td>
			<td>$b_{1}=3(a+3b+3c)$ $-b_{2}+3b_{1}=6(5b+3c)$</td>
		</tr>
		<tr>
			<td>0</td>
			<td>6 0</td>
			<td> </td>
			<td>$2b+c$</td>
			<td>$-b_{2}+3b_{\mathbf{l}}=6(5b+3c)$</td>
		</tr>
	</tbody>
</table>

Therefore $G\cong F/K\cong\mathbf{Z}/3\mathbf{Z}\oplus\mathbf{Z}/6\mathbf{Z}\oplus\mathbf{Z}/0\mathbf{Z}\cong\mathbf{Z}_3\oplus\mathbf{Z}_6\oplus\mathbf{Z}$ If $\bar{v}\varepsilon G$ is the imageof $v+K\varepsilon F/K$ under the isomorphism $F/K\cong G$ , then $G$ is the internal direct sum of a cyclic subgroup of order three with generator $\overline{a+3b+3c}$ , a cyclic sub group of order six with generator $\overline{5b+3c}$ , and an infinite cyclic subgroup with generator $\overline{2b+c}$

## EXERCISES

1. Let fg:E→E $f,g:E\to E$ $f,g:E\to E,h:E\to F,k:F\to G$ h:E→F $h:E\to F$ k:F→G $k:F\to G$ be linear transformations of left vector spaces over a division ring $D$ with $\dim_DE=n$ ， $\dim_DF=m$ ， $\dim_DG=p$ (a) Rank $(f+g)\leq$ rank $f+$ rank $g$

(b) Rank $(kh)\leq$ min {rank $h$ ,rank $k$ 1. (c) Nullity $kh\leq$ nullity $h+$ nullity $k$ (d) Rank $f+$ rank $g-n\leq$ rank fg ≤ min {rank $f$, rank $g\}$

------------------------------------------------------------------

(e) Max { nullity $g$ , nullity $h\}\leq$ nullity hg. (f) If $m\neq n$, then (e) is false for $h$ and $k$

2.An $n\times m$ matrix $A$ over a division ring $D$ has an $m\times n$ left inverse $B$ (that is, $BA=I_m)$ if and only if rank $A=m$ . $A$ has an $m\times n$ right inverse $C$ (with $AC=I_{n}$ if and only if rank $A=n$

3.If $(c_{i1},c_{i2}\cdots c_{im})$ is a nonzero row of a matrix $(c_{ij})$ , then its leading entry is $c_{it}$ where $l$ is the first integer such that $c_{it}\neq0$ .A matrix $C=(c_{ij})$ over a division ring $D$ is said to be in reduced row echelon form provided: (i) for some $r\geq0$ the first $r$ rows of $C$ are nonzero (row vectors) and all other rows are zero; (i) the leading entry of each nonzero row is $1_D$ ; (ii) if $c_{ij}=1_{D}$ is the leading entry of row $i$ , then $c_{kj}=0$ for all $k\neq i;$ (iv) if $c_{1j_{1}},c_{2j_{2}},\ldots,c_{rj_{r}}$ Crir $c_{rjr}$ are the leading entries of rows $1,2,\ldots,r$ , then $j_{1}<j_{2}<\cdots<j_{r}$ (a) If $C$ is in reduced row echelon form, then rank $C$ is the number of nonzero

rows. (b) If $A$ is any matrix over $D$ , then $A$ may be changed to a matrix in reduced

row echelon form by a finite sequence of elementary row operations.

4. (a) The system of $n$ linear equations in $m$ unknowns $x_i$ over a field $K$

$$\begin{aligned}&a_{11}x_{1}\:+\:a_{12}x_{2}+\cdots+\:a_{1m}x_{m}\:=\:b_{1}\\&a_{n1}x_{1}+a_{n2}x_{2}+\cdots+a_{nm}x_{m}\:=\:b_{n}\end{aligned}$$

has a (simultaneous) solution if and only if the matrix equation $AX=B$ has a solution $X$ ,，where $A$ is the $n\times m$ matrix $(a_{ij}),X$ X $X$ is the $m\times1$ column vector $(x_1x_2\cdots x_m)^t$ and $B$ is the $n\times1$ column vector $(b_1b_2\cdots b_n)^t$ (b) If $A_1,B_1$ are matrices obtained from $A,B$ respectively by performing the

same sequence of elementary row operations on both $A_1$ and $B_{1}$ then $X$ is a solution of $AX=B$ if and only if $X$ is a solution of $A_1X=B_1$ (c) Let $C$ be the $n\times(m+1)$ matrix

![](https://storage.simpletex.cn/view/fqxrX96mXs4l8y3kttgf4bIuVfyFxYPHR)

Then $AX=B$ has solution if and only if rank $A=$ rank $C$ . In this case the solu. tion is unique if and only if rank $A=m$ . [Hinr: use (b) and Exercise 3.] (d) The system $AX=B$ is homogeneous if $B$ is the zero column vector.A

homogeneous system $AX=B$ has a nontrivial solution (that is, not all $x_{i}=0$ if and only if rank $A<m$ (in particular, if $n<m$

5.Let $R$ be a principal ideal domain. For each positive integer $r$ and sequence of nonzero ideals $I_1\supset I_2\supset\cdots\supset I_r$ choose a sequence $d_{1},\ldots,d_{r}\in R$ such that $(d_{j})=I_{i}$ and $d_{1}\mid d_{2}\mid\cdots\mid d_{r}$ . For a given pair of positive integers $(n,m)$ ,let $S$ be the st oral $n\times m$ matrices o the form $\begin{pmatrix}L_r&0\\0&0\end{pmatrix}.$ where $r=1,2,\ldots,\min{(n,m)}$ and $L_{r}$ is an $r\times r$ diagonal matrixwithmaindiagonal one of the chosen se-

------------------------------------------------------------------

quences $d_{1},\ldots,d_{r}$ .Show that $S$ is a set of canonical forms under equivalence for the set of all $n\times m$ matrices over $R$

6. (a) If $f:E\to F$ is a linear transformation of finite dimensional vector spaces over a division ring, then there exist bases $\{u_1,\ldots,u_n\}$ of $E$ and $\{v_1,\ldots,v_m\}$ of $F$ and an integer $r$ $(r\leq\min\left(m,n\right))$ such that $f(u_{i})=v_{i}$ for $i=1,2,\ldots,r$ and $f( u_i)$ = 0 for $i=r+1,\ldots,n$ (b) State and prove a similar result for free modules of finite rank over a

principal ideal domain [see Proposition 2.11].

7. Let $R$ be a Euclidean domain with “degree function" $\phi:R-\{0\}\to\mathbb{N}$ (Definition I11.3.8). (For example, let $R=\mathbf{Z}$

(a) If $A=\begin{pmatrix}a\:b\\c\:d\end{pmatrix}$ is a $2\times2$ matrix over $R$ then $A$ can be changed toa diagonal matrix $D$ by a finite sequence of elementary row and column operations. [Hint: If $a\neq 0$, $b\neq 0$ b≠0 $b\neq0$ ，then $b=aq+r$ with $r=0$ ，or $r\neq0$ and $\phi(r)<\phi(a)$ Performing suitable elementary column operations yields:

$$\begin{pmatrix}a&b\\c&d\end{pmatrix}\to\begin{pmatrix}a&b-aq\\c&d-cq\end{pmatrix}=\begin{pmatrix}a&r\\c&*\end{pmatrix}\to\begin{pmatrix}r&a\\*&c\end{pmatrix}.$$

Since $\phi(r)<\phi(a)$ retitinso this argument hange $A$ to $B=\begin{pmatrix}s&0\\u&*\end{pmatrix}$ with $\phi(s)<\phi(a)$ if $s\neq0$ .If $u\neq0$ ，a similar argument with rows changes $B$ to $C=\begin{pmatrix}t&w\\0&*\end{pmatrix}$ with $\phi(t)<\phi(s)<\phi(a)$ if $1\neq0$ : (and posibly $w\neq0$ .Since the degrees of the (1, 1) entries are strictly decreasing,a repetition of these arguments must yied diagoal marix $D=\begin{pmatrix}d_1&0\\0&d_2\end{pmatrix}$ aftera fite numbero stepsil (b) If $A$ is invertible, then $A$ is a product of elementary matrices. [Hint : By (a) and theproof of Corollary 2.10 $D= PAQ$ with $P,Q$ invertible, whence $D$ is inverible and $d_1,d_2$ are unis in $R$ Thus $A= P^{- 1}\binom {d_1}0$ $1_R\binom {1_R}0Q^{- 1}$ use Corollary 2.9.] (c) Every $n\times m$ secondary matrix (see the proof of Proposition 2.11) over a

Euclidean domain is a product of elenentary matrices.

8.(a)Aninvertible matrix over a principal ideal domain is a product of elementary and secondary matrices.

(b) An invertible matrix over a Euclidean domain is a product of elementary matrices [see Exercise 7].

9. Let $n_1,n_2,\ldots,n_t,n$ be positive integers such that $n_1+n_2+\cdots+n_l=n$ and for each $i$ let $M_i$ be an $n_i\times n_i$ matrix. Let $M$ be the $n\times n$ matrix

![](https://storage.simpletex.cn/view/fKIBuLFkGgtePG5XH15hkxf7odDh96fHB)

------------------------------------------------------------------

where themain diagonal of each $M_i$ lies on the main diagonal of $M$ . For each permutation $\sigma$ of $\{1,2,\ldots,1\}$ ， $M$ issimilar to thematrix

$$\sigma M=\begin{pmatrix}M_{\sigma1}&&&&0&\\&M_{\sigma2}&&&0&\\&&&\cdot&&\\&&&\cdot&&\\&&&&\cdot&\\&&&&&M_{at}\end{pmatrix}.$$

[Hhira $t=3$ $\sigma=(13)$ and $P=\begin{pmatrix}0&I_{n_3}\\I_{n_2}\\I_{n_1}&0\end{pmatrix}$, ten $P^{-1}=\begin{pmatrix}0&I_{n1}\\I_{n2}&0\end{pmatrix}$ and $PMP^{-1}=\sigma M.$ In the general case adapt the proof of results 2.8 - 2.10.]

10. Given the set $\{a_{1},\ldots,a_{n}\}$ and the words $w_{1},w_{2},\ldots,w_{r}$ (on the $a_{i}$ 0, let $F^*$ be the free (nonabelian multiplicative) group on the set $\{a_1,\ldots,a_n\}$ and let $M$ be the normal subgroup generated by the words $w_{1},w_{2},\ldots,w_{r}$ $w_r$ W, (see Section I.9). Let $N$ be the normal subgroup generated by all words of the form $a_ia_ja_i^{-1}a_j^{-1}$ (a) $F^*/M$ is the group defined by generators $\{a_1,\ldots,a_n\}$ and relations

$w_{1}=w_{2}=\cdots=w_{r}=e|$ (Definition 1.9.4). (b) $F^*/N$ is the free abelian group on $\{a_1,\ldots,a_n\}$ (see Exercise I1.1.12). (c) $F^*/(M\vee N)$ is (in multiplicative notation) the abelian group defined by generators $\{a_1,\ldots,a_n\}$ and relations $\{w_{1}=w_{2}=\cdots=w_{r}=e\}$ (see p.343). (d) There are group epimorphisms $F^*\to F^*/N\to F^*/(M\vee N)$

11.Let $F$ be afree abelian group withbasis $\{a_{1},\ldots,a_{m}\}$ .Let $K$ be the subgroup of $F$ generated by $b_{1}=r_{11}a_{1}+\cdots+r_{1m}a_{m},\ldots,b_{n}=r_{n1}a_{1}+\cdots+r_{nm}a_{m}\left(r_{ij}\varepsilon\mathbf{Z}\right)$ (a) For each i, both $\{b_{1},\ldots,b_{i-1},-b_{i},b_{i+1},\ldots,b_{n}\}$ and $\{b_{1},\ldots,b_{i-1},b_{i}+rb_{i}$, $b_{i+1},\ldots,b_n\}$ $(r\in\mathbf{Z};i\neq j)$ generate $K$ [See Lemma II.1.5.] (b) For each $i\left\{a_{1},\ldots,a_{i-1},-a_{i},a_{i+1},\ldots,a_{n}\right\}$ is a basis of $F$ relative to which.

$b_{j}=r_{i1}a_{1}+\cdots+r_{j,i-1}a_{i-1}-r_{ji}(-a_{i})+r_{j,i+1}a_{i+1}+\cdots+r_{jm}a_{m}.$ (c) For each iand. $j\neq i\left\{a_{1},\ldots,a_{j-1},a_{j}-ra_{i},a_{j+1},\ldots,a_{m}\right\}$ (r e Z) is a basis

of $F$ relative to which $b_{k}=r_{k1}a_{1}+\cdots+r_{k,i-1}a_{i-1}+(r_{ki}+rr_{kj})a_{i}+r_{k,i+1}a_{i+1}+$
$$\cdots+r_{k,j-1}a_{i-1}+r_{kj}(a_j-ra_i)+r_{k,j+1}a_{j+1}+\cdots+r_{km}a_m.$$

12. Determine the structure of the abelian group $G$ defined-by generators $\{a,b\}$ and relations $2a+4b=0$ and $3b=0$ . Do the same for the group with generators $\{a,b,c,d\}$ and relations $2a+3b=4a\div5c+11d=0$ and for the group with generators $\{a,b,c,d,e\}$ and relations
$$(a-7b+14d-21c=0;5a-7b-2c+10d-15e=0;3a-3b-2c+$$

$6d-9e=0$ $a-b+2d-3e=0\}$

## 3. DETERMINANTS

The determinant function $\mathrm{Mat}_nR\to R$ is defined as a particular kind of $R$ -multilinear function and its elementary properties are developed (Theorem 3.5). The remainder of the section is devoted to techniques for calculating determinants and the connection between determinants and invertibility. With minor exceptions this ma-

------------------------------------------------------------------

terial is not needed in the sequel. Throughout this section all rings are commutative with identity and all modules are unitary. If $B$ is an $R$ -module and $n\geq1$ an integer, $B^n$ will denote the $R$ -module

$B\oplus B\oplus\cdots\oplus B$ $n$ summands). Of course, the underlying set of the module $B^n$ is just the cartesian product $B\times\cdots\times B$

Definition 3.1. Let $\mathbf{B}_{\mathrm{l}},\ldots,\mathbf{B}_{\mathrm{n}}$ $\mathbf{B}_{\mathrm{n}}$ Bn and C be modules over a comnutative ring R with identity. $A$ function $\mathbf{f}:\mathbf{B}_1\times\cdots\times\mathbf{B}_n\to\mathbf{C}$ is said to be R-multilinear if for each $\mathbf{i}=1,2,\ldots,\mathbf{n}$ and all r,s ε R, $b_{\mathrm{j}}\varepsilon B_{\mathrm{j}}$ and $\mathbf{b} , \mathbf{b} ^{\prime }\varepsilon \mathbf{B} _{\mathrm{i} }$

$$\mathrm{f(b_{1},\ldots,b_{i-1},rb+sb^{\prime},b_{i+1},\ldots,b_{n})=rf(b_{1},\ldots,b_{i-1},b,b_{i+1},\ldots,b_{n})+}\\\mathrm{sf(b_{i},\ldots,b_{i-1},b^{\prime},b_{i+1},\ldots,b_{n}).}$$

$If\mathbf{C}=\mathbf{R}$ , then f is called an n-linear or R-multilinear form. $If\mathbf{C}=\mathbf{R}$ and $\mathbf{B}_{1}=\mathbf{B}_{2}$ $= \cdots = \mathbf{B} _{\mathrm{n} }= \mathbf{B}$, then f is called an R-multilinear form on B.

The 2-linear functions are usually called bilinear (see Theorem IV.5.6). Let $B$ and $C$ be $R$ -modules and $f:B^n\to C$ an $R$ -multilinear function. Then fis said to be symmetric if

$$f(b_{\sigma1},\ldots,b_{\sigma n})=f(b_1,\ldots,b_n)$$
for every permutation $\sigma\varepsilon S_n$

and skew-symmetric if

$$f(b_{\sigma1},\ldots,b_{\sigma n})=(\mathrm{sgn}\:\sigma)\:f(b_1,\ldots,b_n)\quad\mathrm{for~every}\quad\sigma\:\varepsilon S_n.$$

$f$ is said to be alternating if

$$f(b_1,\ldots,b_n)=0\quad\text{whenever}\quad b_i=b_j\quad\text{for some}\quad i\neq j.$$

EXAMPLE. Let $B$ be the free $R$ -module $R\oplus R$ and let $d:B\times B\to R$ be de fined by $( ( a_{11}, a_{12}) , ( a_{21}, a_{22}) ) | \mapsto a_{11}a_{22}- a_{12}$ $a_{21}$ . Then $d$ is a skew-symmetric alternating bilinear form on $B$ . If one thinks of the elements of. $B$ as rows of $2\times2$ matrices over $R$ ,then $d$ is simply the ordinary determinant function

Theorem 3.2. If B and C are modules over a commutative ring R with identity, then every alternating R-multilinear function $\mathbf{f}:\mathbf{B}^n\to\mathbf{C}$ is skew-symmetric.

SKETCH OF PROOF. In the special case when $n=2$ and $\sigma = ( 1$ 2) , we have:

$$\begin{aligned}
0=f(b_{1}+b_{2},b_{1}+b_{2})& =f(b_{1},b_{1})+f(b_{1},b_{2})+f(b_{2},b_{1})+f(b_{2},b_{2}) \\
&=\:0+f(b_{1},b_{2})+f(b_{2},b_{1})+0,
\end{aligned}$$

whence $f(b_2,b_1)=-f(b_1,b_2)=($sgn $\sigma)f(b_1,b_2)$ .In the general case,show that it suffices to assume. $\sigma$ is a transposition. Then the proof is an easy generalization of the case $n=2$ .

Our chief interest is in alternating $n$ -linear forms on the free. $R$ -module $R^n$ .Such a form is a function from $(R^{n})^{n}=R^{n}\textcircled {\oplus}\cdots\textcircled {R}^{n}$ (n summands) to $R$

------------------------------------------------------------------

Theorem 3.3.IfR is a commutative ring with identity andr e R,then there exisis a unique alternating R-multilinear form $\mathbf{f}:(\mathbb{R}^n)^n\to\mathbb{R}$ such that f$( \varepsilon _1, \varepsilon _{2}, \ldots , \varepsilon _{\mathrm{n} }) =$r where $\{\epsilon_{1},\ldots,\epsilon_{n}\}$ is the standard basis of $R^n$

REMARK. The standard basis is defined after Definition 2.1. The following facts may be helpful in understanding the proof.Since the elements of $R^n$ maybe identifed with $1\times n$ row vectors, it is clear that there is an $R$ -module isomorphism $(R^n)^n\cong\mathrm{Mat}_nR$ given by $(X_1,X_2,\ldots,X_n)\vdash A$ ，where $A$ is the matrix with rows $X_1,X_2,\ldots,X_n$ . If $\{\varepsilon_{1},\ldots,\varepsilon_{n}\}$ is the standard basis of $R^n$ , then $(\varepsilon_{1},\varepsilon_{2},\ldots,\varepsilon_{n})\models I_{n}$ under this isomorphism. Thus the multilinear form fof Theorem 3.3 may be thought of as a function whose $n$ arguments are the rows of $n\times n$ matrices.

PROOF OF 3.3. (Uniqueness) If such an alternating $n$ -linear form fexists and if $(X_{1},\ldots,X_{n})\varepsilon(R^{n})^{n}$ , then for each i there exist $a_{ij}$ E $R$ such that $X_{i}=(a_{i1},a_{i2},\ldots,a_{in})$ $=\sum_{j=1}^{n}a_{i,\varepsilon_{j}}.$ (I other words nder heisomorphism $(R^n)^n\cong\mathrm{Mat}_nR,(X_1,\ldots,X_n)|\overset{\sim}{\operatorname*{\longmapsto}}$ $(a_{ij}).)$ Therefore by multilinearity.

$$\begin{aligned}
f(X_1,\ldots,X_n)& =\:f(\sum_{j_{1}}a_{1j_{1}}\varepsilon_{j_{1}},\sum_{j_{2}}a_{2j_{2}}\varepsilon_{j_{2}},\ldots,\sum_{j_{n}}a_{nj_{n}}\varepsilon_{j_{n}}) \\
&=\sum_{j_{1}}\sum_{j_{2}}\cdots\sum_{j_{n}}a_{1j_{1}}a_{2j_{2}}\cdots a_{nj_{n}}f(\varepsilon_{j_{1}},\varepsilon_{j_{2}},\ldots,\varepsilon_{j_{n}}).
\end{aligned}$$

Since fis alternating the only possible nonzero terms in the final sum are those where $j_{1},j_{2},\ldots,j_{n}$ are all distinct ; that is, $\{j_1,\ldots,j_n\}$ is simply the set $\{1,2,\ldots,n\}$ in some order, so that for some permutation $\sigma\varepsilon S_n$ ， $(j_1,\ldots,j_n)=(\sigma1,\ldots,\sigma n)$ .Conse quently by Theorem 3.2,

$$\begin{aligned}
f(X_1,\ldots,X_n)& =\sum_{\sigma\epsilon_{i}S_{n}}a_{1\sigma1}a_{2\sigma2}\cdots a_{n\sigma n}\:f(\varepsilon_{\sigma1},\varepsilon_{\sigma2},\:\ldots\:,\:\varepsilon_{\sigma n}) \\
&=\sum_{\sigma\epsilon S_{n}}(\mathrm{sgn}\:\sigma)a_{1\sigma1}\cdots a_{n\sigma n}\:f(\varepsilon_{1},\varepsilon_{2},\ldots,\varepsilon_{n}).
\end{aligned}$$

Since $f(\varepsilon_{1},\ldots,\varepsilon_{n})=r$, wehave

$$f(X_{1},\ldots,X_{n})=\sum_{\sigma\in S_{n}}(\mathrm{sgn}\:\sigma)ra_{1\sigma1}a_{2\sigma2}\cdots a_{n\sigma n}.$$

Equation (1) shows that $f(X_1,\ldots,X_n)$ is uniquely determined by $X_1,\ldots,X_n$ and $r$ (Existence) It suffices to define a function $f:(R^n)^n\to R$ by formula (1) (where $X_{\mathrm{i}}=(a_{\mathrm{il}},\ldots,a_{\mathrm{in}}))$ and verify that $f$ is an alternating $n$ -linear form with $f(\epsilon_{1},\ldots,\varepsilon_{n})=r$ Sine tor $a_{ij}$ hi $i=k$ $k$ verssre $f$ $R$ $\sum_{\sigma eS_{n}}($sgn $\sigma)ra_{1\sigma1}\cdots a_{n\sigma n}$ Since $\varepsilon_{i}=\sum_{j=1}^{n}\delta_{i,j}\varepsilon_{i}$ (Kronecker delta), $f(\varepsilon_{1},\ldots,\varepsilon_{n})=r$ . Fially we must show that $f(X_1,\ldots,X_n)=0$ if $X_{i}=X_{i}$ and $i\neq j.$ Assume for convenience of notation that $i=1,j=2$ .If $\rho=(12)$ ,then the map $A_n\to S_n$ givenby $\sigma\vdash\sigma\rho$ is an injective func. tion whose image is the set of all odd permutations (since $\sigma$ even implies $\sigma\rho$ odd and $|A_n|=|S_n|/2)$ . Thus $S_n$ is a union of mutually disjoint pairs $\{\sigma,\sigma\rho\}$ with $\sigma\varepsilon A_n$ An $A_n$ . If $\sigma$ is even, then the summand of $f(X_1,X_1,X_3,\ldots,X_n)$ corresponding to $\sigma$ is

$$+ra_{1\sigma1}a_{2\sigma2}a_{3\sigma3}\cdots a_{n\sigma n}.$$

------------------------------------------------------------------

Since $X_{1}=X_{2}$ $a_{1\sigma1}=\cdots2\sigma1$ , and $a_{2\sigma2}=a_{1\sigma2}$ ,whence the summand corresponding to the odd permutation $\sigma\rho$ is:

$$\begin{aligned}-ra_{1\sigma\rho1}a_{2\sigma\rho2}a_{3\sigma\rho3}\cdots a_{n\sigma\rho n}&=\:-ra_{1\sigma2}a_{2\sigma1}a_{3\sigma3}\cdots a_{n\sigma n}\\&=\:-ra_{1\sigma1}a_{2\sigma2}a_{3\sigma3}\cdots a_{n\sigma n}.\end{aligned}$$

Thus the summands of $f(X_1,X_1,X_3,\ldots,X_n)$ cancel pairwise and

$$f(X_1,X_1,X_3,\ldots,X_n)=0.$$

Therefore $f$ is alternating.

We can now use Theorem 3.3 and the Remark following it to define determinants In particular, we shall frequently identify $Mat_nR$ and $(R^n)^n$ under the isomorphism (given in the Remark), which maps $(\varepsilon_1,\ldots,\varepsilon_n)\mapsto I_n$ . Consequently, a multilinear form on $Mat_nR$ is an $R$ -multilinear form on $(R^n)^n$ whose arguments are the rows of $n\times n$ matrices considered as elements of $R^n$

Definition 3.4. Let R be a commutative ring with identity. The unigue alternating R-multilinear form $\mathbf{d}:Mat_n\mathbf{R}\to\mathbf{R}$ such that $\mathbf{d} ( \mathbf{I} _{\mathrm{n} }) = \mathbf{l} _{\mathrm{R} }$ is called the determinant function on $Mat_n\mathbf{R}$ .The determinant of amatrixA e $Mat_n\mathbb{R}$ $_{\mathrm{n} }\mathbf{R}$ nR is the element $\mathbf{d}(\mathbf{A})\in\mathbf{R}$ and is denoted $|\mathbf{A}|$

Theorem 3.5.Let R bea commutative ringwith identity and A,B e $Mat_n\mathbb{R}$

(i) Every alternating R-multilinear form f on $Mat_n\mathbb{R}$ nR $_{\mathrm{n} }\mathbf{R}$ is a unique scalar multiple of the determinant function d. (i $If\mathbf{A} = ( \mathbf{a} _{\mathrm{ij}})$ then |Al$= \sum _\sigma eS_{\mathrm{n} }( sgn$ $\sigma ) a_{\mathrm{lol}}a_{2\sigma 2}\cdots a_{\mathrm{n} \sigma \mathrm{n} }.$

(ii) $|AB|=|A||B|$ (iv) If A is invertible in. $Mat_n\mathbf{R}$ ,then $|\mathbf{A}|$ isa unit in $R$ (v)If A and B are similar, then $|\mathbf{A}|=|\mathbf{B}|$ (vi) $|\mathbf{A}^{\dagger}|=|\mathbf{A}|$ (vii) $If\mathbf{A} = ( \mathbf{a} _{\mathrm{i} \mathrm{j} })$ is triangular, then $| \mathbf{A} | = \mathbf{a} _{\mathrm{lI}}\mathbf{a} _{22}\cdots \mathbf{a} _{\mathrm{nn}}$ (vii)IfB is obtained by interchanging rwo rows[columns] ofA ,then $|\mathbf{B}|=-|\mathbf{A}|$

IfBis obtained by multiplying one row[column]of A by 1 =R,then $|\mathbf{B}|=\mathbf{r}|\mathbf{A}|$ .IfBis obtained by adding a scalar multiple ofrowi [column i] to row j [column j] $(\mathbf{i}\neq\mathbf{j})$ ,then $|\mathbf{B}|=|\mathbf{A}|$

SKETCH OF PROOF. (i)Let $f(I_{n})=r\varepsilon R$ . Let d be the determinant function.. Verify that the function $rd: \mathbf{M} \text{at}_nR\to R$ given by $A|\mapsto r|A|=rd(A)$ is also an alternating $R$ -multilinear form on $Mat_nR$ R $R$ such that $rd(I_n)=r$ ,whence $f=$ rdby the uniqueness statement of Theorem 3.3.The uniqueness of $r$ follows immediately (i) is simply a restatement of equation (1) in the proof of Theorem 3.3. (ii) Let $B$

be fixed and denote the columns of $B$ by $Y_1,Y_2,\ldots,Y_n$ Yn $Y_n$ .If $C$ is any $n\times m$ matrix with rows $X_1,\ldots,X_n$ ,then the $(i,j)$ entry of $CB$ is precisely the element $(1\times1$ matrix) $X_iY_j$ . Thus the ith row of $CB$ is $(X_{\iota}Y_{1},X_{i}Y_{2},\ldots,X_{i}Y_{n})$ . Use this fact to verify that the map. $\mathrm{Mat}_nR\to R$ given by $C|{\sim}|CB|$ is an alternating $R$ -multilinear form fon Mat, R. By (i) $f=rd$ for some r e $R.$ Consequently, $|CB|=f(C)=rd(C)$ $=r|C|$ . In particular, $|B|=|I_{n}B|=r|I_{n}|=r$ ,whence $|AB|=r|A|=|A||B|$

------------------------------------------------------------------

(iv) $AA^{-1}=I_{n}$ implies $|A\|A^{-1}|=|AA^{-1}|=|I_n|=1$ by (iii). Hence $|A|$ is a unit in $R$ with $|A|^{-1}=|A^{-1}|$ . (v) Similarly, $B=PAP^{-1}$ implies $|B|=|P||A||P|^{-1}=|A|$ since $R$ is commutative. (vi) Let $A=(a_{ij})$ .If $i_1,\ldots,i_n$ are the integers $1,2,\ldots,n$ in some order, then

since $R$ is commutative any product $a_{i_11}a_{i_22}\cdots a_{i_n^n}$ may be written as $a_{1j_1}a_{2j_2}\cdots a_{nj_n}$ .If $\sigma$ is the permutation such that $\sigma(k)\:=\:i_{k}$ , then $\sigma^{-1}$ is the permutation such that $\sigma^{-1}(k)=j_{k}$ . Furthermore, it is easy to see that for any $\sigma\varepsilon S_n$ $S_n$ Sn , sgn $\sigma=$sgn $\sigma^{-1}$ .Let $A^{t}=(b_{ij})$ ; then since $S_n$ is a group,

$$\begin{aligned}
|A^{t}|& =\sum_{\sigma\varepsilon S_{n}}(\mathrm{sgn}\:\sigma)b_{1\sigma1}\cdots b_{n\sigma n}=\sum_{\sigma\varepsilon S_{n}}(\mathrm{sgn}\:\sigma)a_{\sigma11}\cdots a_{\sigma nn} \\
\end{aligned}$$

(vii) By hypothesis either $a_{ij}=0$ for all $j<i$ or $a_{ij}=0$ for all $j>i.$ In either case show that if $\sigma\varepsilon S_n$ and $\sigma\neq(1)$ ,then $a_{1\sigma1}\cdots a_{n\sigma n}=0$ ,whence

$$|A|=\sum_{\sigma\epsilon S_{n}}(\mathrm{sgn}\:\sigma)a_{1\sigma1}\cdots a_{n\sigma n}\:=\:a_{11}a_{22}\cdots a_{nn}.$$

(vi) Let $X_1,\ldots,X_i,\ldots,X_j,\ldots,X_n$ be the rows of $A$ . If $B$ has rows $X_1,\ldots X_j$, $\ldots,X_{i},\ldots,X_{n}$ then since $d$ is skew-symmetric by Theorem 3.2.

$$\begin{aligned}|B|&=\:d(X_{1},\ldots,X_{j},\ldots,X_{i},\ldots,X_{n})\\&=\:-d(X_{1},\ldots,X_{i},\ldots,X_{i},\ldots,X_{n})\:=\:-|A|.\end{aligned}$$

Similarly if $B$ has rows $X_1,\ldots,X_i,\ldots,rX_i+X_i,\ldots,X_n$ then since $d$ is multilinear and alternating

$$\begin{aligned}
\left|B\right|& =d(X_{1},\ldots,X_{i},\ldots,rX_{i}+X_{j},\ldots,X_{n}) \\
&=r0+|A|=|A|.
\end{aligned}$$

The other statement is proved similarly; use (v) for the corresponding statements about columns.

If $R$ is a field, then the last part of Theorem 3.5 provides a method of calculating. $|A|$ . Use elementary row and column operations to change $A$ into a diagonal matrix $B=(b_{ij})$ , keeping track at each stage (via (vi) of what happens to $|A|$ . By (vii), $|B|=r|A|$ for some $0\neq r\varepsilon R$ .Hence $r|A|=b_{11}b_{22}\cdots b_{nn}$ by (vi) and

$$|A|=r^{-1}b_{11}\cdots b_{nn}.$$

More generally the determinant of an $n\times n$ matrix $A$ over any commutative ring with identity may be calculated as follows.Foreachpair $(i,j)$ let $A_{i,j}$ be the $(n-1)\times(n-1)$ matrix obtained by deleting row $i$ and column $j$ from $A$ . Then $|A_{ij}|\varepsilon\:R$ R $R$ is called the minor of $A=(a_{ij})$ at position $(i,j)$ and $(-1)^{i+j}|A_{i,j|}^{|}\varepsilon R$ is called the cofactor of $a_{ij}$

Proposition 3.6. If A is an $n\times n$ matrix orer a commutative ring R with identity. thenfor each $\mathbf{i}=1,2,\ldots,\mathbf{n}$,

$$|A|\:=\sum_{j=1}^n\:(-1)^{i+j}a_{ij}|A_{ij}|$$

------------------------------------------------------------------

and for each $\mathbf{j}=1,2,\ldots,\mathbf{n}$,

$$|A|=\sum_{i=1}^n(-1)^{i+j}a_{ij}|A_{ij}|.$$

The first [second] formula for $|A|$ is called the expansion of $|\mathbf{A}|$ along row i [column $j]$

PROOF OF 3.6. We let $j$ be fixed and prove the second statement. By Theorem 3.3 and Definition 3.4 it suffices to show that the map $\phi:\mathsf{Mat}_nR\to R$ given by A = (ai)一≥ (-1)i+ia:l Azsl is an alternating $R$ -multilinear form such that $\phi(I_n)=\mathbf{1}_R$ .Let $X_1,\ldots,X_n$ be the rows of $A$ .If $X_{k}=X_{t}$ with $1\leq k<1\leq n$ ,then $\left|A_{ij}\right|=0$ for $i\neq k,t$ since it is the determinant of a matrix with two identical rows. Since $A_{kj}$ may be obtained from $A_{tj}$ by interchanging row t successively with rows $t-1,\ldots,k+1,|A_{kj}|=(-1)^{t-k-1}|A_{tj}|$ by Theorem 3.5. Thus $\phi(A)=(-1)^{k+i}|A_{kj}|$ $+(-1)^{\iota+j}|A_{\iota j}|=(-1)^{k+j+t-k-1}|A_{\iota j}|+(-1)^{\iota+j}|A_{\iota j}|=0$ .Hence $\phi$ is alternating. If forsome $k$ $X_k=rY_k+sW_k$ , let $B=(b_{ij})$ and $C=(c_{ij})$ be the matrices with rows. $X_1,\ldots,X_{n-1},Y_k,X_{k+1},\ldots,X_n$ , and $X_1,\ldots,X_{k-1},W_k,X_{k+1},\ldots,X_n$ respectively. To prove that $\phi$ is $R$ -multilinear we need only show that $\phi(A)=r\phi(B)+s\phi(C)$ . If $i=k$ , then $|A_{kj}|=|B_{kj}|=|C_{kj}|$ ,whence $a_{kj}|A_{kj}|=(rb_{kj}+sc_{kj})|A_{kj}|=rb_{kj}|B_{kj}|+$ $sc_{kj}|C_{kj}|$ $Ifi\neq k$ , then since each $|A_{ij}|$ is a multilinear function of the rows of $A_{ij}$ and $a_{ij}=b_{ij}=c_{ij}$ for $i\neq k$ , we have $a_{ij}|A_{ij}|=a_{ij}(r|B_{ij}|+s|C_{ij}|)=rb_{ij}|B_{ij}|+sc_{ij}|C_{ij}|$ It follows that $\phi(A)=r\phi(B)+s\phi(C)$ ; hence $\phi$ is $R$ -multilinear. Obviously $\phi(I_n)=$ $1_{R}$ . Therefore, $\phi$ is the determinant function. The first statement of the theorem follows readily through the use of transposes. 

Proposition 3.7. 1 $f\mathbf{A} = ( \mathbf{a} _{\mathrm{ij}})$ is an $n\times n$ matrix over a commutative ring R with identity and $\mathbf{A}^{\mathrm{a}}=(\mathbf{b}_{\mathrm{ij}})$ isthe $n\times n$ matrix with $\mathbf{b}_{\mathrm{ij}}=(-1)^{\mathrm{i+j}}|\mathbf{A}_{\mathrm{ji}}|$ ,then $\mathbf{AA}^{\mathbf{a}}=|\mathbf{A}|\mathbf{I}_{\mathbf{n}}$ $=\mathbf{A}^{\mathbf{a}}\mathbf{A}$ . Furthermore A is invertible in. $Mat_n\mathbb{R}$ if and only if $|\mathbf{A}|$ is a unit in R,in which case $\mathbf{A}^{-1}=|\mathbf{A}|^{-1}\mathbf{A}^{\mathbf{a}}$

The matrix $A^a$ is called the classical adjoint of $A$ . Notethat if $R$ is a field, then |A is a unit if and only if $|A|\neq0$

PROOF OF 3.7. The $(i,j)$ entry of $AA^a$ is Ci = ∑ (-1)i+kaxlAul. If $i=j$, then $c_{ii}=|A|$ by Proposition ij $i\neq j$ 3.6. If $i\neq j\left(\text{say }i<j\right)$ and $A$ has rows $X_1,\ldots,X_n$ ,let $B=(b_{ij})$ be the matrix with rows $X_1,\ldots,X_i,\ldots,X_{j-1},X_i,X_{j+1},\ldots,X_n$ .Then $b_{ik}=a_{ik}=b_{ik}$ and $|A_{ik}|=|B_{\eta k}|$ for all $k$ ; in particular, $|B|=0$ since the determinant is an alternating form. Hence
$$c_{ij}=\sum_{k=1}^n(-1)^{j+k}a_{ik}|A_{jk}|=\sum_{k=1}^n(-1)^{j+k}b_{jk}|B_{jk}|=|B|=0.$$

Therefore, $c_{ij}=\delta_{i,l}|A|$ (Kronecker delta) and $AA^{\bullet}=|A|I_{n}$ .In particular, the last statement holds with $A^t$ in place of $A:A^{\prime}(A^{\prime})^a=|A^{\prime}|I_n$ . Since $(A^a)^{\prime}=(A^t)^{\alpha}$ ,we have $|A|I_n=|A^{\prime}|I_n=A^{\prime}(A^{\prime})^a=A^{\prime}(A^a)^t=(A^aA)^t$ ，whence $A^\bullet A=(|A|I_n)^{\prime}=|A|I_n$ .Thus if $|A|$ is a unit in R, $|A|^{-1}A^a\varepsilon\text{Mat}_nR$ and clearly $(|A|^{-1}A^{*})A=I_{n}=A(|A|^{-1}A^{a})$ Hence $A$ is invertible with (necessarily unique) inverse $A^{-1}=|A|^{-1}A^{a}$ .Conversely if $A$ is invertible, then $|A|$ is a unit by Theorem 3.5.

------------------------------------------------------------------

Corollary 3.8. (Cramer's Rule) Let $\mathbf{A}=(\mathbf{a}_{\mathrm{ij}})$ be the matrix of coefficients of the system of n linear equations in n unknowns.

$$\begin{aligned}&\mathrm{a_{11}x_{1}+a_{12}x_{2}+\cdots+a_{1n}x_{n}=b_{1}}\\&\mathrm{a_{11}x_{1}+a_{12}x_{2}+\cdots+a_{nn}x_{n}=b_{n}}\\&\mathrm{a_{n1}x_{1}+a_{n2}x_{2}+\cdots+a_{nn}x_{n}=b_{n}}\end{aligned}$$

over a field K $.If|\mathbf{A}|\neq0$ , then the system has a unique solution which is given by.

$$\mathrm{x_j}\:=\:|\mathrm{A}|^{-1}\biggl(\sum_{i=1}^{n}\:(-1)^{i+j}\mathrm{b_i}|\mathrm{A_{ij}}|\biggr)\quad\mathrm{j}\:=\:1,2,\ldots,\mathrm{n}.$$

PROOF.Clearly thegiven systemhas a solutionif andonly if the matrix equa tion $AX=B$ has a solution, where $X$ and $B$ are the column vectors $X=(x_{1}\cdots x_{n})^{\prime}$, $B\:=\:(b_{1}\cdots b_{n})^{t}$ . Since $|A|\neq0,A$ is invertible by Proposition 3.7, whence $X=A^{-1}B$ is a solution. It is the unique solution since $AY=B$ implies $Y=A^{-1}B$ To obtain the formula for $x_{j}$ simply compute, using the equation

$$X=A^{-1}B=(|A|^{-1}A^{a})B=|A|^{-1}(A^{a}B).\quad\blacksquare $$

## EXERCISES

Note: Unless stated otherwise all matrices have entries in a commutative ring $R$ with identity.

1. If $r+r\neq0$ for all nonzero r e $R$ , then prove that an $n$ -linear form $B^n\to R$ is alternating if and only if it is skew-symmetric. What if char $R=2?$

2. (a) If $m>n$ , then every alternating $R$ -multilinear form on $(R^n)^m$ is zero. (b) If $m<n$ , then there is a nonzero alternating $R$ -multilinear form on $(R^n)^m$

3. Use Exercise 2 to prove directly that if there is an $R$ -module isomorphism $R^{m}\cong R^{n}$ , then $m=n$

4.If $A\in Mat_nR$ ,then $|A^{a}|=|A|^{n-1}$ and $(A^{a})^{a}=|A|^{n-2}A$

5.If $R$ is a field and $A,B\in Mat_nR$ are invertible then the matrix $A+rB$ is invertible for all but a finite number of r e $R$

6. Let $A$ be an $n\times n$ matrix over a feld. Without using Proposition 3.7 prove that $A$ is invertible if and only if $|A|\neq0$ . (Hinr: Theorems 2.6 and 3.5 (viii) and Proposition 2.12.]

7. Let $F$ bea free $R$ -module with basis $U=\{u_{1},\ldots,u_{n}\}.$If$\phi:F\to F$ $\phi:F\to F$ Φ:F→F is an $R$ -mod ule endomorphism with matrix $A$ relative to $U$ , then the determinant of the endo morphism $\phi$ is defined to be $|A|\varepsilon R$ and is denoted $|\phi|$ (a) $|\phi|$ is independent of the choice of $U$

(b) $|\phi|$ is the unique element of $R$ such that $f(\phi(b_1),\phi(b_2),\ldots,\phi(b_n))$

$=\left|\phi\right|f(b_1,\ldots,b_n)$ for every alternating $R$ -multilinear form on $F^n$ and all $b_i\varepsilon F$

8. Suppose that $(b_1,\ldots,b_n)$ is a solution of the system of homogeneous linear equations

1

------------------------------------------------------------------

$$a_{11}x_1+\cdots+a_{1n}x_n\:=\:0$$

$$a_{n1}x_1+\cdots+a_{nn}x_n=0$$

and that $A=(a_{ij})$ is the $n\times n$ matrix of coefficients. Then. $|A|b_i=0$ for every $i$ [Hint: If $B_{i}$ is the $n\times n$ diagonal matrix with diagonal entries. $\mathbf{1}_{R},\ldots,\mathbf{1}_{R},b_{i}$, 1R,bi $1_{R},b_i$, $\mathbf{1}_{R},\ldots,\mathbf{1}_{R}$ , then $|AB_{i}|=|A|b_{i}$ . To show that $|AB_i|=0$ add $b_i$ times column $j$ of $AB_i$ to column $i$ for every $j\neq i$ . The resulting matrix has determinant $|AB_i|$ and $(k,i)$ entry $a_{k1}b_1+a_{k2}b_2+\cdots+a_{kn}b_n=0$ for $k=1,2,\ldots,n.]$

## 4. DECOMPOSITION OF A SINGLE LINEAR TRANSFORMATION AND SIMILARITY

The structure of afinite dimensional vector space $E$ over a field $K$ relative to a linear transformation $E\to E$ is investigated. The linear transformation induces a decomposition of $E$ as a direct sum of certain subspaces and associates with each such decomposition of $E$ a set of polynomial invariants in $K[x]$ (Theorem 4.2). These sets of polynomial invariants enable one to choose various bases of $E$ relative to each of which the matrix of the given linear transformation is of a certain type (Theorem 4.6). This leads to several different sets of canonical forms for the relation of similar. ity in $Mat_nK$ (Corollary 4.7). Note.The results of this section depend heavily on the structure theorems for

finitely generated modules over a principal ideal domain (SectionIV.6). Let $K$ be a field and $\phi:E\to E$ a linear transformation of an $n$ -dimensional

$K$ -vector space $E$ . We first recall some facts about the structure of $\mathrm{Hom}_{K}(E,E)$ and $Mat_nK$ . $\mathrm{Hom}_K(E,E)$ is not only a ring with identity (Exercise IV.1.7),but also a vector space over $K$ with $(k\psi)(u)=k\psi(u)\left(k\in\underline{K,}u\in E,\psi\in\mathrm{Hom}_{K}(E,E)\right)$ ; see the Remark after Theorem IV.4.8). Therefore if $f=\sum k_{i}x^{i}$ is a polynomial in $K[x]$, then $f(\phi)=\sum k_i\phi^i$ is a well-defined element of $\mathrm{Hom}_{\kappa}(E,E)$ (where $\phi^{0}=1_{E}$ as usual). Similarly the ring. $Mat_nK$ is also a vector space over $K$ . If $A\in Mat_nK$ ，then $f(A)=\sum k_iA^i$ is a well-defined $n\times n$ matrix over $K$ (with $A^{0}=I_{n}$

Theorem 4.1. Let E be an n-dimensional vector space over a field K, $\phi:\mathbf{E}\to\mathbf{E}$ a linear trans formation and A an. n×n matrix ouer K

(i) There exists a unique monic polynomial of positive degree, $\mathbf{q}_{\phi}\in\mathbf{K}[\mathbf{x}]$ , such thai $\mathbf{q}_{\phi}(\phi)=0$ and $q_{\phi}|$ f for allfeK[x]suchthat $\mathbf{f}(\phi)=0$ (i) There exists a unique monic polynomial ofpositice degree, $q_{A}\in K[x]$ ,，such

that $\mathbf{q}_{\mathbf{A}}(\mathbf{A})=0$ and qA|f for allfeK[x]suchthat $\mathbf{f}(\mathbf{A})=0$ (ii) If A is the matrix of $\dot{\phi}$ relative to some basis of E, then. $q_{A}=q_{\phi}$

PROOF. (i) By Theorem II1.5.5 there is a unique (nonzero) ring homomorphism $\zeta=\zeta_{\phi}:K[x]\to$Hom$_K(E,E)$ such that $x|\mapsto\phi$ and $k|\mapsto k1_E$ for all $k\varepsilon K$ . Consequently, if $f\varepsilon K[x]$, then $\zeta(f)=f(\phi).\zeta$ is easily seen to be a linear transformation of $K$ -vector spaces. Since $\dim_KE$ $ı_{K}E$ RE is finite, $\mathrm{Hom}_{K}(E,E)$ is fnite dimensional over $K$ by Theorems IV.2.1, IV. 2.4, IV.4.7, and IV.4.9. Thus $Im\zeta$ $\zeta$ 5 is necessarily finite dimen-

------------------------------------------------------------------

sional over $K$ .Since $K[x]$ is infnite dimensional over $K$ , we must have Ker $\zeta\neq0$ by Corollary IV.2.14. Since $K[x]$ is a principal ideal domain whose units are precisely the nonzero elementsof $K$ (Corollary III.6.4). Ker. $\zeta=(q)$ for some monic $q\in K[x]$ Since 5 is not the zero map, $(q)\neq K[x]$, whence deg $q\geq1$ . If Ker $\zeta=(q_1)$ with $q_1\in K[x]$ monic. then $q\mid q_1$ and $q_1\mid q$ by Theorem II1.3.2, whence $q=q_{1}$ since both are monic. Therefore $q_{\phi}=q$ has the stated properties. (ii) The proof is the same as (i) with $A$ in place of $\phi$ and $Mat_nK$ in place of

$\mathrm{Hom}_{K}(E,E)$ $q_{A}\in K[x]$ is the unique monic polynomial such that $(q_{A})=$Ker $\zeta_{A}$ 5.a $\zeta_{1}$ where $\zeta_A:K[x]\to\mathrm{Mat}_nK$ is the unique ring homomorphism given by $f$卜$f(A)$ (ii) Let $A$ be the matrix of $\phi$ relative to a basis $U$ of $E$ and let $\theta:\operatorname{Hom}_K(E,E)\cong$

$Mat_nR$ be the isomorphism of Theorem 1.2, so that $\theta(\phi)=A$ .Then the diagram

![](https://storage.simpletex.cn/view/fYVpvDfZlB1GX37AvQtIndk5C1Gk6Sem3)

is commutative by Theorem I1.5.5 since $\theta\zeta_{\phi}(x)=\theta(\phi)=A=\zeta_{A}(x)$ and $\theta\zeta_\phi(k)$ $=\theta(k1_{E})=kI_{n}=\zeta_{A}(k)$ for all $k\varepsilon K.$ .Since $\theta$ is an isomorphism, $(q_{\phi})=$Ker $\zeta_\phi$ $\theta\zeta_{\phi}=Ker$ 0 = Ker =Ker $\theta\zeta_{\phi}=$Ker $\zeta_A=(q_{\Lambda})$ SA = (qn) $\zeta_{A}=(q_{A})$ . Therefore, $q_{\phi}\mid q_{A}$ and $q_A\mid q_\phi$, whence $q_{\phi}=q_{A}$ since both are monic.

If $K,E$ , and $\phi$ are as in Theorem 4.1, then the polynomial $q_{\phi}$ [resp. $q_A]$ is called the minimal polynomial of the linear transformation $\phi$ [matrix A]. In general, $q_{\phi}$ is nor irreducible. Corollary 1.7 and Theorem 4.1(ii) immediately imply that similar matrices have the same minimal polynomial

Let $K,E$ ,and $\phi$ be as above. Then $\phi$ induces a (left) $K[x]$ -module structure on $E$ as follows. If $f\in K[x]$ and $u\in E$ ，then $f(\phi)\varepsilon\operatorname{Hom}_{\dot{\kappa}}(E,E)$ and $fu$ is defined by $fu=f(\phi)(u)$ .A $K$ -subspace $F$ of $E$ is said to be invariant under $\phi$ (or $\Phi$ -invariant) if $\phi(F)\subset F$ Clearly $F$ is a $\phi$ -invariant $K$ -subspace if andonly if $F$ is a $K[x]$ -submodule of $E$ . In particular, for any $v\in E$ the subspace $E(\phi,v)$ spanned by the set $|\phi^i(v)|i\geq0\}$ is $\phi$ -invariant. It is easy to see that $E(\phi,v)$ is precisely the cyclic $K[x]$ -submodule $K[x]v$ generated by $v.\:E(\phi,v)$ is said to be a $\Phi$ -cyclic (sub)space.

Theorem 4.2. Let $\phi:\mathbf{E}\to\mathbf{E}$ be a linear transformation of ann-dimensional cector space E over a field K.

(i) There exist monic polynomials of positive degree $q_1,q_2,\ldots,q_t\in K[x]$ and $\phi$ cyclic subspaces $E_1,\ldots,E_t$ ofE such that $\mathbf{E}=\mathbf{E}_{1}\oplus\mathbf{E}_{2}\oplus\cdots\oplus\mathbf{E}_{t}$ and $q_1\mid q_2\mid\cdots\mid q_t$ . Furthermore $q_{\mathrm{i}}$ is the minimal polynomial of $\phi\mid E_{\mathrm{i}}:E_{\mathrm{i}}\rightarrow E_{\mathrm{i}}$ .The sequence $(q_{1},\ldots,q_{t})$ is uniquely determined by E and $\phi$ and $q_t$ is the minimal polynomia $of\boldsymbol{\phi}$ (ii) There exist monic irreducible polynomials $\mathbf{p}_{1},\ldots,\mathbf{p}_{\mathrm{в}}\varepsilon\mathbf{K}[\mathbf{x}]$ and $\phi$ cyclic sub-

8 $\mathbf{E}=\sum_{i=1}^{s}\sum_{j=1}^{k_{\mathrm{q}}}\mathbf{E}_{\mathrm{i}}$ spaces Eia,E2! $E_{1k_1},E_{21}$ $\mathrm{E}_{11},\ldots,\mathrm{E}_{1k_{1}},\mathrm{E}_{21},\ldots,\mathrm{E}_{2k_{2}},\mathrm{E}_{31},\ldots,\mathrm{E}_{8k_{8}}\:d$ Erx,Ea $E_{2\mathrm{k}_2,}E_{31}.$ Eecke $E_{\mathrm{ek}_{\mathrm{B}}}$ f E such that =Ein and for each i there is a nonincreasing sequence ofintegers $\mathbf{m}_{\mathrm{il}}\geq\mathbf{m}_{\mathrm{i}2}\geq\cdots\geq\mathbf{m}_{\mathrm{ik}\mathrm{i}}\geq0$ such that $p_{i}^{\mathrm{mij}}$ is the minimal polynomial of $\phi\mid E_{ij}:E_{ij}\rightarrow E_{ij}$ . The family of poly-

------------------------------------------------------------------

nomials $\{p_{\mathrm{i}}^{\mathrm{m}\mathrm{i}\mathrm{j}}\mid1\leq\mathrm{i}\leq\mathrm{s;}1\leq\mathrm{j}\leq\mathrm{k_{i}}\}$ is uniquely determined by $E$ and $\phi$ and $\mathbf{p}_{1}^{\mathrm{m}_{11}}\mathbf{p}_{2}^{\mathrm{m}_{21}}\cdots\mathbf{p}_{s}^{\mathrm{m}_{\mathrm{g}1}}$ is theminimal polynomial of $\dot{\varphi}$

The polynomials $q_1,\ldots,q_t$ in part (i) of the theorem are called the invariant factors of the linear transformation $\phi$ . The prime power polynomials $p_i^{m_ij}$ in part (i) are called the elementary divisors of $\phi$

SKETCH OF PROOF OF 4.2. (i) As indicated above $E$ is a leftmodule over the principal ideal domain $K[x]$ with $fu=f(\phi)(u)\left(f\varepsilon\:K[x],u\in E\right)$ .Since $E$ is finite di mensional over $K$ and $K\subset K[x]$ $E$ is necessarily a finitely generated nonzerc $K[x]$ -module. If $q_{\phi}$ is the minimal polynomial of $\phi$ ，then $q_\phi\neq0$ and $q_{\phi}E=0$ whence $E$ is a torsion $K[x]$ -module. By Theorem IV.6.12(i) $E$ is the internal direct sum $E=E_{1}\oplus\cdots\oplus E_{l}$, where each $E_i$ is a nonzero cyclic $K[x]$ -module of order $q_{i}\left(q_{i}\in K[x]\right)$ and $q_1\mid q_2\mid\cdots\mid q_t$ .By the remarks preceding the theorem each $E_i$ is a $\phi$ -cyclic subspace. Since $E_i$ has order $q_i$ ,there is a $K[x]$ -module isomorphism $E_i\cong K[x]/(q_i)$ by Theorem IV.6.4 and the example following it. Since $E_i\neq0$ and every nonzero ideal in $K[x]$ has a unique monic generator (Theorem I11.3.2 and CorollaryI11.6.4),we may assume that each $q_i$ is monic of positive degree. The uniqueness statement of Theorem IV.6.12(i) and the fact that $q_1\mid q_2\mid\cdots\mid q_t$ imply that $q_1,\ldots,q_t$ are uniquely determined by the $K[x]$ -module $E$ (that is, by $E$ and $\phi$ ).Use the $K[x]$ -module structure of $E_i$ and the fact that $E_i$ is cyclic of order $q_{i}$ to verify that the minimal polynomial of $\phi\mid E_i$ is $q_i$ . Finally $q_tE=q_t(\phi)E_1\oplus\cdots\oplus q_l(\phi)E_t=0$ ，whence $(q_t)\subset(q_\phi)$ . Since $q_{\phi}E=0$ ，we have $q_{\phi}E_{\iota}=0$ ,whence $(q_{\phi})\subset(q_{l})$ . Consequently, $q_{t}=q_{\phi}$ since both are monic and $(q_t)=(q_\phi)$ .The second part of the theorem is proved similarly by decomposing $E$ as a direct sum of cyclic $K[x]$ -submodules of prime power orders (Theorem IV.6.12(ii).

REMARK. If $\phi=0$ , then the proof of Theorem 4.2 shows that the minimal polynomial of $\phi$ is $x$ and its invariant factors [resp. elementary divisors] are $q_1=x$ $q_{2}=x,\ldots,q_{n}=x$ (Exercise 2)

The proof of Theorem 4.2 shows that the invariant factors and elementary divisors of a linear transformation $\phi:E\to E$ are simply the invariant factors and elementary divisors of the $K[x]$ -module $E$ . Consequently, one can obtain the elementary divisors from the invariant factors and vice versa just as in the proof of Theorem IV.6.12 (see also pp. 80-81). A technique for calculating the invariant factors of a specific linear transformation is discussed in Proposition 4.9 below..

EXAMPLE. Let $K=\mathbf{Q}$ and $\dim_KE=15$ and suppose the invariant factors of $\phi$ are $q_{1}\:=\:x^{4}-\:x^{2}-2$ ， $q_{2}\:=\:x^{5}-\:x^{3}-\:2x$ and $q_{3}=x^{6}-x^{4}-2x^{2}$ ：Then $q_{1}=(x^{2}-2)(x^{2}+1)$ $q_2=xq_1$ and $q_3=xq_2$ , whence the elementary divisors of $\phi$ are: $x^2-2,x^2+1,x,x^2-2,x^2+1,x^2,x^2-2,x^2+1.$ See theproof ofTheorem IV.6.12 and also p. 80. Conversely if the elementary divisors of a linear transformation $\psi$ are $x+1,x-1,x-2,x-3,(x-2)^{2},x^{2}+1,x^{2}+1,x^{2}+1$ ,and $(x-1)^3$ then the invariant factors are $q_{1}=(x-1)(x^{2}+1)$ ， $q_{2}=(x-1)(x-2)(x^{2}+1)$ and $q_{3}=(x-3)(x-2)^{2}(x^{2}+1)(x-1)^{3}$

In view of Theorem 4.2 the next step in our analysis should be aninvestigation of $\phi$ -cyclic spaces.

------------------------------------------------------------------

1

Theorem 4.3. Let $\phi:\mathbf{E}\to\mathbf{E}$ be a linear irans formation of a finite dimensional vector spaceE overa fieldK.ThenE is a $\phi$ cyclic space and $\phi$ has minimal polynomial $\mathbf{q}=\mathbf{x}^{r}+\mathbf{a}_{r-1}\mathbf{x}^{r-1}+\cdots+\mathbf{a}_{0}\varepsilon\mathbf{K}[\mathbf{x}]$ if andonly if $dim_{\mathrm{K}}\mathbf{E}=\mathbf{r}$ and E has an ordered basis V relative to which the matrix of $\phi$ is

$$\begin{pmatrix}0&1_\mathrm{K}&0&0&0&\cdots&0&0\\0&0&1_\mathrm{K}&0&0&\cdots&0&0\\0&0&0&1_\mathrm{K}&0&\cdots&0&0\\.\\.\\0&0&0&0&0&\cdots&0&1_\mathrm{K}\\-a_0&-a_1&-a_2&-a_3&-a_4&\cdots&-a_{r-2}&-a_{r-1}\end{pmatrix}.$$

In this case $\mathbf{V}=\{v,\phi(v),\phi^2(v),\ldots,\phi^{r-1}(v)\}$ for some v e E.

The matrix $A$ is called the companion matrix of themonicpolynomial $q\in K[x]$ Note that if $q=x+a_{0}$, then $A=(-a_{0})$

PROOF OF 4.3. (= If $E$ is $\phi$ -cyclic, then the remarks preceding Theorem 4.2 show that for some $v\in E,E$ E $E$ is the cyclic $K[x]$ -module $K[x]v.$ ，with the $K[x]$ -module structure induced by $\phi$ .If $k_0v+k_1\phi(v)+\cdots+k_{r-1}\phi^{r-1}(v)=0$ $(k_{i}\in K)$, then $f=k_{0}+k_{1}x+\cdots+k_{r-1}x^{r-1}$ is a polynomial such that $f(\phi)(v)=0$ ，whence $f(\phi)=0$ on $E=K[x]v$ .Since deg $f\leq r-1<\deg q$ and $q\mid f$ by Theorem 4.1(i), we must have $k_{i}=0$ for all $i$ . Therefore, $\{v,\phi(v),\ldots,\phi^{r-1}(v)\}$ is linearly inde- pendent. If $f\boldsymbol{v}=f(\boldsymbol{\phi})(\boldsymbol{v})(f\varepsilon\boldsymbol{K}[x])$ is an arbitrary element of $E=K[x]v$ , then by the division algorithm $f=qh+s$ where s = > kixa has degree 1 with $1<\deg q$ Consequently, $f(\phi)=q(\phi)h(\phi)+s(\phi)=0+s(\phi)=s(\phi)$ and $fv=f(\phi)(v)=s(\phi)(v)$ $=k_0+k_1\phi(v)$ +··+ $k_t\phi^{\prime}(v)$ with $1\leq s-1$ . Therefore,

$$\{v,\phi(v),\ldots,\phi^{r-1}(v)\}$$

spans $E$ and hence is a basis. Since $q(\phi)=0$ we have $\phi(\phi^{-1}(v))=\phi^{r}(v)=-a_{0}v$ $-a_{1}\phi(v)-\cdots-a_{r-1}\phi^{r-1}(v)$ . It follows immediately that the matrix of $\phi$ relative to $\{v,\phi(v),\ldots,\phi^{r-1}(v)\}$ is the companion matrix of $q$ $(\Leftarrow)$ If $A$ is the matrix of $\phi$ relative to the basis $\{v=v_{1},v_{2},\ldots,v_{\mathrm{r}}\}$ ,then a

simple computation shows that $v_{i}=\phi^{i-1}(v)$ for $i=2,\ldots,r$ and that $\phi^{r}(v)=\phi(v_{\mathrm{r}})$ $=-a_{0}v-a_{1}\phi(v)-\cdots-a_{r-1}\phi^{r-1}(v)$ . Consequently, $E$ is the $\phi$ -cyclic space generated by $v$ and $E=K[x]v$ .Since $q(\phi)(v)=0,q(\phi)=0$ on $E$ . Since

$$\{v,\phi(v),\ldots,\phi^{r-1}(v)\}$$

is linearly independent there can be no nonzero $f\varepsilon K[x]$ of degree less than r such that $f(\phi)=0$ . A routine division algorithm argument now implies that $q$ is the minimal polynomial of $\phi$ .■

2If $E$ is considered asaright $K$ -vector space and matrices of maps are constructed accord ingly (as on p.333) then the companion matrix of $q$ must be defined to be $A^t$ in order to make the theorem true.

------------------------------------------------------------------

Corollary 4.4. $Ler\psi:\mathcal{E}\to\mathcal{E}$ be a linear transformation ofa finite dimensional vector. space $E$ over a field K.Then E is a $\psi$ -cyclic space and $\psi$ has minimal polynomial. $\mathbf{q}=(\mathbf{x}-\mathbf{b})^{\mathbf{r}}\left(\mathbf{b}\varepsilon\mathbf{K}\right)$ if and only ifdim $\mathbf{I}_{\mathrm{K}}\mathbf{E}=\mathbf{r}$ and E has an ordered basis relative to which the matrix of. $\psi$ is

$$\mathbf{B}=\begin{pmatrix}\mathbf{b}&\mathbf{1}_\mathbf{K}&\mathbf{0}&\mathbf{0}&\cdots&\mathbf{0}&\mathbf{0}\\\mathbf{0}&\mathbf{b}&\mathbf{1}_\mathbf{K}&\mathbf{0}&\cdots&\mathbf{0}&\mathbf{0}\\\mathbf{0}&\mathbf{0}&\mathbf{b}&\mathbf{1}_\mathbf{K}&\cdots&\mathbf{0}&\mathbf{0}\\\cdot\\\cdot\\\cdot\\0&0&0&0&\cdots&\mathbf{b}&\mathbf{1}_\mathbf{K}\\0&0&0&0&\cdots&0&\mathbf{b}\end{pmatrix}.$$

The $r\times r$ matrix $B$ is called the elementary Jordan matrix associated with $(x-b)^{r}\in K[x].$ Note that for r = 1 $r=1$ $r=1,B=(b)$

SKETCH OF PROOF OF 4.4. Let $\phi\:=\:\psi\:-\:b\mathbf{l}_E$ E $\mathrm{Hom}_K(E,E)$ . Then $q=(x-b)^{r}$ is the minimal polynomial of $\psi$ if and only if $x^r$ is the minimal polynomial of $\phi$ (for example, $\phi^r=(\psi-b1_E)^r=q(\psi)=0$ . $E$ has two $K[x]$ -module structures induced by $\phi$ and $\psi$ respectively. For every $f\varepsilon K[x]$ and $v\in E,f(x)v$ in the $\phi$ -structure is the same element as $f(x-b)v$ in the $\psi$ -structure. Therefore,. $E$ is $\phi$ -cyclic if and only if $E$ is $\psi$ -cyclic. Since $\psi=\phi+b1_{E}$ , Theorem 1.2 shows that the matrix of $\phi$ relative to a given (ordered) basis of $E$ is the companion matrix $A$ of $x^r$ if and only if the matrix of $\psi$ relative to the same basis is the elementary Jordan matrix $B=A+bI_n$ associated with $(x-b)^r$ . To complete the proof simply apply Theorem 4.3 to $\phi$ and translate the result into statements about $\psi$ ,using the facts just developed.

In order to use the preceding results to obtain a set of canonical forms for the relation of similarity on $Mat_nK$ weneed

Lemma 4.5. Let $\phi:\mathcal{E}\to\mathcal{E}$ be a linear transformation of an n-dimensional vector space E over a fieldK.For each $\mathbf{i}=1,\ldots,\mathbf{t}$ let $M_i$ be an $n_i\times n_i$ matrix ocer $K$ ,with $\mathbf{n}_{1}+\mathbf{n}_{2}+\cdots+\mathbf{n}_{\mathrm{t}}=\mathbf{n}$ . Then $\mathbf{E}=\mathbf{E}_{\mathrm{I}}\oplus\mathbf{E}_{\mathrm{2}}\oplus\cdots\oplus\mathbf{E}_{\mathrm{t}}$ , where each $E_{\mathrm{i}}$ is a $\phi$ -invuriant subspace of E and for each i, $M_i$ is the matrix of $\phi|E_i$ relative to some orderedbasis of $\mathbf{E}_{\mathrm{i}}$ if and only if the matrix of $\phi$ relative to some ordered basis. ofEis

$$\mathbf{M}=\begin{pmatrix}\mathbf{M}_1&&&&0&\\&\mathbf{M}_2&&&0&\\&&&\cdot&&\\&&&&\cdot&\\&&&&&\mathbf{M}_t\end{pmatrix}$$

where the main diagonal of each. $M_i$ lies on the main diagonal of M..

------------------------------------------------------------------

1

A matrix of the form $M$ as in Lemma 4.5 is said to be the direct sum of the ma trices $M_1$ $M_1$ $M_1,\ldots,M_t$ Mt $M_t$ (in this order).

SKETCH OF PROOF OF 4.5. $(\Rightarrow)$ For each $i$ let $V_{\iota}$ be an ordered basis of $E_{i}$ such that the matrix of $\phi\mid E_i$ relative to $V_{i}$ is $M_i$ . Since $E=E_{\mathrm{l}}\oplus\cdots\oplus E_{\mathrm{l}}$ it t follows easily that $V=\bigcup_{i=1}^{t}V_{i}$ is a basis of $E$ . Verify that $M$ is the matri of $\phi$ relative to $V$ (where $V$ is ordered in the obvious way). $(\leftarrow)$ Conversely suppose $U=\{u_{1},\ldots,u_{n}\}$ is a basis of $E$ and $M$ the matrix of $\phi$ relative to $U$ . Let $E_1$ be the subspace of $E$ with basis $\{u_1,\ldots,u_{n_1}\}$ and for $i>1$ let $E_i$ be the subspace of $E$ with basis $\left\{u_{r+1},\ldots,u_{r+ni}\right\}$ where $r=n_{1}+n_{2}+\cdots+n_{i-1}$ . Then $E=E_1\oplus E_2\oplus\cdots\oplus E_l$ each $E_i$ is $\phi$ -invariant and $M_i$ is the matrix of $\phi|E_i$ relative to $\{u_{r+1},\ldots,u_{r+n_i}\}$

Theorem 4.6. Let $\phi:\mathcal{E}\to\mathcal{E}$ be a linear transformation of an n-dimensional vector spaceE over afieldK

(i)E has a basis relative towhich the matrix of $\dot{\phi}$ is the direct sum of the companion matrices ofthe incariant factors qi, .:: , $q_t\in K[x]$ of $\phi$ (i)E has a basis relative towhichthe matrix of $\dot{\phi}$ is the direct sum of the com-

panion matrices o f the elementary divisors $p_{l}^{m_{ll}}$ ...·. $\mathbf{p}_{\mathrm{s}}^{\mathrm{msk}_{\mathrm{s}}}\varepsilon\mathbf{K}[\mathbf{x}]\:of\phi$ (iii) If the minimal polynomial q of factors as $\mathbf{q}=(x-b_{1})^{r_{1}}(x-b_{2})^{r_{2}}\cdots(x-b_{d})^{r_{d}}$

$(\mathbf{b}_i\varepsilon K)$ , which is always the case if K is algebraically closed, then every elementary divisor of $\phi$ is of theform $(\mathbf{x}-b_{i})^{\mathrm{j}}\left(\mathbf{j}\leq\mathbf{r}_{i}\right)$ and E has a basis relative to which the. matrix of\$ is the direct sum of the elementary Jordan matrices associated with the ele. mentary divisors of $\dot{\phi}$

The proof, which is an immediate consequence of results 4.2-4.5 (and unique factorization in $K[x]$ for (ii), is left to the reader. The next corollary immediately yields two (or three if $K$ is algebraically closed) sets of canonical forms for the rela tion of similarity on $Mat_nK$

Corollary 4.7. Let A be an $n\times n$ matrix over a field K

(i) A is similar to a matrix D such that. D is the direct sum of the companior. matrices ofa unique family of polynomials $q_1$ ,...,q.E $K[x]$ such that $q_{1}\mid q_{2}\mid\cdots\mid q_{t}$ The matrix D is uniquely determined..

(ii) A is similar to a matrix M such that M is the direct sum of the companion matrices ofa unique family of prine power polynomials $p_1^{m_{11}}$ ..··. $\mathbf{p}_{\mathrm{в}}^{\mathrm{m}_{\mathrm{B}\mathrm{k}\mathrm{в}}}\varepsilon\:\mathbf{K}[\mathbf{x}]$ where each p; is prime (irreducible) in $K[x]$ .M is uniquely determined except for the order of the companion matrices of the $p_{i}^{\mathrm{mij}}$ along is main diagonal. (ii) If K is algebraically closed,then A is similar to a matrix Jsuch that J is a direct

sum of the elementary Jordan mutrices associated with a unique family of polynomials of the form $(\mathbf{x}-\mathbf{b})^{m}$ (b e K). J is uniquely determined except for the order of the elementary Jordan matrices along its main diagonal

The proof is given below. The matrix $D$ in part (i), is said to be in rational canoni cal form or to be the rational canonical form of the matrix A. Similarly, the matrix $M$

------------------------------------------------------------------

in part (i) is said to be in primary rational canonical form and the matrix $J$ in (ii) is said to be in Jordan canonical form.? The word “rational' refers to the fact that the similarity of matrices occurs in the givenfeld $K$ and not in an extension field of $K$ (see Exercise 7). The uniquely determined polynomials $q_{\mathrm{I}},\ldots,q_{\mathrm{t}}$ in part (i) are called the invariant factors of the matrix $A$ . Similarly, the unique prime power polynomials $D_i^{m_i,}$ in part (ii) are called the elementary divisors of the matrix $A$

SKETCH OF PROOF OF 4.7. (ii)Let $\phi:K^n\to K^n$ be the linear transformation with matrix $A$ relative to the standard basis (Theorem 1.2). Corollary 1.7 and Theorem 4.6 show that $A$ is similar to the matrix $D$ that is the direct sum in some order of the companion matrices of the elementary divisors $D_{i}^{m_{1}j}$ of $\phi$ .If $A$ is also similar to $D_{\mathrm{l}}.$ where $D_1$ is the direct sum of the companion matrices of a family of prime power polynomials $f_{1},\ldots,f_{b\in K}[x]$ then $D_{1}$ is the matrix of $\phi$ relative to some basis of $Kn$ (Corollary 1.7). By Theorem 4.3 and Lemma $4.5\:K^{n}=E_{1}\oplus E_{2}$ $\oplus\cdots\oplus E_{b}$ , where each $E_i$ is a $\phi$ -cyclic subspace and $f_{i}$ is the minimal polynomial of $\phi\mid E_i$ . The uniqueness statement of Theorem 4.2 implies that the polynomials $f_{i}$ are precisely the elementary divisors $p_i^{n_1,}$ of $\phi$ , whence $D$ differs from $D_{\mathbf{l}}$ only in the order of the companion matrices of the $p_{i}^{m_{1}j}$ along the main diagonal. The proof of (i) and (ii) is similar, except that in (i) a stronger uniqueness statement is possible since the invariant factors (unlike the elementary divisors) may be uniquely ordered by divisibility.

Corollary 4.8. Let $\phi:\mathbf{E}\to\mathbf{E}$ be a linear trunsformation of an n-dimensional vector space E over a field K.

(i) $If\phi$ Φ $\phi$ has matrix A e $Mat_nK$ relative to some basis,then the invariant factors [resp. elementary divisors] of $\phi$ are the invariant factors [elementary divisors] of A (ii) Two matrices in $Mat_nK$ are similar if and only if they have the same invariani factors [resp. elementary divisors]..

### PROOF. Exercise.

REMARK. If $k$ is an element of a field $K$ , then the matrix $kI_n$ is a direct sum of the $1\times1$ companion matrices of the irreducible polynomials $x-k,\ldots,x-k$ Therefore, $x-k,\ldots,x-k$ are the elementary divisors of $kI_n$ by Corollary 4.7. Consequently, if. $k_1\neq k_2$ ,then $k_1I_n$ and $k_2I_n$ are not similar by Corollary 4.8.Thus if $K$ is infinite there are infinitely many distinct equivalence classes under similarity in $Mat_nK$ . On the other hand, there are only $n+1$ distinct equivalence classes undere equivalence in $Mat_nK$ nK $_{n}K$ by Theorem 2.6.

EXAMPLE. Let $E$ be a finite dimensional real vector space and $\phi:E\to E$ a linear transformation with invariant factors. $q_{1}=x^{4}-4x^{3}+5x^{2}-4x+4=$ $(x-2)^{2}(x^{2}+1)\varepsilon\mathbf{R}[x]$ and $q_{2}=x^{7}+6x^{6}+14x^{5}-20x^{4}+25x^{3}-22x^{2}+12x-$ $8=(x-2)^{3}(x^{2}+1)^{2}\varepsilon\mathbf{R}[x]$ . By Theorem 4.6(i) $\dim_RE=11$ and the minimal polynomial of $\phi$ is $q_2$ . The remarks after Theorem 4.2 show that the elementary divisors

------------------------------------------------------------------

of $\phi$ in $R[x]$ are $(x-2)^{3}=x^{3}-6x^{2}+12x-8$ 、 $(x-2)^{2}=x^{2}-4x+4$ $(x^{2}+1)^{2}=x^{4}+2x^{2}+1$ ,and $x^2+1$ .By Theorem $4.6E$ has two bases relative tc which the respective matrices of. $\phi$ are

![](https://storage.simpletex.cn/view/fx2s2OInIFGAd3aFpxUm2VlnGbZYKgbWP)
The matrix $D$ is in rational canonical form and $M$ is in primary rational canonical

form. If $E$ is actually a complex vector space and $\psi:E\to E$ is a linear transformatior with the same invariant factors $q_{1}=(x-2)^{2}(x^{2}+1)\varepsilon\mathbf{C}[x]$and$q_2=(x-2)^{3}(x^{2}+1)^{2}$ q2 = (x - 2)(x² + 1)² $q_{2}=(x-2)^{3}(x^{2}+1)^{2}$ $\varepsilon C[x]$ ，then since $x^{2}+1=(x+i)(x-i)$ in $\mathbf{C}[x]$, the elementary divisors of $\psi$ in $\mathbf{C}[x]$ are $(x-2)^{3}$ ， $(x-2)^{2}$ ， (x + i)2 $(x+i)^2$ $(x+i)$ $(x+i)^{2},(x+i),(x-i)^{2}$ (x + i) (x - i)2 $(x-i)^2$ ，and $(x-i)$ . Therefore, relative to some basis of $E,\psi$ $\psi$ $\psi$ has the following matrix in Jordan canonical form

![](https://storage.simpletex.cn/view/fPg5yTTTpYbXVW8huMo29RA9OVygCq47C)

REMARK. The invariant factors in. $K[x]$ of a matrix A $\varepsilon Mat_nK$ nK $_nK$ are the same as the invariant factors of $A$ in $F[x].$ where $F$ is an extensionfieldof $K$ (Exercise 6). As the previous example illustrates, however, the elementary divisors of $A$ over $K$ may differ from the elementary divisors of $A$ over $F$

------------------------------------------------------------------

We close this section by presenting a method of calculating the invariant factors. of a given matrix $A$ ,and hence byCorollary 4.8of any linear transformation that has matrix $A$ relative to some basis. This method is a consequence of

Proposition 4.9. Let A be an $n\times n$ matrix over a feld K. Then the matrix of polynomials $\mathbf{x}\mathbf{I}_{\mathrm{n}}-\mathbf{A}$ E $Mat_nK[x]$ is equivalent (over $K[x])$ 1o a diagonal matrix D with nonzero diagonal entries $\mathbf{f}_{1},\ldots,\mathbf{f}_{n}\in\mathbf{K}[\mathbf{x}]$ such that each f; is monic andf $\mid\mathbf{f}_2\mid\cdots\mid\mathbf{f}_n$ Those polynomials f; which are not constants are the invariant factors of A..

REMARK. If $K$ is a feld, then $K[x]$ is a Euclidean domain (Corollary IIl.6.4) Consequently, the following proof together with the Remarks after Proposition 2.11 show that the matrix $D$ may be obtained from $xI_{n}-A$ by a finite sequence of elementary row and column operations. Thus Proposition 4.9 actually provides a constructive methodfor finding invariant factors. An example is given after the proof.

SKETCH OF PROOF OF 4.9. Let $\phi:K^n\to K^n$ be the $K$ -linear transformation with matrix $A=(a_{i,j})$ relative to the standard basis $\{\varepsilon_{i}\}$ of $K^n$ . As usual $K^n$ is a $K[x]$ -module with structure induced by $\phi$ . Let $F$ be a free $K[x]$ -module with basis. $U=\{u_{1},\ldots,u_{n}\}$ and let $\pi:F\to K^n$ be the unique $K[x]$ -module homomorphism. such that $\pi(u_{i})=\varepsilon_{i}$ for $i=1,2,\ldots,n$ (Theorem IV.2.1). Let $\psi:F\to F$ be the unique $K[x]$ module homomorphism such that y(u) = xu: - aμ, Then the matrix of $\psi$ relative to the basis $U$ is $xI_n-A$

We claim that the sequence of $K[x]$ -modules $F\overset{\psi}{\operatorname*{\rightarrow}}F\overset{\pi}{\operatorname*{\rightarrow}}K^n\to0$ is exact. Clearly $\pi$ is a $K[x]$ -module epimorphism. Since $A$ is the matrix of $\phi$ and the $K[x]$ -module structure of $K^n$ is induced by $\phi$

$$\pi(xu_{i})=x\pi(u_{i})=x\varepsilon_{i}=\phi(\varepsilon_{i})=\sum_{j=1}^{n}a_{ij}\varepsilon_{j}.$$

Consequently, for each i

$$\begin{aligned}
\pi\psi(u_{i})& =\pi\Bigg(xu_{i}-\sum_{j=1}^{n}a_{ij}u_{j}\Bigg)=\pi(xu_{i})-\sum_{j}a_{ij}\pi(u_{j}) \\
&=\sum_{j}a_{ij}\varepsilon_{j}-\sum_{j}a_{ij}\varepsilon_{j}=\:0,
\end{aligned}$$

whence $\operatorname{Im}\psi\subset\operatorname{Ker}\pi$ To show thatKe ${\mathbf{r}}\pi\subset\mathbf{Im}\psi$ it suffices to prove that every element $w$ of $F$ is of the form w = v(o) + ≥ ku; (v e F, k;ε K). For in this case if w εKer $\pi$ , then

$$0=\pi(w)=\pi\psi(v)+\pi(\sum_{j}k_{i}u_{j})=0+\sum_{j}k_{i}\varepsilon_{j}.$$

Since $\{\varepsilon_{j}\}$ is a basis of $K^n,k_j=0$ for all $j.$ . Consequently, $w=\psi(v)$ and hence Ker $\pi\subset\operatorname{Im}\psi$ . Since every element of $F$ is a sum of terms of the form $fu_i$ with $f_{\varepsilon}K[x].$ , we need only show that for each. $i$ and 1 ,there exist $\upsilon_{it}\varepsilon F$ and $k_i\varepsilon K$ such that x'u = V(va) + ≥ kμj. For each $i$ and 1=1 , we have $xu_{i}=\psi(u_{i})+\sum_{j}a_{i,j}u_{j}$

------------------------------------------------------------------

$(a_{ij}\in K)$ . Proceeding inductively assume that for each. $j$ there exist $v_{j.t-1}$ E $F$ and $k_{jr}$ EK such hat $x^{t-1}u_{j}=\psi(v_{i,t-1})+\sum_{r=1}^{n}k_{ir}u_{r-1}$ Then oreach

$$\begin{aligned}
x^{t}u_{i}& =\:x^{t-1}(xu_{i})\:=\:x^{t-1}(\psi(u_{i})\:+\:\sum_{j}\:a_{ij}u_{j})\:=\:\psi(x^{t-1}u_{i})\:+\:\sum_{j}\:a_{ij}x^{t-1}u_{j} \\
&=\psi(x^{t-1}u_{i})+\sum_{j}a_{ij}(\psi(v_{j,t-1})+\sum_{r}k_{jr}u_{r}) \\
&=\psi(x^{t-1}u_{i}+\sum_{j}a_{ij}v_{j,t-1})+\sum_{r}(\sum_{j}a_{ij}k_{j,i})u_{r}.
\end{aligned}$$

Thus $x^{t}u_{i}=\psi(v_{ii})+\sum_{\tau}c_{r}u_{r}$ =(ws) + c,u $=\psi(v_{i,t})+\sum_{r}c_{r}u_{r}\:\mathrm{with~}v_{it}=x^{t-1}u_{i}+\sum_{j}a_{i,j}v_{i,t-1}\varepsilon F$and$c_r=\sum_{j}a_{i,j}k_{ir}\varepsilon K$ C,=aukire K $c_{r}=\sum_{j}a_{ij}k_{ir}\varepsilon K$ and the induction is complete. Therefore $F\overset{\downarrow}{\operatorname*{\rightarrow}}F\overset{\pi}{\operatorname*{\rightarrow}}K^n\to0$ is exact and hence $K^{n}\cong F/$Ker $\pi=F/$Im $\psi$

Since $K[x]$ is a principal ideal domain, Proposition 2.11 shows that $xI_n-A$ is equivlen toa diagonal matix $D=\begin{pmatrix}L_r&0\\0&0\end{pmatrix}$ where $r$ istherank of $xI_{n}-A$ and $L$, is an $r\times r$ diagonal matrix with nonzero diagonal entries $f_{1},\ldots,f_{r}\in K[x]$ such that $f_{1}\mid f_{2}\mid\cdots\mid f_{r}$ .We may assume each $f_i$ is monic (if necessary, perform suitable elementary row operations on $D$ ). Clearly the determinant $|xI_n-A|$ in $K[x]$ is a monic polynomial of degree n. In particular, $|xI_n-A|\neq0$ .By Definition 1.8 and Theorem 3.5(ii), (iv), $|D|$ is a unit multiple of $|xI_n-A|$ ,whence $|D|\neq0$ . Consequently, all the diagonal entries of $D$ are nonzero. Thus $L_{r}=D$ and $r=n$ .Since $D$ is equivalent to $xI_n-A,D$ is the matrix of $\psi$ relative to some pair of ordered bases $V=\{v_{1},\ldots,v_{n}\}$ and $W=\{w_{1},\ldots,w_{n}\}$ of $F$ (Theorem 1.6). This means that $\psi(v_{i})=f_{i}w_{i}$ for each iand Im $\psi=K[x]f_1w_1\oplus\cdots\oplus K[x]f_nw_n$ . Consequently,

$$\begin{aligned}
\text{K}& \cong F/\mathrm{Ker}\:\pi=F/\mathrm{Im}\:\psi=\frac{K[x]w_{1}\bigoplus\cdots\bigoplus K[x]w_{n}}{K[x]\:f_{1}w_{1}\bigoplus\cdots\bigoplus K[x]\:f_{n}w_{n}} \\
&\cong K[x]w_1/K[x]f_1w_1\oplus\cdots\oplus K[x]w_n/K[x]f_nw_n \\
&\cong K[x]/(f_1)\oplus\cdots\oplus K[x]/(f_n),
\end{aligned}$$

where each $f_i$ is monic and $f_1\mid f_2\mid\cdots\mid f_n$ .For some 1 $\cdot(0\leq1\leq n)$ $f_{1}=f_{2}=\cdots$ $=f_{l}=1_{K}$ and $f_{t+1},\ldots,f_n$ are nonconstant. Thus for $i\leq t,K[x]/(f_{i})=K[x]/(1_{K})=0$ and for $i>t,K[x]/(f_{i})$ is a cyclic $K[x]$ -module of order $f_{i}.$ .Therefore, $K^n$ is the internal direct sum of nonzero torsion cyclic $K[x]$ -submodules $\therefore\phi$ -cyclic subspaces $E_{l+1},\ldots,E_n$ of orders $f_{t+1},\ldots,f_n$ respectively such that $f_{t+1}$ fett $f_{l+1}^{..}\mid f_{l+2}\mid\cdots\mid f_{n}$ .Since the $K[x]$ module structure of $K^n$ is induced by $\phi$ Φ $\phi,0=f_{i}E_{i}=f_{i}(\phi)E_{i}$ . It follows readily that $f_i$ is the minimal polynomial of $\phi\mid E_i$ . Therefore, $f_{t+1},\ldots,f_n$ are the invariant factors of $\phi$ (and hence of $A$ )by Theorem 4.2.

EXAMPLE. If $\phi:\mathbf{Q}^3\to\mathbf{Q}^3$ is a linear transformation and relative to some basis Iherui o $\phi$ 标$A=\begin{pmatrix}0&4&2\\-1&-4&-1\\0&0&-2\end{pmatrix}$, Ihcen $xI_3-A=\begin{pmatrix}x&-4&-2\\1&x+4&1\\0&0&x+2\end{pmatrix}.$ Performing suitable elementary row and column operations yields.

$$\begin{pmatrix}x&-4&-2\\1&x+4&1\\0&0&x+2\end{pmatrix}\to\begin{pmatrix}1&x+4&1\\x&-4&-2\\0&0&x+2\end{pmatrix}\to $$

------------------------------------------------------------------

$$\begin{aligned}
&\begin{pmatrix}1&x+4&1\\0&-4-x(x+4)&-2-x\\0&0&x+2\end{pmatrix}\to\begin{pmatrix}1&0&0\\0&-(x+2)^2&-(x+2)\\0&0&x+2\end{pmatrix}\to \\
&\begin{pmatrix}1&0&0\\0&-(x+2)^2&0\\0&0&x+2\end{pmatrix}\to\begin{pmatrix}1&0&0\\0&x+2&0\\0&0&(x+2)^2\end{pmatrix}.
\end{aligned}$$

Therefore by Corollary 4.8 and Proposition 4.9 the invariant factors of $A$ and $\phi$ are $x+2$ and $(x+2)^{2}$ and their minimal polynomial is $(x+2)^2$

## EXERCISES

Nore: Unless stated otherwise, $E$ is an $n$ -dimensional vector space over a field $K$

1. If $A$ and $B$ are $n\times n$ matrices over $K$ with minimum polynomials $q_1$ and $q_2$ re spectively, then the minimal polynomial of the direct sum of $A$ and $B$ (a $2n\times2n$ matrix) is the least common multiple of $q_1$ and $q_2$

 2. The O linear transformation $E\to E$ has invariant factors [resp. elementary divisorsJ $q_1=x$ q1 = x $q_{1}=x,q_{2}=x,\ldots,q_{n}=x$

3. (a) Let $a,b,c$ be distinct elements of $K$ and let $D\varepsilon Mat_6K$ be the diagonal matrix with main diagonal $a,a,a,b,b,c$ . Then the invariant factors of $D$ are $q_{1}=x-a$, $q_{2}=(x-a)(x-b)$ and $q_{3}=(x-a)(x-b)(x-c)$ (b) Describe the invariant factors of any diagonal matrix in $Mat_nK$

4. If $q$ is the minimal polynomial of a linear transformation $\phi:E\to E$, with $\dim_KE=n$ ,then deg $q\leq n$

5. The minimal polynomial of the companion matrix of a monic polynomia $f\varepsilon K[x]$ is precisely $f$

6. Let $F$ be an extension field of $K$ . The invariant factors in $K[x]$ of a matrix $A\varepsilon Mat_nK$ are the same as the invariant factors in $F[x]$ of $A$ considered as a matrix over $F$ .[Hint: A $K.$ basis of $K^n$ is an $F$ basis of $F^n$ .Use linear transforma. tions.]

7. Let $F$ be an extension field of $K.A,B\varepsilon\mathrm{Mat}_nK\subset\mathrm{Mat}_nF$ are similar over $F$ if and only if they are similar over $K$ [see Exercise 6]

8. $A\in Mat_{n}K$ is similar to a diagonal matrix if and onlyif theelementary divisors of $A$ are all linear.

9.If $A\varepsilon Mat_nK$ nK $_{n}K$ is nilpotent (that is, $A^{r}=0$ for some $r>0$ ),then $A$ is similar to a matrix all of whose entries are zero except for certain entries $1_{K}$ on the diagonal next above the main diagonal.

10. Find all possible [primary] rational canonical forms for a matrix $A\in Mat_nQ$ such that (i) $A$ is $6\times6$ with minimal polynomial $(x-2)^{2}(x+3)$ ;(ii) $A$ is $7\times7$ with minimal polynomial $(x^2+1)(x-7)$ .Find all possible Jordan canonical forms of $A$ considered as a matrix over C.

------------------------------------------------------------------

11. If $A$ is the companion matrix of a monic polynomial $f\varepsilon K[x]$ , with deg $f=n$ show explicitly that $A-xI_n$ is similar to a diagonal matrix with main diagonal $1_K,1_K,\ldots,1_K,f.$

12. $A\in Mat_nK$ is idempotent provided $A^{2}=A$ .Show that two idempotent matrices in $Mat_nK$ are similar if and only if they are equivalent

13.An $n\times n$ matrix $A$ is similar to its transpose $A^t$

## 5. THE CHARACTERISTIC POLYNOMIAL, EIGENVECTORS AND EIGENVALUES

In this section we investigate some more invariants of a linear transformation of a finite dimensional vector space over a field. Since several of these results are valid more generally we shall deal whenever possible with free modules of finite rank over a commutative ring with identity. If $A$ is an $n\times n$ matrix over a commutative ring $K$ with identity, then $xI_n-A$ is

an $n\times n$ matrix over $K[x].$ whence the determinant $|xI_n-A|$ is an element of $K[x]$ The characteristic polynomial of the matrix $A$ is the polynomial $p_{A}=|xI_{n}-A|\varepsilon K[x]$ Clearly, $p_{A}$ is a monic polynomial of degree $n$ . If $B\varepsilon Mat_nK$ is similar to $A$ say $B=PAP^{-1}$ , then since $xI_n$ is in the center of the ring $Mat_nK[x]$,

$$\begin{aligned}
p_{B}=|xI_{n}-B|& =\left|xI_{n}-PAP^{-1}\right|=\left|P(xI_{n}-A)P^{-1}\right| \\
&=|P||x\boldsymbol{I}_{n}-A||P|^{-1}=|x\boldsymbol{I}_{n}-A|=p_{A};
\end{aligned}$$

that is, similar matrices have the same characteristic polynomial

Let $\boldsymbol{\phi}:E\to E$ be an endomorphism of a free $K$ -module $E$ of finite rank $n$ (see Defnition IV.2.8 and Corollary IV.2.12). The characteristic polynomial of the endomorphismd $\phi$ (denoted) $p_{\phi.}$ ) is defined to be $p_A$ ,where $A$ is any matrix of $\phi$ relative to some ordered basis. Since any two matrices representing $\phi$ are similar by Corollary $1.7,p_{\phi}$ P $p_{\phi}$ is independent of the choice of $A$

Lemma 5.1. (i) If A1,A2 $\mathbf{A}_1,\mathbf{A}_2.$ ${}^{r}\mathbf{A}_{1},\mathbf{A}_{2},\ldots,\mathbf{A}_{r}$ A $\mathbf{A}_{r}$ are square matrices (of.various sizes) over a commutative ring $K$ with identity and $p_{i}\varepsilon K[x]$ is the characteristic pol ynomial of $\dot{}\mathbf{A}_{\mathrm{i}}$ then $p_1p_2\cdots p_r$ E $K[x]$ isthe characteristic polynomial of the matrix direct sumof $\mathbf{A}_{1},\mathbf{A}_{2},\ldots,\mathbf{A}_{r}$

(i) The companion matrix C of a monic polynomial f e $K[x]$ has characteristic polynomial f.

SKETCH OF PROOF.(i) If $A\in Mat_nK$ and $B\varepsilon Mat_mK$ ,then

$$\begin{pmatrix}A&0\\0&B\end{pmatrix}=\begin{pmatrix}A&0\\0&I_m\end{pmatrix}\begin{pmatrix}I_n&0\\0&B\end{pmatrix},\quad\mathrm{whence}\quad\begin{vmatrix}A&0\\0&B\end{vmatrix}=\begin{vmatrix}A&0\\0&I_m\end{vmatrix}\begin{vmatrix}I_n&0\\0&B\end{vmatrix}=|A||B|.$$

An inductive argument now shows that the determinant of a direct sum of matrices $B_{\mathrm{l}},\ldots,B_{\mathrm{k}}$ $B_k$ Bk is $|B_1||B_2|\cdots|B_k|$ . (ii) To show that $f$ is the characteristic polynomial of $C$ expand $|xI_n-C|$ along the last row.

------------------------------------------------------------------

Theorem 5.2. Let $\phi:\mathbf{E}\to\mathbf{E}$ be a linear trans formation of an n-dimensional vector space over a field K with characteristic polynomial. $p_{\phi}$ Po $\mathbf{p}_{\phi}\in\mathbf{K}[\mathbf{x}]$ , minimal polynomial $\mathbf{q}_{\phi}\in\mathbf{K}[\mathbf{x}]$, and invariant factors $q_1,\ldots,q_t\varepsilon K[x]$

(i) The characteristic polynomial is theproduct of the invariantfactors; that is, $\mathbf{p}_{\phi}=\mathbf{q}_{1}\mathbf{q}_{2}\cdots\mathbf{q}_{t}=\mathbf{q}_{1}\mathbf{q}_{2}\cdots\mathbf{q}_{t-1}\mathbf{q}_{\phi}$ (ii) (Cayley-Hamilton) $\phi$ is root ofits characteristic polynomial; that is, $\mathbf{p}_{\phi}(\phi)=0$ (ii) An irreducible polynomial in $K[x]$ divides $p_{\phi}$ if andonly if it divides $q_{\phi}$ Conclusions (i)-(i) are valid, mutatis mutandis, for any matrix A ε $Mat_nK$ nK $_{\mathrm{n}}\mathbf{K}$

PROOF. By Theorem $4.6\phi$ has a basis relative to which $\phi$ has the matrix $D$ that is the direct sum of the companion matrices of $q_1,\ldots,q_t$ . Therefore, $p_{\phi}=p_{D}$ $=q_1q_2\cdots q_t$ by Lemma 5.1. Furthermore, $q_{\phi}=q_{t}$ by Theorem 4.2, whence $P_{\phi}(\phi)=0$ since $q_{\phi}(\phi)=0$ (i) is an immediate consequence of (i) and the fact that $q_1\mid q_2\mid\cdots\mid q_i$ .The analogous statements about $A\varepsilon Mat_{r_t}K$ are proved similarly using Corollaries 4.7 and 4.8.

REMARK. The Cayley-Hamilton Theorem (Theorem 5.2(ii) is valid over any commutative ring with identity (Exercise 2).

Definition 5.3. Let $\phi:\mathbf{E}\to\mathbf{E}$ be a linear trans formation of a vector space E over a field K. A nonzero vector u ε E is an eigenvector (or characteristic vector or proper vector) o f $\phi$ if $\phi($u)=ku for some k eK.An element k eK is an eigenvalue (or proper value or characteristic value) of $\phi$ if $\phi($u)=ku for some nonzero ue E.

It is quite possible for two distinct(even linearly independent) eigenvectors to have the same eigenvalue.On the other hand,a setofeigenvectors whose corre sponding eigenvalues are all distinct is necessarily linearly independent (Exercise 8).

Theorem 5.4. Let $\phi:\mathbf{E}\to\mathbf{E}$ be a linear transformation of a finite dimensional vector. space E over a field K.Then the eigenvalues of $\phi$ are the roots in K of the characteristic polynomial $\mathbf{p}_{\phi}of\boldsymbol{\phi}$

REMARK. The characteristic polynomial $p_{\phi}\in K[x]$ need not have any roots in $K$ ,in which case $\phi$ has no eigenvalues or eigenvectors.

SKETCH OF PROOF OF 5.4.Let $A$ be the matrix of $\phi$ relative to some ordered basis. If $k\varepsilon K$ ,then $kI_{n}-A$ is the matrix of $k\mathbf{1}_{E}-\phi$ relative to the same basis. If $\phi(u)=ku$ for some nonzero $u\varepsilon E$ ，then $(k1_E-\phi)(u)=0$ whence $k1_E-\phi$ is not a monomorphism. Therefore, $kI_n-A$ is not invertible (Lemma 1.5) and hence $|kI_n-A|=0$ by Proposition 3.7 or Exercise 3.6. Thus $k$ is a root of $p_{\phi}=|xI_{n}-A|$ . Conversely, if $k$ isa root of $p_{\phi}$ , then $|k|_n-A|=0$ . Consequently. $k\mathbf{1}_E-\phi$ is not an isomorphism by Lemma 1.5 andProposition 3.7 (orExercise3.6) Since $E$ is fnite dimensional, $k1_E-\phi$ is not a monomorphism (Exercise IV.2.14) Therefore, there is a nonzero u e $E$ such that $(k\mathbf{1}_E-\phi)(u)=0$ ,whence $\phi(u)=ku$ and $k$ is an eigenvalue of $\phi.$

------------------------------------------------------------------

If k $k$ $k\varepsilon K$ is an eigenvalue of an endomorphism $\phi$ of a $K$ -vector space $E$ , then it is easy to see that $C(\phi,k)=\{v\varepsilon E\mid\phi(v)=kv\}$ is a nonzero subspace of $E$ $:C(\boldsymbol{\phi},k)$ is called the eigenspace or characteristic space of $k$

Theorem 5.5.Let $\phi:\mathbf{E}\to\mathbf{E}$ be a linear transformation of a finitedimensional vector space E over a field K. Then $\phi$ has a diagonal matrix D relative to some ordered basis ofEif and only ifthe eigenvectors ofΦspan E. In this case the diagonal entries of D are the eigenvalues of $\phi$ and each eigenvalue k ε K appears on the diagonal $dim_KC(\phi,k)$ times.

PROOF. By Theorem IV.2.5 the eigenvectors of $\phi$ span $E$ if and only if $E$ has a basis consisting of eigenvectors. Clearly $U=\{u_{1},\ldots,u_{n}\}$ is a basis of eigenvectors with corresponding eigenvalue $k_1$ .... $k_n$ E $K$ if and only if the matrix of $\phi$ relative to $U$ is the diagonal matrix $D$ with main diagonal $k_{1},k_{2},\ldots,k_{n}$ . In this case suppose that $v=\sum_{i=1}^nr_iu_i$ is an eigenvector of $\phi$ with $\phi(v)=kv$ . Sice $U$ is linearly inde pendent and $\sum_{i=1}^{n}kr_{i}u_{i}=kv=\phi(v)=\sum_{i=1}^{n}r_{i}\phi(u_{i})=\sum_{i=1}^{n}r_{i}k_{i}u_{i}$ ,we have $kr_i=r_1k_i$ for all i. Thus for each $i$ such that $r_i\neq0$ ri≠0 $r_{i}\neq0,k=k_{i}$ k=ki $k=k_i$ (since $v\neq0$ , at least one $r_i\neq0$ ). Therefore, $k_1,\ldots,k_n$ are the only eigenvalues of $\phi$ . Furthermore, if $k$ is an eigenvalue of $\phi$ that appears $t$ times on the diagonal of $D$ and $u_{i_1},\ldots,u_{i_n}$ are those ele ments of $U$ with eigenvalue $k$ , then this argument shows that $\{u_{i_1},\ldots,u_{i_t}\}$ spans $C(\phi,k)$ . Since $\{u_{i_1},\ldots,u_i,\}$ is linearly independent it is a basis of $C(\phi,k)$ . Therefore. $\dim_KC(\phi,k)=t$

The eigenvalues and eigenvectors of an n $X$ n matrix A over a field $K$ are defined to be respectively the eigenvalues and eigenvectors of the unique linear transformation $\phi:K^n\to K^n$ that has matrix $A$ relative to the standard basis. Theorem 5.4 shows that the eigenvalues of $A$ are the eigenvalues of any endomorphism of an $n$ -dimen sional vector space over $K$ whichhas matrixA relative to some basis.

We close this section with a brief discussion of another invariant of a matrix under similarity.

Proposition 5.6. Let K be a commutative ring with identity. Let $\phi$ be an endomor phism of a freeK-module of rank n and let $\mathbf{A} = ( \mathbf{a} _{\mathrm{ij}}) \varepsilon Mat_{\mathrm{n} }\mathbf{K}$ be the matrix of $\phi$ relative to some ordered basis. If the characteristic polynomial of $\phi$ andAis $\mathbf{p} _{\phi }= \mathbf{p} _{A}= \mathbf{x} ^{n}+ \mathbf{c} _{\mathrm{n} - 1}\mathbf{x} ^{n- 1}+ \cdots + \mathbf{c} _{\mathrm{i} }\mathbf{x} + \mathbf{c} _{0}\varepsilon \mathbf{K} [ \mathbf{x} ]$, then

$$(-1)^nc_0=|A|\quad and\quad-c_{n-1}=a_{11}+a_{22}+\cdots+a_{nn}.$$

PROOF. $c_{0}=p_{\phi}(0)=|0I_{n}-A|=|-A|=(-1)^{n}|A|$ by Theorem 3:5(viii) Expand $p_{\phi}=|xI_{n}-A|$ along the first row. One term of this expansion is $x-a_{11})(x-a_{22})\cdots(x-a_{nn})=x^{n}-(a_{11}+a_{22}+\cdots+a_{nn})x^{n-1}+b_{n-2}x^{n-2}+$ $\cdots+b_0$ for some $b_i\varepsilon K$ .No other term of this expansion contains any terms with a factor of $\chi^{n-1}$ ,whence $-c_{n-1}=a_{11}+\cdots+a_{nn}$ .

------------------------------------------------------------------

Let $K$ be a commutative ring with identity. The trace of an n $X$ n matrix $A=(a_{ij})$ over $K$ is $a_{11}+a_{22}+\cdots+a_{nn}\varepsilon K$ and is denoted TrA. The trace of an endomorphism $\phi$ of a free $K$ -module of rank $n$ (denoted $Tr\phi$ ）is TrA,where $A$ is the matrix of $\phi$ relative to some ordered basis. Since $p_{\phi}=p_{A}$ is independent of the choice of the matrix $A$ , so is Tr$\phi$ by Proposition 5.6. Similar matrices have the same trace by Corollary 1.7 (or by an easy direct argument using (ii) below). It is easy to see that for any $A,B\varepsilon Mat_nK$ and $k\varepsilon K$

(i)
$$\mathrm{Tr}(A+B)=\mathrm{Tr}A+\mathrm{Tr}B;$$
(ii) $\operatorname{Tr}(kA)=k\operatorname{Tr}A$ (ii) $\operatorname{Tr}(AB)=\operatorname{Tr}(BA)$

The connection between the trace as defined here and the trace function of Galois Theory (Definition V.7.1) is explored in Exercise 9.

### EXERCISES

Note: Unless stated otherwise $K$ is a commutative ring with identity

1.Prove directly that a matrix over $K$ and its transpose have the samecharacteristic polynomial.

2. (Cayley-Hamilton) If $\phi$ is an endomorphism of a free $K$ -module $E$ of finite rank, then $p_{\phi}(\phi)=0.$ [Hint: if $A$ is the matrix of $\phi$ and $B=xI_{n}-A$ , then $B^aB=$ $|B|I_{n}=p_{\phi}I_{n}$ in $Mat_nK[x]$ .If $E$ is a $K[x]$ -module with structure induced by $\phi$ and $\psi$ is the $K[x]$ -module endomorphism $E\to E$ with matrix $B$ , then $\psi(u)=xu-\phi(u)$ $=\phi(u)-\phi(u)=0$ for all $u\varepsilon E$

3.If $A$ is an $n\times m$ matrix over $K$ and $B$ an $m\times n$ matrix over $K$ ，then $x^{m}p_{AB}=x^{n}p_{BA}$ . Furthermore, if $m=n$ , then $p_{AB}=p_{BA}$ . [Hinr: let $C,D$ be the $(m+n)\times(m+n)$ # $|CD|=|DC|$ $K[x]{:}C=\begin{pmatrix}xI_n&A\\B&I_m\end{pmatrix}$ aindl $D=\begin{pmatrix}I_n&0\\-B&xI_m\end{pmatrix}$ 4. (a) Exhibit three $3\times3$ matrices over Q no two of which are similar such that

-2 is the only eigenvalue ofeach of the matrices. (b) Exhibit a $4\times4$ matrix whose eigenvalues over $R$ are $\pm1$ and whose eigen-

values overC are $\pm1$ and $\pm i$

5.Let $K$ be a field and $A\in Mat_nK$

(a) O is an eigenvalue of $A$ if and only if $A$ is not invertible. (b) If $k_{1},\ldots,k_{r}\in K$ are the (not necessarily distinct) eigenvalues of $A$ and $f\in K[x]$, then $f(A)\in\mathbf{Mat}_nK$ has eigenvalues $f(k_1),\ldots,f(k_r)$

6. If $\phi$ and $\psi$ are endomorphisms of a finite dimensional vector space over an algebraically closed field $K$ such that $\phi\psi=\psi\phi$ , then $\phi$ and $\psi$ have a common eigenvector.

7. (a) Let $\phi$ and $\psi$ be endomorphisms of a finite dimensional vector space $E$ such that $\phi\psi=\psi\phi$ . If $E$ has a basis of eigenvectors of $\phi$ and a basis of eigenvectors of $\psi$ ,then $E$ has a basis consisting of vectors that are eigenvectors for both $\phi$ and $\psi$ (b) Interpret (a) as a statement about matrices that are similar to a diagonal

matrix.

------------------------------------------------------------------

8. Let $\phi:E\to E$ be a linear transformation of a vector space $E$ over a field $K.$ If $U$ is a set of eigenvectors of $\phi$ whose corresponding eigenvalues are all distinct, then $U$ is linearly independent. [Hinr: If $U$ were linearly dependent, there would be a relation $r_{1}u_{1}+\cdots+r_{l}u_{l}=0\left(u_{i}\varepsilon U;0\neq r_{i}\varepsilon K\right)$ O≠r;eK $0\neq r_{i}\in K$ with 1 minimal. Apply the transformation $k_1\mathbf{l}_E-\phi$ ，where $\varphi(u_1)=k_1u_1$ ,and reach a contradiction.]

9. Let $F$ be an extension field of a field $K$ and $u\varepsilon F$ .Let $\phi:F\to F$ be the endomorphism of the vector space $F$ given by $v\mapsto uv$ (a) Then Tr$\phi$ is the trace of $u$ $T_KF(u)$ , as in Defnition V.7.1. [Hinr: frst try

the case when $F=K(u)]$ (b) The determinant of $\phi$ is the norm of u, $N_KF(u)$ 10.Let $K$ be a field and $A\in Mat_nK$ (a) If $A$ is nilpotent (that is, $A^{m}=0$ for some $m$ ), then $\mathbf{Tr}A^{\mathbf{r}}=0$ for all $r\geq1$ [Hinr: the minimal polynomial of $A^r$ has the form $x^t$ and $A^r$ is similar to a matrix in rational or Jordan canonical form.] (b) If char $K=0$ and Tr $A^r=0$ for all $r\geq1$ , then $A$ is nilpotent.

------------------------------------------------------------------

# COMMUTATIVE RINGS AND MODULES

For the most part this chapter is a brief introduction to what is frequently called commutative algebra.We begin with chain conditions (Section 1) and prime ideals (Section 2), both of which play a central role in the study of commutative rings. Actually no commutativity restrictions are made in Section 1 since this material is also essential in the study of arbitrary rings (Chapter IX). The theory of commutative ringsfollows a familiar pattern:we attempt toobtain

a structure theory for those rings that possess, at least in some generalized form, properties that have proven useful in various well-known rings. Thus primary de- composition of ideals (the analogue of factorization of elements in an integral domain) is considered in Sections 2 and 3. We then study rings that share certain desirable properties with the ring of integers, such as Dedekind domains (Section 6) and Noetherian rings (Section 4). The analysis of Dedekind domains requires some knowledge about ring extensions (Section 5). This information is also used in proving the Hilbert Nullstellensatz (Section 7), a famous classical result dealing with ideals of the polynomial ring $K[x_1,\ldots,x_n]$ Except in Section 1, all rings are commutative. The approximate interdepen

dence of the sections of this chapter (subject to the remarks below) is as follows:

![](https://storage.simpletex.cn/view/fh7MUGkZcImHLqihP3bp2GyWf29gKSGis)

A broken arrow $A-\rightarrow B$ indicates that an occasional result fromSectionA is used in Section B, but that Section B is essentially independent of Section A. Section 1 is not needed for Section 5 but is needed for Section 4. Only one important result in Section 4 depends on Sections 2 and 3. This dependence can be eliminated by using an alternate proof, which is indicated in the exercises

------------------------------------------------------------------

## 1. CHAIN CONDITIONS

In this section we summarize the basic facts about the ascending and descending chain conditions for modules and rings that will be needed in the remainder of this chapter and in Chapter IX. Rings are not assumed to be commutatice,nor to have identity elements.

Definition 1.1. A module A is said to satisfy the ascending chain condition (ACC) on submodules (or ro be Noetherian) if for every chain $A_1\subset A_2\subset A_3\subset\cdots$ of submodules of A,there is an integer n such that $\mathbf{A}_{\mathrm{i}}=\mathbf{A}_{\mathrm{n}}$ for all $i\geq n$

A moduleB is said to satisfy the descending chain condition(DCC)on submodules (or to be Artinian) if for every chain $\mathbf{B}_1\supset\mathbf{B}_2\supset\mathbf{B}_3\supset\cdots$ of'submodules of B, there is aninteger m such that $\mathbf{B}_{\mathrm{i}}=\mathbf{B}_{\mathrm{m}}$ for all $i\geq m$

EXAMPLE. The $\mathbf{Z}$ -module (abelian group) $\mathbf{Z}$ satisfies the ascending but not the descending chain condition on submodules (Exercise II.3.5). The $\mathbf{Z}$ -module $Z(p^{\infty})$ satisfies the descending but not the ascending chain condition (Exercise II.3.13)

Ifa ring $R$ is considered as a left [resp. right] module over itself, then it is easy to see that the submodules of $R$ are precisely the left [resp. right] ideals of R. Consequently, in this case it is customary to speak of chain conditions on left or right ideals rather than submodules

Definition 1.2. A ring R is left [resp.right] Noetherian if R satisfies the ascending chain condition on left [resp.right] ideals. R is said to be Noetherian if R is both left and right Noetherian

A ring R is left [resp. right] Artinian ifR satisfies the descending chain condition on left [resp. right] ideals. R is said to be Artinian if R is both left and right Artinian.

In other words, a ring $R$ is (left or right) Noetherian if it is a (left or right) Noetherian $R$ -module, and similarly for Artinian. Consequently, all subsequent definitions and results about modules that satisfy the ascending or descending chain condition on submodules apply,mutatis murandis, to (left or right) Noetherian or Artinian rings.

EXAMPLES. A division ring $D$ is both Noetherian and Artinian since the only left or right ideals are $D$ and 0, (Exercise II1.2.7). Every commutative principal ideal ring is Noetherian (Lemma III.3.6); special cases include $\mathbf{Z},Z_n$ ,and $F[x]$ with $F$ a field.

EXAMPLE. The ring $Mat_nD$ nD $_nD$ ofall $n\times n$ matrices over a division ring is both Noetherian and Artinian (Corollary 1.12 below)

REMARKS. A right Noetherian [Artinian] ring need not be left Noetherian [Artinian] (Exercise 1). Exercise II.3.5 shows that a Noetherian ring need not be Artinian. However every left [right] Artinian ring with identity is left [right] Noether. ian (Exercise IX.3.13 below).

------------------------------------------------------------------

A maximal element in a partially ordered set $(C,\leq)$ was definedinSection7 of the Introduction. A minimal element is defined similarly: $b\varepsilon C$ is minimal if for every $c\varepsilon C$ which is comparable to b, $b\leq c$ .Note that it is not necessarily true that $b\leq c$ for all ce $C.$ . Furthermore, $C$ may contain many minimal elements or none at all.

Definition 1.3. A module A is said to satisfy the maximum condition [resp. minimum condition] on submodules ifevery nonempty set of submodules of A contains a maximal [resp. minimal] element (with respect to set theoretic inclusion)

Theorem 1.4. A module A satisfies the ascending [resp. descending] chain condition on submodules if and only if A satisfies the maximal[resp.minimal]condition on submodules.

PROOF. Suppose $A$ satisfies the minimal condition on submodules and $A_1\supset A_2\supset\cdots$ is a chain of submodules. Then the set $\left\{A_{i}\mid i\geq1\right\}$ has a minimal element, say $A_n$ . Consequently, for $i\geq n$ we have $A_n\supset A_i$ by hypothesis and $A_n\subset A_i$ by minimality, whence $A_{i}=A_{n}$ for each $i\geq n$ .Therefore, $A$ satisfies the descending chain condition. Conversely suppose $A$ satisfies the descending chain condition, and $S$ is a non-

empty set of submodules of $A$ . Then there exists $B_0\varepsilon S$ . If S has no minimal element, then for each submodule $B$ in $S$ there exists at least one submodule $B^{\prime}$ in $S$ such that $B\subsetneqq B^{\prime}$ . For each $B$ in $S$ , choose one such $B^{\prime}$ (Axiom of Choice). This choice then defines a function $f:S\to S$ by $B\vdash B^{\prime}$ . By the Recursion Theorem 6.2 of the Introduc tion (with $f=f_n$ for all $n$ ) there is a function $\varphi:\mathbf{N}\to S$ such that

$$\varphi(0)=B_0\quad\mathrm{and}\quad\varphi(n+1)=f(\varphi(n))=\varphi(n)^{\prime}.$$

Thus if $B_n$ Bn $B_n\in S$ denotes $\varphi(n)$ , then there is a sequence $B_0,B_1,\ldots$ such that $B_0\subsetneqq B_1\supsetneq$ $B_2\subsetneqq\cdots.$ This contradicts the descending chain condition. Therefore, $S$ must have a minimal element, whence $A$ satisfies the minimum condition.

The proof for the ascending chain and maximum conditions is analogous.

Theorem 1.5. Let $0\to\mathbf{A}\overset{\mathbf{f}}{\operatorname*{\operatorname*{\rightarrow}}}\mathbf{B}\overset{\mathbf{g}}{\operatorname*{\operatorname*{\rightarrow}}}\mathbf{C}\to0$ be a short exact sequence of modules. Then B satisfies the ascending [resp. descending] chain condition on submodules ifand only if A and C satisfy it.

SKETCH OF PROOF. 1f $B$ satisfies the ascending chain condition, then so does its submodule $f(A)$ .By exactness $A$ is isomorphic to $f(A)$ ，whence $A$ satisfies the ascending chain condition. If $C_1\subset C_2\subset\cdots$ is a chain of submodules of $C$ , then $g^{-1}(C_1)\subset g^{-1}(C_2)\subset\cdots$ is a chain of submodules of $B$ . Therefore, there is an $n$ such that $g^{-1}(C_{i})=g^{-1}(C_{n})$ for all $i\geq n$ .Since $g$ is an epimorphism by exactness, it follows that $C_{i}=C_{n}$ for all $i\geq n$ . Therefore, $C$ satisfies the ascending chain condition.. Suppose $A$ and $C$ satisfy the ascending chain condition and $B_1\subset B_2\subset\cdots$ isa

chain of submodules of $B$ .For each $i$ let

$$A_{\imath}=f^{-\imath}(f(A)\cap B_{\imath})\quad\mathrm{and}\quad C_{\imath}=g(B_{\imath}).$$

------------------------------------------------------------------

Let f=f |Aand g= gB.Verify that for each $i$ the following sequence is exact:

$$0\rightarrow A_{i}\stackrel{f_{i}}{\rightarrow}B_{i}\stackrel{g_{i}}{\rightarrow}C_{i}\rightarrow0.$$

Verify that $A_1\subset A_2\subset\cdots$ and $C_1\subset C_2\subset\cdots$ . By hypothesis there exists an integer n such that $A_{i}=A_{n}$ and $C_{i}=C_{n}$ for all $i\geq n$ .For each $i\geq n$ there is a commutative diagram with exact rows:

$$0\to A_n\overset{f_n}{\operatorname*{\to}}B_n\overset{g_n}{\operatorname*{\to}}C_n\to0\\0\to A_i\overset{f_i}{\operatorname*{\to}}B_i\overset{g_i}{\operatorname*{\to}}C_i\to0,$$

where $\alpha$ and $\gamma$ are the respective identity maps and $\beta_i$ is the inclusion map. The Short Five Lemma IV.1.17 implies that $\beta_i$ is the identity map, whence $B$ satisfies the ascending chain condition. The proof for descending chain condition is analogous.

Corollary 1.6. 1f A is a submodule of a module B, then B satisfies the ascending [resp descending] chain condition if and only if A and B/A satisfiy it..

PROOF. Apply Theorem 1.5 to the sequence $0\to A\overset{\mathsf{F}}{\operatorname*{\rightarrow}}B\to B/A\to0$

Corollary 1.7. IfA, . . . , $\mathbf{A}_{\mathrm{n}}$ are modules,then the direct sum $\mathbf{A_1}\oplus\mathbf{A_2}\oplus\cdots\oplus\mathbf{A_n}$ satisfies the ascending [resp. descending] chain condition on submodules if and only if each $\mathbf{A}_{\mathrm{i}}$ satisfies it.

SKETCH OF PROOF. Useinduction on $n$ .If $n=2$ ,applyTheorem1.5 to the sequence $0\to A_1\overset{\bullet ı}{\operatorname*{\rightarrow}}A_1\oplus A_2\overset{\pi_2}{\operatorname*{\rightarrow}}A_2\to0$

Theorem 1.8. If R is a left Noetherian [resp. Artinian] ring with identity, then every. finitely generated unitary left R-module A satisfies the ascending [resp. descending]. chain condition on submodules.

An analogous statement is true with “left" replaced by "right."

PROOF OF 1.8. If $A$ is finitely generated, then by Corollary IV.2.2 there is a free $R$ -module $F$ with a finite basis and an epimorphism $\pi:F_{--}A$ . Since $F$ is a direct sum of a finite number of copies of $R$ by Theorem IV.2.1, $F$ is left Noetherian [resp. Artinian] by Corollary 1.7. Therefore $A\cong F/\ker\pi$ is Noetherian [resp. Artinian] by Corollary 1.6.

Here is a characterization of the ascending chain condition that has no analogue for the descending chain condition

1

------------------------------------------------------------------

Theorem 1.9.A moduleA satisfies the ascending chain condition on submodules if and only if every submodule of A is finitely generated. In particular, a commutative. ring R is Noetherian if and only if every ideal of R is finitely generated.

PROOF. $(\Rightarrow)$ If $B$ is a submodule of $A$ , let $S$ be the set of all finitely generated submodules of $B$ .Since $S$ is nonempty $(0\varepsilon S)$ $S$ contains a maximal element $C$ by Theorem 1.4. $C$ is finitely generated by $c_1,c_2,\ldots,c_n$ .For each $b\varepsilon B$ let $D_b$ be the submodule of $B$ generated by $b,c_1,c_2,\ldots,c_n$ . Then $D_b\varepsilon S$ and $C\subset D_b$ .Since $C$ is maximal, $D_{b}=C$ for every $b\varepsilon B$ ,whence $b\in D_b=C$ for every $b\varepsilon B$ and $B\subset C$ Since $C\subset B$ by construction, $B=C$ and thus $B$ is finitely generated. $(\Leftarrow)$ Given a chain of submodules $A_1\subset A_2\subset A_3\subset\cdots$ ,then it is easy to verify

that $\bigcup_{i\geq1}A_i$ is also a submodule of $A$ and therefoe finitely generated, say by $a_1,\ldots,a_k$ . Since each $a_i$ is an element of some $A_i$, there is an index $n$ such that $a_1\varepsilon A_n$ for $i=1,2,\ldots,k$ . Consequently, $\bigcup A_{i}\subset A_{n}$ ,whence $A_{i}=A_{n}$ for $i\geq n$ .

We close this section by carrying over to modules the principal results of Section II1.8 on subnormal series for groups. This material is introduced in order to prove Corollary 1.12, which will be useful in Chapter IX. We begin with a host of defini tions, most of which are identical to those given for groups in Section II.8. A normal series for a module $A$ is a chain of submodules: $A=A_0\supset A_1\supset$

$A_2\supset\cdots\supset A_n$ .The factors of the series are the quotient modules

$$A_i/A_{i+1}\quad(i=0,1,\ldots,n-1).$$

The length of the series is the number of proper inclusions ( $i=$ number of nontrivial factors).A refinement of the normal series $A_0\supset A_1\supset\cdots\supset A_n$ is a normal series obtained by inserting a finite number of additional submodules between the given ones. A proper refinement is one which has length larger than the original series. Two normal series are equivalent if there is a one-to-one correspondence between the nontrivial factors such that corresponding factors are isomorphic modules. Thus equivalent series necessarily have the same length. A composition series for $A$ is a normal series $A=A_0\supset A_1\supset A_2\supset\cdots\supset A_n=0$ such that each factor $A_k/A_{k+1}$ $(k=0,1,\ldots,n-1)$ is a nonzero module with no proper submodules.

The various results in Section Il.8 carry overreadily to modules.For example, $a$ composition series has no proper refinements and therefore is equivalent to any of its refinements (see Theorems IV.1.10 and Il.8.4 and Lemma II.8.8). Theorems of Schreier, Zassenhaus, and Jordan-Holder are valid for modules:.

Theorem 1.10. Any rwo normal series of a module A have refinements that are equivalent. Any two composition series of A are equitalent.

PROOF. See the corresponding results for groups (Lemma II.8.9 and Theorems 11.8.10 and 11.8.11).

'If $R$ has an identity, then a nonzero unitary module with no proper submodules is said to be simple. In this case a composition series is a normal series $A=A_0\supset\cdots\supset A_n=0$ with simple factors. If R has no identity simplicity is defined somewhat differently; see Defini tion IX.1.1 and the subsequent Remarks.

------------------------------------------------------------------

Theorem 1.11. A nonzero module A has a composition series if and only ifA satisfies both the ascending and descending chain conditions on submodules

PROOF. $(\Rightarrow)$ Suppose $A$ has a composition series $S$ of length $n$ .If either chain condition fails to hold, one, can find submodules 1

$$A\:=\:A_0\:\supset\:A_1\:\supset\:A_2\:\supset\:\cdots\:\supset\:A_n\:\supset\:A_{n+1},$$

which form a normal series $T$ of length $n+1$ .By Theorem $1.10S$ and $T$ have refinements that are equivalent.This is a contradiction since equivalent serieshave equal length. For every refinement of the composition series $S$ has the same length $n$ as $S$ but every refinement of $T$ necessarily has length at least $n+1$ . Therefore, $A$ satisfies both chain conditions.

$(\Leftarrow)$ If $B$ is a nonzero submodule of $A$ , let $S(B)$ be the set of all submodules $C$ of $B$ such that $C\neq B$ . Thus if $B$ has no proper submodules, $S(B)=\{0\}$ .Also define $S(0)=\{0\}$ . For each $B$ there is a maximal element $B^{\prime}$ of $S(B)$ by Theorem 1.4. Let $S$ be the set of all submodules of $A$ and define a map $f:\mathcal{S}\to\mathcal{S}$ by $f(B)=B^{\prime}$ ;(the Axiom of Choice is needed for the simultaneous selection of the $B^{\prime}$ ).By the Recursion Theorem 6.2 of the Introduction (with $f=f_n$ for all $n$ ） there is a function $\varphi:\mathbb{N}\to S$ such that

$$\varphi(0)=A\quad\mathrm{and}\quad\varphi(n+1)=f(\varphi(n))=\varphi(n)^{\prime}.$$

If $A_i$ denotes $\varphi(i)$ ,then $A\supset A_1\supset A_2\supset\cdots$ is a descending chain by construction. whencefor some $n$ $A_{i}=A_{n}$ for all $i\geq n$ .Since $A_{n+1}=A_{n}^{\prime}=f(A_{n})$ , the definition of $f$ shows that $A_{n+1}=A_{n}$ only if $A_n=0=A_{n+1}$ . Let $m$ be the smallest integer such that $A_{m}=0$ Then $m\leq n$ and $A_k\neq0$ for all $k<m$ . Furthermore for each $k<m$ $A_{k+1}$ is a maximal submodule of $A_k$ such that $A_k\supseteq A_{k+1}$ . Consequently, each $A_k/A_{k+1}$ is nonzero and has no proper submodules by Theorem IV.1.10. Therefore,

$A\supset A_1\supset\cdots\supset A_m=0$ Am = 0 $A_{m}=0$ is a composition series for $A$ .

Corollary 1.12. If D is a division ring, then the ring $Mat_{\mathrm{n}}D$ of all $n\times n$ matrices over D is both Artinian and Noetherian

SKETCH OF PROOF. In view of Definition 1.2 and Theorem 1.11 it suffices to show that $R=\mathbf{Mat}_nD$ has a composition series of left $R$ -modules and a composition of right $R$ -modules. For each i let $e_i\varepsilon R$ be the matrix with $1_{\perp}$ in position $(i,i)$ and 0 elsewhere. Verify that $Re_{\mathrm{i}}=\{Ae_{\mathrm{i}}\mid A\varepsilon R\}$ is a left ideal (submodule) of $R$ consisting of all matrices in $R$ with columnj zerofor all $j\neq i.$ Show that $Re_i$ is a minimal nonzero left ideal (that is, has no proper submodules). One way to do this is via elementary transformation matrices (Definition VII.2.7 and Theorem VII.2.8). Let $M_{0}=0$ and for $i\geq1$ let $M,=R(e_1+e_2+\cdots+e_i)$ .Verify that each $M_i$ is a left ideal of $R$ and that $M_{i}/M_{i-1}\cong Re_{i}$ ,whence $R=M_n\supset M_{n-1}\supset\cdots\supset M_1\supset M_0=0$ is a composition series of left $R$ -modules. A similar argument with the right ideals $e_{i}R=\{e_{i}A\mid A\in R\}$ shows that $R$ has a composition series of right $R$ -modules.

[

[

------------------------------------------------------------------

### EXERCISES

1. a) The ring ofal $2\times2$ matrices $\begin{pmatrix}a&b\\0&c\end{pmatrix}$ such that $a$ isan inter and $b,c$ are rational is right Noetherian but not left Noetherian. (b) The ring ofall $2\times2$ matrices $\begin{pmatrix}d&r\\0&s\end{pmatrix}$ such that $d$ is ational nd $r,s$ are real is right Artinian but not left Artinian.

2. If $I$ is a nonzero ideal in a principal ideal domain $R$ , then the ring $R/I$ is both Noetherian and Artinian.

3. Let $S$ be a multiplicative subset of a commutative Noetherian ring $R$ with identity Then the ring $S^{-1}R$ is Noetherian..

4. Let $R$ be a commutative ring with identity. If an ideal $I$ of $R$ is not finitely generated, then there is an infnite properly ascending chain of ideals CJC $\neq\neq$ $J_{1}\subset J_{2}\subset\cdots$ such that $J_k\subset I$ for all $k$ . The union of the $J_{k}$ need not be $I$ 5. Every homomorphic image of a left Noetherian [resp. Artinian]ring is left Noetherian [resp. Artinian] 6. A ring $R$ is left Noetherian [resp. Artinian] if and only if $Mat_nR$ nR $.nR$ is left Noetheriar [resp. Artinian] for every $n\geq1$ [nontrivial]. 7. An Artinian integral domain is a field. [Hinr: to find an inverse for $a\neq0$ ,consider $(a)\supset(a^2)\supset(a^3)\supset\cdots.\mathbf{J}$

## 2. PRIME AND PRIMARY IDEALS

Our main purpose is to study the ideal structure of certain commutative rings. The basic properties of prime ideals are developed. The radical of an ideal is introduced and primary ideals are defined. Finally primary decomposition of ideals is discussed. Except for Theorem 2.2, all rings are commutative.. We begin with some background material that will serve both as a motivation

and as a source of familiar examples of the concepts to be introduced. The motivation for much of this section arises from the study of principal ideal domains. In particular such a domain $D$ is a unique factorization domain (Theorem IIl.3.7). The unique factorization property of $D$ can be stated in terms of ideals: every

proper ideal of $D$ is a product of maximal (hence prime) ideals, which are determined uniquely up to order (Exercise Ill.3.5). Every nonzero prime ideal of $D$ is of the form $(p)$ with $p$ prime (= irreducible) by Theorem II1.3.4 and $( p) ^n$ = $( p^n)$ Consequently, every proper ideal $(a)$ of $D$ can be written uniquely (up to order) in the form
$$(a)=(p_{1}^{n_{1}})(p_{2}^{n_{2}})\cdots(p_{r}^{n_{r}})=(p_{1}^{n_{1}})\bigcap(p_{2}^{n_{2}})\bigcap\cdots\bigcap(p_{r}^{n_{r}}),$$

where each $n_i>0$ and the $p_i$ are distinct primes (Exercise IIl.3.5). Now an ideal $Q=(p^{n})$ $ip$ prime) has the property: ab e $Q$ and $a\neq Q$ imply $b^k\varepsilon Q$ for some $k$ (ExerciseIl1.3.5). Such an ideal is called primary. The preceding discussion shows that every ideal in a principal ideal domain is the intersection of a finite number of

------------------------------------------------------------------

1

primary ideals in a unique way.Furthermore there is an obvious connection between these primary ideals and the prime ideals of $D$ ; in fact every primary ideal $(p^{n})=(p)^{n}$ is a power of a prime ideal. In the approach just outlined the viewpoint has switched from consideration of

unique factorization of elements as products of primes in $D$ to a consideration of the "primary decomposition" of ideals in the principal ideal domain $D$ . We shall now investigate the "primary decomposition" of ideals in more general commutative rings (where, for instance, ideals need not be principal and primary ideals may not be powers of prime ideals). We begin with some facts about prime ideals.

Theorem 2.1. An ideal P $(\neq\mathbf{R})$ ) in a commutative ring R is prime ifandonly ifR - P is a multiplicative set.

PROOF. This is simply a restatement of Theorem III.2.15; see Definition HI1.4.1.

REMARK. The set of all prime ideals in a ring $R$ is called the spectrum of $R$

[

Theorem 2.2. If S is a multiplicative subset of a ring R which is disjoint from an ideal I of R, then there exists an ideal P which is maximal in the set of all ideals of R disjoint from S and containing I. Furthermore any such ideal P is prime

The theorem is frequently used in the case $I=0$

SKETCH OFPROOFOF2.2.The set S of all ideals of $R$ that are disjoint from $S$ and containIis nonempty since Ie S.Since $S\neq\varnothing$ (Definition III.4.1) every ideal in S is properly contained in R. S is partially ordered by inclusion. By Zorn's Lemma there is an ideal $P$ which is maximal in S. Let $A,B$ be ideals of $R$ such that $AB\subset P$ . If $A\not\subset P$ and $B\not\subset P$ , then each of the ideals $P+A$ and $P+B$ properly contains $P$ and hence must meet $S$ .Consequently, for some $p_i\in P$ ，ae $A$ ， $b\varepsilon B$

$$p_1+a=s_1\varepsilon S\quad\mathrm{and}\quad p_2+b=s_2\varepsilon S.$$

Thus $s_{1}s_{2}=p_{1}p_{2}+p_{1}b+ap_{2}+ab\varepsilon P+AB\subset P$ . This is a contradiction since $s_1s_2\varepsilon S$ and $S\cap P=\varnothing$ . Therefore $A\subset P$ or $B\subset P$ ，whence $P$ is prime.

1

1

Theorem 2.3.Let K be a subring of a commutative ring R. If $\mathbf{P}_{1},\ldots,\mathbf{P}_{\mathrm{n}}$ are prime ideals ofR such that KC P $\mathbf{K}\subset\mathbf{P}_{1}$ $P_2$ P2 $\mathcal{K}\subset\mathcal{P}_1\cup\mathcal{P}_2\cup\cdots\cup\mathcal{P}_n$, Pm, $P_n$, then $\mathbf{K}\subset\mathbf{P_i}$ for some i

REMARK. In the case $n\leq2$ , the following proof does not use the hypothesis that each $P_{i}$ is prime; the hypothesis is needed for $n>2$

PROOF OF 2.3.Assume $K\not\subset P_i$ for every $i$ . It then suffices to assume that $n>1$ and $n$ is minimal; that is, for each i, K U P,. For each $i$ there exists $K\not\subset\bigcup_{j\neq i}P$, ? $a_{i}\in K-\bigcup_{j\neq i}P$, . Since $K\subset\bigcup_iP_i$ , each $a_i\varepsilon P_i$ . The element $a_{1}+a_{2}a_{3}\cdots a_{n}$ lies in $K$

------------------------------------------------------------------

and hence in U P. Therefore $a_{1}+a_{2}a_{3}\cdots a_{n}=b_{j}$ with $b_j\varepsilon P_j.$ Pi $P_{j.}$ If$j>1$ , then $a_1\varepsilon P_j$, which is a contradiction. $\mathbf{If}j=\mathbf{1}$ , then $a_2a_3\cdots a_n\in P_1$ ,whence $a_i\varepsilon P_1$ P $P_1$ for some $i>1$ by Theorem II1.2.15. This also is a contradiction.

Proposition 2.4. IfR is a commututice ring with identity and P is an ideal which is maximal in the set of all ideals of R which are not finitely generated, then $P$ isprime

PROOF. Suppose ab e $P$ but $a\notin P$ and $b\neq P.$ Then $P+(a)$ and $P+(b)$ are ideals properly containing $P$ and therefore finitely generated (by maximality). Consequently $P+(a)=(p_{1}+r_{1}a,\ldots,p_{n}+r_{n}a)$ and $P+(b)=(p_1^{\prime}+r_1^{\prime}b,\ldots$, $p_{m}^{\prime}+r_{m}^{\prime}b)$ for some $p_{i},p_{i}^{\prime}\varepsilon P$ and $r_{i,r_{i}}^{\prime}\varepsilon R$ (see Theorems I11.2.5 and I11.2.6). If $J=\{r\varepsilon R\mid ra\varepsilon P\}$ ,then $J$ is an ideal. Since ab e $P$ $(p_{i}^{\prime}+r_{i}^{\prime}b)a=p_{i}^{\prime}a+r_{i}^{\prime}ab\varepsilon P$ for all $i$ ,whence $P\subseteq_{\not=}P+(b)\subset J.$ . By maximality, $J$ is finitely generated, say $J=$ $(j_1,\ldots,j_k)$ If $x\in P$ , then $x\in P+(a)$ and hence for some s:e R, x = ≥ s(p; + ria) $=\sum_{i=1}^{n}s_{i}p_{i}+\sum_{i=1}^{n}s_{i}r_{i}a$ Consequently, $(\sum_is_ir_i)a=x-\sum_is_ip_i\varepsilon P$ whencesr:e J Thus fr some i e $R,\sum_{i=1}^{n}s_{i}r_{i}=\sum_{i=1}^{k}t_{i}j_{i}$ and $x=\sum_{i=1}^{n}s_{i}p_{i}+\sum_{i=1}^{k}t_{i}j_{i}a$ Therefore, $P$ is generated by $p_{1},\ldots,p_{n},j_{1}a,\ldots,j_{k}a$ ,which is a contradiction. Thus $a\varepsilon P$ P $P$ or $b\varepsilon P$ and $P$ is prime by Theorem I11.2.15.

Definition 2.5. Ler I be an ideal in a commutative ring R. The radical (or nilradical) of I, denoted Rad I, is the ideal $\cap P$ , where the intersection is taken over all prime. ideals $P$ which contain I. If the set of prime ideals containing I is empty, then Rad I is defined to be R.

REMARKS. If $R$ has an identity, every ideal I $(\neq R)$ is contained in a maximal ideal $M$ by Theorem II1.2.18. Since $M\neq R$ and $M$ is necessarily prime by Theorem II1.2.19, Rad $I\neq R$ . Despite the inconsistency of terminology, the radical of the zero. ideal is sometimes called the nilradical or prime radical of the ring $R$

EXAMPLES. In any integral domain the zero ideal is prime; hence Rad 0=0 In the ring $\mathbf{Z}$ , Rad $(12)=(2)\cap(3)=(6)$ and Rad (4)=(2)=Ra ad(32)

Theorem 2.6. If I is an ideal in a commutative ring $R$ , then Rad $\mathbf{I}=\{\mathbf{r}\varepsilon\mathbf{R}\mid\mathbf{r}^{n}\varepsilon\mathbf{I}$ for some $n>0\}$

PROOF.If Rad $I=R$ ，then $\{r\varepsilon R\mid r^{n}\varepsilon I\}\subset$ Rad $I.$ Assume Rad $I\neq R$ .If $r^n\varepsilon I$ and $P$ is any prime ideal containing $I$ , then $r^n\varepsilon P$ whence $r\varepsilon P$ P $P$ by Theorem III.2.15. Thus $\left|r\varepsilon R\mid r^{n}\varepsilon I\right\}\subset$Rad $I.$ Conversely, if 1 E $R$ and $1^n\notin I$ for all $n>0$ , then $S=\{t^{n}+x\mid n\epsilon\mathbf{N}^{*};x\in I\}$ is a

multiplicative set such that $S\cap I=\varnothing$ By Theorem 2.2 there is a prime ideal $P$ dis joint from $S$ that contains $I.$ By construction, $1\notin P$ and hence 1年Rad $I$ .Thus $r\notin\{r\in R\mid r^n\in I\}$ implies 1年Rad $I$ ,whence Rad $I\subset\{r\varepsilon R\mid r^n\varepsilon I\}$ .

------------------------------------------------------------------

Theorem 2.7. IfI, $\mathbf{I} _{1}$, $\mathbf{I} _{2}, \ldots , \mathbf{I} _{n}$ are ideals in a cormmutative ring R, then:

(i $Rad(RadI)=RadI$
$$d\left(\mathbf{I}_{1}\mathbf{I}_{2}\cdots\mathbf{I}_{n}\right)=Rad\left(\bigcap_{j=1}^{n}\mathbf{I}_{j}\right)=\bigcap_{j=1}^{n}\:Rad\:\mathbf{I}_{j};$$
(ii) Rad $( \mathbf{I} ^{m}) = Rad$ $\mathbf{I}$

SKETCH OF PROOF. In each case we prove one of the two required containments. (i) If r ε Rad (Rad $I$ ), then $r^n$ ∈Rad $I$ and hence $r^{nm}$ = $( r^{n}) ^{m}$ $\varepsilon$ $I$ for some $n,m>0$ Therefoe, r e Rad $I$ and Rad(Rad I) C Rad I. (i) $Ifr\varepsilon\bigcap_j$ Rad $I_{j}$, then there are $m_{1},m_{2},\ldots,m_{n}>0$ mn > 0 $m_n>0$ such that $r^{mj}\varepsilon I_{j}$ for each $j$ . If $m=m_{1}+m_{2}+\cdots+m_{n}$ then $r^{m}=r^{m_{1}}r^{m_{2}}\cdots r^{m_{n}}\varepsilon I_{1}I_{2}\cdots I_{n}$ I2... In $I_1I_2\cdots I_n$ , whence Rad $I_j\subset$ Rad $(I_{1}\cdots I_{n})$ . Finally since $I_{1}\cdots I_{n}\subset\bigcap_{j}I_{i}$, we have $\operatorname{Rad}(I_1\cdots I_n)\subset\operatorname{Rad}(\bigcap_jI_i)$ . (i) is a special case of (ii). ■

Definition 2.8. An ideal $\mathcal{Q}(\neq\mathbf{R})$ in a commutativering $R$ is primary if for any a,be R:

$$ab\varepsilon QandatQ\Rightarrow b^n\varepsilon Qforsomen>0.$$

EXAMPLE. Every prime ideal is clearly primary. If $p$ is a prime integer and $n\geq2$ a positive integer, then $(p)^{n}=(p^{n})$ is a primary ideal in $\mathbf{Z}$ which is not prime (Exercise 17). In general, a power $P^n$ of a prime ideal $P$ need not be primary.

EXAMPLE. If $F$ is a feld, the ideal $(x,y)$ is maximal in $F[x,y]$ (Exercise 12) and therefore prime (Theorem III.2.19). Furthermore $(x,y)^{2}=(x^{2},xy,y^{2})\sum_{\not=}(x^{2},y)\sum_{\not=}(x,y)$ The ideal $(x^2,y)$ is primary and $(x,y)$ is the only (proper) prime ideal containing $(x^2,y)$ (Exercise 12). Hence the primary ideal $(x^2,y)$ is not a power of any prime ideal in $F[x,y]$

### In the rest of this section all rings have identity

Theorem 2.9. IfQis a primary ideal in a commutative ring R, then Rad Q is a prime ideal.

PROOF. Suppose ab ε Rad $Q$ and a 年Rad $Q$ . Then $a^nb^n=(ab)^n\varepsilon Q$ for some $n$ Since $a\notin$ Rad $Q,a^n\notin Q$ . Since $Q$ is a primary, there is an integer $m>0$ such that $(b^{n})^{m}\in Q$ ,whence $b$ εRad $Q$ . Therefore, Rad $Q$ is prime by Theorem II1.2.15.

In view of Theorem 2.9 we shall adopt the following terminology. If $Q$ is a primary ideal in a commutative ring $R$ , then the radical $P$ of $Q$ is called the associated prime ideal of $Q$ . One says that $Q$ is a primary ideal belonging to the prime $P$ or that $Q$ is primary for $P$ or that $Q$ is P-primary. For a given primary ideal $Q$ ,the associated prime ideal Rad $Q$ is clearly unique. However, a given prime ideal $P$ may be the associated prime of several different primary ideals.

EXAMPLE. If $p$ is a prime in $Z$ , then each of the primaryideals $(p^2),(p^3),\ldots$ belongs to the prime ideal $(p)$ . In the ring $\mathbb{Z}[x,y]$ the ideals (x²,y) $(x^2,y)$ $(x^{2},y),(x^{2},y^{2}),(x^{2},y^{3})$ .etc are all primary ideals belonging to the prime ideal $(x,y)$ (Exercise 13)

1

------------------------------------------------------------------

Theorem 2.10.Let Q and P beidealsin a cornmurative ring R.Then Qis primary fon P ifandonly if

(i $\mathbb{Q}\subset\mathbb{P}\subset Rad\mathbb{Q}$ and (i) ifab e $\mathbb{Q}$ and a 年Q , then b e P.

SKETCH OF PROOF. Suppose (i) and (i) hold. If ab ε $Q$ with $a\notin Q$ ,then be $P\subset$ Rad $Q$ ，whence $b^n\varepsilon Q$ for some $n>0$ .Therefore $Q$ is primary. To show that $Q$ is primary for $P$ weneed onlyshow $P=$Rad $Q$ Q $Q$ . By (i), $P\subset$ Rad $Q$ If $b$ εRad $Q$ ,let $n$ be the least integer such that $b^n\varepsilon Q$ . If $n=1$ ， $b$ $:Q\subset P$ . If $n>1$ , then $b^{n-1}b=b^{n}\varepsilon Q$ with $h^{n-1}\notin Q$ by the minimality of $n.$ By (ii), $b\varepsilon P$ Thus $b$ ε Rad $Q$ implies $b\varepsilon P$ ,whence Rad $Q\subset P$ .The converse implication is easy.

Theorem 2.11. I $\mathrm{^{\cdot}Q_1,Q_2,}$ $\mathrm{^{\cdot}Q_1,Q_2,}$ $f^{\prime}Q_{1},Q_{2},\ldots,Q_{n}$ Qn $Q_n$ are primary ideals in a commutative ring R, all of which er prinary fo h prinm idelP, hen $\bigcap_{i=1}^nQ_i$ isdlsoa prinar idea blonging to P.

PROOF. Let $Q=\bigcap_{i=1}^nQ_i.$ Then by Theorem 2.7(i), Rad $Q=\bigcap_{i=1}^{n}$ Rad $Q_i$ $=\bigcap_{i=1}^nP=P$ in particular, $Q\subset P\subset\mathbb{R}$ ad $Q$ If abe $Q$ and $a\notin Q$ , then ab e $Q_{i}$ and $a\notin Q_i$ for some i. Since $Q_{i}$ is $P$ -primary, $b\varepsilon P$ by Theorem 2.10(ii). Consequently, $Q$ itself is $P$ -primary by Theorem 2.10.

Definition 2.12. An ideal I in a commutative ring R has $a$ primary decomposition if I = Q $\mathbf{I}=\mathbf{Q}_{\mathbf{l}}$ $\mathbb{Q}_2$ Qz $\mathbf{I}=\mathbf{Q}_1\cap\mathbf{Q}_2\cap\ldots\cap\mathbf{Q}_n$ with each $Q_{i}$ primary. If no $\mathbf{Q}_{\mathrm{i}}$ contains $Q_{\mathrm{l}}$ Qi $Q_1\cap\cdots\cap Q_{i-1}\cap$ $Q_{i+1}\cap\cdots\cap Q_n$ and theradicalsof the $\mathbf{Q_i}$ are all distinct,then the prinary decomposition is said to be reduced (or irredundant)

Theorem 2.13. Let I be an ideal in a comnutative ring R. IfI has a primary decom position, then I has a reduced primary decomposition

PROOF. If $I=Q_{1}\cap\ldots\cap Q_{n}\left(Q_{i}\right.$ Qn $Q_n$ Qi $Q_{i}$ primary) and some $Q_{i}$ contains $Q_1\cap\ldots\cap$ $Q_{i-1}\cap Q_{i+1}\cap\cdots\cap Q_n$ , then $I=Q_{1}\cap\cdots\cap Q_{i-1}\cap Q_{i+1}\cap\cdots\cap Q_{n}$ is also a primary decomposition. By thus eliminating the superfluous $Q_{i}$ (and reindexing) we have $I=Q_{1}\cap\cdots\cap Q_{k}$ Qk $Q_k$ with no $Q_{i}$ containing the intersection of the other $Q_{i}$ . Let $P_{1},\ldots,P_{r}$ be the distinct prime ideals in the set Rad $Q_{\mathrm{i}}$ Q $Q_1,\ldots$ ,Rad $Q_k\}$ .Let $Q_{i}^{\prime}(\mathbf{l}\leq i\leq r)$ be the intersection of all the $Q$ 's that belong to the prime $P_i$ .By Theorem 2.11 each $Q_{i}^{\prime}$ is primary for $P_{i}$ . Clearly no $Q_{i}^{\prime}$ contains the intersection of all the other $Q_{i}^{\prime}$ . Therefore, I = , Q: = , Qi', whence $I$ has a reduced primary decomposition.

At this point there are two obvious questions to ask. Which ideals have a reduced primary decomposition? Is a reduced primary decomposition unique in any way? Both questions will be answered in a more general setting in the next section (Theorems 3.5 and 3.6).

------------------------------------------------------------------

### EXERCISES

Note: $R$ is always a commutative ring.

1. Let $R$ be a commutative Artinian ring with identity.. (a) Every prime ideal of $R$ is maximal [Hinr: Theorems II1.2.16 and I11.2.20 and Exercises 1.5 and 1.7]. (b) $R$ has only a finite number of distinct prime ideals. 2.If $R$ has an identity and $\{P_i\mid i\in I\}$ is a nonemptyfamily of prime ideals of $R$ which is linearly ordered by inclusion, then $\bigcup_{ieI}P_i$ and $\bigcap_{i\in I}P_{i}$ are prime ideals. 3. If P,P2 $P_1,P_2$, $P_{1},P_{2},\ldots,P_{n}$ are prime ideals in $R$ and Iis a ny ideal such that $I\not\subset P_i$ for all i then there exists r e I such that $r\notin P_i$ for all i. 4. If $R$ has an identity and $M_1,\ldots,M_r$ M, $M_r$ are distinct maximal ideals in $R$ ,then show that $M_1\cap M_2\cap\ldots\cap M_r=M_1M_2\cdots M_r$ . Is this true if "maximal" is replaced by "prime"? 5. If $R$ has an identity, then the set of all zero divisors of $R$ is a union of prime ideals. 6. Let $R$ have an identity. A prime ideal $P$ in $R$ is called a minimal prime ideal of the ideal $I$ if $I\subset P$ and there is no prime ideal $P^{\prime}$ such that $I\subset P^{\prime}\subsetneq P$ (a) If an ideal $I$ of $R$ is contained in a prime ideal $P$ of $R$ , then $P$ contains a minimal prime ideal of I. [Hint: Zornify the set of all prime ideals $P^{\prime}$ such that $I\subset P^{\prime}\subset P$ (b) Every proper ideal possesses at least one minimal prime ideal. 7. The radical of an ideal Iin a ring $R$ with identity is the intersection of all its minimal prime ideals [see Exercise 6]. 8.If $R$ has an identity, $I$ is an ideal and $J$ is a finitely generated ideal such that $J\subset$ Rad I, then there exists a positive integer $n$ such that $J^n\subset I$ 9. What is the radical of the zero ideal in $Z_n^{\cdot}$ 10. If $S$ is a multiplicative subset of a commutative ring $R$ and $I$ is an ideal of $R$ then $S^{-1}($Rad $I)=$Rad $(S^-1I)$ (S-1I) $(S^{-1}I)$ in the ring $S^{-1}R$ 11.Let $Q\left(\neq R\right)$ be an ideal in $R$ . Then $Q$ is primary if and only if every zero divisor in $R/Q$ is nilpotent (see Exercise II1.1.12) 12. If $F$ is a feld, then: (a) the ideal $(x,y)$ is maximal in $F[x,y]$ (b) $(x,y)^{2}=\left(x^{2},xy,y^{2}\right)\subseteq_{\not=}(x^{2},y)\subsetneq(x,y);$ (c) the ideal $(x^2,y)$ is primary and the only proper prime ideal containing it is $(x,y)$ 13. In the ring $\mathbf{Z}[x,y]$ the ideals $(x^2,y),(x^2,y^2),(x^2,y^3),\ldots,(x^i,y^j),\ldots$ . are all primary ideals belonging to the prime ideal $(x,y)$ 14. The conclusion of Theorem 2.11 is false if infinite intersections are allowed

[Hint: consider Z.]

------------------------------------------------------------------

15. Let $f{:}R\to S$ be an epimorphism of commutative rings with identity. If $J$ is an ideal of $S$ , let $I=f^{-1}(J)$ (a) Then $I$ is primary in $R$ if and only if $J$ is primary in $S$

(b) If $J$ is primary for $P$ , then $I$ is primary for the prime ideal $f^{-1}(P)$

16. Find a reduced primary decomposition for the ideal $I=(x^{2},xy,2)$ in $\mathbb{Z}[x,y]$ and determine the associated primes of the primaryideals appearing in this decomposition.

17. (a) If $p$ is prime and $n>1$ , then $(p^n)$ is a primary, but not a prime ideal of $Z$ (b) Obtain a reduced primary decomposition of the ideal (12600) in Z.

18. If $F$ is a field and $I$ is the ideal $(x^2,xy)$ in $F[x,y].$ , then there are at least three distinct reduced primary decompositions of $I.$ ; three such are :

$$I=(x)\cap(x^{2},y);(\mathrm{ii})\:I=(x)\cap(x^{2},x+y);(\mathrm{iii})\:I=(x)\cap(x^{2},xy,y^{2}).$$

19. (a) In the ring $\mathbb{Z}[x]$ , the following are primary decompositions:.

$$(4,2x,x^{2})=(4,x)\cap(2,x^{2});\\(9,3x+3)=(3)\cap(9,x+1).$$

(b) Are the primary decompositions of part (a) reduced?

## 3. PRIMARY DECOMPOSITION

We shall extend the results of Section 2 in a natural way to modules.A unique ness statement for reduced primary decompositions (of submodules or ideals) is proved as well as the fact that every submodule [ideal] of a Noetherian module[ring] has a primary decomposition. Throughout this section all rings are commutarive with identity and all modules are unitary..

Definition 3.1.Let R be a cornmutative ring with identity and B an R-inodule.A submoduleA $(\neq\mathbf{B})$ is primary provided tha

r e R, b \$A and rb e A $\Rightarrow$ rB C A for some positive integer n.

EXAMPLE. Consider the ring $R$ as an $R$ -module and let $Q$ be a primary ideal (and hence a submodule) of $R$ If rbe $Q$ with r E $R$ and $b\notin Q$ , then rn $r^n$ $r^n\varepsilon Q$ Q $Q$ for some $n$ Since $Q$ is an ideal, this implies $r^nR\subset Q$ .Hence $Q$ is a primary submodule of the module $R.$ Conversely every primary submodule of $R$ is a primary ideal (Exercise 1). Therefore, all results about primary submodules apply to primary ideals as well.

Theorem 3.2. Let R be a commutatice ring with identity and A a primary submodule of an R-module B. Then $\mathbf{Q} _{\mathrm{A} }= \{ \mathbf{r} \varepsilon \mathbf{R} \mid \mathbf{r} \mathbf{B} \subset \mathbf{A} \}$ is a primury ideal in R

PROOF. Since $A\neq B$ ， $1_R\notin Q_A$ ,whence $Q_{A}\neq R$ . If rse $Q_{A}$ and $s\notin Q_A$ ,then $s\boldsymbol{B}\not\subset A$ .Consequently, for some $b\in B,sb\notin A$ but $r(sb)\in A$ .Since $A$ is primary $r^nB\subset A$ for some $n$ ; that is, $r^n\varepsilon Q_{.4}$ . Therefore, $Q_{A}$ is primary.

------------------------------------------------------------------

Let $R,A,B.$ ,and $Q_A$ be as in Theorem 3.2. By Theorem 2.9 Rad $Q_{A}=P_{1}$ is a prime ideal. It is easy to see that $P_{\mathrm{l}}=\{r\varepsilon R\mid r^{n}B\subset A$ for some $n>0\}$ .A primary submodule $A$ ofa module $B$ is said to belong to a prime ideal $P$ or to be a P-primary submodule of $B$ if $P=\mathbf{R}$ad $Q_{A}=\{r\varepsilon R\mid r^{n}B\subset A$ for some $n>0\}$ . This terminology is consistent with that used for ideals. In particular, if $J$ is a primary ideal, then $Q_J=J$

Definition 3.3. Let R be a commutative ring with identity and B an R-module. A sub-. module C of B has a primary decomposition $if\mathbf{C}=\mathbf{A}_{1}\cap\mathbf{A}_{2}\cap\cdots\cap\mathbf{A}_{n}$ , with each $\mathbf{A_i}$ a $P_{\mathrm{i}}$ -primary submodule of B for some prime ideal. $P_i$ of R. If no $\mathbf{A_{i}}$ contains $\mathbf{A}_1\cap\cdots\cap\mathbf{A}_{i-1}\cap\mathbf{A}_{i+1}\cap\cdots\cap\mathbf{A}_n$ Ai+1 $A_{\mathrm{i}+1}$ and if the ideals $\mathbf{P}_1,\ldots,\mathbf{P}_n$ are all distinct, then the primary decomposition is said to be reduced..

Again the terminology here is consistentwith that used for ideals.If $C,A_i$ and $P_i$ are as in the definition and $P_i\not\subset P_i$ for allj $i\neq i$ , then $P_i$ is said to be an isolated prime ideal of $C$ . In other words, $P_{i}$ is isolated if it is minimal in the set $\{P_1,\ldots,P_n\}$ .If $P_i$ is not isolated it is said to be embedded..

Theorem 3.4. Let R be a commutative ring with identity and B an R-module. If a submodule C of B has a primary decomposition, then C has a reduced primary decom position.

SKETCH OF PROOF. The proofis similar to that of Theorem 2.13. Note that if $Q_A=\{r\varepsilon R\mid rB\subset A\}$ , then , Qa; = Qna. Thus if $A_1,\ldots,A$, are all $P$ -primary submodules for the same prime ideal $P$ ,then $\bigcap_{i=1}^rA_i$ is also $P$ primary by Theorem 2.11.

Theorem 3.5.LerR be a commutativeringwith identity and Ban R-module.Ler $\mathcal{C}(\neq\mathcal{B})$ be a submodule of B with two reduced primary decompositions,.

$$\mathbf{A}_1\cap\mathbf{A}_2\cap\cdots\cap\mathbf{A}_k=\mathbf{C}=\mathbf{A}_1^{\prime}\cap\mathbf{A}_2^{\prime}\cap\cdots\cap\mathbf{A}_8^{\prime},$$

where $\mathbf{A}_{\mathrm{i}}$ is $P_{\mathrm{i}}$ -primary and $\mathbf{A_j}^{\prime}$ is $P_{\mathrm{j}}^{\prime}$ -primary. Then $k=s$ and(afrer reordering if necessary) P;= P' $\mathbf{P_{i}}=\mathbf{P_{i}^{\prime}}$ $\mathbf{P} _{\mathrm{i} }= \mathbf{P} _{\mathrm{i} }^{\prime }fo\mathbf{r} \mathbf{i} = \mathbf{1} , 2, \ldots , \mathbf{k}$ . Furthermore $ifA_i$ and $\mathbf{A}_{\mathrm{i}}^{\prime}$ both are $P_{\mathrm{i}}$ -primary and $P_i$ is an isolated prime, then $\mathbf{A_{i}}=\mathbf{A_{i}}^{\prime}$

PROOF.By changing notation if necessary we may assume that $P_{1}$ is maximal in the set $\{P_{\mathrm{l}},\ldots,P_{k},P_{\mathrm{l}}^{\prime},\ldots,P_{\mathrm{s}}^{\prime}\}$ . We shall first show that $P_{1}=P_{i}^{\prime}$ for some $j$ Suppose, on the contrary, that $P_{1}\neq P_{i}^{\prime}$ for $j=1,2,\ldots,s$ .Since $P_{1}$ is maximal we have $P_1\not\subset P_i^{\prime}$ for $j=1,2,\ldots,s$ . Since the first decomposition is reduced.. $P_{1},P_{2},\ldots,P_{k}$ Pk $P_{k}$ are distinct, whence $P_1\not\subset P_i$ for $i=2,3,\ldots,k.$ By the contrapositive of Theorem 2.3, $P_1\not\subset P_2$ U...U $P_k$ U $P_{1}^{\prime}$ U...U $P_{s}^{\prime}$ . Consequently, there exists $r\varepsilon P_1$ P $P_{1}$ such that $r\notin P_{\mathrm{i}}(i\geq2)$ and $r\notin P_{i}^{\prime}(j\geq1)$ .Since $A_{1}$ is $P_{1}$ -primary $r^nB\subset A_1$ for some positive integer $n$ . Let $C^{*}$ be the submodule $\{x\in B\mid r^{n}x\in C\}$ .If $k=1$ ,then $C=A_{1}$ and hence $C^{*}=B$ .We claim that for $k\geq1$ ， $C^{*}=C$ and for $k>1$

------------------------------------------------------------------

$C^{*}=A_{2}\cap\ldots\cap A_{k}$ Ak $A_k$ . Now it is easy to see that $A_2\cap\cdots\cap A_k\subset C^*$ and $A_1^{\prime}\cap A_2^{\prime}\cap\ldots\cap A_s^{\prime}=C\subset C^*$ A' = C C C* $A_s^{\prime}=C\subset C^*$ for $k>1$ .Conversely, if $x\notin A_i\left(i\geq2\right)$ ,then $r^nx\notin A_i$ (otherwise $r^n\varepsilon P_i$ since $A_i$ is $P_i$ -primary, whence r E $P_{i}$ since $P_{i}$ is prime). Consequently, $r^nx\notin C$ ，whence $x\notin C^*$ . Therefore, $C^*\subset A_2\cap\cdots\cap A_k$ Ak $A_k$ for $k>1$ .A similar argument shows that $C^{*}\subset A_{1}^{\prime}\cap A_{2}^{\prime}\cap\cdots\cap A_{s}^{\prime}=C$ ,so that $C^{*}=C$ $(k\geq1)$ and $C^{*}=A_{2}\cap\cdots\cap A_{k}(k>1)$ .1f $k=1$ , then as observed above $C^{*}=B$ Thus $C=C^{*}=B$ , which contradicts the fact that $C\neq B$ . If $k>1$ ,then

$$A_2\cap\cdots\cap A_k=C^*=C=A_1\cap A_2\cap\cdots\cap A_k,$$

whence $A_2\cap\cdots\cap A_k\subset A_1$ . This conclusion contradicts the fact that the first decomposition is reduced. Thus the assumption that $P_{1}\neq P_{i}^{\prime}$ for every $j$ always leads to a contradiction. Therefore $P_{1}=P_{i}^{\prime}$ for some $j$ $i$, say $j=1$

The proof now proceeds by induction on $k$ . If $k=1$ , then we claim $s=1$ also. For if $s>1$ , then the argument above with $P_{1}=P_{1}^{\prime}$ and the roles of $A_i,A_i^{\prime}$ reversed) shows that $B$ = $C^{* }$ = $A_{2}^{\prime }$ $\cap \cdots \cap$ $A_{s}^{\prime }$ ,whence $A_i^{\prime}=B$ for some $j\geq2$ . Thus the second decomposition of $C$ is not reduced, a contradiction. Therefore, $s=1=k$ and $A_1=C=A_1^{\prime}$ . Now assume that $k>1$ and the theorem is true for all submodules that have a reduced primary decomposition of less than $k$ terms. The argument of the preceding paragraph (with $P_{1}=P_{1}^{\prime}$ ）shows that for $k>1$ the submodule $C^*$ has two reduced primary decompositions:

$$A_2\cap A_3\cap\cdots\cap A_k=C^*=A_2^{\prime}\cap\cdots\cap A_s^{\prime}.$$

By induction $k=s.$ , and (after reindexing) $P_{i}=P_{i}^{\prime}$ for all $i$ . This completes the induction and the proof of the first part of the theorem.

Suppose $A_i$ and $A_i^{\prime}$ are both $P_i$ -primary and $P_{i}$ is an isolated prime. For convenience of notation assume $i=1$ . Since $P_{1}$ is isolated, there exists for each $j\geq2$ $r_{j}\varepsilon P_{i}-P_{\mathrm{l}}.$ Then $t=r_{2}r_{3}\cdots r_{k}\in P_{j}$ for $j>1$ ,but $1\notin P_1$ . Since $A_j$ is $P_i$ -primary, there exists for each $j\geq2$ an integer $n_j$ such that $I^{ni}B\subset A_{j}$ . Similarly, for each $j\geq2$ there is an $m_{j}$ such that $t^{mi}B\subset A_i^{\prime}$ .Let $n=\max{\{n_{2},\ldots,n_{k},m_{2},\ldots,m_{k}\}}$ ; then $t^nB\subset A_j$ and $\iota^nB\subset A_j^{\prime}$ for all $j\geq2.$ Let $D$ be the submodule $\{x\in B\mid t^{n}x\in C\}$ .To complete theuniqueness proof we shall show $A_{\mathrm{l}}=D=A_{\mathrm{l}}^{\prime}$ . If $x\in A_1$ ，then $t^{n}x\varepsilon A_{1}\cap A_{2}\cap\cdots\cap A_{k}=C$ Ak= C $A_k=C$ ,whence $x\varepsilon D$ D $D$ and $A_1\subset D.$If$x\in D$ ,then $t^nx\in C\subset A_1$ Since $A_1$ is $P_{1}$ -primary and $1\notin P_1$, we have $t^mB\not\subset A_1$ , for all $m>0$ .Since $A_1$ is primary, we must have $x\in A_1$ $A_1$ A , (otherwise $I^nX$ E $A_1$ and $x\notin A_1$ imply $t^{nq}B\subset A_1$ for some positive $q$ by Definition 2.1). Hence $D=A_{1}$ . An identical argument shows that $A_{1}^{\prime}=D$ Therefore, $A_{1}=A_{1}^{\prime}$ .■

Thus far we have worked with a module that was assumed to have a primary decomposition. Now we give a partial answer to the question: which modules[ideals] have primary decompositions?

Theorem 3.6. Let R be a commutative ring with identity and B an R-module satisfy ing the ascending chuin condition on submodules. Then every submodule A. $(\neq\mathbf{B})$ hasa reduced primary decomposition. In particular, every submodule A. $(\neq\mathbf{B})$ of a finitely generated module B over a commutative Noetheriun ring R and every ideal $(\neq\mathbf{R}$ of R has a reduced primury decomposition

------------------------------------------------------------------

PROOF OF 3.6. Let S be the set of all submodules of $B$ that do nor have a primary decomposition. Clearly no primary submodule is in S. We must show that S is actually empty.If S is nonempty,then S contains a maximal element $C$ by Theorem 1.4. Since $C$ is not primary, there exist $r\varepsilon R$ and $b\in B-C$ such that $rb\varepsilon C$ but $r^nB\not\subset C$ for all $n>0$ Let $B_{n}=\{x\in B\mid r^{n}x\in C\}$ . Then each $B_n$ is a submodule of $B$ and $B_1\subset B_2\subset B_3\subset\cdots$ .By hypothesis there exists $k>0$ such that $B_{i}=B_{k}$ for $i\geq k$ . Let $D$ be the submodule $\left\{x\in B\mid x=r^{k}y+c\right.$ for some $y\in B,c\in C\}$ . Clearly $C\subset B_k\cap D$ .Conversely, if $x\in B_{k}\cap D$ $D$ D ，then $x=r^{k}y+c$ and $r^kx\varepsilon C$ ,whence $r^{2k}\nu=r^{k}(r^{k}y)=r^{k}(x-c)=r^{k}x-r^{k}c\varepsilon C$ . Therefore, $y\in B_{2k}=B_{k}$ . Consequently $r^ky\varepsilon C$ C $C$ and hence $x=r^{k}y+c\varepsilon C$ . Therefore $B_{k}$ n $D\subset C$ ,whence Bk $B_k$ $B_k\cap D=C$ Now $C\neq B_{k}\neq B$ and $C\neq D\neq B$ since $b\in B_{k}-C$ and $r^kB\not\subset C$ .By the maximality of $C$ in S, $B_k$ and $D$ must have primary decompositions. Thus $C$ has a primary decomposition, which is a contradiction. Therefore S is empty and every submodule has a primary decomposition. Consequently, every submodule has a reduced primary decomposition by Theorem 3.4. The last statement of the theorem is now an immediate consequence of Theorems 1.8 and 1.9. 

## EXERCISES

Note: Unless otherwise stated $R$ is always a commutative ring with identity

1. Consider the ring $R$ as an $R$ -module. If $Q$ is a primary submodule of $R$ ,then $Q$ is a primary ideal. 2. (a) Let $f:B\to D$ be an $R$ -module epimorphism and $C(\neq D)$ a submodule of $D$ Then $C$ is a primary submodule of $D$ if and onlyif $f^{-1}(C)$ is a primary submodule of $B$ (b) If $C$ and $f^{-1}(C)$ are primary,then they both belong to the same prinne ideal $P$ 3. If $A\left(\neq B\right)$ is a submodule of the $R$ -module $B$ and $P$ is an ideal of $R$ such that (i) $rx\varepsilon A$ and $x\notin A\left(r\varepsilon R,x\in B\right)\Rightarrow r\varepsilon P$ ;and (i) r $\varepsilon P\Rightarrow r^{n}B\subset A$ for some positive integer $n$ ， then $P$ is a prime ideal and $A$ is a $P$ -primary submodule of $B$ 4. If $A$ is a $P$ -primary submodule of an $R$ -module $B$ and $rx\in A\left(r\varepsilon R,x\in B\right)$ ,ther either $r\varepsilon P$ or $x\in A$ 5.If $A$ is a $P$ -primary submodule of an $R$ -module $B$ and $C$ is any submodule of $B$ such that $C\not\subset A$ then $\{r\in R\mid rC\subset A\}$ is a $P$ -primary ideal. [Hinr: Exercise 3 may be helpful.] 6. Let $A$ be a $P$ -primary submodule of the $R$ -module $B$ and let $C$ be any submodule of $B$ such that $C\not\subset A$ . Then $A\cap C$ C $C$ is a $P$ -primary submodule of $C$ . [Hint: Exer cise 3 may be helpful.] 7. If $B$ is an $R$ -module and $x\in B$ ,the annihilator of $x$ ，denoted ann $x$, is $\{r\varepsilon R\mid rx=0\}$ . Show that ann $x$ is an ideal. 8. If $B\neq0$ is an $R$ -module and $P$ is maximal in the set of ideals ↑ann $x\mid0\neq x\in B\}$ (see Exercise 7), then $P$ is prime.

------------------------------------------------------------------



------------------------------------------------------------------

satisfies the maximum condition on (two-sided) ideals (Definition 1.2 and Theorem i .4), or equivalently if and only if every ideal of $R$ is finitely generated (Theorem 1.9). As a matter of fact, one need only consider prime ideals of $R$

Proposition 4.1. (1. S. Cohen). A commutative ring R with identity is Noetherian if and only if every prime ideal of R is finitely generated.

SKETCH OF PROOF. $(\Leftarrow)$ Let S be the set of all ideals of $R$ which are not finitely generated. If S is nonempty, then use Zorn's Lemma to find a maximal element $P$ of s. $P$ is prime by Proposition 2.4 and hence finitely generated by hypothesis This is a contradiction unless $S=\varnothing$ . Therefore, $R$ is Noetherian by Theorem 1.9.

We now develop the preliminaries needed to prove the Krull Intersection Theorem.If $B$ is a module over a commutative ring $R$ ,then it is easy to see that $I=\{r\in R\mid rb=0$ for all $b\in B\}$ is an ideal of $R$ .The ideal / is called the annihilator of $B$ in $R$

Lemma 4.2. Let B be a finitely generated module over a commutative ring R with identity and letI be the annihilator ofB inR.ThenB satisfiesthe ascending[resp. descending] chain condition on submodules if and only if R/I is a Noetherian [resp. Artinian] ring.

SKETCH OF PROOF.Let $B$ be generated by $b_1,\ldots,b_n$ bn $b_n$ and assume $B$ satisfies the ascending chain condition. Then $B=Rb_{1}+\cdots+Rb_{n}$ by Theorem IV.1.5. Consequently, $I=I_1$ I=I $I=I_1\cap I_2\cap\ldots\cap I_n$, where $I_{i}$ is the annihilator of the submodule $Rb_i$ By Corollary Ill.2.27 there is a monomorphism of rings $\theta:R/I\to R/I_1\times\cdots\times R/I_n$ It is easy to see that $\theta$ is also an $R$ -module monomorphism. Verify that for each $j$ the map $R/I_i\to Rb_i$ given by $r+I_{j}\mapsto rb_{j}$ is an isomorphism of $R$ -modules. Since the submodule $Rb_1$ of $B$ necessarily satisfies the ascending chain condition, so does $R/I_i$ Therefore, $R/I_1\oplus\cdots\oplus R/I_n$ satisfies the ascending chain condition on $R$ -submodules by Corollary 1.7. Consequently its submodule Im $\theta\cong R/I$ satisfies the ascending chain condition on $R$ -submodules. But every ideal of the ring $R/I$ is an $R$ -submodule of $R/I.$ Therefore, $R/I$ is Noetherian Conversely suppose $R/I$ is Noetherian. Verify that $B$ is an $R/I$ -module with

$(r+I)b=rb$ and that the $R/I$ submodules of $B$ are precisely the $R$ -submodules Consequently, $B$ satisfies the ascending chain condition by Theorem 1.8.

Recall that if $I$ is any ideal in a ring $R$ with identity and $B$ is an $R$ -module, then $IB=\left\{\sum_{i=1}^{n}r_{i}b_{i}\mid r_{i}\in I;b_{i}\varepsilon B;n\varepsilon N^{*}\right\}$ isa submoul of $B$ (Exeris IV.1.).

Lemma 4.3. Ler P be a prime ideal in a commutative ring R with identity. $If\mathbf{C}$ isa P-primary submodule of the Noetherian R-module A, then there exists a positive integer m suchthat $\mathbf{P} ^{\mathrm{m} }\mathbf{A} \subset \mathbf{C}$

------------------------------------------------------------------



------------------------------------------------------------------

PROOF OF 4.5. $\mathrm{(i)\Rightarrow(ii)}$ if $j\varepsilon J$ and $1_R-j$ is not a unit, then the ideal $(1_{R}-j)$ is not $R$ itself (Theorem Il1.3.2) and therefore is contained in a maximal ideal $M\neq R$ (Theorem I11.2.18). But $\mathbf{1}_{R}-j\varepsilon M$ and $j\varepsilon J\subset M$ imply that $1_R\varepsilon M$ which is a contradiction. Therefore, $1_{R^{*}}-j$ is a unit. $(\mathrm{ii})\Rightarrow(\mathrm{iii})$ Since $A$ is finitely generated, there must be a minimal generating set

$X=\{a_{1},\ldots,a_{n}\}$ of $A$ (that is, no proper subset of $X$ generates $A$ 0.If $A\neq0$ ,then $a_1\neq0$ by minimality. Since $JA=A$ ， $a_{1}=j_{1}a_{1}+j_{2}a_{2}+\cdots+j_{n}a_{n}\:(j_{i}\varepsilon J)$ whence $\mathbf{1}_{R}a_{1}=a_{1}$ so that $(1_{R}-j_{1})a_{1}=0$ if $n=1$ and

$$(1_R-j_1)a_1=j_2a_2+\cdots+j_na_n\quad\mathrm{if}\quad n>1.$$

Since $\mathbf{1}_{R}-j_{1}$ is a unit in l $R,\:a_{1}=(1_{R}-j_{1})^{-1}(1_{R}-j_{1})a_{1}$ . Thus if $n=1$ , then $a_{1}=0$ which is a contradiction. If $n>1$ , then $a_1$ is a linear combination of $a_2,\ldots,a_n$ Consequently, $\{a_2,\ldots,a_n\}$ generates $A$ , which contradicts the choice of $X$ $(\mathrm{iii})\Rightarrow(\mathrm{iv})$ Verify that the quotient module $A/B$ is such that $J(A/B)=A/B$

whence $A/B=0$ and $A=B$ by (iii). $(\mathbf{iv})\Rightarrow(\mathbf{i})$ If $M$ is any maximal ideal, then the ideai $JR+M$ contains $M$ .But

$JR+M\neq R$ (otherwise) $R\:=\:M$ by (iv)). Consequently, $JR+M=M$ by maximality. Therefore $J=JR\subset M$ .

We now give several applications of Nakayama's Lemma, beginning with a result that is the starting point of the theory of completions.

Proposition 4.6.Let J bean ideal in a commutative ringR with identity.Then J is contained in every maximal ideal of R if and only if for every R-module A satisfying the aserding hain onditonon submodles $\bigcap_{n=1}^\infty$JnA=0.

PROOF. $(\Longrightarrow)$ If B = JA, then $JB=B$ by Theorem 4.4. Since $B$ is finitely generated by Theorem 1.9, $B=0$ by Nakayama's Lemma 4.5. $(\Leftarrow)$ We may assume $R\neq0$ . If $M$ is any maximal ideal of $R$ ,then $M\neq R$ and

$A=R/M$ is a nonzero $R$ -module that has no proper submodules (Theorem IV.1.10) Thus $A$ trivially satisfies the ascending chain condition, whence $\bigcap J^nA=0$ by hyn pothesis. Since $JA$ is a submodule of $A$ ,either $JA=A$ or $JA=0$ .If $JA=A$ ,then $J^nA=A$ for all $n$ . Consequently, J"A = A ≠ O, which is a contradiction. Hence $JA=0$ .But $0=\boldsymbol{J}A=\boldsymbol{J}(R/M)$ implies that $J\subset JR\subset M$ .■

Corollary 4.7. IfRisa Noetherian localring with maximalideal M, then $\bigcap_{n=1}M^n=0$

PROOF. If $J=M$ and $A=R$ ,then $J^{n}A\:=\:M^{n}$ ; apply Proposition 4.6.

Proposition 4.8. If R is alocal ring, then every finitely generated projectice R-mod ule is free.

------------------------------------------------------------------

Actually a much stronger result due to I. Kaplansky [63] is true, namely: every projective module over a (not necessarily commutative) local ring is free.

PROOF OF 4.8. If $P$ is a finitely generated projective $R$ -module, then by Corollary IV.2.2 there exists a free $R$ -module $F$ with a finite basis and an epimorphism $\pi:F\to P$ . Among all the free. $R$ -modules $F$ with this property choose one with a basis $\{x_{1},x_{2},\ldots,x_{n}\}$ that has a minimal number of elements. Since $\pi$ is an epimor phism $\{\pi(x_1),\ldots,\pi(x_n)\}$ necessarily generate $P$ . We shall first show that $K=$Ker $\pi$ is contained in $MF$ ,where $M$ is the unique maximal ideal of $R$ . If $K\not\subset MF$ , then there exists $k\varepsilon K$ with $k\notin MF$ Now $k=r_{1}x_{1}+r_{2}x_{2}+\cdots+r_{n}x_{n}$ with $r_i\varepsilon R$ uniquely determined. Since $k\notin$ k# $k\notin MF$ , some $r_i$ , say $r_1$ , is not an element of $M$ .By Theorem III.4.13, $r_1$ is a unit, whence $x_{1}-r_{1}^{-1}k=-r_{1}^{-1}r_{2}x_{2}-\cdots-r_{1}^{-1}r_{n}x_{n}$ .Consequently,since k Ker $\pi$ $\pi(x_{1})=\pi(x_{1}-r_{1}^{-1}k)=\pi\left(\sum_{i=2}^{n}-r_{1}^{-1}r_{i}x_{i}\right)=\sum_{i=2}^{n}-r_{1}r_{i}\pi(x_{i})$ Therefore, $\{\pi(x_2),\ldots,\pi(x_n)\}$ generates $P$ . Thus if $F^{\prime}$ is thefree submodule of $F$ with basis $\{x_2,\ldots,x_n\}$ and $\pi^{\prime}:F^{\prime}\dashrightarrow P$ the restriction of $\pi$ to $F^{\prime}$ ,then $\pi^{\prime}$ is an epimor phism. This contradicts the choice of $F$ as having a basis of minimal cardinality Hence $K\subset MF$ Since $0\to K\overset{\mathsf{E}}{\operatorname*{\rightarrow}}F\overset{\mathsf{T}}{\operatorname*{\rightarrow}}P\to0$ is exact and $P$ is projective $K\oplus P\cong F$ by Theorem

IV.3.4. Under this isomorphism $(k,0)\vdash k$ for all $k\varepsilon K$ (see the proof of Theorem 1V.1.18), whence $F$ is the internal direct sum $F=K\oplus P^{\prime}$ with $P^{\prime}\cong P$ .Thus $F=K+P^{\prime}\subset MF+P^{\prime}$ If $u\varepsilon F$ F $F$ ,then $u=\sum_{i}m_{i}v_{i}+p_{i}$ with $m_{i}\varepsilon M,v_{i}\varepsilon F,p_{i}\varepsilon P^{\prime}$ Consequently, in the. $R$ -module $F/P^{\prime}$

$$u+P'=\sum_im_iv_i+P'=\sum_im_i(v_i+P')\varepsilon M(F/P'),$$

whence $M(F/P^{\prime})=F/P^{\prime}$ . Since $F$ is finitely generated, so is $F/P^{\prime}$ . Therefore $K\cong F/P^{\prime}=0$ by Nakayama's Lemma 4.5. Thus $P\cong P^{\prime}=F$ and $P$ is free.

We close this section with two well known theorems. The proofs are independent of theprecedingpart of this chapter

Theorem 4.9. (Hilbert Basis Theorerm) IfR is a commutative Noetheriun ring with identity, then so is $\mathbf{R}[\mathbf{x}_{1},\ldots,\mathbf{x}_{n}]$

PROOF. Clearly it suffices to show that $R[x]$ is Noetherian.By Theorem 1.9we need only show that every ideal $J$ in $R[x]$ is finitely generated. For each $n\geq0$ ,let $I_n$ be the set of all r e $R$ such that $r=0$ or $r$ is the leading co-

efficient of a polynomial $f\varepsilon J$ of degree $n$ . Verify that each $I_n$ is an ideal of $R$ .If $r$ is a nonzero element of $I_{n}$ and $f_{\varepsilon}J$ is a polynomial of degree $n$ with leading coefficient $r$ then $r$ is also the leading coefficient of $xf$, which is a polynomial in $J$ of degree $n+1$ Hence $I_0\subset I_1\subset I_2\subset\cdots$ Since $R$ is Noetherian, there exists an integer $t$ such that $I_n=I_t$ for all $n\geq1$ ; furthermore, by Theorem 1.9 each $I_{n}\left(n\geq0\right)$ is finitely generated say $I_{n}=(r_{n1},r_{n2},\ldots,r_{ni_{n}})$ . For each $r_{n\:j}$ with $0\leq n\leq1$ and $1\leq j\leq i_{n}$ , let $f_{ni}$ ∈Jbe a polynomial of degree $n$ with leading coefficient. $r_{nj}$ .Observe that $f_{0j}=r_{0j}\varepsilon R\subset R[x]$ We shall show that the ideal $J$ of $R[x]$ is generated by the finite set of polynomial $X=\{\:f_{nj}\mid0\leq n\leq r;1\leq j\leq i_n\}$

------------------------------------------------------------------

Clearly $(X)\subset J$ Conversely, the polynomials of degree O in $J$ are precisely the elements of $I_0$ and hence are contained in $(X)$ . Proceeding by induction assume that. $(X)$ contains all polynomials of $J$ of degree less than $k$ and let $g$ E Jhave degree $k$ and leading coefficient $r\neq0$

If $k\leq1$ ,then $r\varepsilon I_k$ Ik $I_k$ and hence $r=s_{1}r_{k1}+s_{2}r_{k2}+\cdots+s_{ik}r_{kik}$ for some $s_j\varepsilon R$ Therefore th polynomiel $\sum_{j=1}^{i_k}s_if_k,\varepsilon(X)$ ha leadin oefient $r$ and dgere $k$ .Con sequently, g - ≥ s; fki; has degree at most $k-1$ .By the induction hypothesis $g-\sum_{j}s_{i}f_{kj}\varepsilon\left(X\right)$ whence $g\varepsilon(X)$ If $k\geq1$ , then r e $I_k=I_t$ and $r=\sum_{j=1}^{i_{t}}s_{i}r_{t_{i}}\left(s_{j}\varepsilon R\right)$ Furthermore s;x-f; (X)

has leading coeficient $r$ and degree $k$ Thus $g-\sum_{j}s_{i}x^{k-t}f_{li}$ has degree at most $k-1$ and lies in $(X)$ by the induction assumption. Consequently, $g\in(X)$ and the in duction is complete. Therefore, $J=(X)$

Proposition 4.10. If R is a commutatire Noetherian ring with identity, then so is $R[[x]]$

REMARK.Our proof makesuse of Proposition 4.1.Although we shall not do so, the technique used to prove Theorem 4.9 may also be used here, with nonzero coefficients of lowest degree replacing those of highest degree in the argument. How. ever, great care must be used to insure that certain power series constructed inductively in the course of the proof are in fact validly defined. The Axiom of Choice and some version of the Recursion Theorem are necessary (this part is frequently obscured in many published proofs of Proposition 4.10)

PROOF OF 4.10. It suffices by Proposition 4.1 to prove that every prime ideal $P$ in $R[[x]]$ is finitely generated.Define an epimorphism of rings $R[[x]]\to R$ by mapping each power eries $f=\sum_{i=0}^{\infty}a_{i}x^{i}$ onto is onstan term $a_0$ .Let $P^*$ be te image of $P$ under this map. Then $P^*$ is a fnitely generated ideal in $R$ (Exercise III.2.13 and Theorem 1.9), say $P^{*}=(r_{1},\ldots,r_{n})$ . For each $r_1$ choose $f_{i}\in P$ with constant term $r_i$

If $x\varepsilon P$ ,we claim that $P$ is generated by $r_1,\ldots,r_n,x$ rn,X $r_n,x$ .First note that if $f_{k}$ = $r_{k}+ \sum _{i= 1}^{\infty }a_{i}x^{i}$ ，then $r_{k}= f_{k}- x\left ( \sum _{j= 0}^{\infty }a_{j+ 1}x^{j}\right ) \varepsilon$ $P$ If $g=\sum_{i=0}^{\infty}b_ix^i\varepsilon P$ ，then $b_0=s_1r_1+\cdots+s_nr_n$ for some $s_i\varepsilon R$ . Consequenily, $g-\sum_{i=1}^ns_ir_i$ hs O constan term; that is, g - > sr: = xgi (gi e R[[x]]). Therefore g = ≥ ss, + xgi and $P$ i generated by $r_1,\ldots,r_n,x$

If $x\notin P$ , we claim that $P$ is generated by $f_{1},\ldots,f_{n}\in P$ If h =cx* e P,then $c_{0}=t_{1}r_{1}+\cdots+t_{n}r_{n}$ for some $I_{i}\in R$ . Consequently, $h-\sum_{i=1}^{n}t_{i}f_{i}=xh^{*}$ for som $I_{l}^{*}\varepsilon R[[x]]$ . Since $x\notin P$ and $xh^{*}=h-\sum_{i}t_{i}f_{i}\varepsilon P$ and $P$ is prime, we have $h^*\varepsilon P$ For each $h\varepsilon P$ , choose $I_i\varepsilon R$ and $h^*\varepsilon P$ such that h = ≥ 1f + xh* (Axiom of

------------------------------------------------------------------

Choice). Let $\lambda:P\to P$ be the map defined by $h\vdash h^*$ .Let $g$ be any element of $P$ Then by the Recursion Theorem 6.2 of the Introduction (with $\lambda=f_{n}$ for all $n$ )there is a function $\phi:\mathbf{N}\to P$ such that

$$\phi(0)=g\quad\mathrm{and}\quad\phi(k+1)=\lambda(\phi(k))=\phi(k)^*$$

Let $\phi(k)=h_k\in R[[x]]$ and denote by $I_{ki}$ the previously chosen elements of $R$ such that

$$h_k=\sum_{i=1}^nt_{ki}f_i+xh_k^*=\sum_{i=1}^nt_{ki}f_i+xh_{k+1}.$$

For each $i\left(1\leq i\leq n\right)$ let g: = tkixk e R[x]]. Then

$$\begin{gathered}
g_{1}f_{1}+\cdots+g_{n}f_{n} =\sum_{i=1}^{n}\left(\sum_{k=0}^{\infty}l_{ki}x^{k}\right)f_{i}=\sum_{k=0}^{\infty}\left(\sum_{i=1}^{n}t_{ki}f_{i}\right)x^{k} \\
=\sum_{k=0}^{\infty}(h_{k}-xh_{k+1})x^{k}. 
\end{gathered}$$

Consequently, for each $m\geq0$ the coefficient of $x^{m}$ in $g_{1}f_{1}+\cdots+g_{n}f_{n}$ is thesame as the coefficient of $x^m$ in ≥ (hz - xhk+1)xk. Sinc

$$\sum_{k=\bullet}^m(h_k-xh_{k+1})x^k=h_0-x^{m+1}h_{m+1}=g-x^{m+1}h_{m+1},$$

the coefficient of $x^m$ in $f_{1}g_{1}+\cdots+f_{n}g_{n}$ isprecisely the coefficient of $x^m$ in $g$ . There fore, $g=g_{1}f_{1}+g_{2}f_{2}+\cdots+g_{n}f_{n}$ and $f_{1},\ldots,f_{n}$ generate $P$ .

### EXERCISES

1. Let $R$ be a commutative ring with identity and $I$ a finitely generated ideal of $R$ Let $C$ be a submodule of an $R$ -module A. Assume that for each r ε Ithere exists a positive integer $m$ (depending on $r$ ）such that $r^{m}A\subset C$ .Show thatfor some integer $n$ $I^nA\subset C$ [Hinr: see Theorems II1.1.2(v) and II1.2.5(vi)]

2. Without using primary decomposition, prove this version of the Krull Inter- section Theorem. If $R$ is a commutative Noetherian ring with identity, $I$ an ideal of $R$ . A a fnitly generated $R$ -module, and $B=\bigcap_{n=1}^\infty I^nA$ , then $IB=B$ [Hints: Let $C$ bemaximal in the set S of all submodules $S$ of $A$ such that $B\cap S=IB$ .It suffices to show $I^mA\subset C$ for some $m$ .By Exercise 1 it suffices to show that for each $r\varepsilon I,r^{n}A\subset C$ for some $n$ (depending onr). For each $k$ ,let $D_{k}=\left\{a\varepsilon A\mid r^{k}a\varepsilon C\right\}$ $D_0\subset D_1\subset D_2\subset\cdots$ is an ascending chain of $R$ -submodules; hence for some $n$ $D_{k}=D_{n}$ for all $k\geq n$ . Show that $(r^nA+C)\cap B=IB$ $B=IB$ B=IB . The maximality of $C$ implies $r^nA+C=C$ , that is, $r^{\prime\prime}A\subset C$

3.Let $R$ be a Noetherian local ring with maximal ideal $M$ . If the ideal $M/M^2$ in $R/M^2$ is generated by $\{a_1+M^2$ ..... $a_n+M^2\}$ , then the ideal $M$ is generated in $R$ by $\{a_1,\ldots,a_n\}$

------------------------------------------------------------------

4. (Nakayama's Lemma, second version) Let $R$ be a commutative ring with identity, J an ideal that is contained in every maximal ideal of $R$ ,and $A$ a finitely generated $R$ -module.If $R/J\otimes_{R}A=0$ ，then $A=0$ .[Hint:use the exact sequence $0\to J\to R\to R/J\to0$ and the natural isomorphism $R\otimes_RA\cong A$ to show $JA=A.$

5.Let $R$ and $J$ be as in Exercise 4; let $A$ be a finitely generated $R$ -module and $f:C\to A$ an $R$ -module homomorphism. Then. $f$ induces a homomorphism $\bar{f}:C/JC\to A/JA$ in the usual way (Corollary IV.1.8). Show that if fis an epimorphisn, then $f$ is an epimorphism

6. (a) Let $R$ be a commutative ring with identity. If every ideal of $R$ can be generated by a finite or denumerable subset, then the same is true of $R[x]$ (b) State and prove an analogue of part (a) for $R[[x]].$ : (the answer is not quite the same here).

7. Let $R$ be a commutative ring with identity and let $f,g\in R|[x]]$ . Denote by In $f$, the initil degre of $f$ (that s, th smallest $n$ such that $a_n\neq0$ . where $f=\sum_{i=0}^\infty a_ix^i)$ Show that (a) In $(f+g)\geq\min\left(\operatorname{In}f,\operatorname{In}g\right)$

(b) In $(fg)\geq$In $f+$In g (c) If $R$ is an integral domain, In $(fg)=$In$f+$In$g$

8. Let $R$ be a commutative Noetherian ring with identity and let $Q_{1}\cap\ldots\cap Q_{n}=0$ be a reducedprimary decomposition of the ideal O of $R$ with $Q_{i}$ belonging to the prime ideal $P_i$ . Then $P_{1}$ P $P_2$ P2 $P_1\cup P_2\cup\ldots\cup P_n$ Pn $P_n$ is the set of zero divisors in $R$

9. Let $R$ be a commutative ring with identity. If every maximal ideal of $R$ is of the form $(c)$ ,where $c^2=c$ , for some $c\varepsilon R$ , then $R$ is Noetherian. [Hinr: show that every primary ideal is maximal; use Proposition 4.1.]

## 5. RING EXTENSIONS

In the first part of this section ring extensions are defined and the essential properties of integral extensions are developed. The last part is devoted to the study of the relations between prime ideals in rings. $R$ and $S$ ,where $S$ is an extension ring of R. Throughout this section all rings are commutatire with identity

Definition 5.1.Let S be a commutatice ringwith identity and R a subring ofS containing 1s. Then S is said to be an extension ring of R.

EXAMPLES. Every extension field $F$ of a field $K$ is obviously an extension ring of $K$ . If $R$ is a commutative ring with identity, then $R[[x]]$ and $R[x_{1},\ldots,x_{n}]$ are ex tension rings of $R$ . The ring $\mathbf{Z}$ is not an extension of the subring $E$ of even integers since $E$ does not contain 1.

------------------------------------------------------------------

Definition 5.2.Ler S be an extension ring of R and se S. If there exists a monic polynomial $\mathbf{f}(\mathbf{x})\in\mathbf{R}[\mathbf{x}]$ such that s is a root off (that is, $\mathbf{f}(\mathbf{s})=0$ ), then s is said to be integral ocer R. If ecery element ofS is integral orer R, S is said to be an integral extension ofR.

Thekey feature of Definition5.2is the requirement that $f$ be monic

EXAMPLES. Every algebraic extension field $F$ of a field $K$ is an integral extension ring (see the Remarks after Definition V.1.4). The ring $R$ is integral over itself since r E $R$ is a root of $x-r\varepsilon R[x]$ . In the extension of $Z$ by the real field R, $1/\sqrt{3}$ is algebraic over $Z$ since it is a root of $3x^2-1$ but $1/\sqrt{3}$ is not integral over $Z$ .However, $1/\sqrt{3}$ is integral over the rational feld $\mathbf{Q}$ since it is a root of $x^{2}-1/3$ Let $S$ be an extension ring of $R$ and $X$ a subset of $S$ . Then the subring generated by

$X$ over $R$ is the intersection of all subrings of $S$ that contain $XUR$ R $R$ ; it is denoted $R[X]$ .The first half of Theorem V.1.3 is valid for rings and shows that $R[X]$consists of all elements $f(s_1,\ldots,s_n)$ with $n\in\mathbf{N}^*$ ， $f\varepsilon\:R[x_1,\ldots,x_n]$ and $s_i\varepsilon X$ . In particular, for any $s_{1},\ldots,s_{t}\in S$ SteS $s_t\varepsilon S$ the subring generated by $\{s_1,\ldots,s_t\}$ over $R$ ,which is denoted $R[s_1,\ldots,s_t]$ , consists of all elements $f(s_1,\ldots,s_t)$ with $f\varepsilon\:R[x_{1},\ldots,x_{t}]$ .An element of $R[s_{1},\ldots,s_{t}]$ is sometimes called a polynomial in S $s_1$ $s_1,\ldots,s_t$ Despite this terminology $R[s_1,\ldots,s_t]$ need not be isomorphic to the polynomial ring. $R[x_1,\ldots,x_t]$ (for example, $f(s_{1},\ldots,s_{t})$ may be zero even though $f$ is a nonzero polynomial). It is easy to see that for each $i\left(1\leq i\leq i\right)$ ， $R[s_1,\ldots,s_{i-1}][s_i]=R[s_1,\ldots,s_i]$ . Since $R[s_1,\ldots,s_t]$ is a ring containing $R,\:R[s_{1},\ldots,s_{t}]$ is an $R$ -module in the obvious way. Likewise every module over $R[s_{\mathrm{l}},\ldots,s_{t}]$ is obviously an $R$ -module

Theorem 5.3. Let S be an extension ring ofR and s e S. Then the following conditions are equivalent.

(i) s is integral orer R; (ii)R[s] is a finitely generated R-module;

(i) there is a subring T ofS containing Is and Rls] which is finitely generated as an

R-module; (iv) there is un R[s]-submodule B of'S which is finitely generated as an R-module and whose annihilutor in R[s] is zero..

SKETCH OF PROOF. $(\mathbf{i})\Longrightarrow$ (ii) Suppose $s$ is a root of the monic polynomia $f\in R[x]$ of degree $n$ . We claim that $1_{R}=s^{0},s,s^{2},\ldots,s^{n-1}$ s"-1 $s^{n-1}$ generate $R[s]$ as an $R$ -module. As observed above, every element of. $R[s]$ is of the form $g(s)$ for some $g\varepsilon R[x]$ .By the Division Algorithm I!l $1.6.2\:g(x)=f(x)q(x)+r(x)$ with deg $r<\deg f$ Therefore in $S,g(s)=f(s)q(s)+r(s)=0+r(s)=r(s)$ .Hence $g(s)$ is an $R$ -linear combination of $1_{R},s,s^2,\ldots,s^m$ with $m=\deg r<\deg f=n$ f=n $f=n$ $\Rightarrow$ → $(\mathbf{i}\mathbf{i})\Rightarrow(\mathbf{i}\mathbf{i}\mathbf{i})$ Let $T=R[s]$

$(\mathrm{iii})\Rightarrow(\mathrm{iv})$ Let $B$ be the subring $T.$ Since $R\subset R[s]\subset T$, $B$ is an $R[s]$ -module that is finitely generated as an $R$ -module by (ii). Since 1s ε B, $uB=0$ for any $u\varepsilon S$ S $S$ implies $u=u\mathbf{l}_{S}=0$ ; that is, the annihilator of $B$ in $R[s]$ is 0. $(\mathrm{iv})\Longrightarrow(\mathrm{i})$ Let $B$ be generated over $R$ by $b_1,\ldots,b_n$ . Since $B$ is an $R[s]$ -module

$sb_i\in B$ for each i. Therefore there exist rii $r_{ij}$ $r_{ij}\varepsilon R$ R $R$ such that

------------------------------------------------------------------

sb=rub+rb+.+rb sb=r2b+r22b+..+ r2nbn
$$sb_{n}=r_{n1}b_{1}+r_{n2}b_{2}+\cdots+r_{nn}b_{n}.$$

Consequently,

$$\begin{aligned}
&(r_{11}-s)b_{1}+r_{12},b_{2}+\cdots+r_{1r}b_{n}= \text{0} \\
&r_{21}b_{1}+(r_{22}-s)b_{2}+\cdots+r_{2n}b_{n}=0 \text{-} \\
&· \\
&r_{n1}b_{1}+r_{n2},b_{2}+\cdots+(r_{nn}-s)b_{n}=0.
\end{aligned}$$

Let $M$ be the $n\times n$ matrix $(r_{ij})$ and let $d\varepsilon R[s]$ be the'determinant of the matrix $M-sI_n$ . Then $db_i=0$ for all $i$ by Exercise Vll.3.8. Since $B$ is generated by the $b_i$ bi $b_{\mathrm{i}},dB=0$ .Since the annihilator of $B$ in $R[s]$ is zero by (iv) we must have $d=0$ .Iff is the polynomial $|M-xI_n|$ in $R[x]$ ,then one of f, $-f$ is monic and

$$\pm\:f(s)=\pm|M-sI_n|\:=\:\pm d=0.$$

Therefore $s$ is integral over $R$ .

Corollary 5.4. IfS is a ring extension of R andS is finitely generated as an R-module thenS is an integral extension ofR.

PROOF. For any $s\varepsilon S$ let $S=T$ in part (i) of Theorem 5.3. Then $s$ is integral over $R$ by Theorem 5.3(i).

The proofs of the next propositions depend on the following fact. If $R\subset S\subset T$ are rings (with $\mathbf{1}_T\varepsilon R)$ such that $T$ is a finitely generated $S$ -module and $S$ is a finitely generated $R$ -module, then $T$ is a finitely generated $R$ -module. The second paragraph of the proof of Theorem IV.2.16 contains a proof of this fact, mutatis mutandis.

Theorem 5.5. IfS is an extension ring of R and $s_{1},\ldots,s_{t}\in S$ ure integral over R, then $\mathbf{R}[s_{1},\ldots,s_{t}]$ is a finitely generated R-module and an integral extension ring o fR.

PROOF. We have a tower of extension rings:

$$R\subset R[s_1]\subset R[s_1,s_2]\subset\cdots\subset R[s_1,\ldots,s_t].$$

For each $i,\:s_i$ Si $s_i$ is integral over $R$ and hence integral over $R[s_{1},\ldots,s_{i-1}]$ .Since $R[s_{1},\ldots,s_{i}]=R[s_{1},\ldots,s_{i-1}][s_{i}],R[s_{1},\ldots,s_{i}]$ is a finitely generated module over $R[s_{1},\ldots,s_{i-1}]$ by Theorem 5.3 (i), (ii). Repeated application of the remarks preced ing the theorem shows that $R[s_1,\ldots,s_n]$ is a finitely generated $R$ -module. Therefore,. $R[s_1,\ldots,s_n]$ is an integral extension ring of $R$ by Corollary 5.4.

------------------------------------------------------------------

Theorem 5.6. IfT is an integral extension ring ofS and S is an integral extension ring ofR,then T is an integral extension ring ofR.

PROOF. $T$ is obviously an extension ring of $R$ .Ifre $T$ ,then $I$ is integral over $S$ and therefore the root of some monic polynomial $f\varepsilon S[x]$ say f= ≥ sx. Since $f$ is also a polynomial over the ring $R[s_0,s_1,\ldots,s_{n-1}]$ ， $t$ is integral over $R[s_0,\ldots,s_{n-1}]$ By Theorem $5.3\:R[s_0,\ldots,s_{n-1}][t]$ is a finitely generated $R[s_0,\ldots,s_{n-1}]$ -module. But since $S$ is integral over $R,R[s_{0},\ldots,s_{n-1}]$ is a finitely generated $R$ -module by Theorem 5.5. The remarks preceding Theorem 5.5 show that

$$R[s_0,\ldots,s_{n-1}][t]=R[s_0,\ldots,s_{n-1},t]$$

 is a finitely generated $R$ -module. Since $R[t]\subset R[s_0,\ldots,s_{n-1},t]$ 1 is integral over $R$ by Theorem 5.3(i).

Theorem 5.7. Let S be an extension ring ofR and let $\hat{R}$ be the set ofall elements ofS that are integral over R.Then $\hat{\mathbb{R}}$ is an integral extension ring ofR which contains every subring ofS that is integral over R.

PROOF. If s,t $\hat{R}$ , then $s,t\in R[s,t]$, whence t-s $R[s,t]$ and ts e $R[s,t]$ . Since $s$ and $t$ are integral over $R$ , so is the ring $R[s,t]$ (Theorem 5.5). Therefore $t-s\varepsilon\hat{R}$ R $\hat{R}$ and ts e $\hat{R}.$ Consequently, $\hat{R}$ is a subring of $S$ (see Theorem 1.2.5). $\hat{R}$ contains $R$ since every element of $R$ is trivially integral over $R$ . The definition of $\hat{R}$ insures that $\hat{R}$ is integral over $R$ and contains all subrings of $S$ that are integral over $R$

If S is an extension ring of $R$ , then the ring $\hat{R}$ of Theorem 5.7 is called the integral closure of $R$ in $S$ . If $\hat{R}=R.$ then $R$ is said to be integrally closed in S.

REMARKS. (i) Since $\mathbf{1}_{R}\in R\subset\hat{R},S$ is an extension ring of $\hat{R}$ . Theorems 5.6 and 5.7 imply that $\hat{R}$ is itself integrally closed in $S$ . (ii) The concepts of integral closure and integrally closed rings are relative notions and refer to a given ring $R$ and a particular extension ring S. Thus the phrase $“R$ is integrally closed"' is ambiguous unless an extension ring $S$ is specified. There is one case, however, in which the ring $S$ is understood without specific mention. An integral domain $R$ is said to be integrally closed provided $R$ is integrally closed in its quotient field (see p.144).

EXAMPLE. The integral domain $\mathbf{Z}$ is integrally closed (in the rational field Q; Exercise 8). However, $\mathbf{Z}$ is not integrally closed in the field C of complex numbers since i e C is integral over $\mathbf{Z}$

EXAMPLE. More generally, every unique factorization domain is integrally closed (Exercise 8). In particular, the polynomial ring $F[x_1,\ldots,x_n]$ $(F$ a field) is integrally closed in its quotient field $F(x_{1},\ldots,x_{n})$ The following theorem is used only in the proof of Theorem 6.10.

Theorem 5.8. Let T be a multiplicarive subset of an integral domain R such that $0\neq T$ .If R is integrally closed,then $T^{-1}R$ is an integrally closed integral domain

------------------------------------------------------------------

SKETCH OF PROOF. $T^{-1}R$ is an integral domain (Theorem III.4.3(ii) and $R$ may be identified with a subring of $T^{-1}R$ (Theorem III.4.4(ii). Extending this identi fication, the quotient field $Q(R)$ of $R$ may be considered as a subfield of the quotient field $Q(T^{-1}R)$ of $T^{-1}R.$ Verify that $Q(R)=Q(T^{-1}R)$

Let ue $Q(T^{-1}R)$ be integral over $T^{-1}R$ ; then for some $r_1\varepsilon R$ and $s_i\varepsilon T$

$$u^n+(r_{n-1}/s_{n-1})u^{n-1}+\cdots+(r_1/s_1)u+(r_0/s_0)=0.$$

Multiply through this equation by $s^n$ ,where $s=s_{0}s_{1}\cdots s_{n-1}\varepsilon T$, and conclude that $su$ is integral over $R$ . Since su ε $Q(T^{-1}R)=Q(R)$ and $R$ is integrally closed, $su\varepsilon R$ $R$ R Therefore, $u=su/s\varepsilon T^{-1}R$ ,whence $T^{-1}R$ is integrally closed.

Theremainder of this section is devoted to exploring therelationships between (prime) ideals in rings $R$ and $S$ ,where $S$ is an extension ring of $R$ . The only point in the sequel where this material is used is in the proof of Lemma 7.3. If $S$ is an extension ring of $R$ and $I\left(\neq S\right)$ is an ideal of $S$ , it is easy to see that

$I\cap R\neq R$ and $I\cap R$ is an ideal of $R$ (Exercise 10). The ideal $J=I\cap R$ R $R$ is called the contraction of $I$ to $R$ and $I$ is said to lie over $J$ If $Q$ is a prime ideal in an extension ring $S$ of a ring $R$ ,then the contraction

$Q\cap R$ of $Q$ to $R$ is a prime ideal of $R$ (Exercise 10). The converse problem is: given a prime ideal $P$ in $R$ does there exist a prime ideal $Q$ in $S$ that lies over $P$ (that is, $Q\cap R=P)?$ There are many examples where the answer is negative (for example. the extension of $\mathbf{Z}$ by the field $\mathbf{Q}$ of rationals). A partial solution to the problem is given by the next theorem,which is due to Cohen-Seidenberg

Theorem 5.9.(Lying-over Theoremi) Ler S be an integral extension ring of R and $Pa$ prime ideal of R. Then there exists a prime ideal Q in S which lies over $P$ (that is, $Q\cap R=P$

PROOF. Since $P$ is prime, $R-P$ is a multiplicative subset of $R$ (Theorem 2.1) and hence a multiplicative subset of S. Clearly $0\notin R-P$ .By Theorem 2.2 thereis an ideal $Q$ ofS that is maximal in the set of allideals /ofS such that I ∩ $(R-P)=\varnothing$ furthermore any such ideal $Q$ is prime in $S$ . Clearly $Q\cap R\subset P$ If $Q\cap R\neq P$ choose ue $P$ such that $u\notin Q$ . Then the ideal $Q+(u)$ in $S$ properly contains $Q$ .By maximality thereexists $c\varepsilon(Q+(u))\cap(R-P)$ , say $c=q+su(q\varepsilon Q;s\varepsilon S)$ .Since $s$ is integral over $R$ , there exist $r_i$ E $R$ such that

$$s^n+r_{r-1}s^{n-1}+\cdots+r_1s+r_0=0.$$

Multiplying this equation by $u^n$ yields

$$(su)^n+r_{n-1}u(su)^{n-1}+\cdots+r_1u^{n-1}(su)+r_0u^n=0.$$

Since $su=c-q$ the Binomial Theorem II1.1.6 implies that

$$r=c^n+r_{n-1}uc^{n-1}+\cdots+r_1u^{n-1}c+r_0u^n\varepsilon\:Q.$$

But $\upsilon\varepsilon R$ and hence $c\in R\cap Q\subset P$ .But $u\varepsilon P$ $P$ $P$ and $v\varepsilon P$ imply $C^n\varepsilon P$ .Since $P$ is prime, $c$ must lie in $P$ , which is a contradiction.

------------------------------------------------------------------

Corollary 5.10. (Going-up Theorem) Let S be an integral extension ring ofR and $P_{1}.$ Pprime ideals in Rsuch that $P_1\subset P$ $IfQ_1$ is a prime ideal ofS lying over. $P_{1}.$ , then there exists a prime ideal QofS such that $\mathbf{Q}_{\mathrm{i}}\subset\mathbb{Q}$ and Q lies over P.

SKETCH OF PROOF. As in the proof of Theorem 5.9, $R-P$ is a multiplica tive set in $S$ . Since $Q_{\mathrm{l}}$ Qi $Q_1\cap R=P_1\subset P$ ,we have $Q_{1}$ Q1 $Q_1\cap(R-P)=\varnothing$ . By Theorem 2.2 there is a prime ideal $Q$ of $S$ that contains $Q_{\mathbf{l}}$ and is maximalin the set of allideals $I$ of $S$ such that $Q_1\subset I$ and $I\cap(R-P)=\varnothing$ .The proof of Theorem 5.9 now carries over verbatim to show that $Q\cap R=P$ .

Theorem 5.11. Let S be an integral extension ring ofR and P a prime ideal in R.IfQ and $\mathbb{Q}^{\prime}$ are prime ideals in S such that $\mathbb{Q}\subset\mathbb{Q^{\prime}}$ and both Q and $\mathbb{Q}^{\prime}$ lie overP,then $Q=Q^{\prime}$

PROOF. It suffices to prove the following statement: if $Q$ is a prime ideal in $S$ such that $Q\cap R=P$ then $Q$ is maximal in the set S of all ideals $I$ in $S$ with the property $I\cap(R-P)=\varnothing$ If $Q$ is not maximal in S, then there is an ideal $I$ in $S$ with

$$Q\subsetneq I\quad\mathrm{and}\quad I\cap(R-P)=\emptyset.$$

Consequently, $I\cap R\subset P$ .Choose $u\in I-Q$ . Since $u$ is integral over $R$ , the set of all monic polynomials $f\varepsilon R[x]$ such that deg $f\geq1$ and $f(u)\in Q$ is nonempty. Choose such an $f$ of least degree, say f = > rxi. Then

$$u^n+r_{n-1}u^{n-1}+\cdots+r_1u+r_0\varepsilon Q\subset I,$$

whence $r_0\varepsilon I\cap R\subset P=Q\cap R\subset Q$ . Therefore

$$u(u^{n-1}+r_{n-1}u^{n-2}+\cdots+r_{2}u+r_{1})\varepsilon Q.$$

By the minimality of deg $f,\left(u^{n-1}+r_{n-1}u^{n-2}+\cdots+r_1\right)\notin Q$ , and $u\notin Q$ by choice This is a contradiction since $Q$ is prime (Theorem I11.2.15). Therefore $Q$ is maximal in $S$ .■

Theorem 5.12. Let S be an integral extension ring ofR and let Q be a prime ideal in S which lies over a primeideal Pin R.ThenQ ismaximal inSifandonly ifPis maximal inR.

PROOF. Suppose $Q$ is maximal in $S$ . By Theorem Ill.2.18 there is a maximal ideal $M$ of $R$ that contains P $P$ $P.M$ is prime by Theorem Il1.2.19. By Corollary 5.10 there is a prime ideal $Q^{\prime}$ in $S$ such that $Q\subset Q^{\prime}$ and $Q^{\prime}$ lies over $M$ .Since $Q^{\prime}$ is prime, $Q^{\prime}\neq S$ (Definition III1.2.14). The maximality of $Q$ implies that $Q=Q^{\prime}$ ,whence $R=Q^{\prime}$ R = Q' $P=Q\cap R=Q^{\prime}\cap R=M.$ R=M $R\:=\:M$ Therefore, $P$ is maximal in $R$ Conversely suppose $P$ is maximal in $R$ . Since $Q$ is prime in $S,Q\neq S$ and there is

a maximal ideal $N$ of $S$ containing $Q$ (Theorem II1.2.18). $N$ is prime by Theorem III.2.19, whence $\mathbf{l}_R=\mathbf{1}_s\notin N$ . Since $P=R\cap Q\subset R\cap N\subseteq R$ we must have $P=R\cap N$ by maximality. Thus $Q$ and $N$ both lie over $P$ and $Q\subset N$ . Therefore, $Q=N$ by Theorem 5.11.

------------------------------------------------------------------

## EXERCISES

Note: Unless otherwise specified,. $S$ is always an extension ring of $R$

1. Let $S$ be an integral extension ring of $R$ and suppose $R$ and $S$ are integral domains. Then $S$ is a field if and only if $R$ is a field. [Hint: Corollary II1.2.21.]

2. Let $R$ be an integral domain.If the quotient field $F$ of $R$ is integral over $R$ , then $R$ is a field.

3.Let $R$ be an integral domain with quotient field $F$ .If $0\neq a\varepsilon R$ and $\mathbf{1}_{R}/a\in F$ is integral over $R$ ,then $a$ is a unit in $R$

4. (a) Let $R$ be an integral domain with quotient field $F$ . If $0\neq a\varepsilon R$ ,then the following are equivalent :

(i) every nonzero prime ideal of $R$ contains $a$ (ii every nonzero ideal of $R$ contains some power of $a$ (ii) $F=R[1_{R}/a]$ (ring extension). An integral domain $R$ that contains an element $a\neq0$ satisfying (i)-(iii) is called a Goldmann ring.

(b) A principal ideal domain is a Goldmann ring if and only if it has only finitely many distinct primes. (c) Is the homomorphic image of a Goldmann ring also a Goldmann ring?

5.If $S$ is an integral extension ring of $R$ and $f:\mathcal{S}\to\mathcal{S}$ is a ring homomorphism such that $f(1_{s})=1_{s}$ then $f(S)$ is an integral extension ring of $f(R)$

6. IfS is an integral extension ring of $R$, then $S[x_{1},\ldots,x_{n}]$ is an integral extensior ring of $R[x_{1},\ldots,x_{n}]$

7. IfS is an integral extension ring of $R$ and $T$ is a multiplicative subset of $R(0\notin T)$ then $T^{-1}S$ is an integral extension of $T^{-1}R$ .[Hint: If $s/t\in T^{-1}S$ ，then $s/t=$ $\phi_T(s)(1_R/t)$ ,where $\phi_T:S\to T^{-1}S$ is the canonical map (Theorem II1.4.4). Show that $\phi_T(s)$ and $1_{R/t}$ are integral over $T^{-1}R$ ,whence $s/t$ is integral over $T^{-1}R$ by Theorem 5.5.]

8. Every unique factorization domain is integrally closed. [Hint: Propositior 111.6.8.]

9. Let $T$ be a commutative ring with identity and {S;|i e I} $\left\{S_{i}\mid i\in I\right\}$ $\left\{S_{i}\mid i\in I\right\},\left\{R_{i}\mid i\varepsilon I\right\}$ families of swerings.ah $R_{i}$ $T$ ins enetes i in $S_{i}$ $S_{i}$ $\bigcap_iR_i$ $S_i$ $R_{i}$ Ssnceteasion ie one $R_{i}$ R $\bigcap S_i$

10. (a) If $I\left(\neq S\right)$ is an ideal of $S$ , then $I\cap R\neq R$ and $I\cap R$ is an ideal of $R$ (b) If $Q$ is a prime ideal of $S$ ,then $Q\cap R$ is a prime ideal of $R$

## 6. DEDEKIND DOMAINS

------------------------------------------------------------------

The definition of a Dedekind domain to be given below is motivated by the following facts. Every principal ideal domain. $D$ is Noetherian (Lemma IIl.3.6). Consequently, every ideal $(\neq D)$ has a prirnary decomposition (Theorem 3.6). The introduction to Section 2 shows that a particularly strong form of primary decomposition holds in a principal ideal domain, namely: every proper ideal is (uniquely) a product of prime ideals.

Definition 6.1.A Dedekind domain is an inregral domainR inwhich every ideal $(\neq\mathbf{R})$ is the product of a finite number of prime ideals..

EXAMPLE. The preceding discussion shows that every principal ideal domain is Dedekind. The converse, however, is false. There is an example after Theorem 6.10 below of a Dedekind domain that is not a principal ideal domain.

It is not immediately evidentfrom the definition that everyDedekind domain is in fact Noetherian. In order to prove this fact and to develop other properties of Dedekind domains we must introduce the concept of a fractional ideal.

Definition 6.2.Ler R be an inregral domain with quotient field K.A fractional ideal ofR is a nonzero R-submodule I of K such that aI $CR$ for some nonzero a e R

EXAMPLE. Every ordinary nonzero ideal I in an integral domain $R$ is an $R$ -submodule of $R$ and hence a fractional ideal of $R$ .Conversely, every fractional ideal of $R$ that is contained in $R$ is an ordinary ideal of $R$

EXAMPLE. Every nonzero finitely generated $R$ -submodule I of $K$ is a fractional ideal of $R$ . For if $I$ is generated by $b_{1},\ldots,b_{n}\in K$ then $I=Rb_{1}+\cdots+Rb_{n}$ and for each i, $b_{i}=c_{i}/a_{i}$ with $0\neq a_i$ ， $c_i\varepsilon R$ .Let $a$ = $a_{1}a_{2}\cdots a_{n}$ . Then $a\neq0$ and $aI=Ra_{2}\cdots a_{n}c_{1}+\cdots+Ra_{1}\cdots a_{n-1}c_{n}\subset R$

REMARK. If Iis a fractional ideal of a domain $R$ and al $\subset R$ $(0\neq a\varepsilon R)$ ,then al is an ordinary ideal in $R$ and the map $I\to aI$ given by $x|\mapsto ax$ is an $R$ -module isomorphism

Theorem 6.3. If R is an integral domain with quotient field $K$ , then the set of all fractional ideals ofR forms a commutative monoid, with identity $R$ and multiplicatior gien by $\mathbf{IJ}= \left \{ \sum _{i= 1}^{n}\mathrm{a_{i}b_{i}| a_{i}\varepsilon I; b_{i}\varepsilon J; n. \varepsilon N^{* }}\right \} .$

PROOF. Exercise, note that if. $I$ and $J$ are ideals in $R$ ,then $IJ$ is the usual product. of ideals.

A fractional ideal $I$ of an integral domain $R$ is said to be invertible if $IJ=R$ for some fractional ideal $J$ of $R$ . Thus the invertible fractional ideals? are precisely those that have inverses in the monoid of all fractional ideals

------------------------------------------------------------------

REMARKS. (i) The inverse of an invertible fractional ideal $I$ is unique and is $I^{-1}=\left\{a\varepsilon K\mid aI\subset R\right\}$ . Indeed for any fractional ideal I the set $I^{-1}=\{a\varepsilon K|aI\subset R\}$ is easily seen to be a fractional ideal such that $I^{-1}I=II^{-1}\subset R$ . If $I$ is invertible and $IJ=JI=R$ , then clearly $J\subset I^{-1}$ . Conversely, since $I^{-1}$ and $J$ are $R$ -submodules of $K,I^{-1}=RI^{-1}=(JI)I^{-1}=J(II^{-1})\subset JR=RJ\subset J$ whence $J=I^{-1}$ (i) If $I,A,B$ are fractional ideals of $R$ such that $IA=IB$ and $I$ is invertible, then

$A=RA=(I^{-1}I)A=I^{-1}(IB)=RB=B$ (ii) If Iis an ordinary ideal in $R$ , then $R\subset I^{-1}$

EXAMPLE. Every nonzero principal ideal in an integral domain $R$ is invertible If $K$ is the quotient field of $R$ and $I=(b)$ with $b\neq0$ ,let $J=Rc\subset K$ where $c=\mathbf{1}_{R}/b$ Then $J$ is a fractional ideal of $R$ such that $IJ=R$ Invertible fractional ideals play a key role in characterizing Dedekind domains.

The next five results develop some facts about them.

Lemma 6.4. Let $\mathbf{I},\mathbf{I}_{1},\mathbf{I}_{2},\ldots,\mathbf{I}_{n}$ beideals in an integral domain R.

(i) The ideal $\mathbf{I}_{1}\mathbf{I}_{2}\cdots\mathbf{I}_{n}$ is inrertible if and only if each $I_{\mathrm{j}}$ is invertible

(i) If $\mathbf{P}_{1}\cdots\mathbf{P}_{\mathrm{m}}=\mathbf{I}=\mathbf{Q}_{\mathrm{l}}\cdots\mathbf{Q}_{\mathrm{n}}$ ,where the $P_i$ and $\mathbb{Q}_{\mathrm{j}}$ are prime ideals in R and every $P_{\mathrm{i}}$ is invertible, then. $m=n$ and (after reindexing) $\mathbf{P_{i}}=\mathbf{Q_{i}}$ for each $\mathbf{i}=1,\ldots,\mathbf{m}$

PROOF. (i) If $J$ is a fractional ideal such that $J(I_1\cdots I_n)=R$ ，then for each $j=1,2,\ldots,n$ ， $I_{j}(JI_{1}\cdots I_{j-1}I_{j+1}\cdots I_{n})=R$ ，whence $I_{j}$ is invertible. Conversely, if each $I_{i}$ is invertible, then (11. . - In) $(I_{1}\cdots I_{n})$ $(I_{1}\cdots I_{n})\:(I_{1}^{-1}\cdots I_{n}^{-1})\:=\:R$ ,whence $I_1\cdots I_n$ is invertible (ii) The proof is by induction on $m$ with the case $m=1$ being left to the reader.

If $m>1$ , choose one of the $P_{i}$, say $P_{1}$, such that $P_{1}$ does not properly contain $P.$ for $i=2,\ldots,m$ .Since $Q_1\cdots Q_n=P_1\cdots P_m\subset P_1$ and $P_{\mathrm{I}}$ is prime some $Q_{i}$ ,say $Q_{1}$, is contained in $P_{1}$ (Definition IIl.2.14). Similarly since $P_{1}\cdots P_{m}=Q_{1}\cdots Q_{n}\subset Q_{1}$ $P_i\subset Q_1$ for some i. Hence $P_{i}\subset Q_{\mathrm{l}}\subset P_{\mathrm{l}}$ .By the minimality of $P_{1}$ we must have $P_{\mathrm{i}}=Q_{\mathrm{l}}=P_{\mathrm{l}}$ . Since $P_{1}=Q_{1}$ is invertible, Remark (i) after Theorem 6.3 implies

$$P_2P_3\cdots P_m=Q_2Q_3\cdots Q_n.$$

Therefore by the induction hypothesis $m=n$ and (after reindexing) $P_{i}=Q_{i}$ for $i=1,2,\ldots,m$ .

The example preceding Lemma 6.4 and Theorem III.3.4 show that every nonzerc prime ideal in a principal ideal domain is both invertible and maximal. Moregenerally we have

1

Theorem 6.5. If R is a Dedekind domain, then erery nonzero prime ideal of R is in vertible and maximal

PROOF. We show first that every invertible prime ideal $P$ is maximal. If $a\in R-P$ ,we must show that the ideal $P+Ra$ generated by $P$ and $a$ is $R$ .If $P+Ra\neq R$ , then since $R$ is Dedekind, there exist prime ideals $P_i$ and $Q_{i}$ such that $P+Ra=P_{1}P_{2}\cdots P_{m}$ and $P+Ra^{2}=Q_{1}Q_{2}\cdots Q_{n}$ . Let $\pi:R\to R/P$ be the canonical epimorphism and consider the principal ideals in $R/P$ ge nerated respectively by $\pi(a)$ and $\pi(a^2)$ . Clearly

$$(\pi(a))\:=\:\pi(P_{1})\cdots\pi(P_{m})\quad\mathrm{and}\quad(\pi(a^{2}))\:=\:\pi(Q_{1})\cdots\pi(Q_{n}).$$

------------------------------------------------------------------

Since ker $\pi=P\subset P_{i}$ and $P\subset Q_{i}$ for each $i$ the ideals $\pi(P_i)$ and $\pi(Q_i)$ are prime in $R/P$ (Exercise II1.2.17(a). Since $R/P$ is an integral domain (Theorem II1.2.]6), every principal ideal in $R/P$ is invertible (see the example preceding Lemma 6.4). Consequently, $\pi(P_i)$ and $\pi(Q_i)$ are invertible by Lemma 6.4(i). Since

$$\pi(Q_1)\cdots\pi(Q_n)=(\pi(a^2))=(\pi(a))^2=\pi(P_1)^2\cdots\pi(P_m)^2,$$

Lemma 6.4(ii) implies $n=2m$ and (after reindexing) $\pi(P_{i})=\pi(Q_{2i})=\pi(Q_{2i-1})$ for $i=1,2,\ldots,m$ .Since Ker $\pi=P\subset P_{i}$ and $P\subset Q_i$ for all $i,i$

$$P_{i}=\pi^{-1}(\pi(P_{i}))=\pi^{-1}(\pi(Q_{2i}))=Q_{2i}$$

and similarly $P_{i}=Q_{2i-1}$ for $i=1,2,\ldots,m$ . Consequently, $P+Ra^{2}=(P+Ra)^{2}$ and $P\subset P+Ra^2\subset(P+Ra)^2\subset P^2+Ra$ If $b=c+ra\varepsilon P$ $( c$ $\varepsilon$ $P^{2}, r$ $\varepsilon$ $R)$ ，then $ra\varepsilon P$ . Thus $r\varepsilon P$ $P$ P since $P$ is prime and $a\notin P$ . Therefore, $P\subset P^2+Pa\subset P$ ,which implies $P=P^{2}+Pa=P(P+Ra)$ . Since $P$ is invertible, $R=P^{-1}P=P^{-1}P(P+Ra)$ $=R(P+Ra)=P+Ra$ This is a contradiction. Therefore every invertible prime ideal $P$ is maximal. Now suppose $P$ is any nonzero prime ideal in $R$ and $c$ is a nonzero element of $P$

Then $(c)=P_{1}P_{2}\cdots P_{n}$ for some prime ideals $P_i$ .Since $P_1P_2\cdots P_n=(c)\subset P$ ,wehave for some $k$ $P_k\subset P$ (Definition IIl.2.14). The principal ideal $(c)$ is invertible and hence so is $P_k$ (Lemma 6.4(i). By the first part of the proof $P_{k}$ is maximal, whence $P_k=P$ . Therefore, $P$ is maximal and invertible.

EXAMPLE. If $F$ is a field, then the principal ideals $(x_1)$ and $(x_2)$ in the polynomial domain $F[x_1,x_2]$ are prime but not maximal (since $(x_{i})\subseteq_{\not=}\left(x_{1},x_{2}\right)\subsetneq F[x_{1},x_{2}])$ Consequently, $F[x_1,x_2]$ is not Dedekind (Theorem 6.5). Since $F[x_1,x_2]$ is Noetherian by Theorem 4.9, the class of Dedekind domains is properly contained in the class of Noetherian domains

Lemma 6.6.IfIisa fractional ideal ofan integral domain R with quotient field K and feHom $_{\mathbf{R}}(\mathbf{I},\mathbf{R})$ , then for all a,b e I: $af(b)=bf(a)$

PROOF. Now $a=r/s$ and $b$ = $v/ t$ $( r, s, v, t$ $\varepsilon$ $R;$ $s, t\neq 0)$ s,≠0 $s,t\neq0$ SO $sa=r$ and $\iota b=\upsilon$ Hence $sab=rb\varepsilon I$ and $tab=va\varepsilon I$ . Thus $sf(tab)=f(stab)=tf(sab)$ inR Therefore, $af(b)=saf(b)/s=f(sab)/s=f(tab)/t=tbf(a)/t=bf(a)$ ?

Lemma 6.7. Every invertible fractional ideal of an integral domain R with quotien field K is a finitely generated R-module.

PROOF. Since $I^{-1}I=R$ , there exist $a_{i}\varepsilon I^{-1},b_{i}\varepsilon I$ such that 1r = abi. If $c\varepsilon I$ , then $c=\sum_{i=1}^{n}(ca_{i})b_{i}$ . Furthermore each $ca_i\varepsilon R$ since $a_i$ 日$I^{-1}=\{a\varepsilon K|aI\subset R\}$ Therefore $I$ is generated as an $R$ -module by $b_1,\ldots,b_n$ (Theorem IV.1.5(iii).

We have seen that every nonzero ideal $I$ in a principal ideal domain $D$ is invertible. Furthermore $I$ is isomorphic to $D$ as a $D$ -module (see Theorem IV.1.5(i)) Thus $I$ is a free and hence projective $D$ -module. This result also holds in arbitrary integral domains.

------------------------------------------------------------------

Theorem 6.8. Let R be an integral domain and I a fractional ideal ofR. Then I is in-. vertible if and only if I is a projective R-module..

PROOF. $(\Rightarrow)$ By Lemma 6.7 and Theorem IV.1.5. $I=Rb_{1}+\cdots+Rb_{n}$ with $b_i$ e I and 1r = ≥ ab;(aze I-). Let $F$ be a free $R$ -module with a basis of $n$ elements $e_1,\ldots,e_n$ . Then the map $\pi:F\to I$ defined by $e_i\vdash b_i$ is an $R$ -module epimorphis (see Theorem IV.2.1), and there is a short exact sequence: $0\to\operatorname{Ker}\pi\to F\overset{\pi}{\operatorname*{\rightarrow}}I\to0$ Define $\zeta:I\to F$ by $\zeta(c)=ca_{1}e_{1}+\cdots+ca_{n}e_{n}\left(c\varepsilon I\right)$ and verify that $\zeta$ is an $R$ -module homomorphism such that $\pi\zeta=1_{I}$ ;(note that $ca_i\varepsilon R$ for each $i$ since $a_i\varepsilon I^{-1}$ ).Consequently the exact sequence splits and $I$ is a direct summand of a free $R$ -module (Theorem IV.1.18). Therefore, $I$ is projective by Theorem IV.3.4. $(\Leftarrow)$ Let $X=\{b_{i}|j\varepsilon J\}$ be a (possibly infinite) set of nonzero generators of the

projective $R$ -module $I.$ Let $b_0$ be a fixed element of $X$ . Let $F$ be a free $R$ -module with basis $\{e_i\mid j\in J\}$ and let $\phi:F\to I$ be the $R$ -module epimorphism defined by $e_i\mapsto b_i$ (Theorem IV.2.1). Since $I$ is projective there is an $R$ -module homomorphism $\psi:I\to F$ such that $\phi\psi=1_{I}$ .For each $j\varepsilon J$ let $\pi_{j}:F\to Re_{i}\cong R$ be the canonical projection that maps $\sum_ir_ie_i\varepsilon F$ onto $r_i$ r $r_i\varepsilon R$ R $R$ (see Theorem IV.2.1) Then fo each j the map $\theta_{j}=\pi_{j}\psi:I\rightarrow R$ is an $R$ -module homomorphism. Let $c_{j}=\theta_{j}(b_{0})$ . For any $c$ $\varepsilon$ $I, c$ $c\:_{j}=$ $c\theta \:_{j}( b_{0})$ = $b_{0}\theta \:_{j}( c)$ byLemma 6.6,whence in the quotient feld $K$ of $R$ $c(c_{i}/b_{0})=cc_{i}/b_{0}=b_{0}\theta_{i}(c)/b_{0}=\theta_{j}(c)\varepsilon R$ .Therefore

$$c_j/b_0\varepsilon I^{-1}=\{a\varepsilon K\mid aI\subset R\}.$$

Consequently, for any. $c$ El

$$\psi(c)=\sum_{j\varepsilon J_1}\theta_j(c)e_j=\sum_{j\varepsilon J_1}c(c_j/b_0)e_j,$$

where $J_{1}$ is the finite subset $\{j\in J\mid\theta_i(c)\neq0\}$ . Therefore, for any nonzero $c\varepsilon I$

$$c=\phi\psi(c)=\phi(\sum_{j\varepsilon J_{1}}c(c_{i}/b_{0})e_{j})=\sum_{j\varepsilon J_{1}}c(c_{j}/b_{0})b_{j}=c(\sum_{j\varepsilon J_{1}}(c_{j}/b_{0})b_{j}),$$

whence 1r = (c;/b)b; with $c_{i}/b_{0}\varepsilon I^{-1}$ . It follows that $R\subset I^{-1}I$ Since $I^{-1}I\subset R$ is always true, $R=I^{-1}I.$ Therefore $I$ is invertible.

The characterization of Dedekind domains to be given below requires us to introduce another concept. A discrete valuation ring is a principal ideal domain that has exactly one nonzeroprime ideal;(the zero ideal is prime in anyintegral domain)

Lemma 6.9.If R is a Noetherian,integrally closed integral domain and R has a unique nonzero prime ideal P, then R is a discrete valuation ring.

PROOF.Weneed onlyshow that everyproper ideal in $R$ is principal. This requires the following facts, which are proved below:

(i) Let $K$ be the quotient field of $R$ .For every fractional ideal $I$ of $R$ the set $\tilde{I}=\{a\varepsilon K|aI\subset I\}$ is precisely $R$ (i) $R\subseteq P^{-1}$

(ii) $P$ is invertible;

------------------------------------------------------------------

(iv) $\bigcap_{n\in N^*}P^n=0;$ (v) $P$ is principal.

Assuming (i)-(v) for now, let $I$ be any proper ideal of $R$ . Then Jis contained in a nonzero maximal ideal $M$ of $R$ (Theorem Il1.2.18), which is necessarily prime (Theorem III.2.19. By uniqueness $M=P$ , whence $I\subset P.$ Since $\bigcap_{n\in N^{*}}P^{n}=0$ by (iv), there is a largest integer $m$ such that $I\subset P^m$ and $I\not\subset P^{m+1}$ . Choose $b\in I-P^{m+1}$ .Since $P=(a)$ for some ae $R$ by $(\mathbf{v})$ ， $P^{m}=(a)^{m}=(a^{m})$ .Since $b\in P^m$ $b=ua^{m}$ . Furthermore, $u\notin P=(a)$ (otherwise $b\in P^{m+1}=\left(a^{m+1}\right)$ . Consequently, $u$ is a unit in $R$ (otherwise $(u)$ wouldbe a proper ideal byTheoremIll.3.2 and hence contained in $P$ by the argument used above). Therefore by Theorem Ill.3.2 $P^{m}=\left(a^{m}\right)=\left(ua^{m}\right)$ $=(b)\subset I$ ,whence $I$ is the principal ideal $P^{m}\:=\:(a^{m})$ Statements (i)-(v) are justified as follows.

(i) Clearly $R\subset\bar{I}.$ It is easy to see that / is a subring of $K$ and a fractional ideal of $R$ ,whence $\tilde{I}$ is isomorphic (as an $R$ -module) to an ideal of $R$ (Remark preceding Theorem 6.3). Thus since $R$ is Noetherian, $\bar{I}$ is finitely generated (Theorem 1.9). Theorem 5.3 (with $T=\bar{I}$ implies that every element of Iis integral over $R$ . Therefore, $\bar{I}\subset R$ since $R$ is integrally closed. Hence $\bar{I}=R$ (ii) Recall that $R\subset J^{-1}$ for everyideal Jin $R$ . Let $\mathcal{F}$ be the set of all ideals Jin R

such that $R\subseteq J^{-1}$ . Since $P$ is a proper ideal (Definition I1.2.14), every nonzero element of $P$ is a nonunit by Theorem II1.3.2. If $J=(a)$ ， $(0\neq a\varepsilon P)$ , then $1_{R}/a\in J^{-1}$ but $1_R/a\notin R$ , whence $R\subseteq J^{-1}$ . Therefore, $\mathcal{F}$ is nonempty. Since $R$ is Noetherian, $\mathcal{F}$ contains a maximal element $M$ (Theorem 1.4). We claim $M$ is a prime ideal of $R$ .If $ab\in M$ with $a,b\in R$ and $a\notin M$ ，choose $c\in M^{-1}-R$ . Then $c(ab)\in R$ ，whence $bc(aR+M)\subset R$ andbc e $:(aR+M)^{-1}$ . Therefore, $bc\varepsilon R$ (otherwise, $aR+M\varepsilon\mathcal{F}$ contradicting the maximality of $M.$ ). Consequently, $c(bR+M)\subset R$ ，and thus $c\in(bR+M)^{-1}$ .Since $c\notin R$ the maximality of $M$ implies that $bR+M=M$ whence $b\varepsilon M$ . Therefore $M$ is prime by Theorem II1.2.15. Since $M\neq0$ ,we must have $P=M$ by uniqueness. Thus $R\subseteq M^{-1}=P^{-1}$

(ii) Clearly $P\subset PP^{-1}\subset R$ .The argument in the first paragraph of the proof shows that $P$ is the unique maximal ideal in $R$ ，whence $P=PP^{-1}$ or $PP^{-1}=R$ But if $P=PP^{-1}$ , then $P^{-1}\subset\bar{P}$ and by (i) and (i), $R\subseteq P^{-1}\subset\bar{P}=R$ , which is a contradiction. Therefore $PP^{-1}=R$ and $P$ is invertible

(iv) If $\bigcap_{n\in N^{*}}P^{n}\neq0$ ,then Pn is a fractional ideal of $R$ .Verify that $P^{-1}\subset\frac{n\dot{\boldsymbol{\varepsilon}}N}{\bigcap_{n\boldsymbol{\varepsilon}N^*}P^n}$ Then by ( and Gi $R\subsetneq P^{-1}\subset\overline{\bigcap_{n\in N^{*}}P^{n}}=R$ whichis a coarae diction.

(v) There exists $a\varepsilon P$ such that $a\notin P^2$ ; (otherwise $P=P^{2}$ , whence $\bigcap_{n\boldsymbol{\varepsilon}N^{*}}P^{n}=$ $P\neq0$ contradicting (iv). Then $aP^{-1}$ is a nonzero ideal in $R$ such that $aP^{-1}\not\subset P$ (otherwise, $a\varepsilon aR=aP^{-1}P\subset P^2)$ 0.The first paragraph of the proof shows that every proper ideal in $R$ is contained in $P$ ，whence $aP^{-1}=R$ .Therefore by (ii), $(a)=(a)R=(a)P^{-1}P=(aP^{-1})P=RP=P.$

Theorem 6.10. The following conditions on an integral domain R are equivalent

(i)R isa Dedekind domain,

------------------------------------------------------------------

(i) every proper ideal in R is uniquely a product of a finite number of prime ideals; (ii)every nonzero ideal in R is invertible;

(iv)every fractional ideal ofR is invertible; (v)the set of all fractional ideals ofR is a group under multiplication, (vi)every ideal in R is projective; (vii) every fractional ideal ofR is projective; (vili) R is Noetherian, integrally closed and every nonzero prime ideal is maximal. (ix) R is Noetherian and for every nonzero prime ideal $P$ of R, the localization

Rp ofR atP is a discrete valuation ring.

PROOF. The equivalence (iv$)\Leftrightarrow(\mathbf{v})$ is trivial (see Theorem 6.3). $(\mathbf{i})\Rightarrow(\mathbf{i}\mathbf{i})$ and $(\mathrm{ii})\Rightarrow(\mathrm{iii})$ follow from Lemma 6.4 and Theorem 6.5. (ii) $\Leftrightarrow(\mathrm{vi})$ and (vii) n $\Leftrightarrow$ $i\Leftrightarrow($iv) are immediate consequences of Theorem 6.8. $(\mathbf{vi})\Rightarrow(\mathbf{vii})$ follows from the Remark preceding Theorem 6.3. In order to complete the proof we need only prove the implications (iv$)\Rightarrow($viii) ， $(\mathrm{viii})\Rightarrow(\mathrm{ix})$ and $(\mathbf{ix})\Rightarrow($i) 》 $\Rightarrow$ $(\mathbf{iv})\Rightarrow(\mathbf{v}$iii) Every ideal of $R$ is invertible by (iv) and hence finitely generated by

Lemma 6.7. Therefore $R$ is Noetherian by Theorem 1.9. Let $K$ be the quotient field of $R$ .If $u\varepsilon K$ is integral over $R$ ,then $R[u]$ is a fnitely generated $R$ -submodule of $K$ by Theorem 5.3. Consequently, the second example after Definition 6.2 shows that $R[u]$ is a fractional ideal of $R$ . Therefore, $R[u]$ is invertible by (iv). Thus since $R[u]R[u]=R[u],R[u]=RR[u]=(R[u]^{-1}R[u])R[u]=R[u]^{-1}R[u]=R$, whence uE $R$ Therefore $R$ is integrally closed. Finally if $P$ is a nonzero prime ideal in $R$ , then there is a maximal ideal $M$ of $R$ that contains $P$ (Theorem III.2.18). $M$ is invertible by (iv). Consequently $M^{-1}P$ is a fractional ideal of $R$ with $M^{-1}P\subset M^{-1}M=R$, whence $M^{-1}P$ is an ideal in $R.$ Since $M(M^{-1}P)=RP=P$ and $P$ is prime; either $M\subset P$ or $M^{-1}P\subset P$ . But if $M^{-1}P\subset P$ ，then $R\subset M^{-1}=M^{-1}R=M^{-1}PP^{-1}\subset PP^{-1}\subset R$, whence $M^{-1}=R$ .Thus $R\:=\:MM^{-1}\:=\:MR\:=\:M$ , which contradicts the fact that $M$ is maximal. Therefore $M\subset P$ and hence $M=P$ .Therefore, $P$ is maximal $(\mathrm{viii})\Rightarrow(\mathrm{ix})\:R_{P}$ Rp $R_P$ is an integrally closed integral domain by Theorem 5.8. By

Lemma I11.4.9 every ideal in $R_{P}$ is of theform $I_{P}=\{i/s\mid i\in I;s\notin P\}$ ,where $I$ is an ideal of $R$ . Since every ideal of $R$ is finitely generated by (vii) and Theorem 1.9, it follows that every ideal of $R_{P}$ is finitely generated. Therefore, $R_P$ is Noetherian by Theorem 1.9. By Theorem Ill.4.11 every nonzero prime ideal of $R_{F}$ is of the form $I_{P.}$ where $I$ is a nonzero prime ideal of $R$ that is contained in $\cdot P$ . Since every nonzero prime ideal of $R$ is maximal by (vii), $P_{F}$ must be the unique nonzero prime ideal in $R_{F}$ . Therefore, $R_P$ is a discrete valuation ring by Lemma 6.9. $(\mathbf{ix})\Rightarrow(\mathbf{i})$ We first show that every ideal $I\left(\neq0\right)$ is invertible. $II^{-1}$ is a fractional

ideal of $R$ contained in $R$ (Remark (i) after Theorem 6.3), whence $II^{-1}$ is an ideal in $R$ If $II^{-1}\neq R$ , then there is a maximal ideal $M$ containing $II^{-1}$ (Theorem III.2.18) Since $M$ is prime (Theorem II1.2.19), the ideal $I_{M}$ in $R_{M}$ is principal by (ix); say $I_{M}\:=(a/s)$ with $a\varepsilon I$ and $s\in R-M$ Since $R$ is Noetherian, $I$ is finitely generated say $I\:=\:(b_1,\ldots,b_n)$ , by Theorem 1.9. For each i, $b_i/1_R\in I_M$ ，whence in $R_{M}$ $b_{i}/\mathbf{1}_{R}=(r_{i}/s_{i})(a/s)$ for some $r_i\varepsilon R$ rieR $r_{i}\varepsilon R,\:s_{i}\varepsilon R-M$ Therefore $s_{i}sb_{i}=r_{i}a\in I$ Let $t=ss_{1}s_{2}\cdots s_{n}$ . Since $R-M$ is multiplicative, $r\in R-M$ . In the quotient field of $R$ we have for every I,. $(t/a)b_{i}=tb_{i}/a=s_{1}\cdots s_{i-1}s_{i+1}\cdots s_{n}r_{i}\in R$, whence $1/a\in I^{-1}$ Consequentlye $t=(t/a)a\varepsilon I^{-1}I\subset M$ , which contradicts the fact that $\tau\in R-M$ Therefore $II^{-1}=R$ and $I$ is invertible. For each ideal $I\left(\neq R\right)$ of $R$ choose a maximal ideal $M_I$ of $R$ such that

------------------------------------------------------------------

$I\subset M_{I}\subseteq R$ (Theorem I1.2.18; Axiom of Choice). If $I=R$ ,let $M_{R}=R$ . Then $IM_I^{-1}$ is a fractional ideal of $R$ with $IM_I^{-1}\subset M_IM_I^{-1}\subset R$ . Therefore, $IM_I^{-1}$ is an ideal of $R$ that clearly contains $I.$ Also, if $I$ is proper, then $I\subseteq IM_I^{-1}$ (other wise since $I$ and $M_1$ are invertible, $R=RR=(I^{-1}I)(M_{I}^{-1}M_{I})=I^{-1}(IM_{I}^{-1})M_{I}=I^{-1}IM_{I}$ = $RM_{I}=$ $M_{I}$, which contradicts the choice of $M_I$ ). Let $S$ be the set of all ideals of $R$ and define a function $f:S\to S$ $f:S\to S$ $f:S\to S$ by $I\vdash IM_I^-1$ $I\vdash IM_{I}^{-1}$ $I\vdash IM_{I}^{-1}$ . Given a proper ideal $J$ ,there exists by the Recursion Theorem 6.2 of the Introduction (with $f_{n}=f$ for all $n$ )a function $\phi:\mathbb{N}\to S$ such that $\phi(0)=J$ and $\phi(n+1)=f(\phi(n))$ . If we denote $\phi(n)$ by $J_n$ and $M_{J_n}$ by $M_n$ , then we have an ascending chain of ideals $J=J_0\subset J_1\subset J_2\subset\cdots$ such that $J=J_0$ and $J_{n+1}=f(J_{n})=J_{n}M_{n}^{-1}$ . Since $R$ is Noetherian and $J$ is proper, there is a least integer $k$ such that
$$J=J_{0}\subseteq J_{1}\subseteq\cdots\subseteq J_{k-1}\subseteq J_{k}=J_{k+1}.$$

Thus $J_{k}=J_{k+1}=f(J_{k})=J_{k}M_{k}^{-1}$ .Theremarks above show that this canoccur only if $J_k=R$ . Consequently, $R=J_{k}=f(J_{k-1})=J_{k-1}M_{k-1}^{-1}$ whence

$$J_{k-1}=J_{k-1}R=J_{k-1}M_{k-1}^{-1}M_{k-1}=RM_{k-1}=M_{k-1}.$$

Since Mk-1 = Jk-1 C Jk = R, $M_{k-1}$ is a maximal ideal. The minimality of $k$ insures that each of $M_0,\ldots,M_{k-2}$ $M_{k-2}$ Mk-2 is also maximal (otherwise $M_{i}=R$ ,whence $J_{i+1}=J_{j}M_{j}^{-1}=J_{j}R^{-1}=J_{j}R=J_{j})$ . It is easy to verify that

$$M_{k-1}=J_{k-1}=J_{k-2}M_{k-2}^{-1}=J_{k-3}M_{k-3}^{-1}M_{k-2}^{-1}=\cdots=JM_{0}^{-1}M_{1}^{-1}\cdots M_{k-2}^{-1}.$$

Consequently, since each $M_i$ is invertible,

$$M_{k-1}(M_0\cdots M_{k-2})=JM_0^{-1}\cdots M_{k-2}^{-1}(M_0\cdots M_{k-2})=J.$$

Thus $J$ is the product maximal (hence prime) ideals. Therefore $R$ is Dedekind.

We close with an example showing that the class of principal ideal domains is properly contained in the class of Dedekind domains.

EXAMPLE. The integral domain $\mathbf{Z}[\sqrt{10}]=\{a+b\sqrt{10}\mid a,b\in\mathbf{Z}\}$ has quotient field $\mathbf{Q}(\sqrt{10})=\{r+s\sqrt{10}\mid r,s\in\mathbf{Q}\}$ . A tedious calculation and elementary number theory show that $\mathbf{Z}[\sqrt{10}]$ is integrally closed (Exercise 14). Since the evaluation map $\mathbf{Z}[x]\to\mathbf{Z}[\sqrt{10}]$ given by $f(x)|\to f(\sqrt{10})$ is an epimorphism and $\mathbf{Z}[x]$ is Noetherian (Theorem 4.9), $\mathbf{Z}[\sqrt{\mathbf{i}0}]$ is also Noetherian (Exercise 1.5). Finally it is not difficult to prove that every nonzero prime ideal of $\mathbf{Z}[\sqrt{10}]$ is maximal (Exercise 15). Therefore $\dot{\mathbf{z}}$д$\sqrt10]$ is a Dedekind domain by Theorem 6.10(vi). However $\mathbf{z}[\sqrt{10}]$ is not a principal ideal domain (Theorem Ill.3.7 and Exercise I11.3.4)

## EXERCISES

1. The ideal generated by 3 and $1+\sqrt{5}i$ in the subdomain $\mathbf{Z}[\sqrt{5}i]$ of $C$ is invertible.

 2. An invertible ideal in an integral domain that is a local ring is principal

3.If $I$ is an invertible ideal in an integral domain $R$ and $S$ is a multiplicative set in $R$ with $0\notin S$ , then $S^{-1}I$ is invertible in $S^{-1}R$

------------------------------------------------------------------

—

4. Let $R$ be any ring with identity and $P$ an $R$ -module. Then $P$ is projective if and only if there exist sets $\{a_i\mid i\varepsilon I\}\subset P$ and $\{f_i\mid i\in I\}\subset\operatorname{Hom}_R(P,R)$ such that for all α e $P$ $a\:=\:\sum_{ieI}f_{i}(a)a_{i}$ See the proof of Theorem 6.8.]

5. (Converse of Lemma 6.9) A discrete valuation ring $R$ is Noetherian and integrally closed. [Hint: Exercise 5.8.]

6. (a) If every prime ideal in an integral domain $R$ is invertible, then $R$ is Dedekind (b) If $R$ is a Noetherian integral domain in which every maximal ideal is invertible, then $R$ is Dedekind.

7.If $S$ is a multiplicative subset of a Dedekind domain $R$ (with $\mathbf{l}_R\varepsilon S,0\notin S)$ ,then $S^{-1}R$ is a Dedekind domain.

8.If $R$ is an integral domain and $P$ a prime ideal in $R[x]$ such that $P\cap R=0$ then $R[x]_P$ is a discrete valuation ring.

9. If a Dedekind domain $R$ has only a finite number of nonzero prime ideals $P_1,\ldots,P_n$ ,then $R$ is a principal ideal domain. [Hinr: There exists $a_{i}\varepsilon P_{i}-P_{i}^{2}$ and by the Chinese Remainder Theorem III.2.25 there exists $b_i\varepsilon P_i$ such that $b_i\equiv a_i$ (mod $P_1$ )and $b_{i}\equiv1_{R}$ (mod $P_{j})$ for $j\neq i$ .Show that $P_{i}=(b_{i})$ which im plies that every ideal is principal.]

10. If $I$ is a nonzero ideal in a Dedekind domain $R$ ,then $R/I$ is an Artinian ring

11. Every proper ideal in a Dedekind domain may be generated by at most two elements.

12.An $R$ -module $A$ is divisible if $rA=A$ for all nonzero r e $R$ .If $R$ is a Dedekind domain, every divisible $R$ -module is injective.[N.B. the converse is also true but harder.]

13. (Nontrivial) If $R$ is a Dedekind domain with quotient feld $K$ $F$ is a fnite dimensional extension field of $K$ and $S$ is the integral closure of $R$ in $F$ (that is,the ring of all elements of $F$ that are integral over $R$ ),then $S$ is a Dedekind domain

14. (a) Prove that the integral domain $\mathbf{Z}[\sqrt{10}]$ is an integral extension ring of $\mathbf{Z}$ with quotient field $\mathbf{Q}(\sqrt{10})$ (b) Let $u\in\mathbf{Q}(\sqrt{10})$ be integral over $\mathbf{Z}[\bar{\mathbf{v}}\vec{\mathbf{0}}]$ . Then $u$ is integral over $\mathbf{Z}$ (Theorem

5.6). Furthermore if $u\varepsilon Q.$ , then u e Z (Exercise 5.8). Prove that if $u\in\mathbf{Q}(\sqrt{10})$ and $u\notin\mathbf{Q}$ , then $u$ is the root of an irreducible monic polynomial of degree 2 in $\mathbf{Z}[x]$ . [Hinr: Corollary II1.6.13 and Theorem V.1.6.] (c)Prove that if $u=r+s\sqrt{10}\varepsilon Q(\sqrt{10})$ and $u$ is a root of $x^{2}+ax+b\in\mathbf{Z}[x]$

then $u=-2r$ and $b\:=\:r^{2}-10s^{2}$ [Hinr: note that $u^{2}-2ru+(r^{2}-10s^{2})=0$ if $u\notin\mathbf{Q}$ use Theorem V.1.6.] (d) Prove that $\mathbf{Z}[\sqrt{10}]$ is integrally closed. [Hint: if $u=r+s\sqrt{10}\varepsilon Q(\sqrt{10})$ is a root of $x^{2}+ax+b\varepsilon\mathbf{Z}[x]$ and $a$ is even, then r e $\mathbf{Z}$ by (c); it follows that s e $\mathbf{Z}$ The assumption that $a$ is odd leads to a contradiction.]

15. (a) If $P$ is a nonzero prime ideal of the ring $\mathbf{Z}[\sqrt{10}]$ , then $P\cap\mathbf{Z}$ is a nonzero prime ideal of $\mathbf{Z}$ [Hint: if $0\neq u\varepsilon P$ , then $u$ is a root of $x^{2}+ax+b\in\mathbf{Z}[x]$ by Exercise 14. Show that one of $a,b$ is nonzero and lies in $P$ ] (b) Every nonzero prime ideal of $\mathbf{Z}[\sqrt{10}]$ is maximal.[Use (a), Theorem II1.3.4

and either an easy direct argument or Theorem 5.12.]

1

1

1

1

------------------------------------------------------------------

16. A valuation domain is an integral domain $R$ such that for all $a,b\in R$ either $a\mid b$ or $b\mid a.$ (Clearly a discrete valuationring is a valuation domain.) A Prifer domain is an integral domain in which every finitely generated ideal is invertible (a) The following are equivalent: (i) $R$ is a Prufer domain; (i) for every prime

ideal $P$ in $R$ $R_P$ is a valuation domain; (ii) for every maximal ideal $M$ in $R$ $R_{M}$ is a valuation domain. (b) A Pruifer domain is Dedekind if and only if it is Noetherian

(c) If $R$ is a Pruifer domain with quotient field $K$ , then any domain $S$ such that $R\subset S\subset K$ is Prifer.

## 7. THE HILBERT NULLSTELLENSATZ

The results of Section VI.1 and Section 5 are used to prove a famous result of classical algebraic geometry, the Nullstellensatz (Zeros Theorem) of Hilbert. Along the way we also prove the Noether Normalization Lemma. We begin with a very brief sketch of the geometric background (this discussion is continued at the end of the section) Classical algebraic geometry is the study of simultaneous solutions of systems of

polynomial equations:

$$f(x_1,x_2,\ldots,x_n)=0\quad(f\varepsilon S)$$

where $K$ is a field and $S\subset K[x_{1},\ldots,x_{n}]$ . A solution of this system is an $n$ -tuple, $(a_1,\ldots,a_n)\varepsilon F^n=F\times F\times\cdots\times F(n)$ 1 factors), where $F$ is an algebraically closed extension field of $K$ and $f(a_{1},\ldots,a_{n})=0$ for all $f\varepsilon S$ . Such a solution is called a zero ofS in $F^n$ . The set of all zeros of $S$ is called the affine $K$ -variety (or algebraic set) in $F^n$ defined by $S$ and is denoted $V(S)$ .Thus

$$V(S)=\{(a_1,\ldots,a_n)\varepsilon F^n\mid f(a_1,\ldots,a_n)=0\quad\text{for all fe S}\}.$$

Note that if $I$ is the ideal of $K[x_{1},\ldots,x_{n}]$ generated by $S$ , then $V(I)=V(S)$ The assignment $S\vdash V(S)$ defines a function from the set of all subsets of

$K[x_1,\ldots,x_n]$ to the set of all subsets of $F^n$ . Conversely, define a function from the setof subsets of $F^{\tau}$ to the set of subsets of $K[x_{1},\ldots,x_{n}]$ by $Y\vdash J(Y)$ ,where $Y\subset F^{n}$ and

$$J(Y)=\{f\varepsilon K[x_1,\ldots,x_n]\mid f(a_1,\ldots,a_n)=0\quad\mathrm{for~all}\quad(a_1,\ldots,a_n)\varepsilon Y\}.$$

Note that $J(Y)$ is actually an ideal of $K[x_1,\ldots,x_n]$ . The correspondence given by $V$ and $J$ has the same formal properties as does the Galois correspondence (priming operations) between intermediate fields of an extension and subgroups of the Galois group. In other words we have the following analogue of Lemma V.2.6.

Lemma 7.1. Ler F be an algebraically closed extension field ofK and let S, T be subsets of $\mathbf{K}[\mathbf{x}_{1},\ldots,\mathbf{x}_{n}]$ and $X,Y$ subsets of $F^n$ .Then

(i)
$$\mathrm{V(K[x_1,\ldots,x_n])=\emptyset;J(F^n)=\emptyset;J(\emptyset)=K[x_1,\ldots,x_n];}$$
(ii) $S\subset T\Rightarrow V(T)\subset V(S)$ and $\mathbf{X}\subset\mathbf{Y}\Rightarrow\mathbf{J}(\mathbf{Y})\subset\mathbf{J}(\mathbf{X})$ (ii) $S\subset J(V(S))$ and $\mathbf{Y}\subset\mathbf{V}(\mathbf{J}(\mathbf{Y}))$ (iv) $\mathbf{V}(\mathbf{S})=$ V$(\mathbf{J}(\mathbf{V}(\mathbf{S})))$ and $\mathbf{J}(\mathbf{Y})=\mathbf{J}(\mathbf{V}(\mathbf{J}(\mathbf{Y})))$

------------------------------------------------------------------

It is natural to ask which objects are closed under this correspondence, that is, which $S$ and $Y$ satisfy $J(V(S))=S$ and $V(J(Y))=Y$ . Closed subsets of $F^n$ are easily described (Exercise 1), but the characterization of closed subsets of $K[x_{1},\ldots,x_{n}]$ requires the Nullstellensatz, which states that $J(V(I))=\mathbf{R}$ Cad I for every proper ideal $I$ of $K[x_1,\ldots,x_n]$ . In order to prove the Nullstellensatz we need two preliminary results, the first of which is of interest in its own right.

Theorem 7.2. (Noether Normalization Lemma) Let R be an integral domain which is a finitely generated extension ring ofa feld K and let r be the transcendence degree over K of the quotient field F of R. Then there exists an algebraically independeni subset $\{t_{1},t_{2},\ldots,t_{r}\}$ of R such that R is integral over $\mathbf{K}[t_{1},\ldots,t_{r}]$

PROOF. Let $R=K[u_{1},\ldots,u_{n}]$ ; then $F=K(u_{1},\ldots,u_{n})$ .If $\{u_1,\ldots,u_n\}$ is algebraically independent over $K$ $\{u_1,\ldots,u_n\}$ is a transcendence base of $F$ over $K$ by Corollary VI.1.6, whence $r=n$ and the theorem is trivially true. If $\{u_1,\ldots,u_n\}$ is algebraically dependent over $K$ , then $r\leq n-1$ (Corollary VI.1.7) and

$$\sum_{(i_{1},\ldots,i_{n})\varepsilon I}k_{i_{1}\ldots i_{n}}{u_{1}}^{i_{1}}{u_{2}}^{i_{2}}\cdots{u_{n}}^{i_{n}}\:=\:0,$$

where $I$ is a finite set of distinct $n$ -tuples of nonnegative integers and $k_{i_1\ldots i_n}$ is a nonzero element of $K$ for every $(i_1,\ldots,i_n)\in I.$ Let $c$ be a positive integer that is greater than every component $i_s$ of every element $(i_1,\ldots,i_n)$ of $I.$ If $(i_1,\ldots,i_n)$ $(i_{1},\ldots,j_{n})\in\mathbb{R}$ : I are such that.

$$i_{1}+ci_{2}+c^{2}i_{3}+\cdots+c^{n-1}i_{n}=j_{1}+cj_{2}+c^{2}j_{3}+\cdots+c^{n-1}j_{n},$$

then $c\mid i_1-j_1$ which is impossible unless $i_{1}=j_{1}$ (since $c>i_{1}\geq0$ and $c>j_{1}\geq0$ imply $c>|i_{1}-j_{1}|)$ . Consequently, $i_{2}+ci_{3}+\cdots+c^{n-2}i_{n}=j_{2}+cj_{3}+\cdots+c^{n-2}j_{n}$ As before $c\mid i_{2}-j_{2}$ ，whence $i_{2}=j_{2}$ . Repetition of this argument shows that $(i_1,\ldots,i_n)=(j_1,\ldots,j_n)$ .Therefore, the set

$$\{i_1+ci_2+c^2i_3+\cdots+c^{n-1}i_n\mid(i_1,\ldots,i_n)\in I\}$$

consists of $|I|$ distinct nonnegative integers; in particular, it has a unique maximum element $j_{1}+cj_{2}+\cdots+c^{n-1}j_{n}$ for some $(j_{1},\ldots,j_{n})\in I$ .Let

$$v_{2}=u_{2}-u_{1}^{c},v_{3}=u_{3}-u_{1}^{c^{2}},\ldots,v_{n}=u_{n}-u_{1}^{c^{n-1}}.$$

If we expand the algebraic dependence relation above, after making the substitutions $u_{i}=v_{i}+u_{1}^{c^{i-1}}$ $(2\leq i\leq n)$ ,we obtain

$$k_{i_{1}\ldots i_{n}}u_{1}^{j_{1}+cj_{1}+c^{2}j_{3}+\ldots+c^{n-1}j_{n}}+f(u_{1},v_{2},v_{3},\ldots,v_{n})=0,$$

where the degree of $f\varepsilon K[x_{1},\ldots,x_{n}]$ in $x_1$ is strictly less than $ij_{1}+cj_{2}+\cdots+c^{n-1}j_{n}$ Therefore, $u_1$ is a root of the monic polynomial

$$x^{j_{1}+cj_{2}+\ldots+c^{n-1}j_{n}}+k_{j_{1}\ldots i_{n}}^{-1}f(x,v_{2},\ldots,v_{n})\:\varepsilon\:K[v_{2},\ldots,v_{n}][x].$$

Consequently, $u_1$ is integral over $K[v_{2},\ldots,v_{n}]$ .By Theorem $5.5K[u_1,c_2,\ldots,c_n]$ $=K[v_{2},\ldots,v_{n}][u_{1}]$ is integral over $K[v_{2},\ldots,v_{n}]$ . Since each $u_i$ $(2\leq i\leq n)$ is ob viously integral over $K[u_{1},v_{2},\ldots,v_{n}]$ ,Theorems 5.5 and 5.6imply that

$$R\:=\:K[u_1,\ldots,u_n]$$

------------------------------------------------------------------

is integral over $K[v_2,\ldots,v_n]$ (whence $F$ is algebraic over $K(v_2,\ldots,v_n))$ .If $\{v_2,\ldots,v_n\}$ is algebraically independent, then $r=n-1$ by Corollary V1.1.6 and the theorem is proved. If not, the preceding argument with $K[v_2,\ldots,v_n]$ in place of $R$ shows that for some Wn $w_{n}$ R $R$ $w_{3},\ldots,w_{n}\varepsilon R,K[v_{2},\ldots,v_{n}]$ K[v2, ... , 心n] $K[v_2,\ldots,v_n]$ is integral over $K[w_{3},\ldots,w_{n}]$ By Theorem $5.6R$ is integral over $K[w_{3},\ldots,w_{n}]$ (whence $F$ is algebraic over $K(w_3,\ldots,w_n)$ and $r\leq n-2$ 0. If $\{w_{3},\ldots,w_{n}\}$ is algebraically independent, we are fnished. If not, the preceding process may be repeated and an inductive argument will yield an algebraically independent subset $\{z_{n-r+1},\ldots,z_{n}\}$ of r elements of $R$ such that $R$ is integral over $K[z_{n-r+1},\ldots,z_n]$ .

Now let $K$ be a field and $F$ an algebraically closed extension field of $K$ .Ifa proper ideal $I$ of $K[x_{1},\ldots,x_{n}]$ is fnitely generated, say $I=(g_{1},\ldots,g_{k})$ , then the affine variety $V(I)$ clearly consists of every $(a_{1},\ldots,a_{n})\in F^{n}$ that is a common root of $g_{1},\ldots,g_{k}$ (see Exercise 4). If $n=1$ ， $K[x_1]$ is a principal ideal domain and it is obvious that $V(I)$ is nonempty. More generally (and somewhat surprisingly) we have:

Lemma 7.3. If F is an algebraically closed extension field ofa field K and I is a proper ideal of. $\mathbf{K} [ \mathbf{x} _{1}, \ldots , \mathbf{x} _{\mathrm{n} }]$, then the affine rariety V(I) defined by I in $F^n$ is nonempty

PROOF. By Theorems I1.2.18 and II1.2.19 I is contained in a proper prime ideal $P$ ,whence $V(P)\subset V(I)$ .Consequently, it suffices to prove that $V(P)$ is nonempty for every proper prime ideal $P$ of $K[x_1,\ldots,x_n]$ . Observe that $P$ n $K=0$ (otherwise) $0\neq a\varepsilon P\cap K$, ，whence $\mathbf{1}_{K}=a^{-1}a\in P$ ，contradicting the fact that $P$ is proper). Let $R$ be the integral domain $K[x_1,\ldots,x_n]/P$ (see Theorem I11.2.16) and let

$\pi:K[x_{1},\ldots,x_{n}]\to R$ be the canonical epimorphism. If we denote $\pi(x_{i})\varepsilon R$ by $u_i$, then $R=\pi(K)[u_1,\ldots,u_n]$ . Furthermore since $K\cap P=0$ $\pi$ maps $K$ isomorphically onto $\pi(K)$ ; in particular, $\pi(K)$ is a field. By the Noether Normalization Lemma there exists a subset $\{t_1,\ldots,t_r\}$ of $R$ such that $\{t_1,\ldots,t_r\}$ is algebraically independent over. $\pi(K)$ and $R$ is integral over $S=\pi(K)[t_{1},\ldots,t_{r}]$ . If $M$ is the ideal of $S$ generated by $I_1,\ldots,I_r$, then the map $\pi(K)\to S/M$ given by $\pi(a)\vdash\pi(a)+M$ is an isomorphism (see Theorem VI.1.2). Consequently $M$ is amaximalideal of $S$ by Theorem Ill.2.20. Therefore, there is a maximal ideal $N$ of $R$ such that $N$ n $S=M$ (Theorems 5.9 and 5.12). Let $\tau:R\to R/N$ be the canonical epimorphism. Then $\tau(R)=R/N$ is a feld by Theorem IIl.2.20. The Second Isomorphism Theorem I1I1.2.12 together with the maps defined above now yields an isomorphism

$$K\cong\pi(K)\cong S/M=S/(N\cap S)\cong(S+N)/N=\tau(S),$$

which is given by $a\vdash,\pi(a)\vdash\pi(a)+M|\overset{\sim}{\operatorname*{\operatorname*{\mapsto}}}\pi(a)+N=\tau(\pi(a))$ . Let $\overline{\tau(R)}$ be an algebraic closure of $\tau(R)$ .Since $R$ is integral over $S$ $\tau(R)$ is an algebraicfield extension of $\tau(S)$ ,whence $\overline{\tau(R)}$ is also an algebraic closure of $\tau(S)$ (Theorem V.3.4). Now $F$ contains an algebraic closure $\bar{K}$ of $K$ (Exercise V.3.7). By Theorem V.3.8 the isomorphism $K\cong\tau(S)$ extends to an isomorphism $\overline{K}\cong\overline{\tau(R)}$ .Restriction of the inverse of this isomorphism yields a monomorphism $\sigma:\tau(R)\to\bar{K}\subset F$ . Let $\phi$ be the composition $K[x_1,\ldots,x_n]\overset{\pi}{\operatorname*{\to}}R\overset{\tau}{\operatorname*{\to}}\tau(R)\overset{\sigma}{\operatorname*{\to}}F$ and verify that $\phi\mid K=1_{K}$ and $\phi\mid P=0$ Consequently, for any $f(x_1,\ldots,x_n)$ 8 $:P\subset K[x_{1},\ldots,x_{n}]$ ， $f(\phi(x_1),\ldots,\phi(x_n))=$ $\phi(x_n))=$ Φ(xn)) =

------------------------------------------------------------------

$\phi(f(x_1,\ldots,x_n))=0$ ,whence $(\phi(x_1),\ldots,\phi(x_n))$ is a zero of $P$ in $F^n$ . Therefore $V(P)$ is nonempty.

Proposition 7.4. (Hilbert Nullstellensaz) Let F be an algebraically closed extension. feld of a field K and I a proper ideal of $\mathbf{K}[\mathbf{x}_{1},\ldots,\mathbf{x}_{n}]$ .Let $\mathbf{V} ( \mathbf{I} ) = \{ ( \mathbf{a} _{1}, \ldots , \mathbf{a} _{\mathrm{n} }) \in$ $\mathbf{F} ^{\mathrm{n} }\mid \mathbf{g} ( \mathbf{a} _{1}, \ldots , \mathbf{a} _{\mathrm{n} }) = 0$ for all g ε I}. Then

$$\begin{aligned}\text{Rad I}&=\mathrm{J}(\mathrm{V}(\mathrm{I}))\\&=\{\mathrm{f}\varepsilon\mathrm{K}[\mathrm{x}_{1},\ldots,\mathrm{x}_{n}]\mid\mathrm{f}(\mathrm{a}_{1},\ldots,\mathrm{a}_{\mathrm{n}})=0\quad for\:all\quad(\mathrm{a}_{1},\ldots,\mathrm{a}_{\mathrm{n}})\varepsilon\:\mathrm{V}(\mathrm{I})\}.\end{aligned}$$

In other words, f( $a_{1}$, $\ldots$, $a_{n}$) = 0 for every zero $(\mathbf{a}_{1},\ldots,\mathbf{a}_{n})$ ofIin $F^n$ if and only if $f^{m}\varepsilon I$ for some $m\geq1$

REMARK. We shall use Lemma 7.3 to prove the theorem. Since the theorem im. plies the lemma (Exercise 6), the two are actually equivalent.

PROOF OF 7.4. If $f\varepsilon$ Rad $I$ ,then $f^{m}\varepsilon I$ for some $m\geq1$ (Theorem 2.6). If $(a_1,\ldots,a_n)$ is a zero of $I$ in $F^n$ ,then $0=f^{m}(a_{1},\ldots,a_{n})=(f(a_{1},\ldots,a_{n}))^{m}$ .Consequently, since $F$ is a feld, $f(a_{1},\ldots,a_{n})=0$ .Therefore, Rad $I\subset JV(I)$ Conversely, suppose $f\varepsilon JV(I)$ .We may assume $f\neq0$ since $0\varepsilon$ Rad $I$ . Consider

$K[x_1,\ldots,x_n]$ as a subring of the ring $K[x_{1},\ldots,x_{n},y]$ of polynomials in $n+1$ indeterminates over $K$ .Let $L$ be the nonzero ideal of $K[x_1,\ldots,x_n,y]$ generated by $I$ and $yf-1_F$ . Clearly if $(a_{1},\ldots,a_{n},b)$ is a zero of $L$ in $F^{n+1}$ then $(a_{1},\ldots,a_{n})$ mustbe a zeroof $I$ in $F^n$ .But $(yf-1_{F})(a_{1},\ldots,a_{n},b)=bf(a_{1},\ldots,a_{n})-1_{F}=-1_{F}$ for all zeros $(a_{1},\ldots,a_{n})$ of $I$ in $F^n$ . Therefore, $L$ has no zeros in $F^{n+1}$ ; that is, $V(L)$ is empty Consequently, $L=K[x_{1},\ldots,x_{n},y]$ by Lemma 7.3,whence $\mathbf{l}_F\varepsilon L$ .Thus

$$\mathbf{1}_{F}=\sum_{i=1}^{t-1}g_{i}f_{i}+g_{t}(yf-1_{F}),$$

where $f_i\in I$ (1$\leq i\leq i-1)$ and $g_i\in K[x_1,\ldots,x_n,y]$ .Define an evaluation homomorphism $K[x_1,\ldots,x_n,y]\to K(x_1,\ldots,x_n)$ by $x_{i}\models x_{i}$ and $y\vdash f^{-1}=$ $\mathbf{1}_{\kappa}/f(x_1,\ldots,x_n)$ (Corollary II1.5.6). Then in the field $K(x_{1},\ldots,x_{n})$

$$1_F=\sum_{i=1}^{t-1}g_i(x_1,\ldots,x_n,f^{-1})f_i(x_1,\ldots,x_n).$$

Let $m$ be a positive integer larger than the degree of. $g_i$ in y for every $i(1\leq i\leq i-1)$ xn], whence
$$\begin{aligned}&\mathrm{Then~for~each~}i,\:f^{m}(x_{1},\ldots,x_{n})g_{i}(x_{1},\ldots,x_{n},f^{-1})\:\mathrm{lies~in~}\:K[x_{1},\ldots,x_{n}\\&f^{m}\:=\:f^{m}1_{F}\:=\:\sum_{i=1}^{t-1}f^{m}(x_{1},\:\ldots,\:x_{n})g_{i}(x_{1},\ldots,\:x_{n},\:f^{-1})\:f_{i}(x_{1},\:\ldots,\:x_{n})\:\varepsilon\:I.\\\end{aligned}$$
Therefore fe Rad $I$ and hence $JV(I)\subset$Rad $I.$ ■

The determination of closed objects as mentioned in the introduction of this section is now straightforward (Exercises 1-3).

We close this section with an informal attempt to establish the connection between geometry and algebra which characterizes the classical approach to algebraic geometry. Let $K$ be a field. Every polynomial $f\varepsilon K[x_{1},\ldots,x_{n}]$ determines a function $F^n\longrightarrow F$ by substitution: $(a_{1},\ldots,a_{n})\vdash f(a_{1},\ldots,a_{n})$ .If $V=V(I)$ is an affine variety contained in $F^n$ , the restriction of this function to $V$ is called a regular function on $V$ The regular functions $V\to F$ form a ring $\Gamma(V)$ whichis isomorphic to

------------------------------------------------------------------

$$K[x_1,\ldots,x_n]/J(V(I))$$

(Exercise 10). This ring is called the coordinate ring of $V$ .Since $I\subset J(V(I))=$Rad$I$ the ring $\Gamma(V)$ has no nonzero nilpotent elements. Furthermore $\Gamma(V)$ is a finitely generated algebra over $K$ (since $K[x_1,\ldots,x_n]$ and the ideal $J(V(I))$ are; see Section IV.7). Conversely it can be proved that every finitely generated $K$ -algebrawith no nonzero nilpotent elements is the coordinate ring of some affine variety. Therefore, there is a one-to-one correspondence between affine varieties and a rather special class of commutative rings. With a suitable definition of morphisms the affine varieties form a category as do the commutative rings in question and this correspondence is actually an "equivalence" of categories. Thus statements about affine varieties are equivalent to certain statements of commutative algebra. For further information see W. Fulton [53] and I. G. MacDonald [55].

### EXERCISES

Note: $F$ is always an algebraically closed extension field of a field $K;J,V$ , and $F^n$ are as above.

1.A subset $Y$ of $F^n$ is closed (that is, $V(J(Y))=Y$ if and only if $Y$ is an affine $K.$ -variety determined by some subset $S$ of $K[x_1,\ldots,x_n]$ 2. A subset $S$ of $K[x_{1},\ldots,x_{n}]$ is closed (that is, $J(V(S))=S$ if and only if $S$ is a radical ideal (that is, $S$ is an ideal and $S=$Rad S 3. There is a one-to-one inclusion reversing correspondence between the set of affine $K$ -varieties in $F^n$ and the set of radical ideals of $K[x_1,\ldots,x_n]$ . [See Exercises 1, 2.] 4. Every affine $K$ -variety in $F^n$ is of the form $V(S)$ where $S$ is a finite subset of $K[x_1,\ldots,x_n]$ . [Hinr: Theorems 1.9 and 4.9 and Exercise 3.] 5.If $V_{1}\supset V_{2}\supset\cdots$ is a descending chain of $K$ -varieties in $F^n$ ,then $V_{m}=V_{m+1}=\cdots$ for some $m$ . [Hinr: Theorem 4.9 and Exercise 3.] 6. Show that the Nullstellensatz implies Lemma 7.3.

7. If $I_1,\ldots,I_k$ are ideals of $K[x_{1},\ldots,x_{n}]$ , then $V(I_1\cap I_2\cap\cdots\cap I_k)=V(I_1)$ U $V(I_2)\cup\cdots\cup V(I_k)$ V(IR) $V(I_k)$ and $V(I_{1}I_{2}\cdots I_{k})=V(I_{1})\cap V(I_{2})\cap\cdots\cap V(I_{k})$ 8. A $K$ variety $V$ in $F^n$ is irreducible provided that whenever $V=W_{1}\cup W_{2}$ with each $W_{i}$ a $K.$ variety in $F^{n}$ , either $V=W_{1}$ or $V=W_{2}$ (a) Prove that $V$ is irreducible if and only if $J(V)$ is a prime ideal in $K[x_{1},\ldots,x_{n}]$ (b) Let $F=\mathbf{C}$ and $S=\{x_{1}^{2}-2x_{2}^{2}\}$ . Then $V(S)$ is irreducible as a Q-variety but not as an R-variety. 9. Every nonempty $K$ -variety in $F^n$ may be written uniquely as a finite union V $V_{1}$ $V_{1}\cup V_{2}\cup\cdots\cup V_{k}$ of affine $K$ -varieties in $F^n$ such that $V_{i}\not\subset V_{i}$ for $i\neq j$ and each $V_{i}$ is irreducible (Exercise 8). 10. The coordinateringofan affine $K$ -variet y $V(I)$ isisomorphicto $K[x_1,\ldots,x_n]/J(V(I))$

------------------------------------------------------------------

# CHAPTER IX

# THE STRUCTURE OF RINGS

In the first part of this chapter a general structure theory for rings is presented. Although the concepts and techniques introduced have widespread application, com plete structure theorems are available only for certain classes of rings.The basic method for determining such a class ofrings might be described intuitively asfollows. One singles out an “undesirable" property $P$ that satisfies certain conditions, in particular, that every ring has an ideal which is maximal with respect to having property $P$ . This ideal is called the $P$ -radical of the ring. One then attempts to find structure theorems for the class of rings with zero $P$ -radical. Frequently one must include additional hypotheses (such as appropriate chain conditions) in order to obtain really strong structure theorems. These ideas are discussed in full detail in the introductions to Sections 1 and 2 below. The reader would do well to read both these discussions before beginning serious study of the chapter. We shall investigate two different radicals, the Jacobson radical (Section 2) and

the prime radical (Section 4). Very deep and useful structure theorems are obtained for left Artinian semisimple rings (that is, left Artinian rings with zero Jacobson radical) in Section 3. Goldie's Theorem is discussed in Section 4. It includes a characterization of left Noetherian semiprime rings (that is, left Noetherian rings with zero prime radical). The basic building blocks for all of these structure theorems are the endomorphism rings of vector spaces over division rings and certain “dense" subrings of such rings (Section 1). The last two sections of the chapter deal with algebras over a commutative ring

with identity. The Jacobson radical and related concepts and results are carried over to algebras (Section 5). Division algebras are studied in Section 6. A theme that occurs continually in this chapter is the close interconnection be-

tween the structure of a ring and the structure of modules over the ring. The use of modules in the study of rings has resulted in a host of new insights and deep theorems.

------------------------------------------------------------------

The interdependence of the sections of this chapter is as follows:

![](https://storage.simpletex.cn/view/fUpY8smzKbwe2feqGILmHe29vgzTawUyr)

Much of the discussion here depends on the results of Section VIll.1 (Chain conditions).

## 1. SIMPLE AND PRIMITIVE RINGS

In this section we study those rings that will be used as the basic building blocks in the structure theory of rings. We beginbyrecalling several facts that motivate a large part of this chapter

(i) If $V$ is a vector space over a division ring $D$ , then $\mathrm{Hom}_D(V,V)$ is a ring (Exercise IV.1.7), called the endomorphism ring of $V$ (ii) The endomorphism ring of a finite dimensional vector space over a division

ring is isomorphic to the ring of all $n\times n$ matrices over a (possibly different) division ring (Theorem Vl1.1.4). (ii) If $D$ is a division ring, then $\mathbf{Mat}_n\boldsymbol{D}$ is simple (that is, has no proper ideals;

Exercise Il1.2.9) and is both left and right Artinian (Corollary VIl1.1.12). Consequently by (ii) every endomorphism ring of a finite dimensional vector space over a division ring is both simple and Artinian. (iv) The endomorphism ring of an infnite dimensional vector space over a divi-

sion ring is neither simple nor Artinian (Exercise 3). However, such a ring is primitive, in a sense tobe defined below.

Matrix rings and endonorphism rings of vector spaces over division rings arise naturally in many different contexts. They are extremely useful mathematical concepts. Consequently it seems reasonable to take such rings, or at least rings that closely resemble them, as the basis of a structure theory and to attempt to describe arbitrary rings in terms of these basic rings. With the advantage of hindsight we single out two fundamental properties of the

endomorphism ring of a vector space $V$ : simplicity (Defnition 1.1) and primitivity (Definition 1.5). As noted above these two concepts roughly correspond to the cases when $V$ is finite or infinite dinensionalrespectively.In this section we shall analyze simple and primitive rings and show that in several important cases they coincide with endomorphism rings. In other cases they come as close to being endomorphism rings as is reasonably possible. More precisely, an arbitrary primitive ring $R$ is shown to be isomorphic to a par-

ticularkind of subring(called a dense subring) of the endomorphism ring of a vector space $V$ over a division ring $D$ (Theorem 1.12). $R$ is left Artinian if and only if $\dim_DV$ DV $_{|DV}$

------------------------------------------------------------------

is finite (Theorem 1.9). In this classical case, simple and primitive rings coincide and $R$ is actually isomorphic to the complete endomorphism ring of $V$ (Theorem 1.14). Furthermore in this situation $\dim_DV$ is uniquely determined and $V$ is determined up to isomorphism (Proposition 1.17). These results amply justify the designation of simplicity and primitivity as fundamental concepts. As noted in the introduction to this chapter modules play a crucial role in ring

theory. Consequently we begin by defining and developing the elementary properties of simplicity for both rings and modules.

Definition 1.1. A (lefi) module A over a ring R is simple (or irreducible) provided $\mathbf{RA}\neq0$ and A has no proper submodules. A ring R is simple $if\mathbf{R}^2\neq0$ and R has no proper (two-sided) ideals.

REMARKS. (i) Every simple module [ring] is nonzero.

(i) Every simple module over a ring with identity is unitary (Exercise IV.1.17) A unitary module $A$ over a ring $R$ with identity has $RA\neq0$ ,whence $A$ is simple if and only if $A$ has no proper submodules. (i)Every simple module $A$ is cyclic; in fact, $A=Ra$ for every nonzero a e $A$

[Proof: both Ra $(a\in A)$ and $B=\{c\in A\mid Rc=0\}$ are submodules of $A$ ，whence each is either O or $A$ by simplicity. But $RA\neq0$ implies $B\neq A$ . Consequently $B=0$ whence $Ra=A$ for all nonzero a e $A$ .] However a cyclic module need not be simple (for example, the cyclic $\mathbf{Z}$ -module $Z_{6}$ (iv) The definitions of "simple''for groups, modules, and rings can be subsumed

into one general definition, which might be roughly stated as: an algebraic object $C$ that is nontrivial in some reasonable sense (for example, $RA\neq0$ or $R^{2}\neq0$ ）is simple, provided that every hornomorphism with domain $C$ has kernel O or $C$ . The point here is that the absence of nontrivial kernels is equivalent to the absence of proper normal subgroups of a group or proper submodules of a module or proper ideals of a ring as the case may be.

EXAMPLE.Every division ring is a simple ring and a simple $D$ -module (see the Remarks preceding Theorem III.2.2).

EXAMPLE. Let $D$ be a division ring and let $R=\mathrm{Mat}_nD\left(n>1\right)$ (n > 1) $(n>1)$ . For each $k$ $k\left(1\leq k\leq n\right)$ ， $I_{k}=\left\{(a_{ij})\varepsilon R\mid a_{i,}=0\mathrm{~for~}j\neq k\right\}$ j≠k $j\neq k\}$ is a simple left $R$ -module (see the proof of Corollary VIll.1.12)

EXAMPLE. The preceding example shows that $Mat_nD$ nD $_{\cdot n}\boldsymbol{D}$ $D$ a division ring) is not a simple left module over itself if $n>1$ . However, the ring $\mathrm{Mat}_nD\left(n\geq1\right)$ (n ≥ 1) $(n\geq1)$ is simple by Exercise Il1.2.9. Thus by Theorem VI1.1.4 the endomorphism ring of any finite dimensional vector space over a division ring is a simple ring.

EXAMPLE. A left ideal I of a ring $R$ is said to be a minimal left ideal if $I\neq0$ and for every left ideal $J$ such that $0\subset J\subset I$ either $J=0$ or $J=I.$ A left ideal $I$ of $R$ such that $RI\neq0$ is a simple left $R$ -module if and only if $I$ is a minimal left ideal

EXAMPLE. Let $F$ be a field of characteristic zero and $R$ the additice group of polynomials $F[x,y]$ . Define multiplication in $R$ by requiring that multiplication be

1

1

------------------------------------------------------------------

distributive and that $xy=yx+1$ and $ax=xa,ay=ya$ for a e $F.$ .Then $R$ is a welldefined simple ring that has no zero divisors and is not a division ring (Exercise 1).

Let $A=Ra$ be a cyclic $R$ -module. The map $\theta:R\to A$ defined by $r\vdash ra$ is an $R$ -module epimorphism whose kernel. $I$ is a left ideal (submodule) of $R$ (Theorem IV.1.5). By the First Isomorphism Theorem IV.1.7 $R/I$ is isomorphic to $A$ .By Theorem IV.1.10 every submodule of $R/I$ is of the form $J/I$ ,where $J$ is a left ideal of $R$ that contains I. Consequently $R/I$ (and hence $A$ has noproper submodules if and only if $I$ is a maximal left ideal of $R$ . Since every simple $R$ -module is cyclic by Remark (ii) above, every simple $R$ -module is isomorphic to $R/I$ for some maximal left ideal I. Conversely, if $I$ is a maximal left ideal of $R,\:R/I$ will be simple provided $R(R/I)\neq0$ . A condition that guarantees that $R(R/I)\neq0$ is given by

Definition 1.2. A left ideal I in a ring R is regular (or modular) if there exists e ε R such that r - re e I for every r e R. Similarly, a right ideal J is regular if there exists e e R such that r- er e J for every r e R.

REMARK. Every left ideal in a ring $R$ with identity is regular (let $e=\mathbf{1}_{R}$

Theorem 1.3. A left module A over a ring R is simple if and only if A is isomorphic to R/1 for some regular maximal left ideal I.

REMARKS. If $R$ has an identity, the theorem is an immediate consequence of the discussion above. The theorem is true if"left" is replaced by “right" throughout.

PROOF OF 1.3. The discussion preceding Defnition 1.2 shows that if $A$ is simple, then $A\:=\:Ra\cong R/I$ where the maximal left ideal I is the kernel of $\theta$ .Since $A\:=\:Ra$ ， $a=ea$ for some $e\varepsilon R$ .Consequently, for any $r\varepsilon R$ ， $ra=rea$ or $(r-re)a=0$ , whence r - re ε Ker $\theta=I.$ Therefore $I$ is regular.

Converselylet / be aregularmaximalleft ideal of $R$ such that $A\cong R/I.$In view of the discussion precedingDefinition 1.2 it suffices to prove that $R(R/I)\neq0$ .If this is not the case, then for all r e $Rr(e+I)=I$ , whence re e $I.$ Since $r-re\varepsilon I$ ,wehave $r\varepsilon I.$ Thus $R=I$ , contradicting the maximality of. $I$ .

Having developed the necessary facts about simplicity we now turn to primitivity. In order to define primitive rings we need:

Theorem 1.4.Let Bbe asubset of alefi module Aover a ring R.Then $G(B)=\{r\varepsilon R|rb=0$ for all bε B}is alefr ideal of R.IfBis a submoduleof A,then $\alpha(\mathbf{B})$ is anideal.

$\alpha(B)$ is called the (left) annihilator of $B$ . The right annihilator of a right module is defined analogously.

SKETCH OF PROOF OF 1.4. It is easy to verify that $G(B)$ is a left ideal. Let $B$ be a submodule. If r e $R$ and s e $G(B)$ , then for every $b\varepsilon B\left(sr\right)b=s(rb)=0$ since $rb\varepsilon B$ . Consequently, sr e $G(B)$ ,whence $G(B)$ is also a right ideal.

------------------------------------------------------------------

Definition 1.5. A (lefi) module A is faithful ifits (left) annihilator (A) is 0. A ring R is (left) primitive if there exists a simple faithful left R-module

Right primitive rings are defined analogously. There do exist right primitive rings that are not left primitive (see G. Bergman [58]). Hereafter "primitive" will always mean “left primitive.However, all results proved for left primitive rings are true, mutatis mutandis, for right primitive rings.

EXAMPLE. Let $V$ be a (possibly infinite dimensional) vector space over a division ring $D$ and let $R$ be the endomorphism ring $\mathrm{Hom}_{D}(V,V)$ of $V$ . Recall that $V$ is a left $R$ -module with $\theta v=\theta(v)$ for UEV $\upsilon\varepsilon V$ $\upsilon\in V,\theta\varepsilon R$ θeR $\theta\varepsilon R$ (Exercise IV.1.7). If $u$ is a nonzero vector in $V$ , then there is a basis of $V$ that contains $u$ (Theorem IV.2.4). If $\upsilon\varepsilon V$ ,then there exists 0v $\theta_v$ $\theta_v\varepsilon R$ $R$ R such that $\theta_{v}\mu=c$ (just define $\theta_v(u)=v$ and $\theta_{v}(w)=0$ for all other basis elements $w$ ;then $\theta_v$ E $R$ by Theorems IV.2.1 and IV.2.4). Therefore $Ru=V$ for any nonzero $u\varepsilon V$ ,whence $V$ has no proper $R$ -submodules. Since $R$ has an identity. $RV\neq0$ . Thus $V$ is a simple $R$ -module. If $\theta V=0\left(\theta\varepsilon R\right)^{j}$ ,then clearly $\theta=0$ ,whence $\alpha(V)=0$ and $V$ is a faithful $R$ -module. Therefore,. $R$ is primitive. If $V$ is finite dimensional over $D$ , then $R$ is simple by Exercise III.2.9 and Theorem VI1.1.4. But if $V$ is infinite dimensional over. $D$ , then $R$ is not simple: the set of all $\theta\varepsilon R$ such that $Im\theta$ $\theta$ 0 is finite dimensional subspace of $V$ is a proper ideal of $R$ (Exercise 3).

The next two results provide other examples of primitive rings.

Proposition 1.6. A simple ring R with identity is primitive.

PROOF. $R$ contains a maximal left ideal / by Theorem Ill.2.18. Since $R$ has an identity I is regular, whence $R/I$ is a simple $R$ -module by Theorem 1.3. Since $G(R/I)$ is an ideal of $R$ that does not contain $1_{R}$ 1R $1_{R}$, $\alpha ( R/ I) = 0$ by simplicity. Therefore. $R/I$ is faithful.

1

Proposition 1.7. A commutative ring R is primitice if and only if R is a field

PROOF. A feld is primitive by Proposition 1.6. Conversely, let $A$ be a faithful simple left $R$ module. Then $A\cong R/I$ for some regular maximal left ideal $I$ of $R$ Since $R$ is commutative, $I$ is in fact an ideal and $I\subset\mathfrak{G}(R/I)=\mathfrak{G}(A)=0$ .Since $I=0$ is regular, there is an $e\varepsilon R$ such that $r=re\left(=er\right)$ (=er) $(=er)$ for all $r\varepsilon R$ . Thus $R$ is a commutative ring with identity. Since $I=0$ is maximal, $R$ is a field by Corollary 111.2.21.

In order to characterize noncommutative primitive rings we need the concept of density.

Definition 1.8. Let V be a (leff) vector space over a division ring D. A subring R of the endomorphism ring. $Hom_{\mathrm{D} }( \mathbf{V} , \mathbf{V} )$ is called a dense ring ofendomorphisms ofV (or a dense subring of $Hom_{\mathrm{D} }( \mathbf{V} , \mathbf{V} ) )$ if for every positive integer n, every linearly independen subset $\{u_{1},\ldots,u_{n}\}$ of $V$ and every arbitrary subset. $\{v_1,\ldots,v_n\}$ of $V$ , there exists $\theta\varepsilon R$ such that $\theta ( u_i) = \mathbf{v_{i}}$ $(\mathbf{i}=1,2,\ldots,\mathbf{n})$

1

—

------------------------------------------------------------------

EXAMPLE. $\operatorname{Hom}_D(V,V)$ is a dense subring of itself. For if $\{u_1,\ldots,u_n\}$ is a linearly independent subset of $V$ , then there is.a basis $U$ of $V$ that contains $u_{1},\ldots,u_{n}$ $u_n$ un by Theorem IV.2.4. If $v_{1},\ldots,v_{m}\in V$ $v_m\in V$ U'm E V , then the map $\theta:V\to V$ defined by $\theta(u_{i})=v_{i}$ and $\theta(u)=0$ for $u\varepsilon U-\{u_1,\ldots,u_n\}$ is a well-defined element of $\mathrm{Hom}_{D}(V,V)$ by TheoremsIV.2.1 and IV.2.4. In the fnite dimensional case, $\mathrm{Hom}_{D}(V,V)$ is the only dense subring as we see in

Theorem 1.9. Let R be a dense ring of endomorphisms of a vector space $V$ over a division ring D. Then R is left[resp. right] Artinian if and only if dimpV is finite, in which case $\mathbf{R}=Hom_{\mathbf{D}}(\mathbf{V},\mathbf{V})$

PROOF. If $R$ is left Artinian and $\dim_DV$ is infnite, then there exists an infnite linearly independent subset $\{u_1,u_2,\ldots\}$ of $V$ .By Exercise $\mathbf{IV.1.7}V$ is a left $\mathrm{Hom}_{D}(V,V)$ -module and hence a left $R$ -module. For each $n$ let $I_n$ be the left annihilator in $R$ of the set $\{u_1,\ldots,u_n\}$ . By Theorem 1.4, $I_1\supset I_2\supset\cdots$ is a descending chain of left ideals of $R$ .Let $w$ be anynonzero element of $V$ .Since $\{u_{1},\ldots,u_{n+1}\}$ is linearly independent for each $n$ and $R$ is dense, there exists $\theta\varepsilon R$ such that

$$\theta u_i=0\quad\mathrm{for}\quad i=1,2,\ldots,n\quad\mathrm{and}\quad\theta u_{n+1}=w\neq0.$$

Conseq uently $\theta\varepsilon I_n$ but $\theta\notin I_{n+1}$ . Therefore $I_{1}\sum_{\not=}I_{2}\sum_{\not=}\cdots$ is a properly descending chain, which is a contradiction. Hence $\dim_DV$ is fnite. Conversely if $\dim_DV$ is fnite, then $V$ has a finite basis $\{v_1,\ldots,v_m\}$ . If $f$ is any

element of $\mathrm{Hom}_{D}(V,V)$ ,then $f$ is completely determined by its action on $v_1,\ldots,v_m$ by Theorems IV.2.1 and IV.2.4. Since $R$ is dense, there exists $\theta\varepsilon R$ such that

$$\theta(v_i)\:=\:f(v_i)\quad\mathrm{for}\quad i\:=\:1,2,\ldots,m,$$

whence $f=\theta\in R$ Therefore $\mathrm{Hom}_{D}(V,V)=R$ .But $\mathrm{Hom}_{l,V}(V,V)$ is Artinian by Theorem VII.1.4 and Corollary VIIl.1.12.

In order to prove that an arbitrary primitive ring is isomorphic to a dense ring of endomorphisms of a suitable vector space we need two lemmas.

Lemma 1.10. (Schur) Let A be a simple module over a ring R and let B be any R-module.

(i) Every nonzero R-module homomorphism $\mathbf{f}:\mathbf{A}\to\mathbf{B}$ is a monomorphism, (i) every nonzero R-module homomorphism $\mathbf{g}:\mathbf{B}\to\mathbf{A}$ is an epimorphism, (ii) the endomorphism ring. $\mathbf{D}=Hom_{\mathbf{R}}(\mathbf{A},\mathbf{A})$ is a division ring.

PROOF. (i) Ker $f$ is a submodule of $A$ and Ker $f\neq A$ since $f\neq0$ . Therefore Ker $f=0$ by simplicity. (ii) Im $g$ is a nonzero submodule of $A$ since $g\neq0$ ,whence $\mathbf{Im}g=A$ by simplicity. (ii) If h e $D$ and $h\neq0$ , then $h$ is an isomorphismby (i) and (ii). Thus $f$ has a two-sided inverse $f^{-1}\varepsilon\operatorname{Hom}_R(A,A)=D$ (see the paragraph after Definition IV.1.2). Consequently every nonzero element of $D$ is a unit, whence $D$ is a division ring.

------------------------------------------------------------------

REMARK. If $A$ is a simple $R$ -module, then $A$ is a vector space over the division. ring $\operatorname{Hom}_R(A,A)$ with $fa=f(a)$ (Exercise IV.1.7 and Lemma 1.10).

Lemma 1.11.Let A be a simple module over a ring R. Consider A as a vector space over the division ring $\mathbf{D}=Hom_{\mathbf{R}}(\mathbf{A},\mathbf{A})$ . If V is a finite dimensional D-subspace o f the. D-vector space A and a e A - V, then there exists r e R such that ra. $\neq0$ and $\mathbf{r}\mathbf{V}=0$

PROOF. The proof is by induction on $n=\dim_DV$ If $n=0$ ,then $V=0$ and $a\neq0$ .Since $A$ is simple, $A=Ra$ by Remark (iii) after Definition 1.1. Consequently, there exists $r\varepsilon R$ R $R$ such that $ra=a\neq0$ and $rV=r0=0$ . Suppose $\dim_DV=n>0$ and the theorem is true for dimensions less than $n$ . Let $\{u_1,\ldots,u_{n-1},u\}$ be a $D$ -basis of $V$ and let $W$ be the $(n-1)$ -dimensional $D$ -subspace spanned by $\{u_1,\ldots,u_{n-1}\}$ $W=0$ if $n=1$ ). Then $V=W\oplus Du$ (vector space direct sum). Now $W$ may not be an $R$ -submodule of $A$ , but in any case the left annihilator $I=G(W)$ in $R$ of $W$ is a left ideal of $R$ by Theorem 1.4. Consequently, $Iu$ is an $\dot{R}$ -submodule of $A$ (Exercise IV.1.3). Since $u\in A-W$ , the induction hypothesis implies that there exists $r\varepsilon R$ R $R$ such that $ru\neq0$ and $rW=0$ (that is, $r\varepsilon I=G(W)$ . Consequently $0\neq ru\in Iu$ whence $Iu\neq0$ . Therefore $A=Iu$ by simplicity. [Note: The contrapositive of the inductive argument used above shows that if

UE $A$ and $rv=0$ for all $r\varepsilon I$ , then $\upsilon\varepsilon W$ 1 We must find r e $R$ such that $ra\neq0$ and $rV=0$ . If no such $r$ exists, then we can

define a map $\theta:A\to A$ as follows. For ru $\varepsilon Iu=A$ let $\theta(ru)=ra\varepsilon A$ .We claim that $\theta$ is well defned. If $r_1u=r_2u$ $(r_{i}\varepsilon I=G(W))$ , then $(r_1-r_2)u=0$ ,whence $(r_1-r_2)V$ $=(r_1-r_2)(W\oplus Du)=0$ . Consequently by hypothesis $(r_{1}-r_{2})a=0$ . Therefore $\theta(r_{1}u)=r_{1}a=r_{2}a=\theta(r_{2}u)$ .Verify that $\theta\varepsilon\operatorname{Hom}_{R}(A,A)=D$ . Then for every $r\varepsilon I$

$$0=\theta(ru)-ra=r\theta(u)-ra=r(\theta(u)-a).$$

Therefore $\theta(u)-a\varepsilon W$ by the parenthetical Note above. Consequently.

$$a=\theta u-(\theta u-a)\varepsilon Du+W=V,$$

which contradicts the fact that $a\notin V$ . Therefore, there exists $r\varepsilon R$ R $R$ such that $ra\neq0$ and $rV=0$ ■

1

Theorem 1.12. (Jacobson Density Theorem) Let R be a primitive ring and A a faithful simple R-module. Consider A as a vector space over the division ring. $Hom_{\mathbf{R}}(\mathbf{A},\mathbf{A})=\mathbf{D}$ Then R is isomorphic to a dense ring of endomorphisms of the D-vector space A.

REMARK.A converse of Theorem 1.12 is also true,in fact in a much stronger form (Exercise 4).

PROOF OF 1.12. For each $r\varepsilon R$ the map $\alpha_r:A\to A$ given by $\alpha_r(a)=ra$ is easily seen to be a $D$ endomorphism of $A$ : that is, $\alpha,\varepsilon\operatorname{Hom}_D(A,A)$ . Furthermore for all $r,s\in R$ R $R$

$$\alpha_{(r+s)}=\alpha_{r}+\alpha_{s}\quad\mathrm{and}\quad\alpha_{rs}=\alpha_{r}\alpha_{s}.$$

Consequently the map $\alpha:R\to\operatorname{Hom}_D(A,A)$ defned by $\alpha(r)=\alpha_r$ is a well-definec homomorphism of rings. Since $A$ is a faithful $R$ -module, $\alpha_{r}=0$ if and only if

1

------------------------------------------------------------------

r $\varepsilon\:{\mathcal{G}}(A)\:=\:0$ . Therefore $\alpha$ is a monomorphism, whence $R$ is isomorphic to the subring $Im\alpha$ α $\alpha$ of $\mathrm{Hom}_D(A,A)$ To complete theproof we must show that Im $\alpha$ is a dense subring of $\mathrm{Hom}_D(A,A)$

Given a $D$ -linearly independent subset $\boldsymbol{U}=\{u_{1},\ldots,u_{n}\}$ of $A$ and an arbitrary subset $\{v_{1},\ldots,v_{n}\}$ of $A$ we must find $\alpha_r$ ∈ Im $\alpha$ such that $\alpha_{r}(u_{i})=v_{i}$ for $i=1,2$ ....,n For each $i$ let $V_{i}$ be the $D$ -subspace of $A$ spanned by $\{u_{1},\ldots,u_{i-1},u_{i+1},\ldots,u_{n}\}$ Since $U$ is $D$ -linearly independent, $u_i\notin V_i$ . Consequently, by Lemma 1.11 there exists $r_i\varepsilon R$ such that $r_iu_i\neq0$ and $r_iV_i=0$ . We next apply Lemma 1.11 to the zero subspace and the nonzero element $r_iU_i$ : there exists $s_i\varepsilon R$ such that $s_{i}r_{i}u_{i}\neq0$ and $s_i0=0$ Since $s_ir_iu_i\neq0$ ,the $R$ -submodule $Rr_il\iota_i$ of $A$ is nonzero, whence $Rr_iu_i=A$ by simplicity. Therefore exists $t_i\varepsilon R$ R $R$ such that $t_{i}r_{i}u_{i}=v_{i}.$ Let

$$r\:=\:t_{1}r_{1}\:+\:t_{2}r_{2}+\cdots+\:t_{n}r_{n}\:\varepsilon\:R.$$

Recall that for $i\neq j,\:u_{i}\in V_{i}$, whence $t_jr_ju_i\in t_j(r_iV_j)=t_i0=0$ . Consequently for each $i=1,2,\ldots,n$

$$\alpha_{r}(u_{i})=(t_{1}r_{1}+\cdots+t_{n}r_{n})u_{i}=t_{i}r_{i}u_{i}=v_{i}.$$

Therefore Im $\alpha$ is a dense ring of endomorphisms of the $D$ -vector space $A$ .

REMARK. The only point in the proof of Theorem 1.12 at which the faithfulness of $A$ is used is to show that $\alpha$ is a monomorphism.Consequently the proof shows that any ring that has a simple module $A$ also has a homomorphic image that is a dense ring of endomorphisms of the $D$ -vector space $A$

Corollary 1.13. If R is a primitive ring, then for some division ring D either R is isomorphic to the endomorphism ring of a finite dimensional vector space over D or for every positive integer m there is a subring $R_m$ of R and an epimorphism ofrings $\mathbf{R}_{\mathrm{m}}\rightarrow Hom_{\mathrm{D}}(\mathbf{V}_{\mathrm{m}},\mathbf{V}_{\mathrm{m}})$ , where $V_{\mathrm{m}}$ is an m-dimensional vector space orer D

REMARK. The Corollary may also be phrased in terms of matrix rings over a division ring via Theorem VIl.1.4.

SKETCH OF PROOF OF 1.13. In the notation of Theorem 1.12,

$$\alpha:R\to\mathrm{Hom}_D(A,A)$$

is a monomorphism such that $R=$Im$\alpha$ and $Im\alpha$ α $\alpha$ is dense in $\mathrm{Hom}_D(A,A)$ .If $\dim_{n}A=n$ is finite, then Im $\alpha=\operatorname{Hom}_{D}(A,A)$ by Theorem 1.9. If $\dim_DA$ is infnite and $\{u_1,u_2,\ldots\}$ is an infnite linearly independent set, let $V_{m}$ be the $m$ -dimensional $D$ -subspace of $A$ spanned by $\{u_1,\ldots u_m\}$ . Verify that $R_{m}=\{r\varepsilon R\mid rV_{m}\subset V_{m}\}$ is a subring of $R.$ Use the density of $R\cong\operatorname{Im}\alpha$ in $\mathrm{Hom}_n(A,A)$ to show that the map $R_m\to\operatorname{Hom}_h(V_m,V_m)$ given by $r\vdash\alpha_{r}\mid V_{m}$ is a well-defined ring epimorphism.

Theorem 1.14. (Wedderburn-Artin) The following conditions on a left Artinian ring R are equivalent.

(i) R is simple; (i) R is primitive;

------------------------------------------------------------------

(ii) R is isomorphic to the endomorphism ring of a nonzero finite dinensional vector space V over a division ring D; (iv) for some positive integer n, R is isomorphic to the ring of all. n×n matrices

over a division ring.

PROOF. $(\mathrm{i})\Rightarrow$ (ii) We frst observe that $I=\{r\varepsilon R\mid Rr=0\}$ is an ideal of $R$ whence $I=R$ or $I=0$ . Since $R^2\neq0.$ ,we must have $I=0$ . Since $R$ is left Artinian thesetof all nonzeroleft ideals of $R$ contains a minimal left ideal J. J has no proper $R$ -submodules, (an) $R$ -submodule of $J$ is a left ideal of $R$ ).Weclaim that theleft annihilator $\alpha(J)$ of $J$ in $R$ is zero. Otherwise $\alpha(J)=R$ by simplicity and $Ru=0$ for every nonzero u ε J. Consequently, each such nonzero $u$ is contained in $I=0$ which is a contradiction. Therefore $\alpha(J)=0$ and $RJ\neq0$ . Thus $J$ is a faithful simple $R$ -module, whence $R$ is primitive. $\Longrightarrow$ = $(\mathrm{ii})\Rightarrow(\mathrm{iii})$ By Theorem $1.12R$ is isomorphic to a dense ring $T$ of endomorphisms

of a vector space $V$ over a division ring $D$ . Since $R$ is left Artinian, $R\cong T=$ $\mathrm{Hom}_D(V,V)$ by Theorem 1.9. (ii) 1 $\Longleftrightarrow$ $\Leftrightarrow($iv) Theorem VII.1.4.

$(\mathbf{i}\mathbf{v})\Longrightarrow($ 》 $\Longrightarrow$ i) Exercise III.2.9.

We close this section by proving that for a simpleleft Artinian ring $R$ the integers $\dim_DV$ and $n$ in Theorem 1.14 are uniquely determined and the division rings in Theorem 1.14 (i) and (iv) are determined up to isomorphism. We need two lemmas

Lemma 1.15. Ler V be a finite dimensional vector space over a division ring D. If A and B are simple faithful modules over the endomorphism ring. $\mathbf{R}=Hom_{\mathbf{D}}(\mathbf{V},\mathbf{V})$ then A and B are isomorphic R-modules

PROOF. By Theorems VI1.1.4, VI11.1.4 and Corollary VI11.1.12, the ring $R$ contains a (nonzero) minimal left ideal I. Since $A$ is faithful, there exists $a\varepsilon A$ such that $la\neq0$ . Thus $Ia$ is a nonzero submodule of $A$ (Exercise IV.1.3), whence $Ia=A$ by simplicity. The map $\theta:I\to Ia=A$ given by $i\vdash$ ia is a nonzero $R$ -module epimorphism. By Lemma $1.10\theta$ $\theta$ 0 is an isomorphism. Similarly $I\cong B$ .■

1

Lemma 1.16. Ler V be a nonzero vector space over a division ring D and ler R be the endomorphism ring . $Hom_{\mathrm{D}}(\mathbf{V},\mathbf{V})$ 1 $f\mathbf{g}:\mathbf{V}\to\mathbf{V}$ is a homomorphism of additive groups such that gr $=\mathbf{rg}$ for all r e R, then there exists d e D such that. $\mathbf{g}(\mathbf{v})=$ dvfor allv eV

PROOF. Let $u$ be a nonzero element of $V$ . We claim that $u$ and $g(u)$ are linearly dependent over $D$ . If $\dim_DV=1$ , this is trivial. Suppose $\dim_{D}V\geq2$ and $\{u,g(u)\}$ is linearly independent. Since. $R$ is dense in itself (Example after Definition 1.8), there exists $r\varepsilon R$ such that $r(u)=0$ and $r(g(u))\neq0$ . But by hypothesis

$$r(g(u))=rg(u)=gr(u)=g(r(u))=g(0)=0,$$

which is a contradiction. Therefore for some d e $D$ $g(u)=du$ . If $\upsilon\varepsilon V$ ,then there exists $s\varepsilon R$ such that $s(u)=v$ by density. Consequently, since $s\varepsilon R=\mathrm{Hom}_{D}(V,V)$ $g(v)=g(s(u))=gs(u)=sg(u)=s(du)=ds(u)=dv$ .！

------------------------------------------------------------------

Proposition 1.17. For i =1,2 let $V_{i}$ be a vector space of finite dimension $n_{i}$ over the division ring $\mathbf{D}_{\mathbf{i}}$

(i) If there is an isomorphism of rings $Hom_{\mathrm{Dl}}(\mathcal{V}_{1},\mathcal{V}_{1})\cong Hom_{\mathrm{D2}}(\mathcal{V}_{2},\mathcal{V}_{2})$ then $dim_{\mathrm{D}_{1}}V_{\mathrm{I}}=dim_{\mathrm{D}_{2}}V_{\mathrm{2}}$ and $\mathbf{D}_{\mathrm{l}}$ is isomorphic to $\mathbf{D}_2$ (ii) If there is an isomorphism ofrings $Mat_{\mathrm{~nl}}\mathbf{D}_{\mathrm{~l}}\cong Mat_{\mathrm{~n}2}\mathbf{D}_{2}$, then $n_{1}=n_{2}$ and $\mathbf{D}_{\mathbf{l}}$ is

isomorphic to $\mathbf{D}_{2}$

SKETCH OF PROOF. (i) For $i=1,2$ the example after Definition 1.5 shows that $V_{i}$ is a faithful simple $\mathrm{Hom}_{D_i}(V_i,V_i)$ -module. Let $R=\mathrm{Hom}_{D_{1}}(V_{1},V_{1})$ and let

$$\sigma:R\to\mathrm{Hom}_{D2}(V_2,V_2)$$

be an isoniorphism. Then $V_{2}$ is a faithful simple $R$ -module by pullback along $\sigma$ (that is, $rv=\sigma(r)v$ for re $R$ ,UE $V_2$ ).ByLemma1.15 there is an $R$ -module isomorphism $\phi:V_1\to V_2$ .For each $\upsilon\varepsilon V_1$ V $V_{1}$ and $f\varepsilon R$ R $R$

$$\phi[f(v)]=f\phi(v)=(\sigma f)[\phi(v)],$$

whence

$$\phi f\phi^{-1}=\sigma(f)$$

as a homomorphism of additive groups $V_2\to V_2$ .For each de $D_i$ let $\alpha_{d}:V_{i}\rightarrow V_{i}$ be the homomorphism of additive groups defined by $x|\to dx$ . Clearly $\alpha_{d}=0$ if and only if $d=0$ .For every $f_{\varepsilon }$ $R=$ $\mathrm{Hom}_{D1}( V_{1}, V_{1})$ and every $d\varepsilon$ $D_{1}, f\alpha _{d}= \alpha _{d}f.$ Conseq uently,

$$\begin{aligned}
[\phi\alpha_{d}\phi^{-1}](\sigma f)& =\phi\alpha_{d}\phi^{-1}\phi f\phi^{-1}=\phi\alpha_{d}f\phi^{-1}=\phi f\alpha_{d}\phi^{-1} \\
&=\:\phi f\phi^{-1}\phi\alpha_{d}\phi^{-1}=(\sigma f)[\phi\alpha_{d}\phi^{-1}].
\end{aligned}$$

Since $\sigma$ is surjective, Lemma 1.16 (with $V=V_{2},g=\phi\alpha_{n}\phi^{-1})$ implies that there exists $d^*\varepsilon D_2$ D2 $D_{2}$ such that $\phi\alpha_{d}\phi^{-1}=\alpha_{d^{*}}$ . Let $\tau:D_{1}\to D_{2}$ be the map given by $\tau(d)=d^*$ Then for every $d\varepsilon D_1$
$$\phi\alpha_{d}\phi^{-1}=\:\alpha_{\tau(d)}.$$

Verify that $\tau$ is a monomorphism of rings. Reversing the roles of $D_{\mathbf{l}}$ and $D_2$ in the preceding argument (and replacing $\phi,\sigma$ by $\phi^{-1},\sigma^{-1})$ yields for every. $k\varepsilon D_2$ anele ment $d\varepsilon D$ D $D$ such that
$$\phi^{-1}\alpha_{k}\phi=\alpha_{d}:V_{1}\to V_{1},$$

whence $\alpha_{k}=\phi\alpha_{d}\phi^{-1}=\alpha_{\tau(d)}$ . Consequently $k=\tau(d)$ and hence $\tau$ is surjective Therefore $\tau$ is an isomorphism. Furthermore for every $d\varepsilon D_1$ and $\upsilon\varepsilon V_1$

$$\phi(dv)=\phi\alpha_{d}(v)=\alpha_{\tau(d)}\phi(v)=\tau(d)\phi(v).$$

Use thisfact toshow that $\{u_1,\ldots,u_k\}$ is $D_{1}$ -linearly independent in $V_{\mathbf{I}}$ if and only if $\left\{\phi(u_1),\ldots,\phi(u_k)\right\}$ is $D_{2}$ -linearly independent in. $V_{2}$ . It follows that $\dim_{D_{1}}V_{1}=\dim_{D_{2}}V_{2}$ (ii) Use (i), Exercise II1.1.17(e) and Theorem VI1.1.4.

## EXERCISES

1. Let $F$ be a field of characteristic O and $R$ $= F[ x, y]$ the additive group of poly nomials in two indeterminates. Define multiplication in $R$ by requiring that multiplication be distributive, that $ax=xa$ ， $ay=ya$ for all $a\varepsilon F$ , that the product of $x$ and $y$ (in that order) be the polynomial $xy$ as usual, but that the product of $y$ and $x$ be the polynomial $xy+1$

------------------------------------------------------------------

T

(a) $R$ is a ring.

(b) $yx^{k}=x^{k}y+kx^{k-1}$ and $y^{k}x=xy^{k}+ky^{k-1}$ (c) $R$ is simple. (Hinr: Let $f$ be a nonzero element in an ideal $I$ of $R$ ; then

either $f$ has no terms involving $y$ or $g=xf-fx$ is a nonzero element of $I$ that has lower degree in $y$ than does $f.$ In the latter case,consider $xg-gx$ . Eventually find a nonzero $h\varepsilon I$ ,which is free of $y$ . If $h$ is nonconstant, consider $hy-yh$ .Ina finite number of steps, obtain a nonzero constant element of $I;$ hence $I=R$ ） (d) $R$ has no zero divisors. (e) $R$ is not a division ring.

2. (a) If $A$ is an $R$ -module, then $A$ is also a well-defined $R/G(A)$ -module with $(r+G(A))a=ra\left(a\varepsilon A\right)$

(b) If $A$ is a simple left $R$ -module, then $R/\mathfrak{Q}(A)$ is a primitive ring.

3. Let $V$ be an infinite dimensional vector space over a division ring $D$

(a) If $F$ is the set of all $\theta\varepsilon\mathrm{Hom}_{I^{\prime}}(V,V)$ such that $Im\theta$ is finite dimensional, then $F$ is a proper ideal of $\mathrm{Hom}_D(V,V)$ . Therefore $\mathrm{Hom}_D(V,V)$ is not simple

(b) $F$ is itself a simple ring. (c) $F$ is contained in every nonzero ideal of $\mathrm{Hom}_D(V,V)$ (d) $\mathrm{Hom}_D(V,V)$ is not (left) Artinian.

4. Let $V$ be a vector space over a division ring $D$ . A subring $R$ of $\mathrm{Hom}_{D}(V,V)$ is said to be n-fold transitive if for every $k$ $(1\leq k\leq n)$ and every linearly independent subset $\{u_1,\ldots,u_k\}$ of $V$ and every arbitrary subset $\{v_1,\ldots,v_k\}$ of $V$ ,there exists $\theta\varepsilon R$ such that $\theta(u_{i})=v_{i}$ for $i=1,2,\ldots,k$

(a) If $R$ is one-fold transitive, then $R$ is primitive. [Hint: examine the example after Defnition 1.5.] (b) If $R$ is two-fold transitive, then $R$ is dense in $\mathrm{Hom}_D(V,V)$ .[Hints: Use (a) to

show that $R$ is a dense subring of $\mathrm{Hom}_{\Delta}(V,V)$ ,where $\Delta=\operatorname{Hom}_{\mathcal{R}}(V,V)$ .Use twofold transitivity to show that $\Delta=\left\{\beta_{d}\mid d\varepsilon D\right\}$ ，where $\beta_{d}:V\to V$ is given by $x\vdash dx$ . Consequently $\mathrm{Hom}_\Delta(V,V)=\mathrm{Hom}_D(V,V).]$

5.If $R$ is a primitive ring such that for all $a,b\in R,a(ab-ba)=(ab-ba)a$ , then $R$ is a division ring. [Hint: show that $R$ is isomorphic to a dense ring of endomorphisms of a vector space $V$ over a division ring $D$ with $\dim_DV=1$ ，whence $R\cong D$ ]

6.If $R$ is a primitive ring with identity and $e\varepsilon R$ R $R$ is such that $e^{2}=e\neq0$ ,then (a) eRe is a subring of $R$ , with identity $e$

(b) eRe is primitive. [Hint: if $R$ is isomorphic to a dense ring of endomorphisms

of the vector space $V$ over a division ring $D$ , then $Ve$ is a $D$ -vector space and eRe is isomorphic to a dense ring of endoniorphisms of $Ve$ ]

7.If $R$ is a dense ring of endomorphisms of a vector space $V$ and $K$ is a nonzero ideal of $R$ ,then $K$ is also a dense ring of endomorphisms of $V$

1

## 2. THE JACOBSON RADICAL

The Jacobson radical is defined (Theorem 2.3) and its basic properties are developed (Theorems 2.12-2.16). The interrelationships of simple, primitive, and semisimple rings are examined (Theorem 2.10) and numerous examples are given.

------------------------------------------------------------------

Before pursuing further our study of the structure of rings, we summarize the general technique that we shall use. There is little hope at present of classifying all rings up to isomorphism. Consequently we shall attempt to discover classes of rings. for which some reasonable structure theorems are obtainable. Here is a classic method of determining such a class. Single out some “bad" or “undesirable" property of rings and study only those rings that do not have this property. In order tomake this method workable in practice one must make some additional assumptions. Let $P$ be a property of rings and call an ideal [ring] $I$ a $P$ -ideal $[P$ -ring] if $I$ has

property $P$ .Assume that

(i) the homomorphic image of a $P$ -ring is a $P$ -ring; (ii) every ring $R$ (or at least every ring in some specified class C) contains a $P$ -ideal $P(R)$ (called the P-radical of $R$ ) that contains all other $P$ -ideals of $R$ (ii) the $P$ -radical of the quotient ring $R/P(R)$ is zero; (iv) the $P$ -radical of the ring $P(R)$ is $P(R)$

## A property $P$ that satisfies (i)--(iv) is called a radical property.

The $P.$ -radical may be thought of as measuring the degree to which a given ring possesses the "* undesirable' property $P$ If we have chosen a radical property $P$ ,we then attempt to find structure theorems for those“nice"rings whose $P$ radical is zero. Such a ring is said to be $P$ -radical free or $P$ -semisimple.In actual practice we are usually more concerned with the $P$ -radical itself rather than the radical property $P$ from which it arises. By condition (i) every ring that has a $P$ -radical has a $P$ -semisimple quotient ring. Thus the larger $P$ -radical is, the more one discards (or factors out) when studying $P$ -semisimple rings. The basic problem is to find radicals that enable us to discard as little as possible and yet to obtain reasonably deep structure theorems. Wedderburn first introduced a radical in the study of finite dimensional algebras..

His results were later extended to (left) Artinian rings.However, the radical of Wedderburn (namely the maximal nilpotent ideal) and the remarkably strong structure theorems that resulted applied only to (left) Artinian rings. In subsequent years many other radicals were introduced. Generally speaking each of these coincided with the radical of Wedderburn in the left Artinian case, but were also defined for non-Artinian rings.. The chief purpose of this section is to study one such radical, the Jacobson

radical. Another radical, the prime radical, is discussed in Section 4; see also Exercise 4.11. For an extensive treatment of radicals see N. J. Divinsky [22] or M. Gray [23]. The host of striking theorems that have resulted from its use provide ample justification for studying the Jacobson radical in some detail. Indeed Section 1 was developed with the Jacobson radical in mind. Rings that are Jacobson semisimple (that is, have zero Jacobson radical) can be described in terms of simple and primitive rings (Section 3). Two preliminaries are needed before we define the Jacobson radical...

Definition 2.1. An ideal P of a ring R is said to be left [resp. right] primitive if the quotient ring R/P is a left [resp. right] primitire ring.

REVIARK. Since the zero ring has no simple modules and hence is not primitive. $R$ itself is not a left (or right) primitive ideal.

------------------------------------------------------------------

1

Definition 2.2.An element a in a ring R is said to be leftquasi-regular ifthere exists reR such that $\mathbf{r}+\mathbf{a}+\mathbf{r}\mathbf{a}=0$ . The element r is called a left quasi-inverse of a. A (right,lefi or two-sided) ideal I ofR is said tobe left quasi-regular ifevery element ofI is left quasi-regular. Similarly, a e R is said to be right quasi-regular if there exists reR such that a +r+ar=0. =0 =0 Right quasi-inverses and right quasi-regular ideals are. defined analogousl y

REMARKS. It is sometimes convenient to write $r\circ a$ for $r+a+ra$ If $R$ has an identity, then $a$ is left [resp. right] quasi-regular if and only if $\mathbf{1}_R+a$ is left [resp right] invertible (Exercise 1).

 In order to simplify the statement of several results, we shall adopt the following convention (which is actually a theorem of axiomatic set theory). Ifthe class C of those subsets ofa ring R that satisfy a given propertyis empty,then

IOe I is defsned o e R.

Theorem 2.3.If R is a ring,then there is an ideal J(R)of R such that:

(ii) J(R) is the intersection of all the regular maximal left ideals of R; (ii) J(R)istheintersection of all theleft primitiveideals of R; (iv)J(R) is a lefi quasi-regular lefi ideal which contains every left quasi-regular

(i) J(R) is the intersection of all the left annihilators of simple left R-modules le ft ideal of R, (v) Statements (i)-(iv) are also true if"left"' is replaced by "right"'

Theorem 2.3 is proved below (p. 428). The ideal $J(R)$ is called the Jacobson radical of the ring R. Historically it was frst defined in terms of quasi-regularity (Theorem 2.3 (iv), which turns out to be a radical property as defined in the introductory remarks above (see p. 431). As the importance of the role of modules in the study of rings became clearer the other descriptions of $J(R)$ were developed (Theorem 2.3 (i)-(i))

REMARKS.According to Theorem 2.3 (i) and the convention adopted above, $J(R)=R$ if $R$ has no simple left $R$ -modules (and hence no annihilators of same). If $R$ has an identity, then every ideal is regular and maximal left ideals always exist (Theorem II1.2.18), whence $J(R)\neq R$ by Theorem 2.3(ii). Theorem 2.3(iv) does not imply that $J(R)$ contains every left quasi-regular element of $R$ ; see Exercise 4.

The proof of Theorem 2.3 (which begins on p. 428) requires five preliminary lemmas.The lemmas are stated and proved for left ideals.However, each ofLemmas 2.4-2.8 is valid with "lefr" replaced by "righr' throughout. Examples are given after the proof of Theorem 2.3.

Lemma 2.4. IfI $(\neq\mathbb{R})$ is aregular leff ideal ofa ringR,thenIis contained in a maximal le ft ideal which is regular.

SKETCH OF PROOF. Since /is regular,there exists $e\varepsilon R$ such that $r-re$ ∈l for all r e $R$ . Thus any left ideal $J$ containing $I$ is also regular (with the same element

------------------------------------------------------------------

$e\varepsilon R)$ . If $I\subset J$ ar.d $e\varepsilon J$ ,then $r-re\varepsilon I\subset J$ implies $r\varepsilon J$ for every $r\varepsilon R$ ，whence $R=J.$ Usethis fact toverify that Zorn's Lemma is applicable to the set S of all left ideals $L$ such that $I\subset L\subseteq R$ , partially ordered by inclusion. A maximal element of

S is a regular maximal left ideal containing $I.$

Lemma 2.5. Let R be a ring and let K be the intersection of all regular maximal lefi ideals of R. Then K is a left quasi-regular left ideal of R.

PROOF. $K$ is obviously a left ideal. If a e $K$ let $T=\{r+ra\mid r\varepsilon R\}$ .If $T=R$ then there exists r E $R$ such that $r+ra=-a$ . Consequently $r+a+ra=0$ and hence $a$ is left quasi-regular. Thus it suffices to show that $T=R$

Verify that $T$ is a regular left ideal of $R$ (with $e=-a)$ .If $T\neq R$ ,then $T$ is contained in a regular maximal left ideal $I_0$ by Lemma 2.4. (Thus $T\neq R$ is impossible if $R$ has no regular maximal left ideals.) Since a E $K\subset I_0$, raE $I_0$ for all $r\varepsilon R$ .Thus since $r+ra\varepsilon T\subset I_{0}$, we must haver E $I_0$ for all $r\varepsilon R$ $R$ R . Consequently, $R$ = $I_{0}$, which contradicts the maximality of $I_0$ . Therefore $T=R$ .

Lemma 2.6.Let R be a ring that has a simple left R-module. If I is a lefi quasiregular left ideal of R, then I is contained in the interseciion of all the left annihila-. tors of simple left R-modules..

PROOF. If $I\not\subset\cap\mathfrak{a}(A)$ ,where the intersection is taken over all simple left $R$ -modules $A$ ,then $IB\neq0$ for some simple left $R$ -module $B$ ，whence $Ib\neq0$ for some nonzero $b\varepsilon B$ . Since $I$ is a left ideal, $Ib$ is a nonzero submodule of $B$ . Consequently $B=Ib$ by simplicity and hence $ab=-b$ for some ae I. Since $I$ is left quasi-regular, there exists $r\varepsilon R$ such that $r+a+ra=0$ . Therefore, $0=0b$ $=(r+a+ra)b=rb+ab+rab=rb-b-rb=-b$ .Since this conclusion contradicts the fact that $b\neq0$ ,we must have $I\subset\cap G(A)$ .

Lemma 2.7. An ideal P ofa ring R is le ft primitive if and only ifP is the left annihila tor ofa simple left R-module.

PROOF. If $P$ is a left primitive ideal, let $A$ be a simple faithful $R/P$ -module. Verify that $A$ is an $R$ -module,with ra $(r\in R,a\in A)$ defined to be $(r+P)a$ . Then $RA=(R/P)A\neq0$ and every $R$ -submodule of $A$ is an $R/P$ -submodule of $A$ ,whence $A$ is a simple $R$ -module. If $r\varepsilon R.$ then $rA=0$ if and only if $(r+P)A=0$ . But $(r+P)A=0$ if and onlyif r e $P$ since $A$ is a faithful $R/P$ -module. Therefore. $P$ is the left annihilator of the simple $R$ -module $A$ Conversely suppose that $P$ is the left annihilator of a simple $R$ -module $B$ .Verify

that $B$ is a simple $R/P$ -module with $(r+P)b=rb$ for $r\in R,b\in B$ . Furthermore if $(r+P)B=0$ , then $rB=0$ ，whence r e $G(B)=P$ and $r+P=0$ in $R/P$ Consequently, $B$ is a faithful $R/P$ -module. Therefore. $R/P$ is a left primitive ring, whence $P$ is a left primitive ideal of $R$ .■

------------------------------------------------------------------

1

Lemma 2.8. Let I be a lefi ideal of a ring R. IfI is lefi quasi-regular, then I is righi quasi-regular

PROOF. 1f $I$ is left quasi-regular and a ε I, then there exists $r\varepsilon R$ such that $r\circ a=r+a+ra=0$ .Since $r=-a-ra\varepsilon I$ ，there exists $s\varepsilon R$ such that $s\circ r=s+r+sr=0$ ,whence $s$ is right quasi-regular. The operation 0 is easily seen to be associative. Consequently

$$a=0\circ a=(s\circ r)\circ a=s\circ(r\circ a)=s\circ0=s.$$

Therefore $a$ ,and hence $I$ , is right quasi-regular..

PROOF OF THEOREM 2.3. Let $J(R)$ be the intersection of all theleff annilators of simple left $R$ -modules. If $R$ has no simple left $R$ -modules, then $J(R)=R$ by the convention adopted above. $J(R)$ is an ideal by Theorem 1.4. We now show that statements (ii)-(iv) are true for all lefr ideals.

Wefrst observe that $R$ itself cannot be the annihilator of a simple left $R$ -module $A$ (otherwise $RA=0$ ).This fact together withTheorem1.3 and Lennma 2.7 implies that the following conditions are equivalent:

(a) $J(R)=R$ (b) $R$ has no simple left $R$ -modules; (c) $R$ has no regular maximal left ideals; (d) $R$ has no left primitive ideals.

Therefore by the convention adopted above, (i), (i), and (iv) are true if $J(R)=R$ (ii) Assume $J(R)\neq R$ and let $K$ be the intersection of all the regular maximal

left ideals of $R$ . Then $K\subset J(R)$ by Lemmas 2.5 and 2.6. Conversely suppose $c\varepsilon J(R)$ By Theorem 1.3, $J(R)$ is the intersection of the left annihilators of the quotients $R/I$ where $I$ runs over allregularmaximal left ideals of $R$ . For each regular maximal ideal $I$ there exists $e\varepsilon R$ such that $c-ce\varepsilon I$ Since $c\in G(R/I)$ creI for all $r\varepsilon R$ R $R$ in particular, ce ε I. Consequently, $c\varepsilon I$ for every regular maximal ideal I. Thus $J(R)\subset\cap I=K$ . Therefore $J(R)=K$ (ii) is an immediate consequence of Lemma 2.7.

(iv) $J(R)$ is a left quasi-regular left ideal by (i) and Lemma 2.5. $J(R)$ contains every left quasi-regular left ideal by Lemma 2.6. To complete the proof we must show that (i)-(iv) are true with “right" in place of

"left." Let $J_1(R)$ be the intersection of the righr annihilators of allsimple right $R$ -modules. Then the preceding proof is valid with “right"' in place of "left, whence (i)-(iv) hold for the ideal $J_1(R)$ . Since $J(R)$ is right quasi-regular by (iv) and Lemma 2.8, $J(R)\subset J_1(R)$ by (iv). Similarly $J_1(R)$ is left quasi-regular, whence $J_1(R)\subset J(R)$ Therefore, $J(R)=J_{\mathrm{t}}(R)$ .

EXAMPLE. Let $R$ be a local ring with unique maximal ideal $M$ (consisting of all nonunits of $R$ ; see Theorem III.4.13). We shall show that $J(R)=M.$ Since $R$ has an identity, $J(R)\neq R$ . Since a proper ideal contains only nonunits by Theorem Ill.3.2, $J(R)\subset M$ . On the other hand if $r\varepsilon M.$ , then $\mathbf{1}_R+r\notin M$ (otherwise $1_{R}\varepsilon M)$ .Consequently, $1_R+r$ is a unit, whence $r$ is left quasi-regular (Exercise 1). Thus $M\subset J(R)$ by Theorem 2.3 (iv).Therefore $J(R)=M$ .Here are two special cases:

1

1

------------------------------------------------------------------

EXAMPLE. The power series ring $F[[x]]$ over a field $F$ is a local ring with principal maximal ideal $(x)$ by Corollary III.5.10. Therefore $J(F[[x]])=(x)$

EXAMPLE. If $p$ is prime, then $Z_{p^n}(n\geq2)$ is a local ring with principal maximal ideal $(p)$ , which is isomorphic as an abelian group to $Z_{p^{n-1}}$ . Therefore $J(Z_{p^n})=(p)$ The radical of $Z_{m}$ $m$ arbitrary) is considered in Exercise 10.

Definition 2.9.A ring R is said to be(Jacobson) semisimple ifirsJacobson radical J(R) is zero. R is said to be a radical ring if $\mathbf{J}(\mathbf{R})=\mathbf{R}$

REMARK. Throughout this book "radical always means “Jacobson radical" and "semisimple" always means "Jacobson semisimple." Whenreading the literature in ring theory, one must determine which notion of radical and semisimplicity is being used in a particular theorem.A number of definitions ofradical (and semisimplicity) require that the ring be (left) Artinian. This is not the case with the Jacobsonradical,which is defined for every ring.

EXAMPLE. Every division ring is semisimple by Theorem 2.3 (ii) since the only regular maximal left ideal is the zero ideal.

EXAMPLE. Every maximal ideal in $\mathbf{Z}$ is of the form $(p)$ with $p$ prime by Theorem II1.3.4. Consequently, J(Z) = M (p) = 0, whence $\mathbf{Z}$ is Jacobson semisimple. $J(\mathbf{Z})=\bigcap_{p}\left(p\right)=0$ For a generalization, see Exercise 9.

EXAMPLE. If $D$ is a division ring,then the polynomial ring

$$R=D[x_1,x_2,\ldots,x_m]$$

is semisimple. For if $f\varepsilon J(R)$ , then $f$ is both right and left quasi-regular by Theorem 2.3 (iv). Consequently $\mathbf{1}_{k}+f=\mathbf{1}_{D}+f$ is a unit in $R$ by Exercise 1. Since the only units in $R$ are the nonzero elements of $D$ (see Theorem I11.6.1), it follows that $f\varepsilon D$ Thus $J(R)$ is an ideal of $D$ ，whence $J(R)=0$ or $J(R)=D$ by the simplicity of $D$ Since $-1_{I}$ is not left quasi-regular (verify!), $-1_D\notin J(R)$ . Therefore $J(R)=0$ ard $R$ is semisimple.

Theorem 2.10. Let R be a ring.

(i) If R is primitive, then R is semisimple. (ii)IfR is simple and semisimple,thenR is primitive. (ii) If R is simple, then R is either a primitive semisimple or a radical ring..

PROOF. (i) $R$ has a faithful simple left $R$ -module $A$ , whence $J(R)\subset\mathfrak{G}(A)=0$ (i) $R\neq0$ by simplicity. There must exist a simple left $R$ -module $A$ ; (otherwise

by Theorem 2.3 (i) $J(R)=R\neq0$ , contradicting semisimplicity). The left annihilator. $G(A)$ is an ideal of $R$ by Theorem 1.4 and $\mathfrak{G}(A)\neq R$ (since $RA\neq0$ ). Consequently $G(A)=0$ by simplicity, whence $A$ is a simple faithful $R$ -module. Therefore $R$ is primitive.

------------------------------------------------------------------

(ii) If $R$ is simple then the ideal $J(R)$ is either $R$ Or zero. In the former case $R$ is a radical ring and in the latter $R$ is semisimple and primitive by (i).

EXAMPLES. The endomorphism ring of a (left) vector space over a division ring is semisimple by Theorem 2.10 (i) and the example after Definition 1.5. Consequently by Theorem VIl.1.4 the ring of all $n\times n$ matrices over a division ring is semisimple.

EXAMPLE.An example of a simple radical ring is given in E.Sasiada and P. M. Cohn [66]

The classical radical of Wedderburn (in a left Artinian ring) is the maximal nilpotent ideal. We now explore the connection between this radical and the Jacobson radical.

Definition 2.11. An element a of a ring R is nilpotent $ifa^n=0$ for some positive integer n. A (left, right, two-sided) ideal I ofR is nil ifevery element ofI is nilpotent; I is nilpotent ij $^r\mathbf{I}^n=0$ for some integer n.

Every nilpotent ideal is nil since $I^{n}=0$ implies $a^n=0$ for all a ε I. It is possible, however, to have a nil ideal that is not nilpotent (Exercise 11).

Theorem 2.12. If R is a ring, then every nil right or left ideal is contained in the radical J(R).

REMARK. The theorem immediately implies that every nil ring is a radical ring

PROOF OF 2.12. If $a^n=0$ ，let $r=-a+a^{2}-a^{3}+\cdots+(-1)^{n-1}a^{n-1}$ Verify that $r+a+ra=0=a+r+ar$ ，whence $a$ is both left and right quasiregular. Therefore every nil left [right] ideal is left [right] quasi-regular and hence is contained in $J(R)$ by Theorem 2.3 (iv).

Proposition 2.13. IfR is a left [resp.right] Artinian ring, then the radical J(R) is a nilpoteni ideal. Consequently every nil left or right ideal ofR is nilpotent and J(R) is the unique maximal nilpotent left (or right) ideal of R.

REMARK. If $R$ is left [resp. right] Noetherian, then every nil left or right ideal is nilpotent (Exercise 16).

PROOF OF 2.13. Let $J=J(R)$ and consider the chain of (left)ideals $J\supset J^2\supset J^3\supset\cdots$ .By hypothesis there exists $k$ such that $J^{i}=\boldsymbol{J}^{k}$ for all $i\geq k$ .We claim that $J^k=0$ If $J^k\neq0$ , then the set $S$ of allleft idealsIsuch that $J^kI\neq0$ isnonempty (since $\boldsymbol{J}^{k}\boldsymbol{J}^{k}=\boldsymbol{J}^{2k}=\boldsymbol{J}^{k}\neq0)$ .By Theorem $\mathbf{VIII.1.4S}$ has a minimal element $I_0$ Since $J^{k}I_{0}\neq0$ , there is a nonzero a e $I_0$ such that $J^ka\neq0$ Clearly $J^ka$ is a left ideal of $R$ that is contained in $I_{0.}$ Furthermore $J^ka\varepsilon S$ since $J^{k}(J^{k}a)=J^{2k}a=J^{k}a\neq0$ Con

1

------------------------------------------------------------------

sequently $J^ka=I_0$ by minimality. Thus for some nonzero $r\varepsilon J^k$ ， $ra=a$ . Since $-r\varepsilon J^k\subset J(R),-r$ is left quasi-regular, whence $s-r-sr=0$ for some $s\varepsilon R$ $R$ R Consequently,

$$a=ra=-[-ra]=-[-ra+0]=-[-ra+sa-sa]\\=-[-ra+sa-s(ra)]=-[-r+s-sr]a=-0a=0.$$

This contradicts the fact that $a\neq0$ . Therefore $J^k=0$ .Thelast statement of the theorem is now an immediate consequence of Theorem 2.12.

Finally we wish to show that left quasi-regularity is a radical property as defined in the introduction to this section.ByTheorem 2.3 (iv) its associated radicalis clearly the Jacobson radical and a left quasi-regular ring is precisely a radical ring (Definition 2.9). Since a ring homomorphism necessarily maps left quasi-regular elements onto left quasi-regular elements, the homomorphic image of a radical ring is also a radical ring. To complete the discussion we must show that $R/J(R)$ is semisimple and that $J(R)$ is a radical ring.

Theorem 2.14. 1f R is a ring, then the quotient ring R/J(R) is semisimple

PROOF. Let $\pi:R\to R/J(R)$ be the canonicalepimorphism and denote $\pi(r)$ by $\bar{r}(r\varepsilon R)$ .Let ୧ be theset of all regular maximal left ideals of $R$ If $I\varepsilon C$ ,then $J(R)\subset I$ by Theorem 2.3 (i) and $\pi(I)=I/J(R)$ is a maximal left ideal of $R/J(R)$ by Theorem IV.1.10. If e e $R$ is such that r - reε Ifor all r e $R$ , then $\bar{r}-\bar{r}\bar{e}\varepsilon\pi(I)$ for all $\bar{r}\in R/J(R)$ Therefore, $\pi(I)$ is regular forevery $I$ in C. Since $J(R)=\bigcap_{I\in\mathbb{C}}$ Iit is easy to verify that if $\bar{r}\varepsilon\bigcap\pi(I)=\bigcap I/J(R)$ then r e $J(R)$ Consequently, by Theorem .3 (i (applied tio $R/J(R))$

$$J(R/J(R))\subset\bigcap_{I\in\mathbb{C}}\pi(I)\subset\pi(J(R))=0,$$

whence $R/J(R)$ is semisimple.

Lemma 2.15. Let R be a ring and a ε R.

(i $If-\mathrm{a}^2$ is left quasi-regular, then so is a. (ii) a e J(R) if and only if Ra is a left quasi-regular left ideal..

PROOF.(i) If $r+(-a^2)+r(-a^2)=0$ ，let $s=r-a-ra$ .Verify that $s+a+sa=0$ ,whence $a$ is left quasi-regular

(ii) Ifae $J(R)$ ,then $Ra\subset J(R)$ . Therefore, $Ra$ is left quasi-regular since $J(R)$ is Conversely suppose $Ra$ is left quasi-regular. Verify that $K=\{ra+na\mid r\varepsilon R,n\varepsilon\mathbf{Z}\}$ is a left ideal of $R$ that contains $a$ and $Ra$ . If $s=ra+na$ , then $-s^{2}\varepsilon Ra$ .By hy pothesis $-s^2$ is left quasi-regular and hence so is $s$ by (i). Thus $K$ is a left quasi regular left ideal. Theref ore $\imath\varepsilon K\subset J(R)$ by Theorem 2.3 (iv). 

Theorem 2.16. (i) If an ideal I of a ring R is iiself considered as a ring, then $\mathbf{J}(\mathbf{I})=\mathbf{I}\cap\mathbf{J}(\mathbf{R})$ )

------------------------------------------------------------------

(ii) IfR is semisimple, then so is every ideal ofR. (ii) J(R) is a radical ring.

PROOF. (i) $I\cap J(R)$ is clearly an ideal of 1. If a e I ∩ $J(R)$ ,then ais left quasiregular in $R$ ,whence $r+a+ra=0$ for some $r\varepsilon R$ .But $r=-a-ra\varepsilon I.$ Thus every element of $I\cap J(R)$ is left quasi-regular in $I$ . Therefore $I\cap J(R)\subset J(I)$ by Theorem 2.3 (iv) (applied to $I$ Suppose a e $J(I)$ . For any re R, $-(ra)^{2}=-(rar)a\varepsilon IJ(I)\subset J(I)$ ,whence $-(ra)^2$

is left quasi-regular in $I$ by Theorem 2.3 (iv). Consequently by Lemma 2.15 (i) $ra$ is left quasi-regular in I and hence in $R.$ .Thus $Ra$ is a left quasi-regular left ideal of $R$ whence $a\in J(R)$ by Lemma 2.15 (i). Therefore a E $J(I)\cap J(R)\subset I\cap J(R)$ .Consequently $J(I)\subset I\cap J(R)$ , which completes the proof that $J(I)=I\cap J(R)$ . Statements (ii) and (ii) are now immediate consequences of (i). 

Theorem 2.17. 1 $f\left\{\mathbf{R}_{\mathrm{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\right\}$ is a family of rings, then ${\mathrm{j}}(\prod_{i\in I}R_{i})=\prod_{i\in I}J(R_{i}).$

SKETCH OF PROOF. Verify that an element $\{a_{i}\}\in\prod_{R_{i}}$ is left quasi-regular in $\prod_{R_i}$ if and only if $a_i$ is left quasi-regular in $R_{i}$ for each i. Consequently $\Pi J(R_i)$ is a left quasi-regular ideal of $\prod R_i$, whence $\prod J(R_i)\subset J(\prod R_i)$ by Theorem 2.3 (iv). For each $k\varepsilon I$ ,let $\pi_k:\prod R_i\to R_k$ be the canonical projection. Verify that

$I_k=\pi_k(J(\prod R_i))$ is a left quasi-regular ideal of $R_{k}$ . It follows that $I_k\subset J(R_k)$ and therefore that $J(\prod_{R_i)}\subset\prod_{J(R_i)}$

### EXERCISES

Note: $R$ is always a ring.

1. For each $a,b\varepsilon R$ let $a\circ b=a+b+ab$

(a) 0 is an associative binary operation with identity element $0\varepsilon R$ (b) The set $G$ of all elements of $R$ that are borh left and right quasi-regulan

forms a group under o. (c) If $R$ has an identity, then a E $R$ is left [resp. right] quasi-regular if and only

if $1_R+a$ is left [resp. right] invertible. $[Hint:(1_R+r)(1_R+a)=1_R+r\circ a$ and $r(1_{R}+a)-1_{R}=(r-1_{R})\circ a.$

2. (Kaplansky) $R$ is a division ring if and only if every element of $R$ except one is left quasi-regular.[Note that the only element in a divisionring $D$ that is norleft quasi-regular is $-1_{\nu}$ ; also see Exercise 1.]

3.Let $I$ be a left ideal of $R$ and let $(I:R)=\{r\varepsilon R\mid rR\subset I\}$ (a) $(I:R)$ is an ideal of $R.$ If $I$ is regular, then $(I:R)$ is the largest ideal of $R$

that is contained in $I$ (b) If I is a regular maximal left ideal of $R$ and $A\cong R/I$ , then $G(A)=(I:R)$

Therefore $J(R)=\cap(I:R)$ ,where $I$ runs over all the regular maximal left ideals of $R$

4. The radical $J(R)$ contains no nonzero idempotents. However, a nonzero idem. potent may be left quasi-regular.[Hint: Exercises 1 and 2].

------------------------------------------------------------------

5.If $R$ has an identity, then

(a) $J(R)=\{r\varepsilon R\mid1_R+sr$ is left invertible for all $s\varepsilon R$ R $R$ 1. (b) $J(R)$ is the largest ideal $K$ such that for all r e $K$ $1_R+r$ is a unit.

6. (a) The homomorphic image of a semisimple ring need not be semisimple (b) If $f:R\to S$ is a ring epimorphism, then $f(J(R))\subset J(S)$

7. If $R$ is the ring of all rational numbers with odd denominators, then $J(R)$ consists of all rational numbers with odd denominator and even numerator.

8. Let $R$ be the ring of all upper triangular $n\times n$ matrices over a division ring $D$ (see Exercise VI1.1.2). Find $J(R)$ and prove that $R/J(R)$ is isomorphic to the direct product $D\times D\times\cdots\times D$ $(n$ factors). [Hint: show that a strictly triangular matrix is nilpotent.]

9. A principal ideal domain $R$ is semisimple if and only if $R$ is a feld or $R$ contains an infinite number of distinct nonassociate irreducible elements.

10.Let $D$ be a principal ideal domain and $d$ a nonzero nonunit element of $D$ .Let $R$ be the quotient ring $D/(d)$ (a) $R$ is semisimple if and only if $d$ is the product of distinct nonassociate

irreducible elements of $D$ . [Hint: Exercise VIII.1.2.] (b) What is $J(R)$

11. $p$ rec $I_n$ prieiee $R$ b $Z_{p^n}$ Ssbinge $\sum_{n\geq1}Z_{p^n}$ $\overline{n\geq1}\:\overline{n\geq1}$ $p\in Z_{p^n}$ 11 $\prod_{n\geq1}Z_{p^n}$ Titeide $R$ $I=\sum_{n\geq1}I_{n}$, nilpotent.

12. Let $R$ be a ring without identity. Embed $R$ in a ring $S$ with identity which has characteristic zero, as in Theorem III.1.10. Prove that. $J(R)=J(S)$ . Consequently every semisimple ring may be embedded in a semisimple ring with identity

13. $J(\mathrm{Mat}_nR)=\mathrm{Mat}_nJ(R)$ .Here is an outline of a proof:

(a) If $A$ is a left $R$ -module, consider the elements of $A^n=A\oplus A\oplus\cdots\oplus A$ $n$ summands) as column vectors; then $A^n$ is a left $(\mathbf{M}_{\mathrm{at}_n}R)$ -module (under ordinary matrix multiplication) (b) If $A$ is a simple $R$ -module, $A^n$ is a simple $(\mathbf{M}_{\mathrm{at}_n}R)$ -module

(c) $J(\mathrm{Mat}_nR)\subset\mathrm{Mat}_nJ(R)$

(d) $\mathrm{Mat}_nJ(R)\subset J(\mathrm{Mat}_nR)$ . [Hint : prove that $Mat_nJ(R)$ is a left quasi-regular

ideal of $Mat_nR$ as follows. For each $k=1,2,\ldots,n$ let $K_k$ consist of all matrices $(a_{ij})$ such that $a_{ij}\in J(R)$ and $a_{ij}=0$ if $j\neq k$ . Show that $K_{k}$ is a left quasi-regulal left ideal of $Mat_nR$ $_{n}R$ nR and observe that $K_{1}+K_{2}+\cdots+K_{n}=\mathrm{Mat}_{n}J(R).$

14. (a) Let $I$ be a nonzero ideal of $R[x]$ and $p(x)$ a nonzero polynomial of least degree in $I$ with leading coefficient $a$ . If $f(x)\in R[x]$ and $a^mf(x)=0$ ，then $a^{r-1}p(x)f(x)=0$

(b) If a ring $R$ has no nonzero nil ideals (in particular,if $R$ is semisimple), then $R[x]$ is semisimple. [Hint: Let $M$ be theset of nonzeropolynomials of least degree in $J(R[x])$ . Let $N$ be the set consisting of O and the leading coefficients of polynomials in $M$ . Use (a) to show that $N$ is a nil ideal of $R$ ,whence $J(R[x])=0.$ (c)There exist rings $R$ such that $R[x]$ is semisimple, but $R$ is not. [Hint, consider $R=F[[x]]$ ,with $F$ a field.)

------------------------------------------------------------------

15. Let $L$ be a left ideal and $K$ a right ideal of $R$ . Let $M(R)$ be theideal generated by all nilpotent ideals of $R$

(a) $L+LR$ is an ideal such that $(L+LR)^n\subset L^n+L^nR$ for all $n\geq1$ (b) $K+RK$ is an ideal such that $(K+RK)^n\subset K^n+RK^n$ for all $n\geq1$ (c) If $L$ [resp. $K]$ is nilpotent, so is the ideal $L+LR$ [resp. $K+RK]$ whence $L\subset M(R)$ [resp. $K\subset M(R)$ (d) If $N$ is a maximal nilpotent ideal of $R$ , then $R/N$ has no nonzero nilpotent

left or right ideals. [Hint: frst show that $R/N$ has no nonzero nilpotent ideals; then apply $(c)$ to the ring $R/N$ (e) If $K$ [resp. $L]$ is nil, but not nilpotent and $\pi:R\to R/N$ is the canonical

epimorphism, then $\pi(K)$ [resp. $\pi(L)]$ is a nil right [resp. left] ideal of $R/N$ which is not nilpotent.

16. (Levitsky) Every nil left or right ideal I in a left Noetherian ring $R$ is nilpotent [Sketch ofProof.It suffices byExercise 15 to assume that $R$ has no nonzero nilpotent left or right ideals. Suppose Iis a left or a right ideal which is not nilpotent and $0\neq a\in I.$ Show that $aR$ is a nil rightideal (eventhough I may be a left ideal), whence the left ideal $\mathfrak{a}(u)$ is nonzero for all u e aR.There exists a nonzero $u_0\varepsilon aR$ with $G(u_0)$ maximal, whence $G(u_{0})=G(u_{0}x)$ for all $x\varepsilon R$ such that $u_0x\neq0$ Show that $(u_{0}y)u_{0}=0$ for all $y\varepsilon R$ R $R$ ,so that $(Ru_{0})^{2}=0$ . Therefore $Ru_{0}=0$ ,which implies that $\{r\varepsilon R\mid Rr=0\}$ is a nonzero nilpotent right ideal of. $R$ ; contradiction.

17. Show that Nakayama's Lemma VIl1.4.5 is valid for any ring $R$ with identity provided condition (i) is replaced by the condition

(i) $J$ is contained in the Jacobson radical of $R$

[Hint: Use Theorem 2.3(iv) and Exercise 1 (c) to show $(\mathrm{i}^{\prime})\Rightarrow(\mathrm{ii}).]$

## 3. SEMISIMPLE RINGS

In accordance with the theory of radicals outlined in the first part of Section 2 we now restrict our study to rings that are Jacobson semisimple. Arbitrary semisimple. rings are characterized as particular kinds of subrings of direct products of primitive rings (Proposition 3.2). Much stronger results are proved for semisimple (left) Artinian rings. Such rings are actually fnite direct products of simple rings (Theorem 3.3). They may also be characterized in numerous ways in terms of modules (Theo rem 3.7). Along the way semisimple modules over arbitrary rings are defined and their basic properties developed (Theorem 3.6).

Definition 3.1. A ring R is said to be a subdirect product of the family of rings $\{\mathbf{R}_{\mathrm{i}}\mid\mathbf{i}\varepsilon\mathbf{I}\}if\mathbf{R}$ is a subring Ofthe direrproduct $\prod_{i\in I}\mathbf{R}_i$ such hat $\pi_{\mathrm{k}}(\mathbf{R})=\mathbf{R}_{\mathrm{k}}$ for ever k e I, where $\pi_{\mathrm{k}}:\prod_{i\in I}\mathbf{R}_{\mathrm{i}}\to\mathbf{R}_{\mathrm{k}}$ is the canonical epimorphism

REMARK. A ring $S$ is isomorphic to a subdirect product of the family of rings $\{R_{i}\mid i\in I\}$ if and only if there is a monomorphism of rings $\phi:S\to\prod_{i\in I}R_i$ such that $\pi_k\phi(S)=R_k$ for every $k$ ∈I.

------------------------------------------------------------------

EXAMPLE. Let $P$ be the set of prime integers. For each $k\varepsilon Z$ and $p\in P$ let $k_p\varepsilon Z_p$ be the image of $k$ under the canonical epimorphism $\mathbf{Z}\to\mathbb{Z}_p$ . Then the map $\phi:\mathbf{Z}\to\prod_{p\in P}Z_{p}$ given by $k\vdash\left\{k_{p}\right\}_{p\boldsymbol{\iota}P}$ is a monomorphism of rings such that $\pi_p\phi(\mathbf{Z})=Z_p$ for every p $p$ $p\in P$ P $P$ . Therefore $\mathbf{Z}$ is isomorphic to a subdirect product of the family of fields $\left\{Z_{p}\mid p\in P\right\}$ . More generally we have:

Proposition 3.2. A nonzero ring R is semisimple if and only ifR is isomorphic to a subdirect product of primitive rings.

REMARK. Propositions 1.7 and 3.2 imply that a nonzero commutative semisimple ring is a subdirect product of fields.

SKETCH OF PROOF OF 3.2. Suppose $R$ is nonzero semisimple and let $\textcircled{P}$ be the set of all left primitive ideals of $R$ .Then for each $P\in\mathcal{Q},R/P$ R/P $R/P$ is a primitive ring (Dehnition 2.1) By Theorem 2.3 (i), $0=J(R)=\bigcap_{P_{e}\Phi}$ P. For each $P$ let $\lambda_P:R\to R/P$ and $\pi_{P}:\prod_{Qe0}R/Q\to R/P$ be the respetive canonicl epimorphisms. he map $\phi:R\to\prod_{P_e\textcircled{0}}R/P$ given by $r\vdash\{\lambda_{P}(r)\}_{P_{\epsilon}Q}=\{r+P|_{P_{\epsilon}Q}$ is a monomorphism of rings such that $\pi_{P}\phi(R)=R/P$ for every $P\varepsilon\textcircled{P}$ Conversely suppose there is a family of primitive rings $\{R_{i}\mid i\in I\}$ and a mono-

morphism of rings $\phi:R\to\prod_{i\in I}R_{i}$ such that $\pi_{k}\phi(R)=R_{k}$ foreach $k$ el. Let $\psi_{k}$ bethe epimorphism $\pi_k\phi$ . Then $R/Ker\psi_k$ is isomorphic to the primitive ring $R_{k}$ (Corollary II1.2.10), whence Ker $\psi_k$ is a left primitive ideal of $R$ (Definition 2.1). Therefore $J(R)\subset\bigcap_{k\in I}$ Ker $\psi_{k}$ by Theorem 2.3 (i). However, if $r\varepsilon R$ R $R$ and $\psi_k(r)=0$ , then the kth component of $\phi(r)$ in $\prod_{R_i}$ is zero. Thus if $r\in\bigcap_{k\in I}$ Ker $\psi_{k}$, we must have $\phi(r)=0$ kel Since $\phi$ is a monomorphism $r=0$ . Therefore $J(R)\subset\bigcap_{k\boldsymbol{\varepsilon}\boldsymbol{I}}$ Ker $\psi_k=0$ , whence $R$ is semisimple.

In view of the results on primitive rings in Section 1, we can now characterize semisimple rings as those rings that are isomorphic to subdirect products of families of rings, each of which is a dense ring of endomorphisns of a vector space over a division ring. Unfortunately subdirect products (and dense rings of endomorphisms. are not always the most tractable objects with which to deal. But in the absence of further restrictions this is probably the best one can do. In the case of (left) Artinian rings, however, these results can be considerably sharpened.

Theorem 3.3. (Wedderburn-Artin). The following conditions on a ring R are equivalent.

(i)R is a nonzero semisimple left Artinian ring: (ii) R is a direct product of a finite number of simple ideals each of which is isomorphic to the endomorphism ring of a finite dimensional vector space over a division ring: (ii) there exist division rings $\mathbf{D}_{\mathbf{l}}$ ,... , D, and positive integers n, ... , $n_t$ such that R is isomorphic to the ring $Mat_{\mathrm{n}_1}\mathbf{D}_1\times Mat_{\mathrm{n}_2}\mathbf{D}_2\times\cdots\times Mat_{\mathrm{n}_t}\mathbf{D}_t$

------------------------------------------------------------------

REMARK. By a simple ideal of $R$ we mean an ideal that is itself a simple ring.

PROOF OF 3.3. (ii) $\Leftrightarrow$ (ii) Exercise I11.2.9 and Theorem VII.1.4. $(\mathrm{ii})\Rightarrow(\mathrm{i})$ By hypoths $R\cong\coprod_{i=1}^iR_i$ wih cach $R_i$ the edomorphism ring o a

vector space. The example after Definition 1.5 shows that each $R_{i}$ is primitive, whence $J(R_{i})=0$ by Theorem 2.10 (i). Consequently by Theorem 2.17

$$J(R)\cong\prod_{i=1}^tJ(R_i)=0.$$

Therefore $R$ is semisimple. $R$ is left Artinian by Theorem VII.1.4 and Corollaries. VIII.1.7 and VIII.1.12. $(\mathrm{i})\Rightarrow$ (ii) Since $R\neq0$ and $J(R)=0$ $R$ has left primitive ideals by Theorem 2.3

(ii). Suppose that $R$ hasonly finitely many distinct left primitive ideals:. $P_1,P_2,\ldots,P_t$ Then each $R/P_i$ is a primitive ring (Definition 2.1) that is left Artinian (Corollary VIl1.1.6). Consequently, by Theorem 1.14 each $R/P_i$ is a simple ring isomorphic to an endomorphism ring of a finite dimensional left vector space over a division ring. Since $R/P_i$ is simple, each $P_i$ is a maximal ideal of $R$ (Theorem III.2.13). Furthermore $R^{2}\not\subset P_{i}$ (otherwise $(R/P_i)^2=0$ ,whence $R^{2}+P_{i}=R$ by maximality. Likewise if $i\neq j$ ，then $P_{i}+P_{j}=R$ by maximality. Consequently by Corollary Il1.2.27 (of the Chinese Remainder Theorem) and Theorem 2.3 (i) there is an isomorphism of rings:

$$R=R/0\:=\:R/J(R)\:=\:R/\bigcap_{i=1}^tP_i\cong R/P_1\times\cdots\times R/P_t.$$

If $\iota_k:R/P_k\to\prod_{i=1}^lR/P_i$ is the canonical monomorphism Theorem I12), hen cach $\iota_k(R/P_k)$ isa simplidal oe $\prod_{i=1}^tR/P_i$ . Uner the ismorphism $\prod_{i=1}^{t}R/P_i\cong R_.$ the images of the $\iota_k(R/P_k)$ are simple ideals of $R$ . Clearly $R$ is the (internal) direct product of these ideals. To complete the proof we need only show that $R$ cannot have an infinite number

of distinct left primitive ideals. Suppose, on the contrary, that $P_{1},P_{2},P_{3},\ldots$ is a se quence of distinct left primitive ideals of. $R$ .Since

$$P_1\supset P_1\cap P_2\supset P_1\cap P_2\cap P_3\supset\cdots $$

is a descending chain of (left) ideals there is an integer $n$ such that $P_1\cap\ldots\cap P_n$ $=P_{1}\cap\ldots\cap P_{n}\cap P_{n+1}$ Pn+1 $P_{n+1}$ ,whence $P_1\cap\cdots\cap P_n\subset P_{n+1}$ The previous paragraph shows that $R^{2}+P_{i}=R$ and $P_{i}+P_{j}=R(i\neq j)$ (i≠j) $(i\neq j)$ for $i,j=1,2,\ldots,n+1$ .The proof of Theorem II1.2.25 shows that $P_{n+1}+(P_{1}\cap\cdots\cap P_{n})=R$ Consequently $P_{n+1}=R$, which contradicts the fact that $P_{n+1}$ is left primitive (see the Remark after Definition 2.1). Therefore $R$ has only finitely many distinct primitive ideals and the. proof is complete.

Corollary 3.4. (i) A semisimple left Artinian ring has an identity. (i) $A$ semisimple ring is left Artinian if and only if it is right Artinian.

(i)A semisimple left Artinian ring is both left and right Noetherian

------------------------------------------------------------------

REMARK. Somewhat more is actually true: any left Artinian ring with identity is left Noetherian (Exercise 13).

SKETCH OF PROOF OF 3.4.(i) Theorem 3.3.(ii) Theorem 3.3 is valid with “left” replaced by “right" throughout. Consequently the equivalence of conditions (i) and (ii) of Theorem 3.3 implies that $R$ is left Artinian if and only if $R$ is right Artinian. (i) Corollaries VII1.1.7 and VIl1.1.12 and Theorem 3.3 (ii).

The following corollary is not needed in the sequel. Recall that an element $e$ of a ring $R$ is said to be idempotent if $e^2=e$

Corollary 3.5.IfI is an ideal in a semisimple left Artinian ringR,then $\mathbf{I}=\mathbf{Re}$ , where e is an idempotent which is in the center ofR.

SKETCH OF PROOF. By Theorem $3.3R$ is a (ring) direct product of simple ideals, $R$ = $I_1$ $\times \cdots \times I_n$ .For each j $,I\cap I_i$ Ij $I_i$ is either O or $I_{i}$ by simplicity.After reindexing if necessary we may assume that $I\cap I_{i}=I_{i}$ for $j=1,2,\ldots,t$ and $I\cap I_i=0$ for $j=t+1,\ldots,n.$ Since $R$ has anidentity by Corollary 3.4, there exist $e_j\varepsilon I_j$ such that $\mathbf{1}_{R}=e_{1}+e_{2}+\cdots+e_{n}$ . Since $I_{j}I_{k}=0$ for $j\neq k$ we have

$$e_{1}+e_{2}+\cdots+e_{n}=1_{R}=(1_{R})^{2}=e_{1}^{2}+e_{2}^{2}+\cdots+e_{n}^{2},$$

whence $e_j^2=e_i$ for each $j$ . It is easy to verify that each $e_i$ lies in the center of $R$ and that $e=e_{1}+e_{2}+\cdots+e_{l}$ is an idempotent in I which is in the center of $R$ . Since $I$ is an ideal, $Re\subset I$ Conversely if $u\varepsilon I$ , then $u=u1_{R}=ue_{1}+\cdots+ue_{n}$ . But for j> 1 $j>t$, $j> t$, $ue_{i}\varepsilon I\cap I_{i}= 0$ Thus $u=ue_{1}+\cdots+ue_{t}=ue$ .Therefore $I\subset Re$ .！

Theorem 3.3 is a characterization of semisimple left Artinian rings in ring theoretic terms. As one might suspect from the close interrelationship of rings and modules, such rings can also be characterized strictly in terms of modules.In order to obtain these characterizations we need a theorem that is valid for modules over an arbitrary ring.

Theorem 3.6.The following conditions on anonzero module A over a ring R are equivalent.

(i) A is the sum of a family of simple submodules. (i)A is the(internal) direct sum of a family of simple submodules. (ii) For every nonzero element a of A, $\mathbf{R}_{\mathbf{a}}\neq0$ ;and every submoduleBofA is a direct summand (that is, $\mathbf{A}=\mathbf{B}\oplus$ C for some submodule C).

A module that satisfies the equivalent conditions of Theorem 3.6 is said to be semisimple or completely reducible. The terminology semisimple is motivated by Theorem 3.3 (i) and the fact (to be proved below) that every module over a (left) Artinian semisimple ring is semisimple.

------------------------------------------------------------------

SKETCH OF PROOF OF 3.6. (i) $\Rightarrow$ (ii) Suppose $A$ is the sum of the family $\{B_i\mid i\in I\}$ of simple submodule that is, $A$ is generated by $\bigcup_{i\in I}B_i)$ . Use Zorn's Lemma to show that there is a nonempty subset $J$ of $I$ which is maximal with respect to the Froe $A=\sum_{j\in J}B_{i}$ uits $\{B_{i}\mid j\in J\}$ Isna $B_i\subset\sum_{j\in J}B_i^j$ $\sum_{jeJ}B_{i}.$ W i e I. Since $B_i$ is simple and Bi $B_{i}$ $B_i\cap(\sum B_i)$ is a submodule of $B_i$, either $B_i\cap(\sum B_j)=$ $B_i$ , which implies $B_i\subset\sum B_i$, or $\overline{B_{\mathrm{i}}}\cap(\sum B_{\mathrm{i}})=0$ The second case cannot occur. For if it did, $K=\{i\}\cup J$ would be a set such that the submodule generated by $\{B_k\mid k\in K\}$ is a direct sum (Theorem IV.1.15): which contradicts the maximality of $J$ (ii$) \Rightarrow$ $\Rightarrow$ ## (i) Suppose $A$ isthe directsum $\sum_{ieI}B_i$ with each $B_i$ a simple submodule. If

$a$ is a nonzero element of $A$ ,then $a=b_{i_{1}}+\cdots+b_{i_{k}}$ with $0\neq b_{i_k}\varepsilon B_{i_k}(i_1,\ldots,i_k\varepsilon I)$ Clearly $Ra=0$ if and only if $Rb_{ik}=0$ for each $i_k$ . But Remark (ii) after Definition 1.1 shows that $Rb_{ik}=B_{ik}\neq0$ . Therefore $Ra\neq0$ Let $B$ be a nonzero submodule of $A$ . By simplicity $B\cap B_i$ is either 0 or $B_i$ . If

$B\cap B_{i}=B_{i}$ for all $i$ ,then $A=B$ and $B$ is trivially a direct summand, $A=B\oplus0$ Otherwise $B\cap B_{i}=0$ for somei. Use Zorn's Lemma to find a subset $J$ of $I$ which is maximal with respect to the property: $B\cap(\sum_{j\in J}B_i)=0$ We claim that $A$ = $B\oplus ( \sum _{jeJ}B_{i})$ .It sffices by Theorem IV.1.15 to show that $B_i\subset B\oplus(\sum B_i)$ for each $i.$ 开$i\varepsilon J$ then $B_i\subset\sum_{j\in J}B_i$ and weaedone If $i\notin J$ and $B_i\not\subset B\oplus\sum_{j\in J}^{j_\mathbf{e}J}B_i$, then $B_{i}\cap(B\oplus\sum_{j\in J}B_{j})=0$ by the simplity of $B_{i}$ It folows that $J\cup\{i\}$ is a set that contradicts the maximality of $J$ . Therefore $B_{i}\subset B\oplus\sum_{j\in J}B_{i}$,

(iii$) \Rightarrow ($i) We first observe that if $N$ is any submodule of $A$ , then every submodule $K$ of $N$ is a direct summand of $N$ . For by hypothesis $K$ is a direct summand of $A$ say $A=K\oplus L$ . Verify that $N=N\bigcap A=(N\cap K)\oplus(N\cap L)=K\oplus(N\cap L)$ Next we show that $A$ has simple submodules. Since $A\neq0$ ,there exists anonzero

element $a$ of $A$ . Use Zorn's Lemma to find a submodule $B$ of $A$ that is maximal with respect to the property that a $\notin B.$ By hypothesis $A=B\oplus C$ for some nonzero submodule $C$ and $RC\neq0$ .We claim that $C$ is simple. If it were not, then $C$ would have a proper submodule $D$ , which would be a direct summand of $C$ by the previous para graph. Consequently $C=D\oplus E$ with $E\neq0$ ,whence $A=B\oplus C=B\oplus D\oplus E$, with $D\neq0$ and $E\neq0$ . Now $B\oplus D$ and $B\oplus E$ both contain $B$ properly. Therefore. by the maximality of $B$ we must have a $\varepsilon$ $B\oplus D$ and $a\in B\oplus E$ . Thus $b+d=a$ $=b^{\prime}+e\left(b,b^{\prime}\varepsilon B;d\varepsilon D;e\varepsilon E\right)$ .Now $0=a-a=(b-b^{\prime})+d-e\varepsilon B\oplus D\oplus E$ implies that $d=0$ $e=0$ ,and $b-b^{\prime}=0$ . Consequently, $a=b\varepsilon B$ which is a contradiction. Therefore. $C$ is simple. Let $A_0$ be the submodule of $A$ generated by all the simple submodules of $A$ . Then

$A$ = $A_0\oplus$ $N$ for some submodule $N$ $N$ satisfies the same hypotheses as $A$ by the paragraph before last. If $N\neq0$ , then the argument in the immediately preceding paragraph shows that $N$ contains a nonzero simple submodule $T$ .Since $T$ is a simple submodule of $A,T\subset A_{0}$ . Thus TCAo $T\subset A_0$ $T\subset A_0\cap N=0$ N=0 $N=0$ ,which is a contradiction. Therefore $N=0$ ，whence $A=A_0$ is the sum of a family of simple submodules.

------------------------------------------------------------------

$R$ -module)areprecisely the left ideals of $R.$ ，some of these characterizations are stated in terms of left ideals. A subset $\{e_1,\ldots,e_m\}$ of $R$ is a set of orthogonal idem- potents if $e_{i}^{2}=e_{i}$ for all $i$ and $e_ie_j=0$ for all $i\neq j$

Theorem 3.7. The following conditions on a nonzero ring R with identity are equiv alent.

(i)R is semisimple left Artinian; (iv) every short exact sequence of unitary left R-modules is split exact, (v)every nonzero unitary left R-module is semisimple, (vi) R is itself a unitary semisimple left R-module, (vi) every left ideal ofR is of the formRe with e idempotent, (vii) R is the(internal) direct sum (as a left R-module) of minimal left ideals

$\mathbf{K}_1,\ldots,\mathbf{K}_m$ Km $K_m$ such that $\mathbf{K}_{\mathrm{i}}=\mathbf{R}\mathbf{e}_{\mathrm{i}}(\mathbf{e}_{\mathrm{i}}\varepsilon\mathbf{R})$ K; = Re;(e; ε R) $\mathbf{K}_{\mathrm{i}}=\mathrm{Re}_{\mathrm{i}}\left(\mathrm{e}_{\mathrm{i}}\varepsilon\mathbf{R}\right)for$i$=1,2,\ldots$,m$a$ nd $\{\mathbf{e}_{1},\ldots,\mathbf{e}_{m}\}$ isaset of orthogonal idempotents with $\mathrm{e_{1}+e_{2}+\cdots+e_{m}=1_{R}}$

REMARKS. Since a semisimple ring is left Artinian if and only if it is right Artinian (Corollary 3.4), each condition in Theorem 3.7 is equivalent to its obvious analogue for right modules or right ideals. There is no loss of generality in assuming $R$ has an identity, since every semisimple left Artinian ring necessarily has one by Corollary 3.4. The theorem is false if the word “unitary" is omitted (Exercise 10).

SKETCH OF PROOF OF 3.7. $(\mathrm{ii})\Leftrightarrow(\mathrm{iii})\Leftrightarrow(\mathrm{iv})$ is Exercise IV.3.1. To complete the proof we shall prove the implications $(\mathbf{iv})\Leftrightarrow(\mathbf{v})$ and $(v)\Rightarrow(vii)\Rightarrow(vi)\Rightarrow$ $(\mathrm{i})\Rightarrow(\mathrm{viii})\Rightarrow(\mathrm{v})$ $(\mathbf{iv})\Rightarrow(\mathbf{v})$ If $B$ is a submodule of a nonzero unitary $R$ -module $A$ , then

$$0\to B\overset{\mathsf{C}}{\to}A\to A/B\to0$$

is a short exact sequence, which splits by hypothesis. The proof of Theorem IV.1.18 shows that $A=B\oplus C$ with $C\cong A/B$ .Since $A$ is unitary, $Ra\neq0$ for everynonzero a E $A$ . Therefore $A$ is semisimple by Theorem 3.6.

$(\mathbf{v})\Rightarrow(\mathbf{i}\mathbf{v})$ Let $0\to A\overset{f}{\operatorname*{\rightarrow}}B\overset{o}{\operatorname*{\rightarrow}}C\to0$ be a short exact sequence of unitary $R$ -modules. Then $f:A\to f(A)$ is an isomorphism. Since $B$ is semisimple by (v), $f(A)$ is a direct summand of $B$ by Theorem 3.6. If $\pi:B\to f(A)$ is the canonical epimorphism then $\pi f=f$and $f^-1\pi:B\to A$ is an $R$ -module homomorphism such that $(f^{-1}\pi)f=1_{A}$ Therefore the sequence splits by Theorem IV.1.18. $(\mathbf{v})\rightarrow(\mathbf{v}$ii) The left ideals of $R$ are precisely its submodules. If $L$ is a left ideal,

then $R=L\oplus I$ for some left ideal $I$ by $(\mathbf{v})$ and Theorem 3.6. Consequently, there are $e_1\varepsilon L$ and $e_2\varepsilon I$ such that $\mathbf{1}_{R}=e_{1}+e_{2}$ . Since eeL $e_1\varepsilon L$ $e_{1}\varepsilon L,\:Re_{1}\subset L.$ if $r\varepsilon L$ , then $r=re_{1}+re_{2}$, whence $re_{2}=r-re_{1}\varepsilon L\cap I=0$ . Thus $r=re_{1}$ for every $r\varepsilon L$ ; in particular, $e_{1}e_{1}=e_{1}$ and $L\subset Re_{1}$ . Therefore, $L=Re_{1}$ with $e_1$ idempotent. $(\mathbf{vii})\Rightarrow(\mathbf{vi})A$ submodule $L$ of $R$ is a left ideal,whence $L=Re$ with $e$ idempotent

Verify that $R(\mathbf{1}_{R}-e)$ is a left ideal of $R$ such that $R=Re\oplus R(1_{R}-e)$ . Therefore, $R$ is semisimple by Theorem 3.6. $(\mathbf{vi})\Longrightarrow(\mathbf{i})$ By hypothesis $R$ is a direct sum $\sum_{i\in I}B_i$ , with each $B_{i}$ a simple submodule

(left ideal) of $R.$ Consequently there is a finite subset $I_0$ of $I$ (whose elements will be

------------------------------------------------------------------

labeled 1,2,... , $k$ for convenience) such that $\mathbf{1}_{R}=e_{1}+e_{2}+\cdots+e_{k}\left(e_{i}\varepsilon B_{i}\right)$ .Thus for every $r\varepsilon R$ · $r=re_{1}+re_{2}+\cdots+re_{k}\varepsilon\sum_{i=1}^{k}B_{i}$, whence $R=\sum_{i=1}^{k}B_{i}$ If $r\varepsilon J(R).$ then $rB_{i}=0$ for all $i$ by Theorem 2.3 (i). Consequently

$$r=r1_R=re_1+re_2+\cdots+re_k=0.$$

Therefore, $J(R)=0$ and $R$ is semisimple. Since $B_{i}$ is simple and

$$(B_1\oplus\cdots\oplus B_i)/(B_1\oplus\cdots\oplus B_{i-1})\cong B_i,$$

the series

$$R=B_1\bigoplus\cdots\bigoplus B_k\supset B_1\bigoplus\cdots\bigoplus B_{k-1}\supset\cdots\supset B_1\bigoplus B_2\supset B_1\supset0$$

is a composition series for $R$ . Therefore, $R$ is left Artinian by Theorem VIll.1.11. $(\mathrm{i})\Rightarrow(\mathrm{viii})$ In vew of Theorem 3it sufices t asyme that $R=\prod_{i=1}^lMat_{n_i}D_i$ with each $n_i>0$ and each $D_i$ a division ring.For each fixed i and each $j=1,2,\ldots,n_{i}$ let $e_{ij}$ be the matrix in $\mathrm{Mat}_{ni}D_i$ with $1_{D_i}$ in position $(j,j)$ and O elsewhere. Then $\{e_{i1},\ldots,e_{in_i}\}$ is a set of orthogonal idempotents in $\mathrm{Mat}_{n_i}D_i=R_i$ whose sum is the identity matrix. The proof of Corollary VIl1.1.12 shows that each $R_ie_{ij}$ is a minimal left ideal of $R_{i}$ and $R_{i}=R_{i}e_{i1}\oplus\cdots\oplus R_{i}e_{in_{i}}$ . Since $R$ is the ring direct product $R_1\times\cdots\times R_t$ , it follows that $R_{i}R_{j}=0$ for $i\neq j$ ; that $Re_{ij}=R_{i}e_{ij}$ that $Re_{ij}$ is a minimal left ideal of $R$ ; and that $\{e_{ij}\mid1\leq i\leq t;1\leq j\leq n_{i}\}$ 1≤j≤n} $1\leq j\leq n_i\}$ is a set of orthogonal idempotents in $R$ Wwhose umis $\sum_{i=1}^{l}(\sum_{j}e_{ij})=\sum_{i=1}^{l}\mathbf{1}_{R_{i}}=\mathbf{1}_{R}$ Clearly $R=\sum_{i=1}^{t}\sum_{j=1}^{n_{i}}Re_{i_{j}}$ $(\mathbf{v}$iii$)\Rightarrow(\mathbf{v})$ Let $A$ be a unitary $R$ -module. For each a e $A$ and each i, $K_ia$ is a sub

module of $A$ (Exercise IV.1.3) and $a=1_{R}a=e_{1}a+\cdots+e_{m}a$ E $K_1a+\cdots+K_ma$ Consequently the submodules $K_ia$ a $a\:(a\varepsilon A,1\leq i\leq m)$ generate $A$ .For each ae $A$ and each $i$ ,themap $f:K_i\to K_ia$ given by $k\mapsto ka$ is an $R$ -module epimorphism Since $K_{i}$ is a minimal left ideal of a ring with identity, $K_{i}$ is a simple $R$ -module. Consequently if $K_{ia\neq0}$ , then $f$ is an isomorphism by Schur's Lemma 1.10. Thus $\left\{K_ia\mid1\leq i\leq m\right.$ ;ae A; $K_{ia}\neq0\}$ is a family of simple submodules whose sum is $A$ Therefore $A$ is semisimple by Theorem 3.6.

Theorems 3.3 and 3.7 show that a semisimple left Artinian ring may be decomposed as a direct product [resp. sum] of simple ideals [resp. minimal left ideals]. We turn now to the question of the uniqueness of these decompositions

Proposition 3.8. Ler R be a semisimple left Artinian ring.

(i) $\mathbf{R}=\mathbf{I}_{1}\times\cdots\times\mathbf{I}_{u}$ where each $I_{\mathrm{j}}$ is a simpleidealofR. (ii)IfJis any simple ideal ofR,then $\mathbf{J}=\mathbf{I}_{\mathbf{k}}$ for some k. (ii) I $f\mathbf{R}=\mathbf{J}_{\mathbf{l}}\times\cdots\times\mathbf{J}_{\mathrm{m}}$ with each $J_k$ a simple ideal ofR, then $\mathbf{n}=\mathbf{m}$ and (after

reindexing) $\mathbf{I}_{\mathbf{k}}=\mathbf{J}_{\mathbf{k}}$ for $\mathbf{k}=1,2,\ldots,\mathbf{n}$

REMARKS. The conclusion $J=I_{j}$ [resp. $J_{k}=I_{k}]$ is considerably stronger than the statement $“J$ [resp. $J_k]$ is isomorphic to $I_k$ "The uniquely determined simple ideals $I_{1},\ldots,I_{n}$ in Proposition 3.8 are called the simple components of $R$

------------------------------------------------------------------

PROOF OF 3.8. (i) is true by Theorem 3.3. (i) If $J$ is a simple ideal of $R$ , then $RJ\neq0$ ,whence $I_{kJ}\neq0$ for some $k$ . Since $I_{k}J$ is a nonzero ideal that is contained in both $I_k$ and $J$ , the simplicity of $I_k$ and $J$ implies $I_{k}=I_{k}J=J.$ (i) The ideals $I_1,\ldots,I_n$ [resp. $J_{1},\ldots,J_{m}]$ are nonzero and mutually disjoint by hypothesis. Define a map $\theta$ from the $m$ element set $\{J_1,\ldots,J_m\}$ to the $n$ element set $\{I_1,\ldots,I_n\}$ by $J_k|\mapsto I_k$, where $J_{k}=I_{k}$ $\theta$ is well defined and injective by (i), whence $m\leq n$ . The same argument with the roles of. $J_{k}$ and $I_{k}$ reversed shows that $n\leq m$ . Therefore $n=m$ and $\theta$ is a bijection.

A semisimple left Artinian ring $R$ is a direct sum of minimal left ideals by Theorem 3.7 (vii). The uniqueness (up to isomorphism) of this decomposition will be an immediate consequence of the following proposition. For $R$ is a semisimple $R$ -module (Theorem $3.7(vi)$ ）and the minimal left ideals of $R$ are precisely its simple submodules.

Proposition 3.9. Let A be a semisimple module over a ring R. Ifthere are direct sum decompositions

$$\mathbf{A}\:=\:\mathbf{B}_{1}\:+\:\cdots\:+\:\mathbf{B}_{\mathrm{m}}\quad and\quad\mathbf{A}\:=\:\mathbf{C}_{1}\:+\:\cdots\:+\:\mathbf{C}_{\mathrm{n}},$$

where each $B_i,C_j$ Cj $\mathbf{C_{j}}$ is a simple submodule of A, then. $m=n$ and (after reindexing) $\mathbf{B_{i}\cong C_{i}}$ for $i=1,2$ ....,m.

REMARK. The uniqueness statement here is weaker than the one in Proposi tion 3.8. Proposition 3.9 is false if $“B_{i}\cong C_{i}”$ is replaced by $“B_{i}=C_{i}”$ (Exercise 11)

PROOF OF 3.9. The series

$$A=B_1\textcircled{+}\cdots\textcircled{+}B_m\supset B_2\textcircled{+}\cdots\textcircled{+}B_m\supset\cdots\supset B_m\supset0$$

is a composition series for $A$ with simple factors $B_{1},B_{2},\ldots,B_{m}$ (see p. 375).Similarly $A=C_1\oplus\cdots\oplus C_n\supset C_2\oplus\cdots\oplus C_m\supset\cdots\supset C_m\supset0$ is a composition series for $A$ with simple factors $C_{\mathbf{l}},\ldots,C_{n}$ . The Jordan-Holder Theorem VIl1.1.10 implies that $m=n$ and (after reindexing) $B_{i}\cong C_{i}$ for $i=1,2,\ldots,m$ .■

The following theorem will be used only in the proof of Theorem 6.7.

Theorem 3.10. Let R be a semisimple left Artinian ring.

(i) Every simple left [resp. right] R-module is isomorphic to a minimal left [resp right] ideal of R. (ii) The number ofnonisomorphic simple left [resp. right] R-modules is the same as

the number of simple components of R.

PROOF. $R$ is right Artinian by Corollary 3.4. Since the preceding results are left-right symmetric, it suffices to prove the theorem for left modules

(i) By Theorem 3.7, $R=K_{1}\oplus\cdots\oplus K_{m}$ with each $K_{i}$ a nonzerominimal left ideal (simple submodule) of R. $R$ has an identity(Corollary 3.4) and every simple $R$ -module $A$ is unitary by Remark (i) after Definition 1.1. The proof of $(\mathbf{viii})\Rightarrow(\mathbf{v})$

------------------------------------------------------------------

of Theorem 3.7 shows that for some i $(1\leq i\leq m)$ and ae $A$ ， $A$ contains a nonzerc submodule $K_ia$ such that $K_{i}a\cong K_{i}$ . The simplicity of $A$ implies that $A$ = $K_{i}a\cong K_{i}$ (i) The simple components of $R$ are the unique simple ideals $I_i$ of $R$ such that

$R=I_{1}\times\cdots\times I_{n}$ (Proposition 3.8). In view of (i) it suffices to prove: (a) each $K_{i}$ is contained in some $I_t$

(b) each $I_t$ contains some $K_i$

(c) $K_{i}\cong K_{j}$ as $R$ -modules if and only if $K_{i}$ and $K_{j}$ are contained in the same

simple component $I_t$ These statements are proved as follows.

(a) Since $R$ has an identity, $K_{i}=RK_{i}=I_{\mathrm{l}}K_{i}\times\cdots\times I_{n}K_{i}$ . Since each $I_jK_i$ is a

left ideal of $R$ contained in $K_{i}$, we must have $I_{\iota}K_{i}=K_{i}$ for some $t$ and $I_{i}K_{i}=0$ for $j\neq1$ by minimality. Therefore $K_{i}=I_{i}K_{i}\subset I_{t}$ (b) If $I_t$ contains no $K_{i,}$ then $R=\sum K_{i}$ is contained in

$$I_1\times\cdots\times I_{t-1}\times I_{t+1}\times\cdots\times I_n$$

by (a). Since $I_t\neq0$ by simplicity and $R=\prod I_i$,

$$0\neq I_t=I_t\cap R=I_t\cap(I_1\times\cdots\times I_{t-1}\times I_{t+1}\times\cdots\times I_n)=0,$$

which is a contradiction

(c) If $K_i\subset I_{t_1}$ and $K_i\subseteq I_{t_2}$ with $t_1\neq t_2$ ,then by (a), $0\neq K_{i}=I_{t_{1}}K_{i}$ and $0\neq K_{j}=I_{t_{2}}K_{j}$ .Since $R$ = $\coprod I_{i}$, $I_{t_1}I_{t_2}=$ 0 = $I_{t_2}I_{t_1}$ . Consequently, there can be no $R$ -module isomorphism $K_{i}\cong K_{j}$ Conversely suppose $K_{i}\subset I_{i}$ and $K_i\subset I_l$ . Then $K_{i}$ and $K_{i}$ are $I_{t}$ -modules. Since $I_{t}$ is simple and $0\neq K_{i}=I_{\iota}K_{i}$ by (a), the left annihilator ideal of $K_{i}$ in $I_i$ must be zero. Conscquently, $K,K_i\neq0$ since $0\neq K_i\subset I_i$ Thus for some a e $K_{i}$ $K_{i}a\neq0$ . Since $K_{i}$ and $K_{j}$ are left ideals of $R$ $K_{ja}$ is a nonzero left ideal of $R$ and $K_{i}a\subset K_{i}$ . Therefore $K,a=K_{i}$ by minimality. The proof $(\mathbf{viii})\Rightarrow$ = $1\Longrightarrow$ $(\mathbf{v})$ of Theorem 3.7 shows that $K_{j}\omega\cong K_{i}$, whence $K_{i}\cong K_{i}$ .

### EXERCISES

1. A ring $R$ is isomorphic to a subdirect product of the family of rings $\{R_{i}\mid i\in I\}$ if and only if there existsfor each i e I an ideal $K_{i}$ of $R$ such that $R/K_{i}\cong R_{i}$ and $\bigcap_{ieI}K_{i}=0$

2. A ring $R$ is subdirectly irreducible if the intersection of all nonzero ideals of $R$ is nonzero. (a) $R$ is subdirectly irreducible if and only if whenever $R$ is isomorphic to a

subdirect product of $\{ R_{i}| i$ $\varepsilon$ $I\}$ ， $R\cong R_i$ for some i ε $I$ [see Exercise 1]. (b) (Birkhoff) Every ring is isomorphic to a subdirect product of a family of

subdirectly irreducible rings. (c) The zero divisors in a commutative subdirectly irreducible ring (together with 0) form an ideal.

3. A commutative semisimple left Artinian ring is a direct product of fields.

4. Determine up to isomorphism all semisimple rings of order 1008. How many of them are commutative? [Hint: Exercise V.8.10.]

5. An element $a$ of a ring $R$ is regular (in the sense of Von Neumann) if there exists $x\varepsilon R$ such that $axa=a$ .If every element of $R$ is regular, then $R$ is said to be a regular ring.

------------------------------------------------------------------

(a) Every division ring is regular. (b) A finite direct product of regular rings is regular. (c) Every regular ring is semisimple. [The converse is false (for example, $\mathbf{Z}$ ). (d) The ring of all linear transformations on a vector space (not necessarily finite dimensional) over a division ring is regular. (e)A semisimple left Artinian ring is regular. (f) $R$ is regular if and only if every principal left [resp. right] ideal of $R$ is generated by an idempotent element. (g) A nonzero regular ring $R$ with identity is a division ring if and only if its only idempotents are O and $1_{R}$

6. (a) Every nonzero homomorphic image and every nonzero submodule of a semisimple module is semisimple (b)The intersection of two semisimple submodules is O or semisimple.

7. The following conditions on a semisimple module $A$ are equivalent:

(a) $A$ is finitely generated. (b) $A$ is a direct sum of a finite number of simple submodules. (c) $A$ has a composition series (see p. 375). (d) $A$ satisfies both the ascending and descending chain conditions on submodules (see Theorem VIII.1.11)

8. Let $A$ be a module over a left Artinian ring $R$ such that $Ra\neq0$ for all nonzero ae $A$ and let $J=J(R)$ . Then $JA=0$ if and only if $A$ is semisimple. [Hinrs: if $JA=0$ ，then $A$ is an $R/J$ -module, with $R/J$ semisimple left Artinian; see Exercise IV.1.17.]

9. Let $R$ be a ring that (as a left $R$ -module)is the sum of itsminimal left ideals. Assume that $\{r\varepsilon R\mid Rr=0\}=0$ .If $A$ is an $R$ -module such that $RA=A$ ,then $A$ is semisimple. [Hinr: if Iis a minimal left ideal and a e $A$ , show that la is either zero or a simple submodule of A.]

10. Show that a nonzero $R$ -module $A$ such that $RA=0$ is not semisimple, but may be projective. Consequently Theorem 3.7 may be false if the word “unitary" is omitted. [See Exercise IV.2.2, Theorem IV.3.2 and Proposition IV.3.5.]

11. Let $R$ be the ring of $2\times2$ matrices over an infinite field.

(a) $R$ has an infinite number of distinct proper left ideals, any two of which are isomorphic as left $R$ -modules (b) There are infinitely many distinct pairs $(B,C)$ such that $B$ and $C$ are minimal left ideals of $R$ and $R=B\oplus C$

12. A left Artinian ring $R$ has the same number of nonisomorphic simple left $R$ -modules as nonisomorphic simple right $R$ -modules. [Hinr: Show that $A$ is a simple $R$ -module if and only if $A$ is a simple $R/J(R)$ -module; use Theorem 2.14 and Theorem 3.10.]

13. (a) (Hopkins) If $R$ is a left Artinian ring with identity, then $R$ is left Noetherian [Hints: Let $n$ be the least positiveinteger such that $J^n=0$ (Proposition 2.13). Let $J^0=R$ .Since $J(J^{i}/J^{i+1})=0$ and $R$ is left Artinian each $Ji/J^{i+1}$ Ji/Ji+1 $J^i/J^{i+1}\left(0\leq i\leq n-1\right)$ has a composition series by Exercises 7 and 8.Use these and Theorem IV.1.10 t0 construct a composition series for $R$ ; apply Theorem VIl1.1.11.]

------------------------------------------------------------------

Remark. Hopkins' Theorem is valid even if the hypothesis. $“R$ has an identity' is replaced by the much weaker hypothesis that. $\{r\varepsilon R\mid rR=0$ and $Rr=0\}=$ 0; see L.Fuchs [13; pp.283-286].

(b) The converse of Hopkins' Theorem is false.

## 4. THE PRIME RADICAL; PRIME AND SEMIPRIME RINGS

We nowintroduce theprime radical of a ring and call aring semiprime if it has zero prime radical (Definition 4.1). We then develop the analogues of the results proved in Sections 2 and 3 for the Jacobson radical and semisimple rings (Propositions 4.2-4.4). There is a strong analogy between the prime radical, prime ideals, semiprime rings, prime rings, and the Jacobson radical, left primitive ideals, semisimple rings, and prinitive rings respectively The remainder of the section is devoted to a discussion of Goldie's Theorem 4.8,

which is a structure theorem for semiprime rings satisfying the ascending chain condition on certaintypes of left ideals.Goldie'sTheorem plays the same role here as do the Wedderburn-Artin Theorems 1.14 and 3.3 for rings with the descending chain condition on left ideals.In fact Goldie's Theorem maybe considered as an extension of theWedderburn-Artin Theorems to a wider class of rings.A fuller explanation of these statements is contained in discussions after Proposition 4.4, preceding Theorem 4.8 and after Corollary 4.9. This section is not needed in the sequel.

Definition 4.1. The prime radical P(R) of a ring R is the intersection of all prime ideals ofR.IfR has no-prime ideals,then $\mathbf{P}(\mathbf{R})=\mathbf{R}$ . A ring R such that $\mathbf{P}(\mathbf{R})=0$ is said to be semiprime.

REMARKS. The prime radical (also called the Baer lower radical or the McCoy. radical) is the radical with respect to a certain radical property, as defined in the introduction to Section 2; for details, see Exercises 1 and 2. A semiprime ring is one that is semisimple withrespect to the prime radical (see the introduction toSection 2). We use the term“semiprime" to avoid both awkward phrasing and confusion with Jacobson semisimplicity. The relationship of the prime radical with the Jacobson radical is discussed in Exercise 3.

Just as in the case of the Jacobson radical, there is a close connection between the prime radical of a ring $R$ and the nilpotent ideals of $R$ . In order to prove one such result, we must recall some terminology

Let $S$ be a subset of a ring $R$ .By Theorem 1.4 the set $\{r\varepsilon R\mid rS=0\}$ is a left ideal of $R$ , which is actually an ideal if $S$ is a left ideal. The set $\{r\varepsilon R\mid rS=0\}$ is called the left annihilator of $S$ and is denoted $G(S)$ .Similarly the set

$$\mathbb{Q}_r(S)\:=\:\{r\:\varepsilon\:R\mid Sr\:=\:0\}$$

is a right ideal of $R$ that is an ideal if $S$ is a right ideal. $Qr(S)$ is called the right annihilator of $S.$ .A left [resp. right] ideal $I$ of $R$ is said to be a left [resp. right] annihilator if $I=\alpha(S)$ [resp. $I=G_{r}(S)]$ for some subset $S$ of $R$

1

1

------------------------------------------------------------------

REMARK. The intersection of two left [resp. right] annihilators is also a left [resp. right] annihilator since $a(s)\cap a(T)=a(s\cup T)$ . If $S$ and $T$ are actually left ideals, then $\alpha(s)\cap\alpha(T)=\alpha(s\cup T)=\alpha(s+T)$

Proposition 4.2.A ring R is semiprime if and only ifRhas no nonzero nilpoteni ideals.

SKETCH OFPROOF. $(\Longrightarrow)$ If $I$ is a nilpotent ideal and $K$ is any prime ideal, then for some n, $I^{n}=0\varepsilon K$ , whence $I\subset K$ . Therefore $I\subset P(R)$ . Consequently, if $R$ is semiprime, so that $P(R)=0$ ,then the only nilpotent ideal is thezero ideal.

$(\Leftarrow)$ Conversely suppose that $R$ has no nonzero nilpotent ideals. We must show that $P(R)=0$ . It suffices to prove that for every nonzero element $a$ of $R$ there is a prime ideal $K$ such that $a\notin K$ , whence $a\notin P(R)$ . We frst observe that $G(R)\cap R$ is a nilpotent ideal of $R$ since

$$(\alpha(R)\cap R)(\alpha(R)\cap R)\subset\alpha(R)R=0.$$

Consequently, $G(R)=G(R)\cap R=0$ . Similarly $\alpha_r(R)=0$ . If $b$ is any nonzerc element of $R.$ weclaim that $RbR\neq0$ . Otherwise $Rb\subset\mathfrak{G}(R)=0$ ,whence $Rb=0$ Thus $b\varepsilon G_r(R)=0$ , which is a contradiction. Therefore. RbR is a nonzero ideal of $R$ and hence not nilpotent. Consequently $bRb\neq0$ (otherwise $(RbR)^2\subset RbRbR=0$ For each nonzero $b$ E $R$ choose f(b) $f(b)$ $f(b)\varepsilon bRb$ such that $f(b)\neq0$ .Then by the Recursion Theorem 6.2 of the Introduction there is a function. $\varphi:\mathbb{N}\to R$ such that

$$\varphi(0)=a\quad\mathrm{and}\quad\varphi(n+1)=f(\varphi(n)).$$

Let $a_{n}=\varphi(n)$ so that $a_{n+1}=f(a_{n})\neq0$ an+1 = f(an) ≠ 0 $a_{n+1}=f(a_{n})\neq0.$Let$S=\{a_i\mid i\geq0\}$ S={ai|i0} $S=\{a_{i}\mid i\geq0\}$ . Use Zorn's Lemma to find an ideal $K$ that is maximal with respect to the property K $\cap S=\varnothing$ (since $0\neq S$ there is at least one ideal disjoint from $S$ ).

Since $a=a_{0}\varepsilon S,a\notin K$ and $K\neq R.$ .To complete the proof we need only show that $K$ is prime. If $A$ and $B$ are ideals of $R$ such that $A\not\subset K$ and $B\not\subset K$ , then (A + K) $(A+K)$ $(A+K)\cap S\neq\varnothing$ $S\neq\varnothing$ S≠Q and $(B+K)$ (B+ K) $(B+K)\cap S\neq\varnothing$ S≠Q $S\neq\varnothing$ by maximality. Consequently for some $i,j,a_i\varepsilon A+K$ and $a_{j}\in B+K$ . Choose $m>$ max $\{i,j\}$ . Since $a_{n+1}=f(a_{n})$ E $a_nRa_n$ for each $n.$ ，it follows that $a_{n_{i}}\varepsilon\left(a_{i}Ra_{i}\right)\cap\left(a_{i}Ra_{i}\right)\subset\left(A+K\right)\cap\left(B+K\right)$ (B+ K) $(B+K)$ .Consequently,

$$a_{m+1}=f(a_m)\varepsilon\:a_mRa_m\subset(A+K)(B+K)\subset AB+K.$$

Since $a_{m+1}\notin K$ , we must have $AB\not\subset K$ . Therefore $K$ is a prime ideal.

Aring $R$ is said to be a prime ring if the zero ideal is a prime ideal (that is, if $I,J$ are ideals such that $IJ=0$ , then $I=0$ or $J=0$ ). The relationships among prime ideals, prime rings, and semiprime rings are analogous to the relationships betweer left primitive ideals, primitive rings, and semisimple rings. In particular, we note the following: (i) The prime [resp. Jacobson] radical is the intersection of all prime [resp.

primitive] ideals (see Theorem 2.3(iii).. (ii) Every prime ring is semiprime since O is a prime ideal. This corresponds to

the fact that every primitive ring is semisimple (Theorem 2.10(i)).

------------------------------------------------------------------

Proposition 4.3.K is a prime ideal of a ringR ifand only ifR/K is a prime ring

REMARK. This is the analogue of Definition 2.1 (left primitive ideals).

SKETCH OF PROOF OF 4.3. If $R/K$ is prime, let $\pi:R\to R/K$ be the canonical epimorphism. If $I$ and $J$ are ideals of $R$ such that $IJ\subset K$ , then $\pi(I),\pi(J)$ are ideals of $R/K$ (Exercise III.2.13(b)) such that $\pi(I)\pi(J)=\pi(IJ)=0$ .Since $R/K$ is prime, either $\pi(I)=0$ or $\pi(J)=0$ ; that is, $I\subset K$ or $J\subset K$ . Therefore, $K$ is a prime ideal(Definition II1.2.14). The converse is an easy consequence of Theorem I11.2.13 and Definition II1.2.14.

The final part of the semiprime-semisimple analogy is given by

Proposition 4.4.A ring R is semiprime if and only ifR 'is isomorphic 1o a subdirecl product of prime rings.

SKETCH OF PROOF. Proposition 4.4 is simply Proposition 3.2 with the words “semisimple" and “primitive" changed to “semiprime" and “prime' respectively. With this change and the use of Proposition 4.3 in place of Definition 2.1, the proof of Proposition 3.2 carries over verbatim to the present case.

We have seen that primitive rings are the basic building blocks for semisimple rings. Proposition 4.4 shows that the basic building blocks for semiprime rings are the prime rings. At this point the analogy between primitive and prime rings fails. Primitive rings may be characterized in terms of familiar matrix rings and endomorphism rings of vector spaces (Section 1). There are no comparable results for prime rings. But the situation is not completely hopeless. We have obtained very striking results for primitive and semisimple left Artinian rings (Sections 1 and 3). Consequently it seems plausible that one could obtain useful characterizations of prime and semiprime rings that satisfy certain chain conditions. We shall now do precisely that. We first observe that in a left Artinian ring the prime radical coincides with the

Jacobson radical (Exercise 3(c)). Consequently, left Artinian semiprime rings are also semisimple, whence their structure is determined by the Wedderburn-Artin Theorem 3.3. Since every semiprime (semisimple) left Artinian ring is also left Noetherian by Corollary 3.4, the next obvious candidate to consider is the class of semiprime left Noetherian rings (that is, semiprime rings that satisfy the ascending chain condition on left ideals). Note that there are semiprime left Noetherian rings that are not left Artinian (for example, $\mathbf{Z}$ ). Consequently, a characterization of semiprime left Noetherian rings would be a genuine extension of our previous results. We shall actually characterize a wider class of rings that properly includes the

class of all semiprime left Noetherian rings. The class in question is the class of all semiprime left Goldie rings, which we now define. A family of left ideals of $R\left\{I_{i}\mid j\in J\right\}$ is said to be independent provided that for

each Ik $I_k$ $k\:\varepsilon\:J,\:I_{k}\:\cap\:I_{k}^{*}\:=\:0$ ，where $I_k^*$ is the left ideal generated by $\{I_j|j\neq k\}$ . In other words, $\{I_{j}\mid j\in J\}$ is independent if and only if the left ideal $I$ generated by $\{I_i\mid j\in J\}$ is actually the internal direct sum I; (see Theorem IV.1.15)

------------------------------------------------------------------

## Definition 4.5.A ring R is said to be a (left) Goldie ring if

(i) R satisfies the ascending chain condition on left annihilators; (i) every independent set of left ideals ofR is finite

REMARKS. (i) Condition (i) of Definition 4.5 means that given any chain of left annihilators $\alpha(S_1)\subset\alpha(S_2)\subset\cdots$ , there exists an $n$ such that $G(S_{i})=G(S_{n})$ for all $i\geq n$ . This condition is equivalent to the condition

(i') R satisfies the maximum condition on left annihilators (that is, every nonempty set of left annihilators contains a maximal element with respect to set. theoretic inclusion).

To see this one need only observe that theproof of TheoremVIl1.1.4 carries over to the present situation, mutatis mutandis.

(ii) Right Goldie rings are defined in the obvious way. A right Goldie ring need not be a left Goldie ring; see A. W. Goldie [62]

EXAMPLE. Every left Noetherian ring $R$ is a left Goldie ring. Condition (i) is obviously satisfied. If $\{I_{j}\mid j\in J\}$ were an infinite independent set of left ideals, then there would exist $I_1,I_2$, ... such that $I_{1}\subseteq I_{1}\times I_{2}\subsetneq I_{1}\times I_{2}\times I_{3}\subsetneq\cdots$ , which contradicts the ascending chain condition. Therefore (i) is satisfied and $R$ is a Goldie ring. There do exist left Goldie rings that are nor left Noetherian rings.

The preceding example shows that the class of semiprime left Goldie rings contains the class of semiprime left Noetherian rings. Our characterization of semiprime left Goldie rings will be given in terms of their left quotient rings, in the sense of the following definitions.

Definition 4.6. A nonzero element a in a ring R is said to be regular if a is neither a left nor right zero divisor.

Definition 4.7. A ring Q(R) with identity is said to be a leftquotient ring ofa ring R if

(i) $\mathbb{R}\subset\mathbb{Q}(\mathbb{R})$ (i) every regular element in R is a unit in Q(R); (ii) every element c ofQ(R) is ofthe form $\mathbf{c}=\mathbf{a}^{-1}\mathbf{b}$ , where a,b ε R and a is regular

REMARKS. (i) A ring $R$ need not have a left quotient ring. If it does, however,it is easy to see that $Q(R)$ is determined up to isomorphism by Definition 4.7. (i) A right quotient ring of $R$ is defined in the same way, except that * $`c=a^{-1}b^{,,}$

is replaced by. $“c=ba^{-1}$, in condition (i). A ring may have a right quotient ring, but no left quotient ring (see N. J. Divinsky [22; p. 71]). (ii) If $R$ is a ring that has a left quotient ring $Q(R)=T$ then $R$ is said to be a

left order in $T$

EXAMPLE. Let $R$ be a commutative ring that has at least one regular element Let $S$ be the set of all regular elements of $R$ .Then thecomplete ring of quotients $S^{-1}R$

------------------------------------------------------------------

T

 is a ring with identity (Theorem II1.4.3) that contains an isomorphic copy $\varphi_{S}(R)$ of $R$ (Theorem II1.4.4(ii). If we identify $R$ and $\varphi_{S}(R)$ as usual, then $R\subset S^{-1}R$ ,every regular element of $R$ is a unit in $S.^{-1}R$ (Theorem II1.4.4(i)) and every element of $S^{-1}R$ is of the form $s^{-1}r$ s-lr R $R$ $s^{-1}r\left(r\varepsilon R,s\varepsilon S\subset R\right)$ SCR $S\subset R$ . Therefore $S^{-1}R$ is a left quotient ring of $R$ Special case: the rational field $\mathbf{Q}$ is a left quotient ring of the left Noetherian ring $\mathbf{Z}$

EXAMPLE. Every semisimple left Artinian ring is its own left quotient ring (Exercise 6).

It is clear from Definition 4.7 that the structure of a left quotient ring $Q(R)$ is intimately connected with the structureof the ring $R$ .Consequently, if one cannot explicitly describe the ring. $R$ in terms of well-known rings, the next best thing is to show that $R$ has a leftquotientring that can be explicitly described in such terms. This is precisely what Goldie's Theorem does.

Theorem 4.8. (Goldie) R is a semiprime [resp. prime] left Goldie ring if and only if R has a left quotient ring Q(R) which is semisimple [resp. simple] left Artinian

Theorem 4.8 will not be proved here for reasons of space. One of the best proofs is due to C. Procesi and L. Small [65]; a slightly expanded version appears in I. Herstein [24]. Although long, this proof is no more difficult than many proofs presented earlier in this chapter. It does use Ore's Theorem, a proof of which is sketched in 1. N. Herstein [24; p. 170] and given in detail in N. J. Divinsky [22; p. 66].

Since the structure of semisimple left Artinian rings has been completely determined, Theorem 4.8 gives as good a description as we are likely to get of semiprime left Goldie rings (special case: semiprime left Noetherian rings). The “distance' between the rings $R$ and $Q(R)$ is the price that must be paid for replacing the descending chain condition with the ascending chain condition. For as we observed in the discussion after Proposition 4.4 and in Exercise 3.13, the latter is a consider. ably weaker condition than the former..

Corollary 4.9. R is a semiprime [resp. prime] left Goldie ring if and only if R has a quotient ring Q(R) such that. $\mathbb{Q}(\mathbb{R})\cong Mat_{n_1}\mathbb{D}_1\times\cdots\times Mat_{n_k}\mathbb{D}_k$ ,[resp. $\mathbf{Q}(\mathbf{R})\cong$ $Mat_{\mathrm{nl}}\mathbf{D}_{\mathrm{l}}]$ ,where $\mathbf{n}_1,\ldots,\mathbf{n}_k$ ,nk $,n_k$ are positive integers and $\mathbf{D}_{\mathrm{l}},\ldots,\mathbf{D}_{\mathrm{n}}$ Dn $D_n$ are division rings.

PROOF. Theorems 1.14, 3.3, and 4.8.

Goldie's Theorem, as rephrased in Corollary 4.9, may be thought of as an extension of the Wedderburn-Artin Theorems 1.14 and 3.3 to a wider class of rings. For instance, Theorem 3.3.states that a semisimple left Artinian ring is a direct product of matrix rings over division rings. Goldie's Theorem states that every semiprime left Goldie ring has a quotient ring that is a direct product of matrix rings over division rings. But every semisimple left Artinian ring is a semiprime left Goldie ring (Corollary 3.4, Exercise 3(a), and the Example after Definition 4.5). Furthermore every semisimple left Artinian ring is its own quotient ring (Exercise 6). Thus Goldie's Theorem reduces to the Wedderburn-Artin Theorem in this case. An analogous argument holds for simple left Artinian rings and Theorem 1.14.

------------------------------------------------------------------

### EXERCISES

Note: $R$ is always a ring.

1. A subset $T$ of $R$ is said to be an m-system (generalized multiplicative system) if

for some x ε $R$
$$c,d\varepsilon T\Rightarrow cxd\varepsilon T$$

(a) $P$ is a prime ideal of $R$ if and only if $R-P$ is an m-system. [Hint: Exercise 111.2.14.] (b) Let $I$ be an ideal of $R$ that is disjoint from an $m$ -system T. Show that I is

contained in an ideal $Q$ which is maximal respect to the property that $Q\cap T=\varnothing$ . Then show that $Q$ is a prime ideal. [Hint: Adapt the proof of Theorem VIll.2.2.J (c) An element r of $R$ is said to have the zero property if every $m$ -system that

contains $r$ also contains O. Show that the prime radical $P(R)$ is the set $M$ of all elements of $R$ that have the zero property. [Hint: use (a) to show $M\subset P(R)$ and (b) to show $P(R)\subset M.$ (d) Every element $c$ of $P(R)$ is nilpotent. [Hint: $\{c^i\mid i\geq1\}$ is an $m$ -system.] If

$R$ is commutative, $P(R)$ consists of all nilpotent elements of $R$

2. (a) If $I$ is an ideal of $R$ , then $P(I)=I\cap P(R)$ . In particular, $P(P(R))=P(R)$ [Hinr: Exercise 1(c).] (b) $P(R)$ is the smallest ideal $K$ of $R$ such that $P(R/K)=0$ . In particular

$P(R/P(R))=0$ ，whence $R/P(R)$ is semiprime. (Hint: Exercise III.2.17(d). (c) An ideal $I$ is said to have the zero property if every element of $I$ has the zero property (Exercise 1(c)). Show that the zero property is a radical property (as defined in the introduction to Section 2), whose radical is precisely $P(R)$

3.(a)Every semisimple ring is semiprime (b) $P(R)\subset J(R)$ . [Hinr: Exercise 1(d); or (a) and Exercise 2(b).]

(c) If $R$ is left Artinian, $P(R)=J(R)$ . [Hint: Proposition 2.13.]

4. $R$ is semiprime if and only if for all ideals $A,B$

$$AB=0\quad\Rightarrow\quad A\cap B=0.$$

5. (a) Let $R$ be a ring with identity. The matrix ring $Mat_nR$ is prime if and only if $R$ is prime. (b) If $R$ is any ring, then $P(\mathrm{Mat}_nR)=\mathrm{Mat}_nP(R)$ .[Hinr: Use Exercise 2 and part

(a) if $R$ has an identity. In the general case, embed $R$ in a ring $S$ with identity via Theorem II1.1.10; then $P(R)=R\cap P(S)$ by Exercise 2.]

6. If $R$ is semisimple left Artinian, then $R$ is its own quotient ring. [Hint: Since $R$ has anidentity by Theorem 3.3, it suffices to show that everyregular element of R is actually a unit. By Theorem 3.3 and a direct argument it suffices to assume $R=Mat_nD$ for some division ring $D$ . Theorem VI1.2.6 and Proposition V1I.2.12 may be helpful.]

7. The following are equivalent : (a) $R$ is prime;

(b) $a,b\in R$ and $a\boldsymbol{R}b=0$ imply $a=0$ or $b=0$ (c) the right annihilator of every nonzero right ideal of $R$ is O; (d) the left annihilator of every nonzero left ideal of $R$ is O.

------------------------------------------------------------------

8. Every primitive ring is prime [see Exercise 7].

9. The center of a prime ring with identity is an integral domain. [See Exercise 7; for the converse see Exercise io.]

10. Let $J$ be an integral domain and let $F$ be the complete field of quotients of $J$ . Let $R$ be the set of all infinite matrices (row, columns indexed by $N^*$ ) of the form

![](https://storage.simpletex.cn/view/fZGQgore10dVydAr6ko7sZetoAGgC0uGl)

where $A_n\in\mathbf{Mat}_n(F)$ and $d_{\varepsilon}J\subset F$ (a) $R$ is a ring. (b) The center of $R$ is the set of all natrices of the form

![](https://storage.simpletex.cn/view/fSOhfqzxEnpfdliCivbCD22Bych7VCmHC)

with $d\varepsilon J$ and hence is isomorphicto $J$ (c) $R$ is primitive (and hence prime by Exercise 8).

11. The nil radical $N(R)$ of $R$ is the idealgenerated bytheset of all nil ideals of $R$ (a) $N(R)$ is a nil ideal. (b) $N(N(R))=N(R)$

(c) $N(R/N(R))=0$ (d) $P(R)\subset N(R)\subset J(R)$ (e) If $R$ is left Artinian, $P(R)=N(R)=J(R)$ (f) If $R$ is commutative $P(R)=N(R)$

1

## 5. ALGEBRAS

The concepts and results of Sections 1-3 are carried over to algebras over a commutative ring $K$ with identity. In particular, the Wedderburn-Artin Theorem is proved for $K.$ algebras(Theorem 5.4).The latter part of the section deals with algebras over a feld, including algebraic algebras and the group algebra of a finite group. Throughout this section $K$ is always a commuatice ring with identity..

The first step in carrying over the results of Sections 1-3 to $K$ -algebras is to review the definitions of a $K.$ -algebra, a homomorphism of $K$ -algebras, a subalgebra and an algebra ideal (Section IV.7). We recall that if a $K$ algebra $A$ has an identity,then (left, right, two-sided) algebra idealscoincide with (left, right, two-sided) ideals of the ring A (see the Remarks after Definition IV.7.3).Thisfact will be used frequently without explicit mention.

------------------------------------------------------------------

A left ArtinianK-algebra is a $K$ -algebra that satisfies the descending chain condi tion on left algebra ideals. A left Artinian $K$ -algebra may not be a left Artinian ring (Exercise 1).

EXAMPLE. If $D$ is a division algebra over $K$ ，then $Mat_nD$ is a $K$ -algebra (p. 227) which is left Artinian by Corollary VIll.1.12.

Definition 5.1. Let A be an algebra over a commutatuve ring K with identity.

(i)A left (algebra)A-module is a unitary left K-module M such that M is aleft module over the ring A and k( rc) = ( kr) c= r( kc) for all k e K, I e A, c e M. (i)AnA-submodule ofan A-moduleM isa subset ofMwhich is itself an algebra

A-module (under the operations in M). (iii) An algebra A-module M is simple (or irreducible) if AM $\neq0$ and M has no

proper A-submodules (iv) A homomorphism $\mathbf{f}:\mathbf{M}\to\mathbf{N}$ of algebra A-modules is a map that is both a

K-module and an A-module homomorphism

REMARKS. If $A$ is a $K$ -algebra the term “A-module' will always indicate an algebra $A.$ -module. Modules over the ringA will beso labeled.A right $A$ -module $N$ is defined analogously and satisfies $k(cr)=(kc)r=c(kr)$ for all $k\in K,r\varepsilon A,c\varepsilon N$

Simple $K.$ -algebras, primitive $K$ -algebras, the Jacobson radical of a $K$ -algebra, semisimple $K.$ -algebras, etc. are now defined in the same way the corresponding concepts for rings were defined, with algebra ideals, modules, homomorphisms, etc. in place of ring ideals, modules, and homomorphisms. In order to carry over the results of Sections 1-3 to $K$ -algebras (in particular, the Wedderburn-Artin Theorems) the following two theorems are helpful.

Theorem 5.2.Let A be a K-algebra

(i)A subsetI of Ais a regular maximal left algebra ideal if and only ifI is a regular maximal left ideal of thering A. (ii) The Jacobson radical of the ring A coincides with the Jacobson radical of the

algebra A. In particular A is a semisimple ring ifand only if A is a semisimple algebra

REMARK. Theorem 5.2 is trivial if $A$ has an identity since algebra ideals and ring ideals coincide in this case.

PROOF OF 5.2. (i) If $I$ is a regular maximal left ideal of the ring $A$ ,it suffices to show that kI C Ifor all $k\varepsilon K$ . Suppose $kI\not\subset I$ for some $k\varepsilon K$ Since $r(kI)=k(rI)$ by Definition 5.1(i), $I+kI$ is a left ideal of $A$ that properly contains $I.$ .Therefore, $A=I+kI$ by maximality. By hypothesis there exists $e\varepsilon A$ such that r - re e I for all re $A$ . Let $e=a+kb\left(a,b\in I\right)$ .Then

$$e^2=e(a+kb)=ea+e(kb)=ea+(ke)b\varepsilon I.$$

Since $e-e^2\varepsilon I$ and $e^2\varepsilon I$ ,we must have e ε I. Consequently, the fact that $r-re\varepsilon I$ for all $r\varepsilon A$ implies $A=I.$ This contradicts the maximality of $I$ . Therefore, $kI\subset I$ for all $k\varepsilon K$

------------------------------------------------------------------

Conversely let $I$ be a regular maximal left algebra ideal and hence a regular left ideal of thering $A$ . By Lemma $2.4I$ is contained in aregular maximal left ideal $I_1$ of the ring $A$ . The previous paragraph shows that $I_{1}$ is actually a regular left algebra ideal, whence $I=I_1$ by maximality (ii) follows from (i) and Theorem 2.3(ii).

Theorem 5.3. Let A be a K-algebra.Euery simple algebra A-module is a simple module over the ring A. Every simple module M over the ring A can be given a unique K-module structure in such a way that M is a simple algebra A-module.

PROOF. Let $N$ be a simple algebra $A$ -module, whence $AN\neq0$ . If $N_{1}$ is a sub module of $N$ , then $AN_1$ is an algebra submodule of $N$ , whence $AN_{1}=N$ or $AN_{1}=0$ If $AN_{1}=N$ , then $N_{1}=N$ . If $AN_{1}=0$ , then $N_{1}\subset D=\left\{c\varepsilon\boldsymbol{N}\mid Ac=0\right\}$ . But $D$ is an algebra submodule of $N$ and $D\neq N$ since $AN\neq0.$ . Therefore $D=0$ by simplicity, whence $N_{1}=0$ . Consequently, $N$ has no proper submodules and hence is a simple module over the ring $A$ If $M$ is a simple module over the ring $A$ , then $M$ is cyclic, say $M=Ac\left(c\varepsilon M\right)$

by Remark (ii) after Definition 1.1. Define a $K$ -module structure on $M=Ac$ by

$$k(rc)=(kr)c,\quad(k\varepsilon K,r\varepsilon A).$$

Since $kr\varepsilon A,(kr)c$ (kr)c $(kr)c$ is an element of $Ac=M$ . In order to show that the action of $K$ on $M$ is well defnedwemust show that

$$rc\:=\:r_1c\quad\Rightarrow\quad(kr)c\:=\:(kr_1)c,\quad(k\:\varepsilon\:K;\:r,r_1\:\varepsilon\:A).$$

Clearly it will suffce to prove

$$rc\:=\:0\quad\Rightarrow\quad(kr)c\:=\:0,\quad(k\:\varepsilon\:K,r\:\varepsilon\:A).$$

Now by the proof of Theorem 1.3, $M\cong A/I$ where theregular maximal left ideal /is the kernel of the map $A\to Ac=M$ given by $x\vdash xc$ . Consequently, $rc=0$ implies $r\varepsilon I.$ .But Iis an algebra ideal by Theorem 5.4, whence kr ε I. Therefore $(kr)c=0$ and the action of $K$ on $M$ is well defined. It is now easy to verify that $M$ isa $K$ -module and an algebra $A$ -module. The $K.$ -module structure of $M$ is uniquely determined since any $K$ -module structure on $M$ that makes $M=Ac$ an $A$ -module necessarily satisfies $k(rc)=(kr)c$ for all $k\varepsilon K,r\varepsilon A$ .■

1

Theorem 5.4. A is a semisimple left Artinian K-algebra if and only if there is an isomorphism of K-algebras

$$\mathrm{A\cong Mat_{n_1}D_1\times Mat_{n_2}D_2\times\cdots\times Mat_{n_t}D_t,}$$

where each $n_i$ is a positice integer and each $\mathbf{D}_{\mathrm{i}}$ a division algebra over K.

REMARK. Theorem 5.4 is valid for any semisimple finite dimensional algebra $A$ over a field $K$ since any such $A$ is left Artinian (Exercise 2).

SKETCH OF PROOF OF 5.4. Use Theorems 5.2 and 5.3 and Exercises 3 and 4 to carry over the proof of the Wedderburn-Artin Theorem 3.3 to $K.$ algebras.

------------------------------------------------------------------

The remainder of this section deals with selected topics involving algebras over a field.We first obtain a sharper version of Theorem 5.4 in case $K$ is an algebraically closed field and finally we consider group algebras over a field. If $A$ is a nonzero algebra with identity over a field $K$ ,then the map $\alpha:K\to A$ ,de-

defined by $k\vdash k\mathbf{1}_A$ , is easily seen to be a homomorphism of $K.$ algebras. Since $\alpha(1_{K})=1_{A}\neq0$ , ker $\alpha\neq K$ .But the field $K$ has no proper ideals, whence Ker $\alpha=0$ Thus $\alpha$ is a monomorphism. Furthermore the image of $\alpha$ lies in thecenter of $A$ since for all $k\varepsilon K$ K $K$ ,re A:

$$\alpha(k)r=(k1_A)r=k(1_Ar)1_A=(1_Ar)(k1_A)=r\alpha(k).$$

Consequently we adopt the following convention:

If A is a nonzero algebra with identity over a field K, then $K$ is to be identified with. Im $\alpha$ and considered to be a subalgebra of the center of A.

Under this identification the $K$ module action of $K$ on $A$ coincides with multiplica tion by elements of the subalgebra $K$ in $A$ since $ka=(k1_{A})a=\alpha(k)a$

Definition 5.5. An element a of an algebra A over a field K is said to be algebraic over K ifa is the root of some polynomial in $K[x]$ .A is said to be an algebraic algebra overKif every elementofA is algebraic overK.

EXAMPLE. If $A$ is finite dimensional then $A$ is an algebraic algebra. For if $\dim_KA=n$ and ae $A$ ,then the $n+1$ elements $a,a^{2},a^{3},\ldots,a^{n+1}$ an+1 $a^{n+1}$ must be linearly dependent. Thus $k_{1}a+k_{2}a^{2}+\cdots+k_{n+1}a^{n+1}=0$ for some $k_i\varepsilon K$ ,not all zero.Thus $f(a)=0$ where $f$ is the nonzero polynomial $k_{1}x+k_{2}x^{2}+\cdots+k_{n+1}x^{n+1}\varepsilon K[x].$

EXAMPLE. The algebra of countably infinite matrices over a field $K$ with only a finite number of nonzero entries is an infinite dimensional simple algebraic algebra (Exercise 5).

REMARK. The radical of an algebraic algebra is nil (Exercise 6).

Lemma5.6.IfD is analgebraic division algebra over an algebraically closed field K then $\mathbf{D}=\mathbf{K}$

PROOF. $K$ is contained in the center of $D$ by the convention adopted above If ae $D$ ，then $f(a)=0$ for some $f\varepsilon K[x]$ .Since $K$ is algebraically closed $f(x)=k(x-k_{1})(x-k_{2})\cdots(x-k_{n})$ $(k,k_{i}\varepsilon K;k\neq0)$ ,whence

$$0=f(a)=k(a-k_1)(a-k_2)\cdots(a-k_n).$$

Since $D$ is a division ring, $a-k_i=0$ , for some $i.$ Therefore $a=k_{i}\in K$ and thus $D\subset K$

Theorem 5.7. Let A be a finite dimensional semisimple algebra over an algebraically closed field K. Then there are positive integers $\mathbf{n}_1,\ldots,\mathbf{n}_t$ and an isomorphism of K-algebras
$$\mathrm{A\cong Mat_{n_1}K\times\cdots\times Mat_{n_t}K.}$$

------------------------------------------------------------------

I

PROOF. By Theorem 5.4 (and the subsequent Remark) $A\cong\mathrm{Mat}_{n_1}D_1\times$ $\mathrm{Mat}_{n_2}D_2\times\cdots\times\mathrm{Mat}_{n_t}D_t$ where each $D_i$ is a division algebra over $K$ .Each $D_i$ is necessarily finite dimensional over $K$ ; (otherwise $\mathrm{Mat}_{n_i}D_i$ and hence $A$ would be infinite dimensional). Therefore $D_{1}=K$ for every $i$ by Lemma 5.6.

A great deal of research over the years has been devoted to group algebras over a field (see p. 227). They are useful, among other reasons, because they make it possible to exploit ring-theoretic techniques in the study ofgroups.

Proposition 5.8. (Maschke) Let K(G) be the group algebra ofa finite group G over a field K. IfK has characteristic 0, then K(G) is semisimple. IfK has prime characteristic p, then K(G) is semisimple if and only ifp does not divide $|\mathbf{G}|$

SKETCH OF PROOF. Suppose char $K=0$ or $p$ ,-where $pX|G|$ .If $B$ is any $K$ -algebra with identity (in particular $K(G)$ ),verify that there is a well-defined monomorphism of $K$ -algebras $\alpha:B\to\operatorname{Hom}_K(B,B)$ given as follows: $\alpha(b)$ is defined to be the map $\alpha_b:B\to B$ ,where $\alpha_b(x)=b.$ If $g\varepsilon G$ , we denote the element $1_{K}g$ of $K(G)$ simply by $g$ .By definition $K(G)$ is a

$K.$ -vector space with basis $X=\{g|g\varepsilon G\}$ and finite dimension $n=|G|$ . For each ue $K(G)$ let $M_u$ be the matrix of $\alpha_u$ relative to the basis $X$ . Let $g\varepsilon G$ with $g\neq e$ Then for all $g_{1}\varepsilon G,\alpha_{o}(g_{1})=gg_{1}\neq g_{1}$ (since $G$ is a group). Thus $\alpha_{Q}$ simply permutes the elements of the basis $X$ and leaves no basis element fixed. Consequently, the matrix $M_{o}$ of $\alpha_{a}$ relative to the basis $X$ may be obtained from the identity matrix $I_n$ by an appropriate permutation of the rows that leaves no row fixed (see Theorem VII.1.2). Recall that the trace, Tr $M_{u}$ , is the sum of the main diagonal entries of $M_u$ (see p. 369). It is easy to see that

(i) Tr $M_{o}=0$ for $g\in G,g\neq e;$ $g\neq e$ $g\neq e$ (ii) $M_{e}=I_{n,}$ whence Tr $M_e=n\mathbf{1}_K$ (ii) if $u=k_{1}g_{1}+\cdots+k_{n}g_{n}\varepsilon K(G)$ then

$$\alpha_{u}=\sum_{i=1}^{n}k_{i}\alpha_{qi}\quad\mathrm{and}\quad\mathrm{Tr}\:M_{u}=\sum_{i=1}^{n}k_{i}\:\mathrm{Tr}\:M_{qi}.$$

If the radical $J$ of $K(G)$ is nonzero, then there is a nonzero element $v\varepsilon J$ with $v=k_{1}g_{1}+\cdots+k_{n}g_{n}$ . We may assume $g_{1}=e$ and $k_1=1_K$ (if not, replace $v$ by $k_{i}^{-1}g_{i}^{-1}v$ , where $k_i\neq0$ , and relabel). Since $K(G)$ is finite dimensional over $K,K(G)$ is left Artinian (Exercise 2). Consequently $J$ is nilpotent by Proposition 2.13 (for algebras). Therefore $\upsilon\varepsilon J$ is nilpotent, whence $\alpha_v$ is nilpotent. Thus by Theorem VII.1.3 $M_v$ is a nilpotent matrix. Therefore Tr $M_{v}=0$ (Exercise VI1.5.10). On the other hand (i)-(ii) above imply

$$\begin{aligned}
\mathrm{Tr}\:M_{v}& \stackrel{\cdot}{=}\sum_{i=1}^{n}k_{i}\:\mathrm{Tr}\:M_{qi}=\:\mathbf{1}_{K}\:\mathrm{Tr}\:M_{e}+\sum_{i=2}^{n}k_{i}\:\mathrm{Tr}\:M_{qi} \\
&=\mathrm{~Tr~}M_{e}+0=n1_{K}.
\end{aligned}$$

But nl $K\neq0$ since char $K=0$ or char $K=p$ and $p$ does not divide $|G|=n$ .This is a contradiction. Therefore $J=0$ and $K(G)$ is semisimple.

Conversely suppose char $K=p$ and p $p$ $p\mid n$ .Let $w$ be the sum in $K(G)$ of all theelements of the basis $X$ ; that is, $w=g_{1}+g_{2}+\cdots+g_{n}\varepsilon K(G)$ . Clearly $w\neq0$ Verify

------------------------------------------------------------------

that $wg=gw$ for all $g\varepsilon G$ , which implies that $w$ is in the center of $K(G)$ .Show that $w^{2}=nw=(n1_{K})w$, whence $w^{\cdot2}=0$ (since $p\mid n)$ . Thus $(K(G)w)(K(G)w)=0$ so that the nonzero left ideal $K(G)w$ is nilpotent. Since $K(G)w\subset J$ by Theorem 2.12, $J\neq0$ Therefore $K(G)$ is not semisimple.

The following corollary (with $K$ the field of complex numbers) is quite useful in the study of representations and characters of finite groups

Corollary 5.9. Let K(G) be the group algebra ofa finite group G over an algebraically closed field K. If char $K=0$ or char $K=p$ and $pf|G|$ ，then there exist positive integers $\mathbf{n}_{1},\ldots,\mathbf{n}_{\mathrm{t}}$ and an isomorphism of K-algebras.

$$\mathrm{K(G)\cong Mat_{n_1}K\times\cdots\times Mat_{n_t}K.}$$

PROOF. Since $G$ is finite, $K(G)$ is a finite dimensional $K$ -algebra and hence left Artinian (Exercise 2). Apply Theorem 5.7 and Proposition 5.8.

### EXERCISES

Note: $K$ is always a commutative ring with identity and $A$ a $K$ -algebra

1. The Q-algebra $A$ of Exercise IV.7.4 is a left Artinian Q-algebra that is nor a left Artinian ring.

2. A finite dimensional algebra over a field $K$ satisfies both the ascending and de scending chain conditions on left and right algebra ideals.

3. (a) If $M$ is a left algebra $A.$ -module, then $\hat{\alpha}(M)=\{r\varepsilon A\mid rc=0$ for all c e $M\}$ is an algebra ideal of $A$ (b) An algebra ideal $P$ of $A$ is said to be primitive if the quotient algebra $R/P$ is

primitive (that is, has a faithful simple algebra $R/P$ -module). Show that every primitive algebra ideal is a primitive ideal of the ring $A$ and vice versa.

4. Let $M$ be a simple algebra $A.$ -module

(a) $D=\operatorname{Hom}_A(M,M)$ is a division algebra over $K$ ,，where $\operatorname{Hom}_A(M,M)$ denotes all endomorphisms of the algebra $A$ -module $M$ (b) $M$ is a left algebra $D$ -module.

(c)The ring $\mathrm{Hom}_D(M,M)$ of all $D$ -algebra endomorphisms of $M$ is a $K$ -algebra (d) The map $A\to\operatorname{Hom}_D(M,M)$ given by $r|\mapsto\alpha_r$ (where $\alpha_r(x)=rx$ isa $K$ -algebra homomorphism

5.Let $A$ be the set of all denumerably infinite matrices over a field $K$ (that is, ma- trices with rows and columns indexed by $N^*$ ) which have only a finite number of nonzero entries. (a) $A$ is a simple $K$ -algebra

(b) $A$ is an infinite dimensional algebraic $K$ -algebra

6. The radical $J$ of an algebraic algebra $A$ over a field $K$ is nil. [Hinr: if $r\varepsilon J$ and $k_nr^n+k_{n-1}r^{n-1}+\cdots+k_lr^l=0$ $(k_{t}\neq0)$ , then $r^t=r^tu$ with $u=-k_{t}^{-1}k_{n}r^{n-t}$ $-\cdots-k_t^{-1}k_{t+1}r$ ，whence $-u$ is right quasi-regular, say $-u+v-uv=0$ Show that $0=r^{\prime}(-u+v-uv)=-r^{\prime}.]$

------------------------------------------------------------------

?

7. Let $A$ be a $K$ -algebra and $C$ the center of the ring $A$ (a) $C$ is a $K$ -subalgebra of $A$

(b) If $K$ is an algebraically closed field and $A$ is finite dimensional semisimple then the number 1 of simple components of $A$ (as in Theorem 5.7) is precisely $\dim_KC$ rC $_{|K}C$

## 6. DIVISION ALGEBRAS

Wefirst consider certain simple algebras over afield and then turn to the special case of division algebras over a field. We show that the structure of a division algebra is greatly influenced by its maximal subfields. Finally the Noether-Skolem Theorem. (6.7) is proved. It has as corollaries two famous theorems due to Frobenius and Wedderburn respectively (Corollaries 6.8 and 6.9). The tensor product of algebras (Section IV.7) is used extensively throughout this section.

1

Definition 6.1. An algebra A with identity over a field K is said to be central simple if A is a simple K-algebra and the center of A is precisely K.

EXAMPLE. Let $D$ be a division ring and let $K$ be the center of $D$ . It is easy to verify that if $d$ is a nonzero element of $K$ , then $d^{-1}\varepsilon K$ . Consequently $K$ is a field. Clearly $D$ is an algebra over $K$ (with $K$ acting by ordinary multiplication in $D$ ). Furthermore since $D$ is a simple ring with identity, it is also simple as an algebra. Thus $D$ is a central simple algebra over $K$

Recall that if $A$ and $B$ are $K.$ -algebras with identities, then so is their tensor product $A\otimes_KB$ (Theorem IV.7.4). The product of $a\textcircled{8}b$ and $a_1\otimes b_1$ is aal $\textcircled{8}bb_1$ .Here and belowweshall denote theset $\{1_A\otimes b\mid b\in B\}$ by $1_{A}\otimes_{N}B$ and $\{a\otimes1_{k}\mid a\in A\}$ by $A\otimes_K\mathbf{1}_B$ . Note that $A\otimes_KB=(A\otimes_K\mathbf{1}_B)(\mathbf{1}_A\otimes_KB)$ ; see p. 124.

1

1

Theorem 6.2. 1f A is a central simple algebra orer a fieid $\dot{K}$ and B is a simple K-algebra with identity,then A $\textcircled{8}_{\mathrm{K}}$ B is a simple K-algebra

PROOF. Since $B$ is a vector space over $K$ , it has a basis $Y$ and by Theorem IN.1.1 very lement $u$ of $A\otimes_KB$ can be writen $\sum_{i=1}^na_i\otimes y_i$, with $y_i$ 片$y_i\varepsilon Y$ Y $Y$ and the $a_i$ unique. If $U$ is any nonzero ideal of $A\otimes_KB$ , choose a nonzero $u\varepsilon U$ such that $u=\sum_{i=1}^na_i\otimes y_i.$ wih all $a_i\neq0$ and $n$ minimal Since $A$ is imple withidentity, and $Aa_1A$ is a nonzero ideal, $Aa_1A=A$ . Consequently there are elements $r_1,\ldots$ $r_{t},s_{1},\ldots,s_{t}\in A$ such that 1A = ≥rμaus. Since $U$ is an ideal, the element $v=$ $\sum_{j=1}^{i}(r_j\otimes\mathbf{1}_B)u(s_j\otimes\mathbf{1}_H)$ is in $U$ Now

------------------------------------------------------------------

$$v=\sum_{j}\:(r_{j}\otimes1_{B})(\sum_{i}\:a_{i}\otimes y_{i})(s_{j}\otimes1_{B})=\sum_{i}\:(\sum_{j}\:r_{i}a_{i}s_{j})\otimes y_{i}\\=\sum_{j}r_{i}a_{1}s_{j}\otimes y_{1}+\sum_{i=2}^{n}\:(\sum_{j}r_{i}a_{i}s_{i})\otimes y_{i}=1_{A}\otimes y_{1}+\sum_{i=2}^{n}\:\bar{a}_{i}\otimes y_{i},$$

where a; = ≥, r;us. By the minimality of $n$ $,\:\bar{a}_{i}\neq0$ for all $i\geq2$ . If ae $A$ ,then the element $w=(a\otimes1_{B})v-v(a\otimes1_{B})$ is in $U$ and

$$\begin{aligned}\text{w}&=\left(a\otimes y_{1}+\sum_{i=2}^{n}a\bar{a}_{i}\otimes y_{i}\right)-\left(a\otimes y_{1}+\sum_{i=2}^{n}\bar{a}_{i}a\otimes y_{i}\right)\\&=\sum_{i=2}^{n}\:(a\bar{a}_{i}-\bar{a}_{i}a)\otimes y_{i}.\end{aligned}$$

By the minimality of $n$ $w=0$ and $a\bar{a}_{i}-\bar{a}_{i}a=0$ for all $i\geq2$ . Thus $a\bar{a}_{i}=\bar{a}_{i}a$ for all ae $A$ andeach $\bar{a}_i$ is in the center of $A$ , which by assumption is precisely $K$ . Therefore

$$v=1_A\otimes y_1+\sum_{i=2}^n\bar{a}_i\otimes y_i=1_A\otimes y_1+\sum_{i=2}^n1_A\otimes\bar{a}_iy_i=1_A\otimes b,$$

where $b=y_{1}+\bar{a}_{2}\nu_{2}+\cdots+\bar{a}_{n}y_{n}\varepsilon B$ .Since each $\bar{a}_i\neq0$ and the $y_i$ are linearly in dependent over K. $,b\neq0$ .Thus, since. $B$ has an identity,the ideal BbB is precisely $B$ by simplicity. Therefore,

$$\begin{aligned}
1_{A}\otimes_{K}B& =\:1_{A}\bigotimes BbB=(1_{A}\bigotimes_{K}B)(1_{A}\bigotimes b)(1_{A}\bigotimes_{K}B) \\
&=(1_{A}\bigotimes_{K}B)v(1_{A}\bigotimes_{K}B)\subset U.
\end{aligned}$$

Consequently,

$$A\bigotimes_KB=(A\bigotimes_K1_B)(1_A\bigotimes_KB)\subset(A\bigotimes_K1_B)U\subset U.$$

Therefore $U=A\otimes_KB$ and there is only one nonzero ideal of $A\otimes_KB$ .Since $A\otimes_KB$ has an identity $1_A\otimes1_B,(A\otimes_KB)^2\neq0$ ，whence $A\otimes_KB$ is simple.

We now consider division rings. If $D$ is a division ring and $F$ is a subring of $D$ containing $1_{D}$ that is a field, $F$ is called a subfield of $D$ . Clearly $D$ is a vector space over any subfield $F$ .A subfield $F$ of $D$ is said to be a maximal subfield if it is not properly contained in any other subfield of $D$ .Maxinal subfelds always exist (Exer cise 4).Every maximal subfield $F$ of $D$ contains the center $K$ of $D$ (otherwise $F$ and $K$ would generate a subfield of $D$ properly containing $F$ ; Exercise 3). It is easy to see that $F$ is actually a simple $K$ -algebra. The maximal subfields of a division ring strongly influence the structure of the division ring itself, as the following theorems indicate.

Theorem 6.3. Let D be a division ring with center K and let F be a maximal subfield of D. Then $\mathbf{D}\otimes_{\mathbf{K}}$F is isomorphic (as a K-algebra) to a dense subalgebra of $Hom_{\mathrm{F}}(D,D)$ ,where D is considered as a vector space over F

PROOF. $\mathrm{Hom}_F(D,D)$ is an $F$ algebra (third example after Definition IV.7.1) and hence a $K$ -algebra. For each a e $D$ let $\alpha_a:D\to D$ be defined by $\alpha_a(x)=xa$ .For eachcE $F$ let $\beta_c:D\to D$ be defined by $\beta_{c}(x)=cx$ .Verify that αa,βc $\alpha_{a,\beta_c}$ $\alpha_{a},\beta_{c}\varepsilon\mathrm{~Hom}_{F}(D,D)$

------------------------------------------------------------------

T

1

and that $\alpha_{a}\beta_{c}=\beta_{c}\alpha_{a}$ for all D $D$ $a\varepsilon D,c\varepsilon F$ .Verify that the map $D\times F\to\operatorname{Hom}_F(D,D)$ given by $(a,c)\vdash\alpha_a\beta_c$ is $K$ -bilinear. By Theorem IV.5.6 this map induces a $K$ -module homomorphism $\theta:D\otimes_KF\to\mathrm{Hom}_F(D,D)$ such that

$$\theta\:(\sum_{i=1}^na_i\otimes c_i)=\sum_{i=1}^n\alpha_{a_i}\beta_{c_i}\:(a_i\varepsilon D,c_i\varepsilon F).$$

Verify that $\theta$ is a $K$ -algebra homomorphism, which is not zero (since $\theta(1_D\otimes1_D)$ is the identity map on $D$ ). Since $D$ is a central simple and $F$ a simple $K$ -algebra, $\bar{D}\otimes_{K}F$ is simple by Theorem 6.2. Since $\theta\neq0$ and Ker $\theta$ is an algebra ideal, Ker $\theta=0$ whence $\theta$ is a monomorphism. Therefore $D\textcircled{\mathbb{X}}_KF$ is isomorphic to the $K$ -subalgebra $Im\theta$ $\theta$ 0 of $\mathrm{Hom}_{F}(D,D)$ .We must show that $A=\operatorname{Im}\theta$ is dense in $\mathrm{Hom}_F(D,D)$ $D$ is clearlya left module over $\mathrm{Hom}_F(D,D)$ with $fd=f(d)(f\varepsilon\operatorname{Hom}_F(D,D),d\varepsilon D)$

Consequently $D$ is a left module over $A=\operatorname{Im}\theta$ .If $d$ is anonzero element of $D$ ,then since $D$ is a division ring,

$$Ad=\{\theta(u)(d)\mid u\varepsilon D\bigotimes_{K}F\}\:=\:\{\sum_{i}c_{i}da_{i}\mid i\:\varepsilon\:\mathbf{N}^{*};\:c_{i}\:\varepsilon\:F;\:a_{i}\:\varepsilon\:D\}\:=\:D.$$

Consequently, $D$ has no nontrivial $A$ -submodules, whence $D$ is a simple $A$ -module Furthermore $D$ is a faithful $A$ -module since the zero map is the only element $f$ of $\mathrm{Hom}_F(D,D)$ such that $fD=0$ . Therefore by the Density Theorem $1.12A$ is isomorphic to a dense subring of $\mathrm{Hom}_{\Delta}(D,D)$ ,where $\Delta$ is the division ring $\operatorname{Hom}_A(D,D)$ and $D$ is a lett $\Delta$ -vector space. Under the monomorphism $A\to\operatorname{Hom}_\Delta(D,D)$ the image of $f\varepsilon A$ is $f$ considered as an element of $\mathrm{Hom}_{\Delta}(D,D)$ We now construct an isomorphism of rings $F\cong\Delta$ . Let $\beta:F\to\Delta=\mathrm{Hom}_{A}(D,D)$

be given by $c\vdash\beta_c$ (notation as above).Verify that βc $\beta_{c}$ $\beta_{c}\varepsilon\Delta$ △ $\Delta$ and that $\beta$ is a monomor phism of rings. If $f\varepsilon\Delta$ and $x\in D$ ,then $\alpha_{x}=\theta(x\otimes1_{D})\varepsilon A$ and

$$f(x)=f(1_{D}x)=f[\alpha_{z}(1_{D})]=\alpha_{z}(f(1_{D}))=f(1_{D})x=\beta_{c}(x),$$

where $c=f(1_D)$ . In order to show that $\beta$ is an epimorphism it suffices to prove that $c\varepsilon F$ ;for in that case $f(x)=cx=\beta_{c}(x)$ for all $x\varepsilon D$ ，whence $f=\beta_{c}=\beta(c)$ .If $y\varepsilon F$ , then $\beta_{y}=\theta(1_{D}\otimes y)\varepsilon A$ I and $\alpha_{u}=\theta(y\otimes1_{D})\varepsilon A$ and

$$\begin{aligned}\text{cy}&=f(1_{D})y=\alpha_{y}(f(1_{D}))=f(\alpha_{y}(1_{D}))=f(1_{D}y)=f(y1_{D})\\&=f(\beta_{y}(1_{D}))=\beta_{y}f(1_{D})=\beta_{y}(c)=yc.\end{aligned}$$

Therefore $c$ commutes with every element of $F$ If $c\notin F$ , then $c$ and $F$ generate a subfield of $D$ that properly contains the maximal subfield $F$ (Exercise 3). Since this would be a contradiction, we must have $c\varepsilon F$ . Therefore $\beta{:}\mathbf{F}\cong\Delta$

To complete the proof, let $v_{1},\ldots,v_{n}\in D$ Un $v_n$ D $D$ and let $\{u_1,\ldots,u_n\}$ be a subset of $D$ that is linearly independent over. $F$ .Weclaim that $\{u_1,\ldots,u_n\}$ is alsolinearly independent over $\Delta$ If gu; = 0, (g: e ), ther

$$0=\sum g_{i}u_{i}=\sum\beta_{c_{i}}(u_{i})=\sum c_{i}u_{i},$$

where $c_i$ Ci $c_i\varepsilon F$ F $F$ and $g_{i}=\beta(c_{i})=\beta_{c_{i}}$ . The $F$ -linear independence of $\{u_{1},\ldots,u_{n}\}$ implies that every $c_i=0$ ,whence $g_{i}=\beta(0)=0$ for all $i.$ Therefore $\{u_1,\ldots,u_n\}$ is linearly independent over. $\Delta$ .By the density of $A$ in $\mathrm{Hom}_{\Delta}(D,D)$ (Definition 1.7), there exists he $A$ such that $h(u_{i})=v_{i}$ for every $i$ . Therefore $A$ is dense in $\mathrm{Hom}_{F}(D,D)$ .

Theorem 6.3 has an interesting corollary that requires two preliminary lemmas

------------------------------------------------------------------

Lemma 6.4. Let A be an algebra with identity over afield K and F a feld containing $K$ ; then A $\textcircled{\times}_{\mathrm{K}}F$ is anF-algebra such that $dim_{\mathrm{K}}\mathbf{A}=dim_{\mathrm{F}}(\mathbf{A}\otimes_{\mathrm{K}}\mathbf{F})$

SKETCH OF PROOF. Since $F$ is commutative and a $K-F$ bimodule, $A\otimes_KF$ is a vector space over $F$ with $b(a\otimes b_{1})=(a\otimes b_{1})b=a\otimes b_{1}b\left(a\in A;b,b_{1}\right.\varepsilon F;$ see Theorem IV.5.5 and the subsequent Remark). $A\otimes_KF$ is a $K$ -algebra by Theorem IV.7.4 and is easily seen to be an $F$ -algebra as well. If $X$ is a basis of $A$ over $K$ then by (the obvious analogue of) Theorem IV.5.11 every element of $A\otimes_{K}F$ can be written

$$\sum_ix_i\bigotimes c_i=\sum_i(x_i\bigotimes1_F)c_i=\sum_ic_i(x_i\bigotimes1_F)(x_i\varepsilon X;c_i\varepsilon F),$$

with the elements $x_i$ and $c_i$ uniquely determined. It follows that

$$X\bigotimes_{K}\mathbf{1}_{F}=\{x\bigotimes\mathbf{1}_{F}\mid x\in X\}$$

is a basis of $A\otimes_KF$ over $F.$ Clearly $\dim_KA=|X|=|X\otimes_K1_F|=\dim_F(A\otimes_KF)$

Lemma 6.5. Let D be a division algebra over a field K and A a finite dimensional K-algebra with identity. Then $D\otimes_{\mathrm{K}}$ A is alefi ArtinianK-algebra.

SKETCH OF PROOF. $D\otimes_{K}A$ is a vector space over $D$ with the action of de Dona generator d $\textcircled{8}$ aof $D\otimes_{K}.$ A givenby $d(d_{1}\otimes a)=dd_{1}\otimes a=(d\otimes1_{A})(d_{1}\otimes a)$ (Theorem IV.5.5). Consequently every left ideal of $D\otimes_{K}A$ is also a $D$ -subspace of $D\otimes_KA$ . The proof of Lemma 6.4 is valid here, mutatis murandis, and shows that $\dim_{D}(D\otimes_{K}A)=\dim_{K}A$ Since $\dim_KA$ is finite, a routine dimension argument shows that $D\textcircled{\otimes}_KA$ is left Artinian.

Theorem 6.6.Let D be a division ring with center K and maximal subfield F. Then $dim_\mathrm{K}D$ is finite if and only if dim $\kappa F$ is finite,in which case $dim_{\mathrm{F}}\mathbf{D}=dim_{\mathrm{K}}\mathbf{F}$ and $dim_{\mathrm{K}}$D$=(dim_\mathrm{K}$F$)^2$

PROOF. If $\dim_KF$ is infinite, so is $\dim_KD$ . If $\dim_KF$ is finite, then $D\otimes_KF$ is a left Artinian $K$ -algebra by Lemma 6.5. Thus $D\otimes_{K}F$ is isomorphic to a dense left Artinian subalgebra of $\mathrm{Hom}_F(D,D)$ by Theorem 6.3. The proof of Theorem 6.3 shows that this isomorphism is actually an $F$ -algebra isomorphism. Consequently, there is an $F.$ -algebra isomorphism $D\textcircled{\times}_KF\cong\mathrm{Hom}_F(D,D)$ and $n=\dim_FD$ is finite by Theorem 1.9. Therefore $D\otimes_KF\cong\operatorname{Hom}_F(D,D)\cong\operatorname{Mat}_nF$ by Theorem Vll.1.4 (and the subsequent Remark). Lemma 6.4 now implies

$$\mathrm{dim}_{K}D=\mathrm{dim}_{F}(D\bigotimes_{K}F)=\mathrm{dim}_{F}(\mathrm{Mat}_{n}F)=n^{2}=(\mathrm{dim}_{F}D)^{2}.$$

On the other hand $\dim_{K}D=(\dim_{F}D)(\dim_{K}F)$ by Theorem IV.2.16. Therefore $\dim_{K}F=\dim_{F}D$ .

Recall that if $u$ is a unit in a ring $R$ with identity, then the map $R\to R$ given by $r\vdash uru^{-1}$ is an automorphism of the ring $R$ . It is called the inner automorphism induced by $u$

------------------------------------------------------------------

Theorem 6.7.(Noether-Skolem) Let R be a simple left Artinian ring and let K be the center of R (so that R is a K-algebra). Let A and B be finite dimensional simple K-subalgebras of R that contain $K$ .If $\alpha:\mathbf{A}\to\mathbf{B}$ is aK-algebra isomorphism that leaves K fixed elementwise, then $\alpha$ extends to an inner automorphism ofR.

PROOF. It suffices by the Wedderburn-Artin Theorem 1.14 to assume $R=\operatorname{Hom}_{D}(V,V)$ ,where $V$ is an $n$ -dimensional vector space over the division ring $D$ The remarks after Theorem VI1.1.3 show that there is an anti-isomorphism of rings $R=\operatorname{Hom}_D(V,V)\to\operatorname{Mat}_nD$ . Under this map the center $K$ of $R$ is necessarily mapped isomorphically onto the center of. $Mat_nD$ .But the center of $Mat_nD$ is isomorphic to the center of $D$ by Exercise VII.1.3. Consequently we shall identify $K$ with the center of $D$ so that $D$ is a central simple $K$ -algebra. Observe that $V$ is a left $R$ -module with rv = r(v) $rv=r(v)$ $rv=r(v)\left(v\varepsilon V;r\varepsilon R=\mathrm{Hom}_D(V,V)\right)$

Since $V$ is a left $D$ -vector space, it follows that $V$ is a left algebra module over the $K$ -algebra $D\otimes_{K}R$ ，with the action of a generator dr of $D\textcircled{X}_KR$ on $v\varepsilon V$ given by

$$(d\otimes r)v=d(rv)=d(r(v))=r(dv).$$

If $\bar{A}$ is the subalgebra $D\otimes_KA$ of $D\otimes_{K}R$ , then $V$ is clearly a left $\bar{A}$ -module. Similarly if $\boldsymbol{B}=D\otimes_{K}B$ then $V$ is a left $B$ -module. Now the map $\bar{\alpha}=1_{D}\otimes\alpha:\bar{A}\to\bar{B}$ is an isomorphism of $K.$ -algebras. Consequently, $V$ has a second $\bar{A}$ -module structure given by pullback along $\bar{\alpha}$ ; (that is, $\bar{a}v$ is defined to be $\bar{\alpha}(\bar{a})v$ for $v\in V,\bar{a}\varepsilon\bar{A}$ A $\bar{A}$ ; see p. 170). Under this second $\bar{A}$ -module structure the action of a generator $d\textcircled{8}r$ of $\bar{A}=D\otimes_{K}A$ on $\upsilon\varepsilon V$ is given by

$$(d\bigotimes r)v=\bar{\alpha}(d\bigotimes r)v=(d\bigotimes\alpha(r))v=d(\alpha(r)(v))=\alpha(r)(dv).$$

By Theorem 6.2 and Lemma $6.5\:\bar{A}$ A $\bar{A}$ is a simple left Artinian $K$ -algebra. Consequently by Theorem 3.10 there is (up to isomorphism) only one simple $\bar{A}$ -module. Now $V$ with either the $\bar{A}$ -module structure (i) or (ii) is semisimple by Theorem 3.7. Consequently there are $\bar{A}$ -module isomorphisms

$$V=\sum_{iel}U_{i}\quad\text{(corresponding to structure (i)) and}\\V=\sum_{jeJ}W_{j}\quad\text{(corresponding to structure (ii)),}$$

with each $U_{i}$ ， $W_{i}$ a simple $\bar{A}$ -module and $U_i\cong W_r$ for all $i,j$ . Since $dv=(d\otimes1_R)v$ $(d\varepsilon D,v\in V)$ ,every $\bar{A}$ -submodule of $V$ is a $D$ -subspace of $V$ and every $\bar{A}$ -module isomorphism is an isomorphism of $D$ -vector spaces. Since $\dim_DV=n$ is fnite, each $U_i,W_i$ has finite dimension $t$ over $D$ and the index sets $I,J$ J $J$ are finite, say

$$I=\{1,2,\ldots,m\}\quad\mathrm{and}\quad J=\{1,2,\ldots,s\}.$$

Therefore

$$\begin{gathered}
dim_{D}V =\dim_{D}\left(\sum_{i=1}^{m}U_{i}\right)=\sum_{i=1}^{m}\dim_{D}U_{i}=mt,\quad\mathrm{a} \\
dim_{D}V =\dim_{D}\left(\sum_{j=1}^{s}W_{j}\right)=\sum_{j=1}^{s}\dim_{D}W_{j}=\:st, 
\end{gathered}$$

whence $m=s.$ Sincer $U_{i}\cong W_{i}$ for all $i,j,\sum_{i=1}^{m}U_{i}\cong\sum_{j=1}^{m}W_{i}$ This somorphism com-

------------------------------------------------------------------

bined with the isomorphisms (i) and (iv) above yields an $\bar{A}$ -module isomorphism $\beta$ of $V$ (with the $\bar{A}$ -module structure (i)) and $V$ (with the $\bar{A}$ -module structure (i). Thus for all $\bar{a}\varepsilon\bar{A}$ A $\bar{A}$ and $\upsilon\varepsilon V$

$$\beta(\bar{a}v)=\bar{\alpha}(\bar{a})(\beta(v)).$$

In particular, for $d\varepsilon D$ $D$ D and ${\mathcal Z}=d\otimes{\mathbf{1}}_{A}\varepsilon\bar{A}$

$$\beta(dv)=\beta(\bar{d}v)=\bar{\alpha}(\bar{d})(\beta(v))=(d\bigotimes\mathbf{1}_{B})\beta(v)=d\beta(v),$$

whence $\beta$ E $\mathrm{Hom}_D(V,V)=R$ . Since $\beta$ is an isomorphism, $\beta$ is a unit in $R$ . Further more for r $r$ $r\varepsilon A$ A $A$ and $\bar{r}=\mathbf{1}_{D}\otimes\boldsymbol{r}\varepsilon\bar{A}$

$$\begin{aligned}
\beta r(v)& =\beta[r(v)]=\beta[\bar{r}v]=\bar{\alpha}(\bar{r})\beta(v) \\
&=(1_{D}\bigotimes\alpha(r))\beta(v)=\alpha(r)[\beta(v)]=[\alpha(r)\beta](v),
\end{aligned}$$

whence $\beta r=\alpha(r)\beta$ in $R=\operatorname{Hom}_{D}(V,V)$ . In other words,

$$\beta r\beta^{-1}=\alpha(r)\quad\mathrm{for~all}\quad r\in A.$$

Therefore the inner automorphism of. $R$ induced by $\beta$ extends the map $\alpha:A\to B$

The division algebra of real quaternions, which is mentioned in the following corollary is defined on pages 117 and 227.

Corollary 6.8. (Frobenius) Let D be an algebraic division algebra over the field R of real numbers. Then D is isomorphic to either R or the field C ofcomplex numbers or the division algebra T ofreal guaternions

SKETCH OF PROOF. Let $K$ be the center of $D$ and $F$ a maximal subfeld. We have $\mathbb{R}\subset K\subset F\subset D$ ，with $F$ an algebraic field extension of R.Consequently $\dim_KF\leq\dim_RF\leq2$ by Corollary V.3.20. By Theorem $6.6\dim_{F}D=\dim_{K}F$ and $\dim_KD=(\dim_KF)^2$ . Thus the only possibilities are $\dim_KD=1$ and $\dim_KD=4$ .If $\dim_{K}D=1$ ,then $D=F$ ,and $D$ is isomorphic to R or $\mathbf{C}$ by Corollary V.3.20.

If $\dim_KD=4$ ,then $\dim_KF=2=\dim_FD$ ,whence $K=\mathbf{R}$ and $F$ is isomorphic to C by Corollary V.3.20. Furthermore $D$ is noncommutative; otherwise $D$ would be a proper algebraic extension field of the algebraically closed field C. Since $F$ is isomorphic to C, $F=\mathbf{R}(i)$ for some i e $F$ such that $i^{2}=-1$ . The map $F\to F$ given by $a+bi\mapsto a-bi$ is a nonidentity automorphism of $F$ that fixes $R$ elementwise. By Theorem 6.7 it extends to an inner automorphism $\beta$ of $D$ , given by $\beta(x)=dxd^{-1}$ for some nonzero $d\varepsilon D$ Since $-i=\beta(i)=did^{-1}$ ， $-id=di$ and hence $id^{2}=d^{2}i$ . Consequently $d^2\varepsilon D$

commuteswith every element of $F=\mathbf{R}(i)$ . Therefore $d^2\varepsilon F$ ; otherwise $d^2$ and $F$ would generate a subfield of $\boldsymbol{D}$ that properly contained the maximal subfield $F$ Since the only elements of $F$ that are fixed by $\beta$ are the elements of $R$ and $\beta(d^2)$ $=dd^{2}d^{-1}=d^{2}$ , we have $d^2\varepsilon R.$ If $d^2>0$ , then $d\varepsilon R.$ . This is impossible since $d\varepsilon R$ implies $\beta$ is the identity map. Thus $d^{2}=-r^{2}$ for some nonzero $r\varepsilon R$ ，whence $(d/r)^2=-1.$Let $j=d/r$ $j=d/r$ j=d/r and $k=ij$ Verify that $\{1,i,j,k\}$ is a basis of $D$ over $R$ and that there is an R-algebra isomorphism $D\cong T$ .

------------------------------------------------------------------

Corollary 6.9. (Wedderburn) Erery finite dicision ring D is a field.

REMARK. An elementary proof of this fact, via cyclotomic polynomials, is given in Exercise V.8.10.

PROOF OF 6.9. Let $K$ be the center of $D$ and $F$ any maximal subfield. By Theorem $6.6\dim_{k}D=n^2$ ,where $\dim_{\dot{\kappa}}F=n$ .Thus everymaximal subfield is afinite field of order $q^n$ ,where $q=|K|$ .Hence any two maximal subfields $F$ and $F^{\prime}$ are iso- morphic under an isomorphism $\beta:F\to F^{\prime}$ that fixes $K$ elementwise (Corollary V.5.8). By Theorem 6.7, $\beta$ is given by an inner automorphism of $D$ .Thus $F^{\prime}=aFa^{-1}$ for some nonzero $a\varepsilon D$ If $u\varepsilon D$ , then $K(u)$ is a subfield of $D$ (Exercise 3). $K(u)$ is contained in some

maximal subfield that is o the form aFa- (for some a e $D$ ). Thus $D\:=\:\bigcup_{0\neq neD}aFa^{-1}$ and $D^{*}=\bigcup aF^{*}a^{-1}$ (where $D^*,F^*$ are the multiplicative groups of nonzero eleGED* ments of $D$ $F$ respectively). This is impossible unless $F=D$ according to Lemma 6.10 below.

Lemma 6.10. IfG is a finite(multiplicarive) group and $H$ is a proper subgroup,then

$$\bigcup_{x\in G}xHx^{-1}\subsetneqq G.$$

PROOF. The number of distinct conjugates of $H$ is $[G:N]$, where $N$ is the normalizer of $H$ in $G$ (Corollary II.4.4). Since $H<N<G$ and $H\neq G$ $[G:N]\leq$ $[G:H]$ and $[G:H]>1$ If $r$ is the number of distinct elements in $\bigcup_{x_{\varepsilon}G}xHx^{-1}$ , then

$$\begin{aligned}r\leq1+(|H|-1)[G:N]&\leq1+(|H|-1)[G:H]\\&=1+|H|[G:H]-[G:H]=1+|G|-[G:H]<|G|,\end{aligned}$$

since $[G:H]>1$ .

## EXERCISES

1. If $A$ is a finite dimensional central simple algebra over the field $K$ ,then $A\left(\mathbb{X}\right)_{I^{\prime}},A^{nI^{\prime}}\cong\mathrm{Mat}_{n}K$, where $n=\dim_{K}A$ and $A^{n}I^{\prime}$ is defined in Exercise II.1.17.

2. If $A$ and $B$ are central simple algebras over a field $K$ , then so is $A\otimes_KB$

3.Let $D$ be a division ring and $F$ a subfield. If d e $D$ commutes with every element of $F$ , then the subdivision ring $F(d)$ generated by $F$ and $d$ (the intersection of al subdivision rings of $D$ containing $F$ and $d$ ) is a subfeld. [See Theorem V.1.3.]

4.If $D$ is a division ring, then $D$ contains a maximal subfield.

5.If $A$ is a finite dimensional central simple algebra over a field $K$ ,then $\dim_{K}A$ KA $|_{K}A$ is a perfect square.

6. If $A$ and $B$ are lefi Artinian algebras over a field $K.$ ,then $A\otimes_KB$ need not be left Artinian. [Hint: let $A$ be a division algebra with center $K$ and maximal subfield $B$ such that $\dim_BA$ $|BA$ BA is infinite.]

------------------------------------------------------------------

7. If $D$ is finite dimensional division algebra over its center $K$ and $F$ is a maximal subfield of $D$ , then there is a $K$ -algebra isomorphism $D\otimes_KF\cong\mathrm{Mat}_nF$ where $n=\dim_FD$ 8. If $A$ is a simple algebra finite dimensional over its center, then any automorphism of $A$ that leaves the center fixed elementwise is an inner automorphism. 9. (Dickson) Let $D$ be a division ring with center $K$ . If $a,b\varepsilon D$ D $D$ are algebraic over the field $K$ and have the same minimal polynomial, then $b=dad^{-1}$ for some $d\varepsilon D$ $D$ D

------------------------------------------------------------------

# CHAPTER X

# CATEGORIES

This chapter completes the introduction to the theory of categories, which was begun. in Section I.7. Categories and functors first appeared in the work of Eilenberg-Mac. Lane in algebraic topology in the 1940s. It was soon apparent that these concepts had far wider applications. Many different mathematical topics may be interpreted in. terms of categoriesso that thetechniques and theorems of the theory of categories may be applied to these topics.For example, two proofs in disparate areas frequently use "similar" methods. Categorical algebra provides a means of precisely expressing these similarities. Consequently it is frequently possible to provide a proof in a cate-. gorical setting, which has as special cases the previously known results from two different areas. This unification process provides a means of comprehending wider areas of mathematics as well as new topics whose fundamentals are expressible in categorical terms. In this book category theory is used primarily in the manner just described - as

a convenient language of unification. In recent years, however, category theory has. begunto emerge as a mathematical discipline in its ownright.Frequently the source of inspiration for advances in category theory now comes to a considerable extent from within the theory itself. This wider development of category theory is only hinted at in this chapter. The basic notions of functor and natural transformation are thoroughly dis-

cussed in Section 1. Two especially important types of functors are representable functors (Section 1) and adjoint pairs of functors (Section 2). Section 3 is devoted to carrying over to arbitrary categories as many concepts as possible from well-knowr categories, such as the category of modules over a ring. This chapter depends on Section I.7, but is independent of the rest of this book.

 except for certain examples. Sections 1 and 3 are essentially independent. Section 1 is a prerequisite for Section 2.

------------------------------------------------------------------

## 1. FUNCTORS AND NATURAL TRANSFORMATIONS

As we have observed frequently in previous chapters the study of any mathematical object necessarily requires consideration of the “maps"of such objects. In the present case the mathematical objects in question are categories (Section I.7). A functor may be roughly described as a “map' from one category to another which preserves the appropriate structure. A natural transformation, in turn, is a “map' from one functor to another. We begin with the definition of covariant and contravariant functors and numer.

ous examples. Natural transformations are then introduced and more examples given. The last part of the section is devoted to some important functors in the theory of categories, the representable functors. The reader should review the basic properties of categories (Section I.7), par-

ticularly the notion of universal object (which is needed in the study of representable functors). We shall frequently be dealing with several categories simultaneously Consequently, if $A$ and $B$ are objects of a category C, the set of all morphisms in @ from $A$ to $B$ will sometimes be denoted by hom. $e(A,B)$ rather than hom $(A,B)$ as previously.

Definition 1.1. Ler C and $\mathcal{D}$ be categories. A covariant functor T from C to D (denoted $\mathsf{T}:\mathsf{C}\to\mathfrak{O})$ is a pair of functions (both denoted by T), an object function that assigns to each object CofC an object T(C) $of\mathfrak{D}$ and amorphism function which as-. signs to each morphism f : $\mathbf{C}\to\mathbf{C^{\prime}}$ of $C$ a morphism

$$\mathrm{T(f):T(C)\to T(C^{\prime})}$$

of $\mathcal{D}$ , such that

(i) $T(1_{(\cdot)}=1_{T(\mathrm{C})}$ for ecery identity morphism lc ofC; (i) $\mathsf{T}(\mathbf{g}\circ\mathbf{f})=\mathsf{T}(\mathbf{g})\circ\mathsf{T}(\mathbf{f})$ for any two morphisms f,gof Cwhose compositeg of

is defined.

EXAMPLE. The (covariant) identity functor $I_{\mathrm{e}}:\mathbb{C}\to\mathbb{C}$ assigns eachobject and each morphism of the category ୧ to itself.

EXAMPLE. Let $R$ be a ring and $A$ a fixed left $R$ -module. For each $R$ -module $C$ let $T(C)=\operatorname{Hom}_{R}(A,C)$ . For each $R$ -module homomorphism $f:C\to C^{\prime}$ ,let $T(f)$ be the usual induced map $\bar{f}:\operatorname{Hom}_k(A,C)\to\operatorname{Hom}_n(A,C^{\prime})$ (see the remarks after Theorem IV.4.1). Then $T$ is a covariant functor from the category of left $R$ -modules to the category of abelian groups.

EXAMPLE. More generally, let $A$ be a fixed object in a category C. Define a covariant functor $h_{.1}$ from C to the category S of sets by assigning to an object $C$ of ୧ the set $h_{A}(C)=\hom(A,C)$ of all morphisms in C from $A$ to $C$ . If $f:C\to C^{\prime}$ is a morphism ofe, let $h_{.4}(f):\hom(A,C)\to\hom(A,C^{\prime})$ be thefunctiongiven by $g\vdash f\circ g$ $(g\varepsilon\hom(A,C))$ .The functor $h_{A}$ ，which will be discussed in some detail below, is called the covariant hom functor

EXAMPLE. Let $F$ be the following covariant functor from the category of sets to the category of left modules over a ring $R$ with identity. For each set $X$ X $X,F(X)$ is

------------------------------------------------------------------

the free $R$ -module on $X$ (see the Remarks after Theorem IV.2.1). If $f:X\to X^{\prime}$ is a function, let $F(f):F(X)\to F(X^{\prime})$ be the unique module homomorphism $\bar{f}:F(X)\to F(X^{\prime})$ such that $\bar{f}i=f$, where $i$ is the inclusion map $X\to F(X)$ (Theorem IV.2.1).

EXAMPLE.Let C be a concrete category (Definition I.7.6), such as the category of left $R$ -modules or groups or rings. The (covariant) forgetful functor from ୧ to the category S of sets assigns to each object $A$ its underlying set (also denoted $A$ )and to each morphism $f:A\to A^{\prime}$ the function $f:A\to A^{\prime}$ (see Defnition I.7.6).

Definition 1.2. Let C and $\mathcal{D}$ be categories.A contravariant functor S from C to D (denoted $\mathcal{S}:\mathcal{C}\to\mathcal{D})$ is apair of functions(both denotedbyS),an object function which assigns to each object C ofC an object S(C) of $\textcircled{1}$ and a morphism function which assigns to each morphism f : $\mathbf{C}\to\mathbf{C^{\prime}}$ of C u morphism

$$\mathrm{S(f):S(C^{\prime})\to S(C)}$$

of such that

(i S( $1_{C}$) = $1_{S( C) }$ for erery identity morphism $1_{\mathrm{C}}$ ofC; (i) S( g$\circ$f) = S( f) $\circ$S( g) for any two morphisms f, g of @ whose composite gof

is defined.

Thus the morphism function of a contravariant functor $S:\mathbb{C}\to\mathbb{D}$ reverses the direction of morphisms.

EXAMPLE. Let $R$ be a ring and $B$ a fixed left $R$ -module. Define a contravariant functor $S$ from the category of left $R$ -modules to the category of abelian groups by defning $S(C)=\operatorname{Hom}_R(C,B)$ for each $R$ -module $C$ . If $f:C\to C^{\prime}$ is an $R$ -module homomorphism, then $S(f)$ is the induced map $\bar{f}:\operatorname{Hom}_R(C^{\prime},B)\to\operatorname{Hom}_k(C,B)$ (see the Remarks after Theorem IV.4.1).

EXAMPLE. More generally, let $B$ be a fixed object in a category C. Define a con-. travariant functor. $h^{B}$ from C to the category S of sets by assigning to each object. $C$ of ୧ the set $h^B(C)=$ hom$(C,B)$ of all morphisms in C from $C$ to $B$ . If $f:C\to C^{\prime}$ is a morphism of C, let $h^B(f):\hom(C^{\prime},B)\to\hom(C,B)$ be the function given by $g\vdash g\circ f$ $(g\varepsilon\hom(C^{\prime},B))$ . The functor $h^{R}$ is called the contravariant hom functor.

The following method nay be used to reduce the study of contravariant functors to the study of covariant functors. If C is a category, then the opposite (or dual) cate. gory of ୧ , denoted $୧^{\mathrm{op}}$ , is defined as follows. The objects of $C^{\mathrm{op}}$ are the same as the objects of C. The set $\hom_{\mathcal{C}^{\prime\prime}}(A,B)$ of morphisms in $୧^{0\mathbf{p}}$ from $A$ to $B$ is defined to be the set $\hom_{\mathrm{e}}(B,A)$ of morphisms in C from $B$ to $A$ . When a morphism $f\varepsilon\hom_{\mathrm{e}(B,A)}$ is considered as a morphism in $\hom_{\mathrm{e}^\mathrm{op}(A,B)}$ , we denote it by $f^\mathrm{op}$ . Composition of morphisms in $୧^{0}$ is defined by

$$g^{\mathrm{op}}\circ f^{\mathrm{op}}=(f\circ g)^{\mathrm{op}}.$$

If $S:\mathbb{C}\to\mathcal{D}$ is a contravariant functor, let $\tilde{S} : \mathbb{C} ^{\mathrm{op}}\to \mathcal{D}$ be the unique covarian functor defined by

$$\tilde{S}(A)\:=\:S(A)\quad\mathrm{and}\:\bar{S}(f^{\mathrm{op}})\:=\:S(f)$$

1

1

------------------------------------------------------------------

for eachobject $A$ and morphism fof. $C^op$ .Conversely, it is easy to verify that every covariant functor on $୧^{\mathrm{op}}$ arises in this way from a contravariant functor on C. Recall that every statement involving objects and morphisnis in a category has a

dual statement obtained by reversing the direction of the morphisms (see p. 54). It follows readily that a statement is true in a category C if and only if the dual statement is true in $୧^{\mathrm{op}}$ . Consequently a statement involving objects, morphisms and a contravariant functor $S$ on ୧ is true provided the dual statement is true for the covariant functor $\bar{S}$ on $୧^{\mathrm{op}}$ . For this reason many results in the sequel will be proved only for covariant functors, the contravariant case being easily proved by dualization In order to define functors of several variables, it is convenient to introduce the

concept of a product category. If ୧ and $\textcircled{1}$ are categories, their product is the category $୧×D$ whose objects are all pairs $(C,D)$ , where $C$ and $D$ are objects of ୧ and $\mathcal{D}$ re- spectively. A morphism $(C,D)\to(C^{\prime},D^{\prime})$ of $\mathbb{C}\times\mathbb{D}$ is a pair $(f,g)$ ,where $f:C\to C^{\prime}$ is a morphism of ୧ and $g:D\to D^{\prime}$ is a morphism of $\textcircled{1}$ . Composition is given by $(f^{\prime},g^{\prime})\circ(f,g)=(f^{\prime}\circ f,g^{\prime}\circ g)$ . The axioms for a category are readily verifed. The product of more than two categories is defined similarly. Functors of several variables are defined on an appropriate product category

Such a functor may be covariant in some variables and contravariant in others. For example, if $୧,୬,δ$ are categories, a functor $T$ of two variables (contravariant in the frst and covariant in the second variable)from $୧×୬$ to & consists of an object function, which assigns to each pair of objects $(C,D)$ in $୧×୬$ an object $T(C,D)$ of8 and a morphism function, which assigns to each pair of morphisms $f:C\to C^{\prime}$ $g:D\to D^{\prime}$ of $\mathbb{C}\times\mathbb{D}$ a morphism of 8:

$$T(f,g):T(C^{\prime},D)\to T(C,D^{\prime}),$$

subject to the conditions:

(i) $T(1_{C},1_{D})=1_{T(C.D)}$ for all $(C,D)$ in $୧×୬$ (i) $T(f^{\prime}\circ f,g^{\prime}\circ g)=T(f,g^{\prime})\circ T(f^{\prime},g)$ , whenever the compositions. $f^{\prime}\circ f,g^{\prime}\circ g$ are defined in C and $\mathcal{J}$ respectively. The second condition implies that for each fixed object $C$ of C the object function $T(C,-)$ and the morphism function $T(\mathbf{1}_{c,-})$ constitute a covariant functor $\mathcal{D}\to\mathcal{E}$ . Similarly for each fixed object $D$ of $\mathcal{D}$ $T(-,D)$ and $T(-,1_{n})$ constitute a contravariant functor $\mathbb{C}\to\mathcal{E}$

EXAMPLE. $\mathrm{Hom}_{R}(-,-)$ is a functor of two variables, contravariant in the frst and covariant in the second, from the category 9r of left $R$ -modulesl to thecategory of abelian groups.

EXAMPLE. More generally let C be any category. Consider the functor that assigns to each pair $(A,B)$ ofobjectsof etheset hom $ı_{\mathrm{c}}(A,B)$ and to each pair of morphisms $f:A\to A^{\prime}$ $g:B\to B^{\prime}$ the function

$$\hom(f,g):\hom_{\mathrm{e}}(A^{\prime},B)\to\hom_{\mathrm{e}}(A,B^{\prime})$$

given by $h|\mapsto g\circ h\circ f$ Then $\hom_{\mathrm{e}}(-,-)$ is a functor of two variables from ୧ to the category S of sets, contravariant in the frst variable and covariant in the second Note that for a fixed object $A$ $\mathbf{1,hom}_{\mathrm{e}}(A,-)$ is just the covariant hom functor $h_{.1}$ and $h_A(g)=$ hom$(1_A,g)$ .Similarly for fixed $B$ B $B$ home$(-,B)$ is the contravariant hom functor $h^B$ and $h^B(f)=$hom$(f,1_B)$

'Strictly speaking $\mathrm{Hom}_{R}(-,-)$ is a functor on $\mathfrak{m}\times\mathfrak{m}$ ,but this abuse of language is common and causes no confusion

------------------------------------------------------------------

EXAMPLE. Let $K$ be a commutative ring with identity. Then the functor given by

$$T(A_{1},\ldots,A_{n})=A_{1}\otimes_{K}\cdots\otimes_{K}A_{n}\\T(f_{1},\ldots,f_{n})=f_{1}\otimes\cdots\otimes f_{n}$$

is a functor of $n$ covariant variables from the category of $K$ -modules to itself.

If $T_{1}:\mathbb{C}\to\mathbb{D}$ and $T_2:\mathcal{D}\to\mathcal{E}$ are functors, then their composite (denoted $T_{2}T_{1,}$ is the functor from C to & with object and morphism functions given by

$$C\to T_2(T_1(C));\\f\to T_2(T_1(f)).$$

$T_2T_1$ is covariant if $T_{\mathrm{l}}$ and $T_2$ are both covariant or both contravariant. $T_2T_1$ is con travariant if one $T_{i}$ is covariant and the other is contravariant.

Definition 1.3. Ler C and $\mathcal{D}$ be categories and $\mathcal{S}:\mathcal{C}\to\mathcal{D}$ ， $\mathbf{T}:\mathbb{C}\to\mathcal{D}$ covariant functors. A natural transformation. $\alpha:\mathcal{S}\to\mathcal{T}$ is a function that assigns to each object $C$ of C a morphism $\alpha_{\mathrm{C}}:$S$(\mathbf{C})\to$T$(\mathbf{C})$ of $\mathcal{D}$ in such a way thatfor every morphism $\mathbf{f}:\mathbf{C}\to\mathbf{C^{\prime}}$ of ୧ ,the diagram

$$\begin{array}{c}S(C)\xrightarrow{\alpha_C}T(C)\\S(f)\\S(C^{\prime})\xrightarrow{}T(C^{\prime})\end{array}$$

in D is commutative. $If\alpha_{\mathrm{C}}$ is an equiralence for every $C$ in ୧. then $\alpha$ is a natural iso morphism (or natural equivalence) of the functors S and T..

A natural transformation [isomorphism] $\beta:S\to T$ of contravariant functors $S,T:\mathbb{C}\to\mathcal{D}$ is defined in the same way, except that the required commutative diagram is:

$$S(C)\overset{\beta_c}{\operatorname*{\longrightarrow}}T(C)\\S(C^{\prime})\overset{\uparrow}{\operatorname*{\longrightarrow}}T(C^{\prime}),$$

for each morphism $f:C\to C^{\prime}$ of ୧

REMARKS. The composition of two natural transformations is clearly a natural transformation. Natural transformations of functors of several variables are defined. analogously.

EXAMPLE. If $T:\mathbb{C}\to\mathbb{C}$ is any functor, then the assignment $C\vdash1_{r(c)}$ defines a natural isomorphism $I_{T}:T\to T$, called the identity natural isomorphism

------------------------------------------------------------------

EXAMPLE. Let 9r7 be the category of left modules over a ring $R$ and $T:\mathfrak{m}\to\mathfrak{m}$ the double dual functor,which assigns to each module $A$ its double dual module $A^{**}=\mathrm{Hom}_{R}(\mathrm{Hom}_{R}(A,R),R)$ . For each module $A$ let $\theta_A:A\to A^{**}$ be the homo morphism of Theorem IV.4.12. Then the assignment $A\vdash\theta_{\Lambda}$ defnes a natural trans formation from the identity functor $I_\mathrm{9\pi}$ to the functor $T$ (Exercise IV.4.9). If the category ${:}MC$ is replaced by the category ૧ of all finite dimensional left vector spaces over a division ring and $T$ considered as a functor ${\mathfrak{U}}\to{\mathfrak{U}}$ , then the assignment $A\vdash\theta_A$ $(A\in\mathcal{U})$ defines a natural isomorphism from $I_{\mathcal{U}}$ to $T$ by Theorem IV.4.12 (ii). Also see Exercise 5.

Natural transformations frequently appear in disguised form in specific categories. For example, in the category of $R$ -modules (and similarly for groups, rings, etc.), a statement may be made that a certain homomorphism is natural, without any mention of functors.This is usually a shorthand statement that means:there are two (reasonably obvious) functors and a natural transformation between them.

EXAMPLE. If $B$ is a unitary left module over a ring $R$ with identity, then there is a natural isomorphism of modules $\alpha_{II}:R\otimes_{R}R\cong B$ (see Theorem IV.5.7). It is easy to verify that for any module homomorphism $f{:}B\to C$ ,the diagram

$$\begin{array}{c}R\otimes_RB\xrightarrow{\alpha_B}B\\1_R\otimes f\\R\otimes_RC\xrightarrow{\alpha_C}C\end{array}f$$

is commutative. Thus the phrase “natural isomorphism" means that the assignment $B\vdash\alpha_{13}$ defines a natural isomorphism $\alpha:T\to I\mathfrak{m}$ ,where $m$ is the category of unitary left $R$ -modules and $T:\mathfrak{m}\to\mathfrak{m}$ is given by $B\vdash R\otimes_{R}B$ and $f\vdash\mathbf{1}_{R}\otimes f$

EXAMPLE. If $A,B,C$ are left modules over a ring $R$ ,then the isomorphism of abelian groups

$$\phi:\mathrm{Hom}_R(A\oplus B,C)\cong\mathrm{Hom}_R(A,C)\oplus\mathrm{Hom}_R(B,C)$$

of Theorem IV.4.7 is natural. One may interpret the word “natural here by fixing any two variables, say $A$ and $C$ ,and observing thatfor each module homomorphism $f{:}B\to B^{\prime}$ the diagram

$$\begin{array}{c}\mathrm{Hom}_R(A\oplus B^{\prime},C)\xrightarrow{\phi}\mathrm{Hom}_R(A,C)\oplus\mathrm{Hom}_R(B^{\prime},C)\\\mathrm{Hom}(1_A\oplus f,1_C)\\\mathrm{Hom}_R(A\oplus B,C)\xrightarrow{\phi}\mathrm{Hom}_R(A,C)\oplus\mathrm{Hom}_R(B,C)\end{array}$$

is commutative, where $\mathbf{1}_A\oplus f{:}A\oplus B\to A\bigoplus B^{\prime}$ is given by $(a,b)\vdash(a,f(b))$ .Thus $\phi$ defines a natural isomorphism of the contravariant functors $S$ and $T$ where

$$S(B)=\mathrm{Hom}_R(A\bigoplus B,C)\quad\mathrm{and}\quad T(B)=\mathrm{Hom}_R(A,C)\bigoplus\mathrm{Hom}_R(B,C).$$

One says that the isomorphism $\phi$ is natural in B. A similar argument shows that $\phi$ is natural in $A$ and $C$ as well. Other examples are given in Exercise 4.

------------------------------------------------------------------

Definition 1.4. Let T be a covariant functor from a category C to the category S of sets. T is said to be a representable functor if there is an object A in C and a natural isomorphism $\alpha$ from the covariant hom functor. $\mathbf{h}_{\mathbf{A}}=hom_{\mathbf{e}}(\mathbf{A},-)$ to thefunctor T The pair $(\mathbf{A},\alpha)$ is called $a$ representation ofT and T is said to be represented by the object A.

Similarly a contravariant functor. $\mathbf{S}:\mathbf{e}\to\mathbf{S}$ is said to be representable if there is an object B of C and a natural isomorphism. $\beta:\mathbf{h}^{\mathbf{B}}\rightarrow\mathbf{S}$ ,where $\mathbf{h}^{\mathrm{B}}=\hom_{\mathrm{e}}(-,\mathbf{B})$ .The pair $(\mathbf{B},\mathbf{\beta})$ is suid to be a representation of S.

EXAMPLE. Let $A$ and $B$ be unitary modules over a comniutative ring $K$ with identity andfor each $K$ -module $C$ let $T(C)$ be the set ofall $K$ -bilinear maps $A\times B\to C$ If $f:C\to C^{\prime}$ is a $K.$ -module homomorphism, let. $T(f):T(C)\to T(C^{\prime})$ be the function that sends a bilinear map $g:A\times B\to C$ to the bilinear map $fg:A\times B\to C^{\prime}$ Then $T$ is a covariant functor from the category 9it of $K$ -modules to the category S of sets. We claim that $T$ is represented by the $K$ -module $A\otimes_KB$ .To see this, define for each $K$ -module $C$ a function

$$\alpha_C:\mathrm{Hom}_K(A\otimes_KB,C)\to T(C)$$

by $\alpha_{C}(f)=fi$ ,where $i:A\times B\to A\otimes_{K}B$ is the canonical bilinear map (see p. 211). Now $\alpha_{\mathrm{C}}(f):A\times B\to C$ is obviously bilinear for each $f\varepsilon\operatorname{Hom}_K(A\otimes_KB,C)$ By Theorem IV.5.6 every bilinear map $g:A\times B\to C$ is of the form $\bar{g}i$ for a unique $K$ -module homomorphism $\bar{g}:A\otimes_{\kappa}B\to C.$ Therefore $\alpha_C$ is a bijection of sets (that is, an equivalence in the category S). It is easy to verify that the assignment $C\vdash\alpha_C$ defines a natural isomorphism from $h_{\Lambda\otimes K^B}$ to $T.$ ,whence $(A\otimes_{\kappa}B,\alpha)$ is a representa tion of $T$ . It is not just coincidence that $A\otimes_{K}B$ is a universal object in an appropri ate category (TheoremIV.5.6).We shall now show that a similar fact is true for any representable functor.

Let $(A,\alpha)$ be a representation of a covariant functor $T:\mathcal{C}\to\mathcal{S}.$ Let $\mathbb{C}_T$ be the category with objects all pairs $(C,s)$ ,where $C$ is an object of C and $s\in T(C)$ .Amorphism in $\mathrm{e}_{T}$ from $(C,s)$ to $(D,t)$ is defined to be a morphism $f:C\to D$ of ୧ such that $T(f)(s)=t\in T(D)$ . Note that $f$ is an equivalence in $\mathrm{୧}_T$ if and only if $f$ is an equivalence in C. A universal object in the category $\mathrm{C}_T$ (see Definition I.7.9) is called a universal element of the functor $T.$

EXAMPLE. In the example after Definition 1.4 the statement that $(A\otimes_{k}B,\alpha)$ is a representation of the functor $T:\Re{\mathcal{C}}\to\Im$ clearly implies that for each $K$ -module $C$ and bilinear map $f:A\times B\to C$ (that is, for each pair $(C,f)$ with $f_{\varepsilon}T(C))$ ,there is a unique $K.$ -module homomorphism $\bar{f}:A\otimes_KB\to C$ such that $\bar{f}i=f$ (that is, such that $T(\bar{f})(i)=f$ with $i=\alpha_{\Lambda\bigotimes K}(1_{A\bigotimes KR})\varepsilon T(A\otimes_{K}B))$ .Consequently the pair $(A\otimes_KB,i)=(A\otimes_KB,\alpha_{A\otimes_KB}(1_{A\otimes_KH}))$ is a universal object in the category $\Re r_T$ that is, a universal element of $T$

With the preceding example as motivation we shall now show that representations of a functor $T:\mathbb{C}\to\mathbb{S}$ are essentially equivalent to universal elements of T. We shall need

Lemma 1.5. Let T $:\mathbb{C}\to\mathbb{S}$ be a covariantfunctor from a category C to the category Sof sets and let A be an object of C

1

1

------------------------------------------------------------------

(i) $If\alpha:\mathbf{h}_{\mathbf{A}}\to\mathbf{T}$ is a natural trans formation from the covariant hom functor hA t0 T and $\mathbf{u} = \alpha _{\mathrm{A} }( 1_{\mathrm{A} }) \varepsilon$T$(\mathbf{A})$ ,then for any object C of C and g ε home(A,C)

$$\alpha_\mathrm{C}(\mathrm{g})=\mathrm{T}(\mathrm{g})(\mathrm{u}).$$

(ii) Ifu ε T(A)and for each object $\mathsf{C} \textit{of© β }_{\mathsf{C} }: hom_{\mathsf{e} }( \mathsf{A} , \mathsf{C} ) \to \mathsf{T} ( \mathsf{C} )$ is the map de. $finedbyg\vdash T(g)(u)$ ,then $\beta:\mathbf{h}_{\mathbf{A}}\to\mathbf{T}$ is a natural transformation such that. $\beta_{\mathrm{A}}(1_{\mathrm{A}})=u$

PROOF. (i) Let $C$ be an object of ୧ and $g\in\hom_{\mathrm{e}}(A,C)$ .By hypothesis the diagram

$$\begin{aligned}h_A(A)&=\hom_{\mathfrak{e}}(A,A)\overset{\alpha_A}{\operatorname*{\to}}T(A)\\h_A(g)&=\hom_{\mathfrak{e}}(A,C)\to T(C)\\h_A(C)&=\hom_{\mathfrak{e}}(A,C)\to T(C)\end{aligned}$$

is commutative. Consequently,e

$$\begin{aligned}
\alpha_{C}(g)& =\alpha_{C}(g\circ1_{A})=\alpha_{C}[h_{A}(g)(1_{A})] \\
&=[\alpha_{C}h_{A}(g)]\left(1_{A}\right)=(T(g)\alpha_{A})(1_{A})=T(g)[\alpha_{A}(1_{A})] \\
&=T(g)(u).
\end{aligned}$$

(ii) We must show that for every morphism $k:B\to C$ of ୧ the diagranr

$$\begin{aligned}h_A(B)&=\hom_{\mathfrak{e}}(A,B)\overset{\beta_B}{\operatorname*{\to}}T(B)\\h_A(k)&\overset{\beta_B}{\operatorname*{\to}}T(k)\\h_A(C)&=\hom_{\mathfrak{e}}(A,C)\rightarrow T(C)\end{aligned}$$

is commutative. This fact follows immediately since for any $f\varepsilon\hom_{\mathbb{C}}(A,B)$

$$\begin{aligned}
[\beta_{C}h_{A}(k)](f)& =\beta_{C}(k\circ f)=T(k\circ f)(u)=[T(k)T(f)](u) \\
&=T(k)[T(\:f)(u)]=T(k)[\beta_{B}(\:f)] \\
&=[T(k)\beta_{B}](f).
\end{aligned}$$

Therefore $\beta$ is a natural transformation. Finally,

$$\beta_A(1_A)=T(1_A)(u)=1_{T(A)}(u)=u.\quad\blacksquare $$

Theorem 1.6. Let T : $C\to S$ be a covariant functor from a category C to the category S of sets. There is a one-to-one correspondence between the class $X$ of all representa tions ofT and the class. $Y$ of all universal elements of T, gicen. $by\left(\mathbf{A},\alpha\right)\vdash\left(\mathbf{A},\alpha_{\mathrm{A}}(\mathbf{1}_{\mathrm{A}})\right)$

REMARK. Since $\alpha_A:\hom_{\mathbb{C}}(A,A)\to T(A)$ $\alpha_A(1_A)$ is an element of $T(A)$

PROOF OF 1.6. Let $(A,\alpha)$ be a representation of $T$ and let $\alpha_{A}(1_{A})=u\varepsilon T(A)$ Suppose $(B,s)$ is an object of $\mathrm{C}_{T}$ .By hypothesis $\alpha_B:h_A(B)=\hom_{\mathbb{C}}(A,B)\to T(B)$ is a bijection, whence $s=\alpha_{B}(f)$ for a unique morphism $f:A\to B$ .By Lemma 1.5 $T(f)(u)=\alpha_B(f)=s.$ .Therefore,. $f$ is a morphism in $\mathrm{C}_{T}$ from $(A,u)$ to $(B,s)$ .If $g$ is another morphism in $\mathbb{C}_T$ from $(A,u)$ to $(B,s)$ then $g\in\hom_{\mathfrak{c}}(A,B)$ and $T(g)(u)=s$

------------------------------------------------------------------

Consequently, by Lemma 1.5 $\alpha _{B}( g) = T( g) ( u) = s= \alpha _{B}( f)$ Since $\alpha_B$ is a bijection, $f=g$ . Therefore, $f$ is the unique morphism in $\mathcal{C}_T$ from $(A,u)$ to $(B,s)$ ,whence $(A,u)$ is universal in $\mathrm{ల}_T$ . Thus $(A,u)$ is a universal element of $T$ Conversely suppose $(A,u)$ is a universal element of T. Let $\beta:h_{A}\to T$ be thenatural

transformation of Lemma 1.5 (i) such that for any object $C$ of ୧ $\beta_C{:}\hom_{\mathrm{e}}(A,C)\to$ $T(C)$ is given by $\beta_{C}(f)=T(f)(u)$ .If $s\in T(C)$ ,then $(C,s)$ is in $\mathrm{e}_{T}$ .Since $(A,u)$ is universal in $\mathrm{C}_{T}$ , there exists $f_{\varepsilon}\operatorname{hom}_{\mathrm{e}}(A,C)$ such that $s$ = $T( f) ( u)$ = $\beta _{C}( f)$ . Therefore $\beta_{C}$ is surjective. If $\beta_{C}(f_{1})=\beta_{C}(f_{2})$ ,then $T(f_{1})(u)=\beta_{C}(f_{1})=\beta_{C}(f_{2})=T(f_{2})(u)$, whence $f_1$ and $f_2$ are both morphisms in $\mathrm{ల}_{T}$ from $(A,u)$ to $(C,T(f_{1})(u))=(C,T(f_{2})(u))$ . Consequently, $f_1=f_2$ by universality. Therefore each $\beta_{C}$ is injective and hence a bijection (equivalence in S). Thus $\beta$ is a natural isomorphism, whence $(A,\beta)$ is a representation of $T$ To complete the proof use Lemma 1.5 toverify that $\phi\psi=1_{Y}$ and $\psi\phi=1_{x}$

where $\phi:X\to Y$ is given by $(A,\alpha)\vdash(A,\alpha_A(1_A))$ and $\psi:Y\to X$ is given by $(A,u)\vdash$ $(A,\beta)$ $\vdots\beta$ as in the previous paragraph). Therefore $\phi$ is a bijection. 

Corollary 1.7. Let T : $\mathbb{C}\to\mathbb{S}$ be a covariant functor from a category C to the category Sof sers. $If(\mathbf{A},\alpha)$ and $(\mathbf{B},\beta)$ are representations of T, then there is u unique equivalence. $\mathbf{f}:\mathbf{A}\to\mathbf{B}$ such that the following diagram is commutative for all objects. C ofC:

$$\begin{aligned}h_b(C)&=\mathrm{hom}_{\mathrm{e}}(B,C)\\\hom(f,1_C)\\h_A(C)&=\mathrm{hom}_{\mathrm{e}}(A,C)\end{aligned}_{T(C)}$$

PROOF. Let $u=\alpha_A(1_A)$ and $v=\beta_{B}(1_{B})$ . By Theorem $1.6\left(A,u\right)$ and $(B,v)$ are universal elements of $T.$ ,whence by Lemma I.7.10 there is a unique equivalence $f:A\to B$ in ୧ such that $T(f)(u)=v.$ Lemma 1.5 (i) implies that for any object $C$ of ୧ and 8 $g$ $g\varepsilon\hom_{\mathfrak{c}}(B,C)$

$$\begin{aligned}
[\alpha_{C}\hom(f,1_{C})](g)& =\alpha_{C}(g\circ f)=T(g\circ f)(u) \\
&=[T(g)T(f)](u)=T(g)[T(f)(u)]=T(g)(v) \\
&=\beta_{c}(g),
\end{aligned}$$

so that the required diagram is commutative. Furthermore if $f_{\mathrm{l}}:A\to B$ also makes the diagram commutative, then for $C=B$ and $g=1_{B}$

$$T(f_1)(u)=\alpha_B(f_1)=\alpha_B(1_B\circ f_1)=\alpha_B[\hom{(f_1,1_B)(1_B)}]=\beta_B(1_B)=v.$$

Therefore $f_1=f$ by uniqueness.

Corollary 1.8. (Yoneda) Let T : $\mathbb{C}\to\mathbb{S}$ be a covariant functor from a category C tc the category S of sets and let A be an objectof C. Then there is a one-to-one correspondence between the set T(A) and the set Nat. $(\mathbf{h}_{\mathbf{A}},\mathbf{T})$ of all natural trans formations. from the covariant hom functor. $h_{A}$ to the functor T. This bijection is natural in A andT..

SKETCH OF PROOF. Define a function $\boldsymbol{\psi}=\boldsymbol{\psi}_A:\mathsf{Nat}(h_A,T)\to T(A)$ by

$$\alpha\mapsto\alpha_A(1_A)\varepsilon T(A)$$

1

1

------------------------------------------------------------------

and a function $\phi:T(A)\to\operatorname{Nat}(h_A,T)$ by

$$u\mapsto\beta,$$

where $\beta$ is given by Lemma 1.5 (i).Verify that $\phi\psi$ and $\psi\phi$ are the respective identity maps. Therefore $\psi_{A}$ is a bijection. The naturality statement of the corollary means that the diagrams

$$\begin{gathered}
 \\
\begin{array}{c}{\mathrm{Nat}(h_{A},T)\xrightarrow{\psi_{A}}T(A)}\\{N^{*}(f)}\\{Nat(h_{B},T)\xrightarrow{\psi_{B}}T(B)}\end{array}, \\
\mathsf{Nat}(h_{A},T)\xrightarrow{\psi_{A}}T(A) \\
\mathbf{N}_{*}(\alpha)\bigcup_{\mathbf{Nat}(h_{A},S)\xrightarrow[\psi_{A}]{\longrightarrow}S(A)}\alpha_{A} 
\end{gathered}$$

are commutative, where $f:A\to B$ is any morphism of @ , $\alpha : \mathcal{T} \to \mathcal{S}$ is any natura transformation of functors and $N^*(f),N_*(\alpha)$ are defined as follows. For each objeci $C$ of ୧ and $\beta\varepsilon$Nat$(h_A,T)$

$$N^*(f)(\beta)_C:h_B(C)=\hom_{\mathsf{e}}(B,C)\to T(C)$$

is given by $g\vdash\beta_{\mathrm{C}}(g\circ f)$ . The map $N_*(\alpha):$Nat$(h_A,T)\to$Nat$(h_A,S)$ is given by $\beta|\mapsto\alpha\beta$ .

A representable functor is a functor of one variable that is naturally isomorphic to the covariant (or contravariant) hom functor. But for a given category $\mathcal{D}$ $\hom_{\mathfrak{D}}(-,-)$ is a functor of two variables. We now investigate conditions under which a functor $T$ of two variables is naturally isomorphic to $\hom_{\mathfrak{D}(-,-)}$ We shall deal with the following somewhat more general situation. Let C and D

be categories and $T{:}\mathbb{C}\times\mathbb{D}\to\mathbb{S}$ a functor that is contravariant in the first variable and covariant in the second. If $S:\mathbb{C}\to\mathcal{D}$ is a covariant functor, then it is easy to verify that the assignments $(C,D)\vdash\hom_{\mathcal{D}}(S(C),D)$ and $(f,g)\vdash\hom_{\mathbb{D}}(S(f),g)$ define a functor $\mathbb{C}\times\mathbb{D}\to\mathbb{S}$ that is contravariant in thefirstvariable and covariant in the second.

Theorem 1.9. Let C and D be categories andT a functor from the product category $୧×D$ to the category S of sets, contravariant in the first variable and covariant in the second, such that for each object C o fC, the covariant functor $\mathsf{T}(\mathsf{C},-):\mathfrak{D}\to\mathfrak{S}$ has $a$ representation $( \mathbf{A} _{\mathrm{C} , \alpha }\mathbf{C} )$ . Then there is a unigue covariant functor $\mathbf{S}:\mathcal{C}\to\mathcal{D}$ such thal S( C) = $A_{C}$ and there is a natural isomorphism from hon $r_{\mathcal{D}}($S(-),-) to T,given by

$$\alpha^\mathbf{C}_\mathbf{D}:hom_\mathbf{D}(\mathbf{S}(\mathbf{C}),\mathbf{D})\to\mathbf{T}(\mathbf{C},\mathbf{D}).$$

REMARK ON NOTATION. For each object $C$ ofe, $A_C$ is an object in 30 and $\alpha^C$ is a natural isomorphism from h $\mathbf{om}_{\mathcal{D}}(\mathbf{A}_{\mathcal{C}},-)$ to $T(C,-)$ . Thus for each $D$ in $\mathcal{D}$ there is an equivalence $\alpha^{C}_{D}:\hom_{\mathcal{D}}(A_{\mathcal{C}},D)\to T(C,D)$

------------------------------------------------------------------

1

[

PROOF OF 1.9. The object function of the functor $S$ is defined by $S(C)=A_{C}$ for each object $C$ of ୧ . The morphism function of $S$ is defined as follows. For each object $C$ of $\mathcal{C}\:\alpha^{C}_{AC}:\hom_{\mathcal{D}}(A_{C},A_{C})\to T(C,A_{C})$ and $u_{C}=\alpha^{C}_{\Lambda C}(1_{AC})\varepsilon T(C,A_{C})$ .By Theorem 1.6 $(A_C,u_C)$ is a universal element of the functor $T(C,-)$ . If $f:C\to C^{\prime}$ is a morphism of ୧ ,let $v=T(f,\mathbf{1}_{A\boldsymbol{C}^{\prime}})(u_{C^{\prime}},)\varepsilon T(C,A_{C^{\prime}})$ . By the universality of $(A_C,u_C)$ in $\mathcal{D}$ there exists a unique morphism $\tilde{f}$ $:A_{C}\to A_{C^{\prime}}$ in $\mathcal{D}$ such that

$$T(1_C,\bar{f})(u_C)=v=T(f,1_{AC^{\prime}})(u_{C^{\prime}}).$$

Define $S(f)$ to be the morphism $\bar{f}.$ Clearly $S(1_{C})=1_{AC}=1_{S(C)}$ . If $C\overset{f}{\operatorname*{\to}}C^{\prime}\overset{g}{\operatorname*{\to}}C^{\prime\prime}$ are morphisms of ୧ , then by

definition $S(g)$ is the unique morphism $\bar{g}:A_{C^{\prime}}\to A_{C^{\prime}}$ such that

$$T(1_{C^{\prime}},\bar{g})(u_{C^{\prime}})=T(g,1_{AC^{\prime\prime}})(u_{C^{\prime\prime}}).$$

Similarly $S(g\circ f)$ is the unique morphism $\bar{h}:A_{\mathcal{C}}\to A_{\mathcal{C}^{\prime\prime}}$ such that

$$T(1_C,\bar{h})(u_C)=T(g\circ f,1_{AC^{\prime\prime}})(u_{C^{\prime\prime}}).$$

Consequently $S(g)\circ S(f)=\bar{g}\circ\bar{f}$ is a morphism $A_C\to A_{C^{\prime}}$, such that

$$\begin{aligned}
T(1_{c,\bar{g}}\circ\bar{f})(u_{C})& =T(1_{C},\bar{g})T(1_{C},\bar{f})(u_{C})=T(1_{C},\bar{g})T(f,1_{AC^{\prime}})(u_{C^{\prime}}) \\
&=T(f,\bar{g})(u_{C^{\prime}})=T(f,1_{AC^{\prime\prime}})T(1_{C^{\prime}},\bar{g})(u_{C}^{\prime}) \\
&=T(f,1_{AC^{\prime\prime}})T(g,1_{AC^{\prime\prime}})(u_{C^{\prime\prime}})=T(g\circ f,1_{AC^{\prime\prime}})(u_{C^{\prime\prime}}) \\
&=T(1_{C},\bar{h})(u_{C}).
\end{aligned}$$

Therefore by the uniqueness property of universal objects in $\mathcal{D}_{T(C.-)}$ we must have

$$S(g)\circ S(f)=\bar{g}\circ\bar{f}=\bar{h}=S(g\circ f).$$

Thus $S:\mathbb{C}\to\mathcal{D}$ is a covariant functor.

In order to show that $\alpha:\hom_{\mathfrak{B}}(\mathfrak{S}(-),-)\to T$ is a natural isomorphism we neec only show that for morphisms $f:C\to C^{\prime}$ in ୧ and $g:D\to D^{\prime}$ in $\mathcal{D}$ the diagram

$$\begin{array}{c|c}\hom_{\mathfrak{E}}(A_{c^{\prime}},D)\xrightarrow{\alpha^{C^{\prime}}_{D}}T(C^{\prime},D)\\\\\hom(S(f),1_{D})\\\\\hom_{\mathfrak{E}}(A_{C},D)\xrightarrow{\alpha^{C}_{D}}T(C,D)\\\\\\\hom(1_{AC},g)\\\hom_{\mathfrak{E}}(A_{C},D^{\prime})\xrightarrow{\alpha^{C}_{D^{\prime}}}T(C,D^{\prime})\end{array}T(1_{c,g})$$

is commutative. The lower square is commutative since for fixed $C$

$$\alpha^C:\hom_{\mathbb{D}}(A_C,-)\to T(C,-)$$

is a natural isomorphism by hypothesis. As for the upper square let k $k$ $k\varepsilon\hom_{\mathcal{D}}(\mathbf{A}_{\mathcal{C}^{\prime},D})$ Then by Lemma 1.5 (i):

1

1

------------------------------------------------------------------

$$\begin{aligned}
T(f,1_{D})\alpha^{C\prime}{}_{D}(k)& =T(f,1_{D})T(1_{C^{\prime}},k)(u_{C^{\prime}})=T(f,k)(u_{C}^{\prime}) \\
&=\:T(1_{C},k)T(\:f,1_{AC^{\prime}})(u_{C^{\prime}})\:=\:T(1_{C},k)T(1_{C},\bar{f})(u_{C}) \\
&=T(1_{C},k\circ\bar{f})(u_{C})=T(1_{C},k\circ S(f))(u_{C}) \\
&=\:\alpha^{C}{}_{D^{\prime}}(k\circ S(f)) \\
&=\alpha^{C}{}_{D^{\prime}}\mathrm{hom}(S(f),1_{D})(k).\quad\blacksquare 
\end{aligned}$$

### EXERCISES

Note:In these exercises Sis the category of sets and functions; $\textcircled{R}$ is the category of rings and ring homomorphisms; $R$ is a ring; 9n is the category of left $R$ -modules and $R$ -module homomorphisms; S is the category of groups and group homomorphisms

1. Construct functors as follows: (a) A covariant functor $S\to S$ that assigns to each group the set of all its

subgroups. (b) A covariant functor $\mathcal{R}\to\mathcal{R}$ that assigns to each ring $N$ the polynomial

ring $N[x]$ (c) A functor, covariant in both variables $\mathfrak{m}\times\mathfrak{m}\to\mathfrak{m}$ such that

$$(A,B)\mapsto A\oplus B.$$

(d) A covariant functor $\mathcal{S}\to\mathcal{G}$ that assigns to each group $G$ its commutator subgroup $G^{\prime}$ (Definition II.7.7).

2. (a) If $T:\mathbb{C}\to\mathbb{D}$ is a covariant functor, let ImT consist of the objects $\left\{T(C)\right|C\varepsilon e\left\{\right\}$ and the morphisms $\left\{T(f):T(C)\to T(C^{\prime})\mid f:C\to C^{\prime}\right.$ a mor phism inCl. Then show that ImT need not be a category. (b) If the object function of $T$ is injective, then show that ImT is a category

3. (a) If $S:\mathbb{C}\to\mathcal{D}$ is a functor, let $\sigma(S)=1$ if $S$ is covariant and -1 if $S$ is con travariant. If $T:\mathcal{D}\to\mathcal{E}$ is another functor, show that $TS$ is a functor from ୧ to8 whose variance is given by $\sigma(TS)=\sigma(T)\sigma(S)$ (b) Generalize part (a) to any finite number of functors, $S_{1}:\mathcal{C}_{1}\to\mathcal{C}_{2},S_{2}:\mathcal{C}_{2}\to$

$\mathbb{C}_3,\ldots,\mathbb{S}_n:\mathbb{C}_n\to\mathbb{C}_{n+1}$

4. (a) If $A,B,C$ are sets, then there are natural bijections: $A\times B\to B\times A$ and $(A\times B)\times C\to A\times(B\times C)$ (b) Prove that the isomorphisms of Theorems IV.4.9, IV.5.8, IV.5.9, and IV.5.10

are all natural.

5. Let $ଅ$ be the category whose objects are all finite dimensional vector spaces over a field $F$ (of characteristic $\neq2,3$ ）and whose morphisms are all vector-space isomorplhisms. Consider the dual space $V^*$ of a left vector space $V$ as a left vector space (see the Remark after Proposition VII.1.10).

(a) If $\phi:V\to V_1$ is a vector-space isomorphism (morphism of $ଅ$ ), then so is the dual map $\bar{\phi}:V_1^*\to V^*$ (see Theorem IV.4.10). Hence $\bar{\phi}^{-1}:V^{*}\to V_{1}^{*}$ is also a morphism of U

(b) $D:\mathfrak{U}\to\mathfrak{U}$ is a covariant functor, where $D(V)=V^{*}$ and· $D(\phi)=\bar{\phi}^{-1}$ (c) For each $V$ in U choose a basis $\{x_{1},\ldots,x_{n}\}$ and let $\{f_{x_1},\ldots,f_{x_n}\}$ be the dual bases of $V^*$ (Theorem IV.4.11). Then the map $\alpha_{V}:V\to V^{*}$ defined by $x_i|\mapsto f_{x_i}$ is an isomorphism. Thus $\alpha_{V}:V\cong D(V)$

------------------------------------------------------------------

(d) The isomorphism $\alpha_V$ is nor natural; that is, the assignment $V\vdash\alpha_V$ is not a natural isomorphism from the identity functor $Iv$ to $D$ .[Hinr: consider a one dimensional space with basis $\{x\}$ and let $\phi(x)=cx$ with $c\neq0,\pm1_F.$

6. (a) Let $S:\mathbb{C}\to\mathbb{D}$ and $T:\mathbb{C}\to\mathbb{D}$ be covariant functors and $\alpha:S\to T$ a natural isomorphism. Then there is a natural isomorphism $\boldsymbol{\beta}:\boldsymbol{T}\to\boldsymbol{S}$ such that $\beta\alpha=I_{s}$ and $\alpha\boldsymbol{\beta}=I_{T}$ ,where $I_s:S\to S$ is the identity natural isomorphism and similarly for $I_T$ . [Hinr: for each $C$ of C, $\alpha_C:S(C)\to T(C)$ is an equivalence and hence has an inverse morphism $\beta_c:T(C)\to S(C).$ (b) Extend (a) to functors of several variables.

7. Covariant representable functors from S to S preserve surjective maps.

8. (a) The forgetful functor $\mathfrak{m}\to\mathfrak{s}$ (see the Example preceding Definition 1.2) is representable. (b) The forgetful functor $S\to S$ is representable..

9. (a) Let $P:\mathcal{S}\to\mathcal{S}$ be the functor that assigns to each set $X$ its power set (set of all subsets) $P(X)$ and to each function $f{:}A\to B$ the map $P(f):P(B)\boldsymbol{ー}P(A)$ that sends a subset $X$ of $B$ onto $f^{-1}(X)\subset A$ . Then $P$ is a representable contravariant functor. (b) Let the object function of $Q:\mathcal{S}\to\mathcal{S}$ be defined by $Q(A)=P(A)$ .If f: $A\to B.$

let $Q(f):Q(A)\to Q(B)$ be given by $X\vdash f(X)$ . Then $Q$ is a covariant functor. Is $Q$ representable?

10. Let $(A,\alpha)$ and $(B;\beta)$ be representations of the covariant functors $S:\mathbb{C}\to\mathbb{S}$ and $\boldsymbol{T}:\mathcal{C}\to\mathcal{S}$ respectively. If $\tau:S\to T$ is a natural transformation, then there is a unique morphism $f:A\to A$ in ୧ such that thefollowing diagram is commuta tive for every object $C$ ofC：

$$\operatorname*{hom}_{\mathrm{hom}(f,\mathbf{1}_C)}\bigcup_{\mathrm{hom}_\mathbf{e}(B,C)}^{\mathrm{hom}_\mathbf{e}(A,C)}\overset{\alpha_\mathbf{C}}{\operatorname*{\longrightarrow}}S(C)$$

## 2. ADJOINT FUNCTORS

Adjoint pairs of functors are defined and discussed. Although they occur in many branches of mathematics formal descriptions of them are relatively recent.

Let $S:\mathbb{C}\to\mathbb{D}$ and $T:\mathcal{D}\to\mathcal{C}$ be covariant functors. As observed in the discussion preceding Theorem 1.9, the assignments $(C,D)\vdash\hom_{\mathcal{D}}(S(C),D)$ and $(f,g)\vdash\hom_{\mathfrak{D}}(\mathfrak{S}(f),g)$ define a functor $\mathbb{C}\times\mathbb{D}\to\mathbb{S}$ which is contravariant in the first variable and covariant in the second. We denote this functor by hon $n_{\textcircled{2}}(S(-),-)$ Similarly the functor $\hom _{\mathrm{e} }( - , T( - ) ) : \mathbb{C} \times \mathbb{D} \to \mathbb{S}$ is defined by

$(C,D)\vdash\hom_{\mathrm{e}}(C,T(D))$ and $(f,g)\vdash\hom_{\mathrm{e}}(f,T(g))$

------------------------------------------------------------------

Definition 2.1. Let $\mathbf{S}:\mathbb{C}\to\mathbb{D}$ and $\mathbf{T}:\mathcal{D}\to\mathcal{C}$ be covariant functors. S is said to be a left adjoint ofT (or T a right adjoint ofS, $or$ (S,T) an adjoint pair) if there is a natural isomorphism from the functor hor $n_{\textcircled{1}}($S(-),-) to thefunctor $hom_{\mathrm{e}}(-$,T(-))

Thus if $S$ is a left adjoint of $T$ , there is for each $C$ of ୧ and $D$ of $\mathcal{D}$ a bijection

$$\alpha_{C,D}:\hom_{\otimes}(S(C),D)\to\hom_{\mathbb{C}}(C,T(D)),$$

which is natural in $C$ and $D$ . The theory of adjoint functors was first suggested by the following example.

EXAMPLE. Let $R,S$ be rings and $A_{R}, \:_{R}B_{S}$, $C_{S}$ Cs $C_{\boldsymbol{s}}$ (bi)modules as indicated. By Theorem IV.5.10 there is an isomorphism of abelian groups

$$\mathrm{Hom}_S(A\otimes_RB,C)\cong\mathrm{Hom}_R(A,\mathrm{Hom}_S(B,C)),$$

which is easily shown to be natural in $A$ and $C$ (also in $B$ ). Note that $A\otimes_RB$ is a right S-module by Theorem IV.5.5 (ii) and Homs$( B, C)$ a right $R$ -module by Exercise IV.4.4 (c). Let $B$ be a fixed $R-S$ bimodule. Let C be the category of right $R$ -modules and $\mathcal{D}$ the category of right $S$ -modules so that $\hom_{\mathbb{C}}(X,Y)=\operatorname{Hom}_{\mathbb{R}}(X,Y)$ and $\hom_{p}(U,V)=\mathrm{Hom}_{s}(U,V)$ .Then the isomorphism above simply states that the functor $-\textcircled{\times}_RB$ from ୧ to $\mathcal{D}$ is a left adjoint of the functor hom $s(B,-)$ from $\mathcal{D}$ to C.

EXAMPLE. Let $R$ be a ring with identity and 97 the category of unitary left R-modules. Let $T:9\mathbb{C}\to\mathbb{S}$ be the forgetful functor, which assigns to each module its underlying set. Then for each set $X$ and module $A$ ， $\hom_g(X.T(A))$ is just the set of all functions $X\to A$ . Let $F:\mathcal{S}\to\mathfrak{S}$ be the functor that assigns to each $X$ the free $R$ -module $F(X)$ on the set $X$ (see p. 182). Let $i_X:X\to F(X)$ be the canonical map. For each set $X$ and module $A$ , the map

$$\alpha_{X,A}:\mathrm{Hom}_R(F(X),A)\to\mathrm{hom}_\mathrm{S}(X,T(A))$$

defined by $g\vdash gi_x$ is easily seen to be natural in $X$ and $A$ Since $F(X)$ is free on X $X$ I$X,\alpha_{X.A}$ is injective (Theorem IV.2.1 (iv)). Furthermore every function $f:X\to T(A)$ is of the form $f=\bar{f}i_{x}$ for a unique homomorphism $\bar{f}:F(X)\to A$ (Theorem IV.2.1 (iv)). Consequently $\alpha_{X,A}$ is surjective and hence a bijection. Therefore $F$ is a left adjoint of $T$

Other examples are given in the exercises

There is a close connection between adjoint pairs of functors and representable functors.

Proposition 2.2. A covariant functor T : $\textcircled {1}\to \mathbb{C}$ has a left adjoint if and only if for each object C in ୧ the functor hon $\iota _{\mathrm{e} }( \mathbf{C} , \mathbf{T} ( - ) ) : \mathcal{D} \rightarrow \mathcal{S}$ is representable

PROOF. If $S:\mathbb{C}\to\mathbb{D}$ is a left adjoint of $T$ , then there is for each object $C$ of ୧ and $D$ of $\mathcal{D}$ a bijection

$$\alpha_{C.D}:\hom_{\mathfrak{D}}(S(C),D)\to\hom_{\mathfrak{C}}(C,T(D)),$$

which is natural in $C$ and $D$ . Thus for a fixed $C$ $,(S(C),\alpha_{C,-})$ is a representation of the functor h $\mathbf{om}_{\mathbf{e}}(C,T(-))$

------------------------------------------------------------------

Conversely suppose that for each $C,A_C$ Ac $A_C$ is an object of $\mathcal{D}$ that represents $\hom_{\mathrm{e}}(C,T(-))$ . By Theorem 1.9 there is a covariant functor $S:\mathbb{C}\to\mathbb{D}$ such that $S(C)=A_{C}$ and there is a natural isomorphism of functors

$$\hom_{\otimes}(S(-),-)\to\hom_{\mathbb{C}}(-,T(-)).$$

Therefore $S$ is a left adjoint of $T$

Corollary 2.3. A covariant functor $\mathbf{T}:\mathcal{D}\to\mathcal{C}$ has a left adjoint if and only if there exists for each object C ofC an objecr S(C)of $\mathfrak{I}$ and amorphism $\mathbf{u}_{\mathbf{C}}{:}\mathbf{C}\to\mathbf{T}(\mathbf{S}(\mathbf{C}))$ such that $(\mathrm{S(C),u_{C})}$ is a universal element of the functor. $hom_{\mathrm{e}}(\mathbb{C},\mathbb{T}(-)):\mathbb{D}\to\mathbb{S}.$

PROOF. Exercise; see Theorem 1.6.

Corollary 2.4. Any two left adjoints of a covariant functor $\mathbf{T}:\mathcal{D}\rightarrow\mathcal{C}$ are naturally isomorphic.

PROOF. If $S_1:\mathbb{C}\to\mathbb{D}$ and $S_2:\mathbb{C}\to\mathbb{D}$ areleft adjoints of $T$ then thereare natural isomorphisms

$$\alpha:\hom_{\mathbb{D}}(S_{1}(-),-)\to\hom_{\mathbb{C}}(-,T(-)),\\\beta:\hom_{\mathbb{D}}(S_{2}(-),-)\to\hom_{\mathbb{C}}(-,T(-)).$$

For each object $C$ of ୧ the objects $S_1(C)$ and $S_2(\mathbb{C})$ both represent the functor $\hom_{\mathrm{e}}(C,T(-))$ by the first part of the proof of Proposition 2.2. Consequently for each object $C$ of ୧ there is by Corollary 1.7 an equivalence $f_c:S_1(C)\to S_2(C)$ We need only show that $f_c$ is natural in $C$ ; that is, given a morphism $g:C\to C^{\prime}$ ofCwe must prove that

$$S_1(g)\overset{S_1(C)\overset{f_C}{\operatorname*{\longrightarrow}}S_2(C)}{\operatorname*{\longrightarrow}}S_2(g)\\S_1(C^{\prime})\overset{S_2(g)}{\operatorname*{\longrightarrow}}S_2(C^{\prime})$$

is commutative. We claim that it suffices to prove that

$$\begin{array}{c}\hom_{\mathbb{D}}(S_1(C^{\prime}),S_2(C^{\prime}))\xrightarrow{\hom(f_{C^{\prime},1})}\hom_{\mathbb{D}}(S_2(C^{\prime}),S_2(C^{\prime}))\\\hom(S_1(g),1)\\\hom_3(S_1(C),S_2(C^{\prime}))\overbrace{\hom(f_C,1)}\hom_3(S_2(C),S_2(C^{\prime}))\end{array}$$

is commutative (where $1\:=\:1_{S_{2}(C^{\prime})}$ 0. For the image of $\mathbf{1}_{S_2(C^{\prime})}$ in one direction is $S_2(g)\circ f_c$ and in the other direction $f_{C^{\prime}}\circ S_{\mathrm{l}}(g)$ Consider the following three-dimensional diagram (in which. $1\:=\:1\:s_{2(C^{\prime})}$

$\alpha_{X}=\alpha_{X},_{S_{2}(C^{\prime})}$ and the induced map hom $ı(k,1)$ is denoted $\bar{k}$ for simplicity)

1

1

1

------------------------------------------------------------------

![](https://storage.simpletex.cn/view/ftVo86Iqh2gYyl0m9o7TIewlsShDLtRcr)

We must prove that the left rear rectangle is commutative. The top and bottom triangles are commutative by Corollary 1.7. The front and right rear rectangles are commutative since $\alpha$ and $\beta$ respectively are natural. Consequently

$$\alpha_{C}\overline{S_{1}(g)}\:\bar{f}_{C^{\prime}}=\bar{g}\alpha_{C^{\prime}}\bar{f}_{C^{\prime}}=\bar{g}\beta_{C^{\prime}}=\beta_{C}\overline{S_{2}(g)}=\alpha_{C}\:\bar{f}_{C}\overline{S_{2}(g)}.$$

Since $\alpha_{C}=\alpha_{C.S_{2}(C^{\prime})}$ is injective by hypothesis, we must have $\overline{S_{1}(g)}\bar{f}_{C^{\prime}}=\bar{f}_{C}\overline{S_{2}(g)}$ Therefore the left rear rectangle is commutative.

### EXERCISES

Note: S denotes the category of sets.

1.If $T:$ల$\to\mathfrak{S}$ is a covariant functor that has a left adjoint, then $T$ is representable

2.Let ୧ be a concrete category and $T:\mathbb{C}\to\mathbb{S}$ the forgetful functor. If $T$ has a left adjoint $F:\mathcal{S}\to\mathcal{C}$ , then $F$ is called a free-object functor and $F(X)\left(X\in S\right)$ is called a free $F$ -object on $X$

(a) The category of groups has a free-object functor. (b) The category of commutative rings with identity and identity preserving

homomorphisms has a free-object functor. [If $X$ is finite, use Exercise I11.5.11 to define $F(X).$

3. Let $X$ be a fixed set and define a functor $S:\mathcal{S}\to\mathcal{S}$ by $Y\vdash X\times Y$ . Then $S$ is a leff adjoint of the covariant hom functor $h_{X}=\hom_{\mathrm{s}}(X,-)$

4. Let S be the category of groups, $G$ the category of abelian groups, $\mathcal{F}$ the category of fields, 3 the category of integral donains, Sm the category of unitary left $K$ modules, and $\textcircled{8}$ the category of unitary $K-K$ bimodules $(K,R$ rings with identity). In each of the following cases let $T$ be the appropriate forgetful functor (for

example,e $T:\mathcal{F}\to\mathcal{B}$ sends each field $F$ to itself, considered as an integral domain). Show that $(S,T)$ is an adjoint pair. (a) $T:\mathbb{Q}\to\mathbb{G}$ $S:\mathcal{G}\to\mathcal{G}$ ,where $S(G)=G/G^{\prime}$ with $G^{\prime}$ the commutator sub-

group of $G$ (Definition II.7.7) (b) $T{:}\mathfrak{F}{\to}\boldsymbol{0},S{:}\boldsymbol{0}{\to}\mathfrak{F}$ ,where $S(D)$ is the field of quotients of. $D$ (Section II1.4)

(c) $T:\mathfrak{M}\to G$ $S:\mathbb{G}\to\Re$ , where $S(A)=K\otimes_\mathbf{Z}A$ (see Theorem IV.5.5) (d) $T:\mathcal{B}\to\Re$ $S:\Re\to\mathcal{B}$ ,where $S(M)=M\otimes_\mathbf{Z}R$

------------------------------------------------------------------

## 3. MORPHISMS

A significant part of the elementary theory of categories is the attempt to general. ize as many concepts as possible from well-known categories (for example, sets or modules) to arbitrary categories. In this section we extend to (more or less) arbitrary categories the concepts of monomorphisms, epimorphisms, kernels and cokernels of morphisms.

NOTATION. Hereafter we shall usually denote the composite of two morphisms of a category by gfinstead of $g\circ f$ as previously.

We begin by recalling that a morphism $f:C\to D$ in a category is an equivalence if and only if there is a morphism $g:D\to C$ such that $gf=\mathbf{l}_{c}$ and $fg=1_D$ . This definition is simply a reflection of the fact that a homomorphism in the category of groups (or rings, or modules, etc.) is an isomorphism if and only if it has a two sided inverse (see Theorem I.2.3). In a similar fashion we may extend the concepts of monomorphisms and epimorphisms to arbitrary categories as follows.

Definition 3.1. A morphism f : $\mathbf{C}\to\mathbf{D}$ of a category C is monic (or a monomor. phism) if
$$\begin{matrix}\mathbf{fh}=\mathbf{fg}&\Rightarrow&\mathbf{h}=\mathbf{g}\\\end{matrix}$$

for all objects B and morphisms g,h e hom(B,C). The morphism f is epic (or an epimorphism) if

$$\begin{array}{rcl}\mathrm{kf}=\mathrm{tf}&\Rightarrow&\mathrm{k}=\mathrm{t}\end{array}$$

for all objectsE and morphisms $k$ , t E hom(D,E)

EXAMPLE.A morphism in the category of sets is monic [resp. epic] if and only if it is injective [resp. surjective] (Exercise 1).

EXAMPLES. Let ୧ be any one of the following categories: groups, rings, left modules over a ring. If $f:C\to D$ and $g,h:B\to C$ are homomorphisms (that is, morphisms of C),then by Exercise IV.1.2(a), $fh=fg$ implies $h=g$ if and only if fis an injective homomorphism (that is, a monomorphism in the usual sense). Thus the categorical definition of monomorphism agrees with the previous definition in these familiar categories

EXAMPLES. Exercise IV.1.2(b) shows that a morphism fin the category of left modules over a ring $R$ is epic if and only if fis a surjective homomorphism (that is, an epimorphism in the usual sense). The same fact is true in the category of groups, but the proof is more difficult (Exercise 2). Thus the categorical definition of epimorphism agrees with the previous definition in these two categories.

EXAMPLES. In the category of rings every surjective homomorphism is easily. seen to be epic. However, if $f,g:\mathbf{Q}\to R$ are homomorphisms of rings such that

2The Exercise deals only with modules, but the same argument is valid for groups and rings.

1

------------------------------------------------------------------

$f\mid\mathbf{Z}=g\mid\mathbf{Z}$, then $f=g$ by Exercise Ill.1.18. Consequently the inclusion map $\mathbf{Z}\to\mathbf{Q}$ is epic in the category of rings. But this map is obviously not surjective.

EXAMPLE. In the category of divisible abelian groups (p. 195) and group homomorphisms the canonical map $\pi:\mathbf{Q}\to\mathbf{Q}/\mathbf{Z}$ is monic, but clearly not injective. To see this, suppose $g,h:A\to\mathbf{Q}$ are homomorphisms with $A$ divisible and $\pi g=\pi h$ If $g\neq h.$ then there exist a e A,r,s ε Z $(s\neq\pm1]$ such that $g(a)-h(a)=r/s\neq0.$ By hypothesis $rb=a$ for some $b\varepsilon A$ .Consequently, $r(g(b)-h(b))=g(a)-h(a)$ $=r(1/s)$ ,whence $g(b)-h(b)=1/s$ . Therefore $0=\pi g(b)-\pi h(b)=\pi(g(b)-h(b))$ $=\pi(1/s)$ . Thus 1/s $1/s$ $1/s\varepsilon$Ker $\pi=\mathbf{Z}$ π=Z $\pi=\mathbf{Z}.$ .which is a contradiction since $s\neq\pm1$ . There fore $g=h$ and hence $\pi$ is monic.

Proposition 3.2. Let $\mathbf{f}:\mathbf{B}\to\mathbf{C}$ and $\mathbf{g}:\mathbf{C}\to\mathbf{D}$ be morphisms of a category C

(i) f and g monic $\Rightarrow$ gf monic; (i) gf monic $\Rightarrow\mathbf{f}$ monic; (ii) f and g epic $\Rightarrow$ gf epic; (iv) gf epic $\Rightarrow\mathbf{g}$ epic; (v)f is an equivalence $\Rightarrow\mathbf{f}$ is monic and epic.

PROOF. Exercise.

REMARK. The two examples preceding Proposition 3.2 show that the converse of $(\mathbf{v})$ is false.

An object O in a category ୧ is said to be a zero object if O is both universal and couniversal in $\mathbb{C}$ (see Definition I.7.9). Thus for any object $C$ of ୧ there is a unique morphism $0\to C$ and a unique morphism $C\to0$

EXAMPLE. The zero module is a zero object in the category of left modules. over a ring; similarly for groups and rings. The category of sets has no zero objects.

Proposition3.3.Ler C be a category and C an object ofC

(i) Any two zero objects ofC are equivalent. (i) If O is a zero object,then the unique morphism $0\to\mathbb{C}$ is monic and the

unique morphism $\mathbb{C}\to0$ is epic

SKETCH OF PROOF. (i)Theorem I.7.10.(ii) If $0_{C}\circ f=0_{C}\circ g$ ，where $0_c:0\to C$ ,then $f=g$ by the couniversality of O. Therefore $0_C$ is monic.

Proposition 3.4. Let C be a category which has a zero object 0. Then for each pair. C,Dofobjecis ofCthere is a unique morphism $0_{\mathrm{C.D}}:\mathbf{C}\to\mathbf{D}$ such tha.

$$\mathbf{f}\circ0_{\mathrm{C.D}}=0_{\mathrm{C.E}}\quad and\quad0_{\mathrm{C.D}}\circ\mathbf{g}=0_{\mathrm{B,D}}$$

for all morphisms f ∈ hom(D,E), g e hom(B,C)

------------------------------------------------------------------

REMARK. $0_{c.D}$ is called a zero morphism.

PROOF OF 3.4. (Uniqueness) If $\{0_{C,D}^{\prime}\}$ and $\{0_{C.D}\}$ are two families of morphisms with the stated properties, then for each pair $C,D$

$$0_{C.D}=0_{D.D}^{\prime}0_{C.D}=0_{C.D}^{\prime}.$$

(Existence) For each object $A$ of c let $\iota_A:0\to A$ and $\pi_A:A\to0$ be the unique morphisms. For any fe hom(D,E), $f_{\boldsymbol{\iota}D}=\iota_{E}:0\to E$ by universality. For any $g\varepsilon hom(B,C)\pi_{C}g=\pi_{B}:B\to0$ by couniversality. Define $0_{C.D}$ to be the composition $C\overset{\pi c}{\operatorname*{\to}}0\overset{\bullet D}{\operatorname*{\to}}D$ Then for $f\varepsilon\hom(D,E),f\circ0_{C,D}=f\iota_{D}\pi_{C}=\iota_{E}\pi_{C}=0_{C,E}$ and similarly in the other case.

The final step in extending properties of morphisms in familiar categories to morphisms in arbitrary categories is to develop reasonable definitions of kernels and cokernels of morphisms. We begin in a somewhat more general setting

Definition 3.5. Let $\mathbf{f}:\mathbf{C}\to\mathbf{D}$ and $\mathbf{g}:\mathbf{C}\to\mathbf{D}$ be morphisms ofa category C.A difference kernel (or equalizer) for the pair (f,g) is a morphism i $:\mathbf{B}\to\mathbf{C}$ such that.

(i) $\mathbf{fi}=\mathbf{gi}$

(ii) $if\mathbf{h}:\mathbf{A}\to\mathbf{C}$ is a morphism with. $\mathbf{fh}=\mathbf{gh}$ , then there exists a unique morphisn $\mathbf{h}:\mathbf{A}\to\mathbf{B}$ such that $\mathbf{i}\mathbf{h}=\mathbf{h}$ A difference cokernel (or coequalizer) for the pair (f,g) is a morphism $\mathbf{j}:\mathbf{D}\to\mathbf{E}$

such that: (i) $\mathbf{jf}=\mathbf{jg}$

(iv) $if$k$:\mathbf{D}\to\mathbf{F}$ is a morphism with $kf=kg$ , then there exists a unique morphism $\mathbf{k}:\mathbf{E}\to\mathbf{F}$ such that $\mathbf{K}\mathbf{j}=k$

EXAMPLES.In the category S of sets a difference kernel of $f:C\to D$ and $g:C\to D$ is the inclusion map $B\to C$ ,where $B=\{c\in C\mid f(c)=g(c)\}$ . The same construction shows that every pair of morphisms has a difference kernel in the categories of groups, rings, and modules respectively.

EXAMPLE. Let $f:G\to H$ and $g:G\to H$ be homomorphisms of groups. Let $N$ be the smallest normal subgroup of $H$ containing $\{f(a)g(a)^{-1}\mid a\in G\}$ . Then the canonical epimorphism $H\to H/N$ is a difference cokernel of ( $f,g)$ by Theorem I.5.6

Proposition 3.6. Ler f : $\mathbb{C}\to\mathbb{D}$ and $\mathbf{g}:\mathbf{C}\to\mathbf{D}$ be morphisms of a category C.

(i) $If\mathbf{i}:\mathbf{B}\to\mathbf{C}$ is a difference kernel of(f,g), then i is a monomorphism

(ii) $If\mathbf{i}:\mathbf{B}\to\mathbf{C}$ andj ${\mathrm{i}}:\mathbf{A}\to\mathbf{C}$ are difference kernels of(f,g), then there is a unique equivalence $\mathbf{h}:\mathbf{A}\to\mathbf{B}$ such that ih $=\mathbf{j}$

PROOF. (i) Let h $,k:F\to B$ be morphisms such that $ih=ik$ .Then $f(ih)=(fi)h=(gi)h=g(ih)$ .Since $i$ is a difference kernel of $(f,g)$ , there is a unique morphism $\iota:F\to B$ such that $it=ih$ .But both $t=h$ and $t=k$ satisfy this condi tion, whence. $h=k$ by uniqueness. Therefore $i$ is monic.

------------------------------------------------------------------

(ii) By hypothesis there exist unique morphisms $h:A\to B$ and $k:B\to A$ such that $ih=j$ and $jk=i$ respectively.Consequently $ihk=jk=i=i\circ1_B$ and $jkh=ih=j=j\circ1_{A}$ . Since $i$ and $j$ are monomorphisms by (i), $hk=1_B$ and $kh=1_{A}$ . Therefore $h$ is an equivalence.

REMARK. Difference cokernels are epimorphisms and the dual of Proposition 3.6 (ii) holds for difference cokernels

Suppose that C is a category with a zero object O and hence zero morphisms (Proposition 3.4). A kernel of a morphism $f{:}C\to D$ (if one exists) is defined to be any differencekernel of the pair $(f,0_{\boldsymbol{C}.D})$ ; it is sometimes denoted Ker $f.$ Definition 3.5 andPropositions 3.4 and 3.6 show that $k:K\to C$ is a kernel of $f:C\to D$ if and only if

(i) $k$ is a monomorphism with $fk=0_{K.D}$ ; and

(ii) if $h:B\to C$ is a morphism such that $fh=0_{B,D}$ , then there is a unique morphism $h:B\to K$ such that $k\hbar=h$ By Proposition $3.6K$ is unique up to equivalence.

A cokernel $\iota:D\to E$ of a morphism $f:C\to D$ is defined dually as a difference cokernel of the pair $(f,0_{\boldsymbol{c}.D})$ ; it is sometimes denoted Coker $f.$ As above $I$ is char. acterized by the conditions:

(ii) 1 is an epimorphism with $\iota f=0_{\boldsymbol{C},\boldsymbol{E}}$ ; and

(iv) if $g:D\to F$ is a morphism such that $gf=0_{C.F}$ ,then there is a unique morphism $\bar{g}:E\to F$ such that $\bar{g}t=g$

EXAMPLES. In the categories of groups, rings and modules, a kernel of the morphism $f:C\to D$ is the inclusion map $K\to C$ ，where $K$ is the usual kernel. $K=\{c\varepsilon C\mid f(c)=0\}$ .In the category of modules, the canonical epimorphism $D\to D/\mathbf{Im}f$ is a cokernel of $f.$

## EXERCISES

1. A morphism in the category of sets is monic [resp. epic] if and only if it is injective [resp. surjective].

2. A morphism $f:G\to H$ in the category of groups is epic if and only if $f$ is a surjective homomorphism (that is, an epimorphism in the usual sense). [Hinr: If fis epic, $K=\operatorname{Im}f$, and $j:K\to H$ is the inclusion map, then $j$ is epic by Proposition 3.2.Show that $f$ is surjective (that is, $K=H]$ ) as follows. Let. $S$ be theset of left cosets of $K$ in $H$ ;let $T=S\cup$ $\{u\}$ with $u\notin S.$ Let $A$ be the group of all permutations of $T$ .Let $\iota:H\to A$ be given by $\iota(h)(h^{\prime}K)=hh^{\prime}K$ and $r(h)(u)=u$ .Let $s:H\to A$ be given by $\sigma t(h)\sigma$ ,where $\sigma\varepsilon A$ A $A$ is the transposition interchanging $u$ and $K$ .Show that $s$ and 1 are homomorphisms such that $sj=ij$ ，whence $s=1$ .Show that $hK=K$ for all he $H$ ; therefore $K=H.$

------------------------------------------------------------------

3.A commutative diagram

$$\begin{array}{c}B\xrightarrow{g_1}C_1\\\\\\C_2\xrightarrow{f_2}D\end{array}f_1$$

of morphisms of a category ୧ is called a pullback for $f_1$ and $f_2$ if for every pair of morphisms $h_1:B^{\prime}\to C_1$, $h_2:B^{\prime}\to C_2$ such that $f_1h_1=f_2h_2$ there exists a unique morphism $\iota:B^{\prime}\rightarrow B$ such that $h_1=g_1t$ and $h_{2}=g_{2}t$ (a)If there is another pullback diagram for $f_1,f_2$ with $B_{1}$ in the upper left-hanc

corner, then $B$ and $B_1$ are equivalent (b) In the pullback diagram above, if $f_2$ is a monomorphism, then so is $g_1$

(c)Every pair of functions $f_1:C_1\to D,f_2:C_2\to D$ in the category of sets has a

pullback.

4. Show that every pair of functions $f,g:C\to D$ has a difference cokernel in the category of sets.

5.Let $f,g:C\to D$ be morphisms of a category C.For each $X$ in ୧ let

$$\mathrm{Eq}(X,f,g)\:=\:\{h\:\varepsilon\:\mathrm{hom}(X,C)\mid fh\:=\:gh\}\:.$$

(a) $\mathsf{Eq}(-,f,g)$ is a contravariant functor from ୧ to the category of sets. (b) A morphism $i:K\to C$ is a difference kernel of $(f,g)$ if and only if $\mathsf{Eq}(-,f,g)$

is representable with representing object $K$ (that is, there is a naturalisomorphism $\tau:\hom_{\mathrm{c}}(-,K)\to\operatorname{Eq}(-,f,g))$ . [Hinr: show that for $h:X\to K$ $\tau_{x}(h)=ih$ ,where $i=\tau_{K}(1_{K}).]$

6. If each square in the following diagram is a pullback. and $B^{\prime}\to B$ is a monomorphism, then the outer rectangle is a pullback. [Hint : See Exercise 3.]

![](https://storage.simpletex.cn/view/fDdYcSdCI4T941uu5VtXI1rgwzlTIDDWz)

7. In a category with a zero object, the kernel of a monomorphism is a zero morphism.

------------------------------------------------------------------

# List ofSymbols

### MEANING

### PAGE REFERENCE

field of rational numbers field of real numbers field of complex numbers implies if and only if is an element of is not an element of the class of all $x$ such that $P(x)$ is true is a subclass (or subset) of empty set power set of $A$ union of the sets $A_i$ intersection of the sets $A_i$ relative complement of $A$ in $B$ complement of $A$ $f$ is a function from $A$ to $B$ the function fmaps a to $f(a)$ restriction of the function fto $S$ Jidentity function on the set $A$ l identity element of the ring $A$ [composite function of $f$ and $g$ [ composite morphism of $f$ and $g$ image of the function $f$ inverse image of the set $T$

------------------------------------------------------------------

SYMBOL

MEANING PAGE REFERENCE AXB [Cartesirn droduet oses $A$ $A$ and $B$ $B$ Iis equivalen twith equivalence class of $a$ (Cartesian) product of the sets $A_i$ product of the family of objects $\{A_i\mid i\epsilon I\}$ IA direct product of the family of groups 59, 130, 173 [or rings or modules] $\{A_i\mid i\epsilon I\}$ 9 set ofintegers 9 set of nonnegative integers (natural numbers) 9 set of positive integers $a\not\bot b$ $a\mid b$ $a$ divides $b$ 11,135 a does not divide $b$ $(a_1,a_2,\ldots,a_n)$ [geates ermong $a_1,\ldots,a_n$ $a_n$ $a_{1},\ldots,a_{n}$ a=b(mod m） $a$ is congruent to $b$ modulo $m$ [ cardinal number of the set $A$ order of the group $A$ [determinant of the matrix $A$ aleph-naught group of symmetries of the square symmetric group on n letters $G\oplus H$ direct sum of additive groups $G$ and $H$ integers modulo $m$ group of rationals modulo one $\mathbf{Q}/\mathbf{Z}$ $Z(p^{\infty})$ Sylow $P$ -subgroup of $\mathbf{Q}/\mathbf{Z}$ is isomorphic to Ker f kernel of the homomorphism $f$ $H<G$ $H$ is a subgroup of $G$ $<x>$ subgroup generated by the set $X$ <a> cyclic (sub)group generated by $a$ $H\vee K,H+K$ the join of subgroups $H$ and $K$ quaternion group order of the element $a$ $a\equiv_rb\left(\mathrm{mod}\:H\right)$ $ab^{-1}\epsilon H$ α =b(mod H) $a^{-1}b\epsilon H$ right and left cosets of $a$ Ha,aH index of a subgroup $H$ in a group $G$ $[G{:}H]$ $\{ab\mid a\epsilon H,b\epsilon K\}$ $N$ is a normal subgroup of $G$ $N\lhd G$ factor group of $G$ by $N$ $G/N$

$S_n$ $No$ $D_4*$ $Z_m$ I $|a|$ 0al $Q_8$ HK

------------------------------------------------------------------

### SYMBOL

sgn T $A_n$ $D_n$ G[m] $G(p)$ G. $G_t$ $G_{x}$ $C_H(x)$ $N_H(K)$ $C(G)$ $C_n(G)$ $G^{\prime}$ $G^{(n)}$ End $A$
$$\binom nk$$
$(a)$ $(X)$ $R^{op}$ $S^{-1}R$ $R$ $R_P$ $R[x]$ $R[x_1,\ldots,x_n]$ $R[[x]]$ deg $f$ C(S) $\operatorname{Hom}_R(A,B)$ $\dim_DV$ $_{R}\mathbf{A}_{\mathbf{S}}$ $A,[A_R]$ A* $<a,f>$ $\delta_{ij}$ $\mathfrak{m}(A,B)$

PAGE REFERENCE MEANING sign of the permutation $\tau$ alternating group on n letters dihedral group of degree $n$ disjoint union of the sets $A_i$ weak direct product of the groups $G_i$ direct sum of the groups (or modules) $G_i$ 60,173 free product of the groups $G_{i}$ 77,224
$$\{u\epsilon G\mid mu=0\}$$
77,222 $\{u\in G\mid u$ has order a power of $p$ torsion subgroup [submodule] of $G$ 78,220 stabilizer of $x$ centralizer of $x$ in $H$ normalizer of $K$ in $H$ center of $G$ $n$ -th term of ascending central series commutator subgroup of $G$ $n$ -th derived subgroup of $G$ endomorphism ring of $A$ binomial coefficient characteristic of the ring $R$ opposite ring of $R$ ideal generated bythe set $X$ principal ideal generated by $a$ ring of quotients of $R$ by $S$ localization of $R$ at $P$ ring of polynomials over $R$ ring of polynomials in n indeterminates over $R$ ring of formal power series over $R$ degree of the polynomial $f$ content of the polynomial $f$ set of all $R$ -module homomorphisms $A\to B$ dimension of the $D$ -vector space $V$ $R-S$ bimodule $A$ left [resp. right] $R$ -module A dual module of $A$ $f(a)$ Kronecker delta category of middle linear maps on $A\times B$

------------------------------------------------------------------

PAGE REFERENCE SYMBOL MEANING tensor product of modules $A$ and $B$ ARB induced map on the tensor product fαg $\mathcal{O}_a$ order ideal of $a$ dimension of field $F$ as a $K.$ -vector space $[F:K]$ $K[u_{1},\ldots,u_{n}]$, subring generated by $K$ and $u_1,\ldots,u_n$ un $u_n$ [resp. X [resp. $K[X]]$ subfeld generated by $K$ and $u_1,\ldots,u_n$ $K(u_1,\ldots,u_n)$ [resp. $X]$ [resp. $K(X)]$ feld of rational functions in $n$ indeterminates $K(x_1,\ldots,x_n)$ $Aut_KF$ Galois group of $F$ over $K$ discriminant of a polynomial A $\Delta$ $Fp^n$ $\{u^{p^n}\mid u\in F\}$ char $F=p$ $[F{:}K]_s$ separable degree of $F$ over $K$ $[F{:}K]_i$ inseparable degree of $F$ over $K$ $N_{K}F(u)$ norm of $u$ $T_KF(u)$ trace of $u$ $g_n(x)$ $n$ -th cyclotomic polynomial transcendence degree of $F$ over $K$ tr.d. $F/K$ $K^{1/p^n}$ $\{u\in C\mid u^{p^{n}}\epsilon K\}$ $K^{1/p^\infty}$ $\{u\in C\mid u^{pn}\epsilon K$ for some $n\geq0$ $n\times n$ identity matrix $I_n$ $Mat_nR$ ring of $n\times n$ matrices over $R$ transpose of the matrix $A$ $A^t$ A $A^{-1}$ inverse of the invertible matrix $A$ a certain matrix $E_r^{n,m}$ $A^{a^{\prime}}$ classical adjoint of the matrix $A$ $q_{\phi}(x),q_{A}(x)$ mirimal polynomial of $\phi$ [resp. A] Tr $A$ trace of the matrix $A$ Rad $I$ radical of the ideal I $V(S)$ affine variety determined by $S$ $\alpha(B)$ left annihilator of $B$ $r+a+ra$ $r\circ a$ Jacobson radical of $R$ $J(R)$ $P(R)$ primeradical of $R$ hom $(A,B)$ or set of morphisms $A\to B$ in a category ୧ hom $_{\mathrm{le}}(A,B)$ covariant hom functor. $h_{A}$ $h^{B}$ $\mathbb{C}_T$ contravariant hom functor 照category formed from ୧ and $T$ zero morphism from. $C$ to $D$ $0_{C,D}$